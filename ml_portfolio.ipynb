{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKN+Me+YGHSV7I94yWi85s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "e4PiESSn5Wx4"
      },
      "outputs": [],
      "source": [
        "# ÔºÅpip install functorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from os import path\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# print(torch.cuda.get_device_name())\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tlvPo68Pnpf",
        "outputId": "a13aefa4-cb48-498b-acf0-9a5834863593"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MA_DAYS = 25\n",
        "trading_days_in_year = 252"
      ],
      "metadata": {
        "id": "26v-Cnl1lg6t"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import raw data from yahoo finance"
      ],
      "metadata": {
        "id": "MRi8JtX9gAb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_files_path_prefix = \"/content/drive/MyDrive\"\n",
        "data_files_path = \"ML-Portfolio-Data\"\n",
        "data_files_path = path.join(data_files_path_prefix, data_files_path)\n",
        "\n",
        "high_risk_file = 'SPY.csv'\n",
        "low_risk_file = 'IEF.csv'\n",
        "high_risk = pd.read_csv(path.join(data_files_path, high_risk_file))\n",
        "low_risk = pd.read_csv(path.join(data_files_path, low_risk_file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puHUCbHEMIoP",
        "outputId": "e9e8bff1-be3b-4c4f-a793-ffc45bea5707"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read files from the same directory\n",
        "#high_risk = pd.read_csv('SPY.csv')\n",
        "#low_risk = pd.read_csv('O9P.SI.csv')"
      ],
      "metadata": {
        "id": "tmNxB-dXPdjh"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# high_risk = high_risk[:1008]\n",
        "# low_risk = low_risk[:1008]\n",
        "print(high_risk.shape)\n",
        "print(low_risk.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEp0KCBSE3uX",
        "outputId": "b2800f09-ce49-4de0-f41f-ed581ab74cf0"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5147, 7)\n",
            "(5147, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffmGB06pT8_q",
        "outputId": "85319fb3-e25a-48b7-8a98-858e673d4997"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939  47532200\n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453  44669900\n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054  66571900\n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895  51772900\n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496  47191300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67f6683f-550e-472a-bbf3-1a157df8cc24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67f6683f-550e-472a-bbf3-1a157df8cc24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-67f6683f-550e-472a-bbf3-1a157df8cc24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-67f6683f-550e-472a-bbf3-1a157df8cc24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DY4FPgNCEssV",
        "outputId": "841743d5-76fc-417e-b306-0f7129433365"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300\n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600\n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400\n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300\n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bce9bf32-9c30-42d0-bd5e-cda5ffe847fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bce9bf32-9c30-42d0-bd5e-cda5ffe847fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bce9bf32-9c30-42d0-bd5e-cda5ffe847fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bce9bf32-9c30-42d0-bd5e-cda5ffe847fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Portfolio"
      ],
      "metadata": {
        "id": "RnPRd0TkrMsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset"
      ],
      "metadata": {
        "id": "IvSntSIA4qiC"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enrich data"
      ],
      "metadata": {
        "id": "5EZ0sQ3rTgn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate daily returns"
      ],
      "metadata": {
        "id": "NraBWrzef4BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Daily Return\"]  = market_data['Close'] - market_data['Open']\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ],
      "metadata": {
        "id": "2e03XXEgf1r4"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate moving average (MA) of daily returns"
      ],
      "metadata": {
        "id": "2dqBMvFWo4oQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_moving_average(market_data, ma_days):\n",
        "    temp_vars = []\n",
        "\n",
        "    # df = market_data\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data[temp_var] = market_data[\"Daily Return\"].shift(i)\n",
        "        temp_vars.append(temp_var)\n",
        "\n",
        "    market_data[\"MA\"] = market_data[temp_vars].mean(axis=1)\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data.drop(temp_var, axis = 1, inplace = True)\n",
        "\n",
        "add_moving_average(high_risk, MA_DAYS)\n",
        "add_moving_average(low_risk, MA_DAYS)\n"
      ],
      "metadata": {
        "id": "p9EW2Fzjo9ly"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xp5iRKB4FeRZ",
        "outputId": "b4b398a7-e96c-4f16-ef8b-017a084c951e"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "5142  2022-12-30  380.640015  382.579987  378.429993  382.429993  382.429993   \n",
              "5143  2023-01-03  384.369995  386.429993  377.829987  380.820007  380.820007   \n",
              "5144  2023-01-04  383.179993  385.880005  380.000000  383.760010  383.760010   \n",
              "5145  2023-01-05  381.720001  381.839996  378.760010  379.380005  379.380005   \n",
              "5146  2023-01-06  382.609985  389.250000  379.410004  388.079987  388.079987   \n",
              "\n",
              "         Volume  Daily Return        MA  \n",
              "5142   83975100      1.789978 -0.368799  \n",
              "5143   74850700     -3.549988 -0.530798  \n",
              "5144   85934100      0.580017 -0.380398  \n",
              "5145   76970500     -2.339996 -0.441199  \n",
              "5146  104041300      5.470002 -0.709999  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d8bb022-2545-4a21-a4d9-a6e080167062\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>380.640015</td>\n",
              "      <td>382.579987</td>\n",
              "      <td>378.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>83975100</td>\n",
              "      <td>1.789978</td>\n",
              "      <td>-0.368799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>384.369995</td>\n",
              "      <td>386.429993</td>\n",
              "      <td>377.829987</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>74850700</td>\n",
              "      <td>-3.549988</td>\n",
              "      <td>-0.530798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>383.179993</td>\n",
              "      <td>385.880005</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>85934100</td>\n",
              "      <td>0.580017</td>\n",
              "      <td>-0.380398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>381.720001</td>\n",
              "      <td>381.839996</td>\n",
              "      <td>378.760010</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>76970500</td>\n",
              "      <td>-2.339996</td>\n",
              "      <td>-0.441199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>382.609985</td>\n",
              "      <td>389.250000</td>\n",
              "      <td>379.410004</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>104041300</td>\n",
              "      <td>5.470002</td>\n",
              "      <td>-0.709999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d8bb022-2545-4a21-a4d9-a6e080167062')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d8bb022-2545-4a21-a4d9-a6e080167062 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d8bb022-2545-4a21-a4d9-a6e080167062');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtkml8ylGG47",
        "outputId": "0262192b-be78-4c8e-92ed-2a27ce320423"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date       Open       High        Low      Close  Adj Close  \\\n",
              "5142  2022-12-30  95.860001  96.269997  95.620003  95.779999  95.779999   \n",
              "5143  2023-01-03  96.910004  97.000000  96.339996  96.529999  96.529999   \n",
              "5144  2023-01-04  97.339996  97.419998  96.989998  97.269997  97.269997   \n",
              "5145  2023-01-05  96.699997  97.220001  96.570000  97.129997  97.129997   \n",
              "5146  2023-01-06  97.169998  98.430000  97.080002  98.379997  98.379997   \n",
              "\n",
              "       Volume  Daily Return        MA  \n",
              "5142  5039800     -0.080002  0.050399  \n",
              "5143  6808300     -0.380005  0.025599  \n",
              "5144  7800100     -0.069999  0.025599  \n",
              "5145  3177900      0.430000  0.043600  \n",
              "5146  6807700      1.209999  0.050399  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86834297-ab67-4a01-990e-b69614b62aa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.860001</td>\n",
              "      <td>96.269997</td>\n",
              "      <td>95.620003</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>5039800</td>\n",
              "      <td>-0.080002</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.910004</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>96.339996</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>6808300</td>\n",
              "      <td>-0.380005</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.339996</td>\n",
              "      <td>97.419998</td>\n",
              "      <td>96.989998</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>7800100</td>\n",
              "      <td>-0.069999</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>96.699997</td>\n",
              "      <td>97.220001</td>\n",
              "      <td>96.570000</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>3177900</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.043600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>97.169998</td>\n",
              "      <td>98.430000</td>\n",
              "      <td>97.080002</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>6807700</td>\n",
              "      <td>1.209999</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86834297-ab67-4a01-990e-b69614b62aa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86834297-ab67-4a01-990e-b69614b62aa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86834297-ab67-4a01-990e-b69614b62aa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate ROE"
      ],
      "metadata": {
        "id": "O6a-Fc3EZNxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_roe(market_data):    \n",
        "    market_data[\"Next Close\"] = market_data[\"Close\"].shift(-1)\n",
        "    market_data[\"ROE\"] = (market_data[\"Next Close\"] - market_data[\"Close\"]) / market_data['Close']\n",
        "\n",
        "add_roe(high_risk)\n",
        "add_roe(low_risk)"
      ],
      "metadata": {
        "id": "42UscmnQZMpE"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_roe_binary(market_data, tau=-0.005):    \n",
        "    market_data[\"ROE Binary\"] = np.where(market_data[\"ROE\"].values < tau, 0, 1)\n",
        "\n",
        "add_roe_binary(high_risk)\n",
        "add_roe_binary(low_risk)"
      ],
      "metadata": {
        "id": "V5kEAXakgkCs"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKK4t3UVfl_6",
        "outputId": "06f63431-da89-471b-cafa-4a97575fcefd"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  \\\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939   \n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453   \n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054   \n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895   \n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496   \n",
              "\n",
              "     Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0  47532200      1.620002  1.620002   91.160004  0.002419           1  \n",
              "1  44669900      0.670006  1.145004   88.779999 -0.026108           0  \n",
              "2  66571900     -2.099998  0.063337   86.790001 -0.022415           0  \n",
              "3  51772900     -1.709999 -0.379997   83.769997 -0.034797           0  \n",
              "4  47191300     -2.720001 -0.847998   86.589996  0.033664           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-037b51ce-04d9-40c7-a958-233bb520b744\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>0.002419</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "      <td>0.670006</td>\n",
              "      <td>1.145004</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "      <td>-2.099998</td>\n",
              "      <td>0.063337</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>-0.022415</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "      <td>-1.709999</td>\n",
              "      <td>-0.379997</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>-0.034797</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "      <td>-2.720001</td>\n",
              "      <td>-0.847998</td>\n",
              "      <td>86.589996</td>\n",
              "      <td>0.033664</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-037b51ce-04d9-40c7-a958-233bb520b744')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-037b51ce-04d9-40c7-a958-233bb520b744 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-037b51ce-04d9-40c7-a958-233bb520b744');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uurD8aCKfmH3",
        "outputId": "11186d49-139e-4123-c425-97970e7e5be3"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume  \\\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300   \n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600   \n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400   \n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300   \n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300   \n",
              "\n",
              "   Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0     -0.170005 -0.170005   82.519997  0.009172           1  \n",
              "1      0.469994  0.149994   82.860001  0.004120           1  \n",
              "2      0.320000  0.206663   83.500000  0.007724           1  \n",
              "3      0.480003  0.274998   83.919998  0.005030           1  \n",
              "4      0.239998  0.267998   83.239998 -0.008103           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-de3c22a7-c8b1-49e2-9c71-f87b12d5ec08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "      <td>0.469994</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>0.004120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.206663</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>0.007724</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "      <td>0.480003</td>\n",
              "      <td>0.274998</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "      <td>0.239998</td>\n",
              "      <td>0.267998</td>\n",
              "      <td>83.239998</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de3c22a7-c8b1-49e2-9c71-f87b12d5ec08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-de3c22a7-c8b1-49e2-9c71-f87b12d5ec08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-de3c22a7-c8b1-49e2-9c71-f87b12d5ec08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build feature space"
      ],
      "metadata": {
        "id": "_L1SeZ_ggNPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_for_ma(market_data, ma_days):\n",
        "  return market_data[ma_days:]\n",
        "\n",
        "high_risk = remove_for_ma(high_risk, MA_DAYS)\n",
        "low_risk = remove_for_ma(low_risk, MA_DAYS)"
      ],
      "metadata": {
        "id": "TKS0pN_Ola5g"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(high_risk.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnHuHNjPmrQO",
        "outputId": "ceb6d92c-a9f0-4ce7-9ed7-c5daeb573217"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5122, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_columns(market_data, columns):\n",
        "  for column in columns:\n",
        "    market_data[column] = market_data[column]/market_data[column].std()\n",
        "\n",
        "standardize_columns(high_risk, ['Volume', 'Daily Return', 'MA'])\n",
        "standardize_columns(low_risk, ['Volume', 'Daily Return', 'MA'])"
      ],
      "metadata": {
        "id": "0L7qIEJvdIvp"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tqgwASZBIDOa",
        "outputId": "bcf2b389-f27a-439b-97c7-30ff56bb77be"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.550024      0.479605  0.276737   88.779999 -0.008488           0  \n",
              "26  0.723874      0.149555  0.229367   90.000000  0.013742           1  \n",
              "27  0.415721      0.128926  0.522307   90.660004  0.007333           1  \n",
              "28  0.365951      0.804501  0.929931   91.699997  0.011471           1  \n",
              "29  0.445799      0.288793  1.338801   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48e6ad4c-919a-4d8f-8497-37028bf43358\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48e6ad4c-919a-4d8f-8497-37028bf43358')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48e6ad4c-919a-4d8f-8497-37028bf43358 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48e6ad4c-919a-4d8f-8497-37028bf43358');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-55dkiIJIal",
        "outputId": "d423e511-7b85-40b3-fdfa-ebb65d199de5"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d9e3c289-3396-449e-bc4f-3f637d48bc36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9e3c289-3396-449e-bc4f-3f637d48bc36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d9e3c289-3396-449e-bc4f-3f637d48bc36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d9e3c289-3396-449e-bc4f-3f637d48bc36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def to_dataset(low_risk, high_risk):\n",
        "#   return np.vstack((low_risk['Daily Return'], low_risk['MA'], low_risk['Volume'], high_risk['Daily Return'], high_risk['MA'], high_risk['Volume'],high_risk['ROE Binary']))\n",
        "\n",
        "# dataset = to_dataset(low_risk, high_risk).T\n",
        "# print(dataset.shape, dataset)"
      ],
      "metadata": {
        "id": "10wATCSHPIYZ"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.concat([low_risk, high_risk], join='outer', axis=1)[['Date'],['Daily Return'],['MA'],['Volume'],['ROE Binary']]\n",
        "# pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['Date','ROE Binary']]\n",
        "master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']]\n",
        "master_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "49t7Zc8bKsUQ",
        "outputId": "758a9da5-1560-4b37-a833-880ec83482ed"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date  l_Daily Return      l_MA  l_Volume  h_Daily Return  \\\n",
              "25    2002-09-04        0.135391  0.912126  0.023505        0.479605   \n",
              "26    2002-09-05       -0.203112  0.564337  0.017606        0.149555   \n",
              "27    2002-09-06       -0.710926  0.216542  0.009791        0.128926   \n",
              "28    2002-09-09       -0.609368 -0.216563  0.027002        0.804501   \n",
              "29    2002-09-10        1.184878 -0.144378  0.006507        0.288793   \n",
              "...          ...             ...       ...       ...             ...   \n",
              "5142  2022-12-30       -0.270837  0.826825  1.532486        0.923099   \n",
              "5143  2023-01-03       -1.286460  0.419968  2.070246       -1.830743   \n",
              "5144  2023-01-04       -0.236973  0.419968  2.371829        0.299117   \n",
              "5145  2023-01-05        1.455712  0.715269  0.966325       -1.206745   \n",
              "5146  2023-01-06        4.096301  0.826824  2.070063        2.820901   \n",
              "\n",
              "          h_MA  h_Volume  h_ROE Binary  \n",
              "25    0.276737  0.550024             0  \n",
              "26    0.229367  0.723874             1  \n",
              "27    0.522307  0.415721             1  \n",
              "28    0.929931  0.365951             1  \n",
              "29    1.338801  0.445799             0  \n",
              "...        ...       ...           ...  \n",
              "5142 -1.149319  0.903889             1  \n",
              "5143 -1.654172  0.805676             1  \n",
              "5144 -1.185467  0.924976             0  \n",
              "5145 -1.374945  0.828493             1  \n",
              "5146 -2.212630  1.119878             1  \n",
              "\n",
              "[5122 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-14f49277-ff09-4d60-af5b-f53578a9741d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Daily Return</th>\n",
              "      <th>l_MA</th>\n",
              "      <th>l_Volume</th>\n",
              "      <th>h_Daily Return</th>\n",
              "      <th>h_MA</th>\n",
              "      <th>h_Volume</th>\n",
              "      <th>h_ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>-0.270837</td>\n",
              "      <td>0.826825</td>\n",
              "      <td>1.532486</td>\n",
              "      <td>0.923099</td>\n",
              "      <td>-1.149319</td>\n",
              "      <td>0.903889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>-1.286460</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.070246</td>\n",
              "      <td>-1.830743</td>\n",
              "      <td>-1.654172</td>\n",
              "      <td>0.805676</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>-0.236973</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.371829</td>\n",
              "      <td>0.299117</td>\n",
              "      <td>-1.185467</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>1.455712</td>\n",
              "      <td>0.715269</td>\n",
              "      <td>0.966325</td>\n",
              "      <td>-1.206745</td>\n",
              "      <td>-1.374945</td>\n",
              "      <td>0.828493</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>4.096301</td>\n",
              "      <td>0.826824</td>\n",
              "      <td>2.070063</td>\n",
              "      <td>2.820901</td>\n",
              "      <td>-2.212630</td>\n",
              "      <td>1.119878</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows √ó 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14f49277-ff09-4d60-af5b-f53578a9741d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14f49277-ff09-4d60-af5b-f53578a9741d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14f49277-ff09-4d60-af5b-f53578a9741d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_tensor = torch.from_numpy(master_dataset[:,:-1])\n",
        "# Y_tensor = torch.from_numpy(master_dataset[:,-1])"
      ],
      "metadata": {
        "id": "nrXWLxZw6GJk"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build graph"
      ],
      "metadata": {
        "id": "_zmM8pF0Nxl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 500\n",
        "torch.manual_seed(42)\n",
        "lambda1 = 1e-3 #0.5\n",
        "lambda2 = 1e-3 #0.5\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "qjzCkZxbRPke"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds=10\n",
        "splits=KFold(n_splits=folds,shuffle=True,random_state=42)"
      ],
      "metadata": {
        "id": "yjgtH2co3IPg"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no cross-validation\n",
        "\n",
        "def train_and_get_a_b(dataset):\n",
        "\n",
        "  a = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  b = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  # print(a, a.size(), b, b.size())\n",
        "\n",
        "  optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "  X_tensor = torch.from_numpy(dataset[:,:-1])\n",
        "  Y_tensor = torch.from_numpy(dataset[:,-1])\n",
        "  # print(X_tensor, Y_tensor)\n",
        "    \n",
        "    \n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "      yhat = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "\n",
        "      loss = loss_fn(yhat, Y_tensor)\n",
        "      loss.backward()   \n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "  return a,b"
      ],
      "metadata": {
        "id": "LUEtsz9ZRRFN"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Backtesting"
      ],
      "metadata": {
        "id": "lYyH6QC07N4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from datetime import date\n",
        "from datetime import timedelta"
      ],
      "metadata": {
        "id": "pt5JBhCLyjYr"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_date = date(2003,9,21)\n",
        "last_date = date(2023,1,1)"
      ],
      "metadata": {
        "id": "Bbj-yDR504Fv"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delta_50weeks = timedelta(weeks=50)\n",
        "delta_1week = timedelta(weeks=1)"
      ],
      "metadata": {
        "id": "4v4UTD431hJ4"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "daterange = pd.date_range(first_date, last_date, freq='1W')\n",
        "daterange"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKt0kekQ21Ts",
        "outputId": "8561614e-e485-4e1e-e8ce-6c03b37fcfea"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2003-09-21', '2003-09-28', '2003-10-05', '2003-10-12',\n",
              "               '2003-10-19', '2003-10-26', '2003-11-02', '2003-11-09',\n",
              "               '2003-11-16', '2003-11-23',\n",
              "               ...\n",
              "               '2022-10-30', '2022-11-06', '2022-11-13', '2022-11-20',\n",
              "               '2022-11-27', '2022-12-04', '2022-12-11', '2022-12-18',\n",
              "               '2022-12-25', '2023-01-01'],\n",
              "              dtype='datetime64[ns]', length=1007, freq='W-SUN')"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(master_dataset['l_Date']) > startdate) & (pd.to_datetime(master_dataset['l_Date']) <= enddate)\n",
        "  subset = master_dataset.loc[mask]\n",
        "  # print(subset)\n",
        "  dataset = subset[['l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']].to_numpy()\n",
        "  # print(dataset)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "EV3MvASZ7kOM"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_dataset_for_date(first_date)\n",
        "dataset[:-1]"
      ],
      "metadata": {
        "id": "fra6gOlGT1-v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a198a9-7462-4a71-eb1f-2359aa5668ec"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.10155789,  1.89647755,  0.02441736, ..., -0.97480731,\n",
              "         0.57250387,  1.        ],\n",
              "       [ 0.40625526,  1.88335059,  0.04092873, ..., -0.59959326,\n",
              "         0.8560541 ,  0.        ],\n",
              "       [ 0.16925525,  1.88991473,  0.02873525, ..., -0.83893149,\n",
              "         0.86063301,  1.        ],\n",
              "       ...,\n",
              "       [ 0.20311239,  0.702162  ,  0.02435655, ...,  0.53227856,\n",
              "         0.40786757,  1.        ],\n",
              "       [ 1.11718079,  1.03027115,  0.05385199, ...,  0.41510118,\n",
              "         0.3432117 ,  1.        ],\n",
              "       [-0.06772444,  1.33868853,  0.04019894, ...,  0.66191837,\n",
              "         0.32553542,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a,b = train_and_get_a_b(dataset[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWm27_faerS",
        "outputId": "69b69a70-14a2-4868-9748-ae649a062267"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 0.7215387084732557\n",
            "Epoch: 10. Loss: 0.6810488372594536\n",
            "Epoch: 20. Loss: 0.6619500050935622\n",
            "Epoch: 30. Loss: 0.6521565567197636\n",
            "Epoch: 40. Loss: 0.6464397969752089\n",
            "Epoch: 50. Loss: 0.6426307457433627\n",
            "Epoch: 60. Loss: 0.6398216117779618\n",
            "Epoch: 70. Loss: 0.6376153153449661\n",
            "Epoch: 80. Loss: 0.6358225985627264\n",
            "Epoch: 90. Loss: 0.6343410710924327\n",
            "Epoch: 100. Loss: 0.6331068216799932\n",
            "Epoch: 110. Loss: 0.6320747596039019\n",
            "Epoch: 120. Loss: 0.6312103348754365\n",
            "Epoch: 130. Loss: 0.6304858042589387\n",
            "Epoch: 140. Loss: 0.629878352162473\n",
            "Epoch: 150. Loss: 0.6293690012873694\n",
            "Epoch: 160. Loss: 0.6289418863431444\n",
            "Epoch: 170. Loss: 0.6285837156714381\n",
            "Epoch: 180. Loss: 0.6282833454216006\n",
            "Epoch: 190. Loss: 0.6280314310362333\n",
            "Epoch: 200. Loss: 0.6278201373411659\n",
            "Epoch: 210. Loss: 0.6276428956928688\n",
            "Epoch: 220. Loss: 0.6274942000225749\n",
            "Epoch: 230. Loss: 0.6273694354503347\n",
            "Epoch: 240. Loss: 0.6272647343062115\n",
            "Epoch: 250. Loss: 0.6271768552427145\n",
            "Epoch: 260. Loss: 0.6271030817955745\n",
            "Epoch: 270. Loss: 0.6270411373097088\n",
            "Epoch: 280. Loss: 0.6269891136217124\n",
            "Epoch: 290. Loss: 0.6269454112948777\n",
            "Epoch: 300. Loss: 0.6269086895478526\n",
            "Epoch: 310. Loss: 0.6268778243117208\n",
            "Epoch: 320. Loss: 0.6268518730994737\n",
            "Epoch: 330. Loss: 0.6268300455827005\n",
            "Epoch: 340. Loss: 0.6268116789482844\n",
            "Epoch: 350. Loss: 0.6267962172577939\n",
            "Epoch: 360. Loss: 0.6267831941583027\n",
            "Epoch: 370. Loss: 0.6267722183992034\n",
            "Epoch: 380. Loss: 0.6267629616983522\n",
            "Epoch: 390. Loss: 0.6267551485752878\n",
            "Epoch: 400. Loss: 0.626748547831577\n",
            "Epoch: 410. Loss: 0.6267429654105127\n",
            "Epoch: 420. Loss: 0.6267382384120478\n",
            "Epoch: 430. Loss: 0.6267342300753899\n",
            "Epoch: 440. Loss: 0.626730825572235\n",
            "Epoch: 450. Loss: 0.626727928479206\n",
            "Epoch: 460. Loss: 0.6267254578194402\n",
            "Epoch: 470. Loss: 0.6267233455811787\n",
            "Epoch: 480. Loss: 0.6267215346361861\n",
            "Epoch: 490. Loss: 0.626719976993358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "  print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsYhNrSeoDv",
        "outputId": "247b11ab-a50c-4bea-d817-906fb45f2e68"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7145, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1"
      ],
      "metadata": {
        "id": "MsH_YCVPyOer"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = calculate_ml_portfolio_weights(y_test.numpy(), 0.5)\n",
        "weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJY6MNe079u",
        "outputId": "ab7a7b33-6d38-4f77-cf9a-9d9ef67bdf4a"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_date"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqF9cz1V0rO5",
        "outputId": "abb5244d-4020-4226-bcb2-e2120a0540a4"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.date(2003, 9, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_backtest_data(date, weight):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "\n",
        "  investment = low_risk if weight == 0 else high_risk\n",
        "    \n",
        "  backtest_mask = (pd.to_datetime(investment['Date']) > startdate) & (pd.to_datetime(investment['Date']) <= enddate)\n",
        "  backtest_data = investment.loc[backtest_mask]\n",
        "\n",
        "  return backtest_data"
      ],
      "metadata": {
        "id": "CkX6whwN4KX0"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ],
      "metadata": {
        "id": "7grWmruL4LNu"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_backtest_return(date, weight):\n",
        "  backtest_data = get_backtest_data(date, weight)\n",
        "  return calculate_backtest_return(backtest_data)"
      ],
      "metadata": {
        "id": "zGPtDN524CA0"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backtest_data = get_backtest_data(first_date, weight)\n",
        "backtest_data.iloc[-1]['Close']\n",
        "backtest_data.iloc[0]['Open']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWzbQZb01qHF",
        "outputId": "1bfbc15b-6908-4dde-cadb-95acc2e96e7d"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102.849998"
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_backtest_return(first_date, weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxw0Vpct44Bq",
        "outputId": "cd8426bb-5785-4190-d380-269f6b9dc820"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.028196412799152443"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if weight == 0:\n",
        "  print(low_risk.loc[low_risk['Date'] == first_date])\n",
        "elif weight == 1:\n",
        "  pass"
      ],
      "metadata": {
        "id": "LrzbavSZ0Ae_"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backtest_returns = {}\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_dataset_for_date(date)\n",
        "  a,b = train_and_get_a_b(dataset[:-1])\n",
        "  with torch.no_grad():\n",
        "    y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "    print(y_test)\n",
        "  weight = calculate_ml_portfolio_weights(y_test.numpy(), 0.5)\n",
        "  ret = get_backtest_return(date, weight)\n",
        "  backtest_returns[date] = ret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8zIjtzG4xOv",
        "outputId": "33bf9c2d-add9-4c55-9eb7-7597c3d24c7b"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 430. Loss: 0.5792344553998144\n",
            "Epoch: 440. Loss: 0.5792179909400019\n",
            "Epoch: 450. Loss: 0.5792041471138083\n",
            "Epoch: 460. Loss: 0.579192504572068\n",
            "Epoch: 470. Loss: 0.579182711579611\n",
            "Epoch: 480. Loss: 0.5791744729962807\n",
            "Epoch: 490. Loss: 0.5791675410806006\n",
            "tensor(0.9888, dtype=torch.float64)\n",
            "2021-03-07 00:00:00\n",
            "Epoch: 0. Loss: 3.700318248437614\n",
            "Epoch: 10. Loss: 1.6217001995774516\n",
            "Epoch: 20. Loss: 0.8523053443053644\n",
            "Epoch: 30. Loss: 0.6768278306758663\n",
            "Epoch: 40. Loss: 0.6274131517005561\n",
            "Epoch: 50. Loss: 0.6074411111519081\n",
            "Epoch: 60. Loss: 0.5979778990245317\n",
            "Epoch: 70. Loss: 0.5927103496028076\n",
            "Epoch: 80. Loss: 0.5893202258259215\n",
            "Epoch: 90. Loss: 0.5869193046071116\n",
            "Epoch: 100. Loss: 0.5851289847961778\n",
            "Epoch: 110. Loss: 0.5837597132965624\n",
            "Epoch: 120. Loss: 0.582699265561636\n",
            "Epoch: 130. Loss: 0.5818722158937859\n",
            "Epoch: 140. Loss: 0.5812239993128596\n",
            "Epoch: 150. Loss: 0.5807137246473957\n",
            "Epoch: 160. Loss: 0.5803102895203948\n",
            "Epoch: 170. Loss: 0.5799898978787605\n",
            "Epoch: 180. Loss: 0.5797342951299662\n",
            "Epoch: 190. Loss: 0.5795294492338577\n",
            "Epoch: 200. Loss: 0.5793645478551976\n",
            "Epoch: 210. Loss: 0.5792312335110643\n",
            "Epoch: 220. Loss: 0.5791230213022217\n",
            "Epoch: 230. Loss: 0.5790348568251926\n",
            "Epoch: 240. Loss: 0.5789627811718897\n",
            "Epoch: 250. Loss: 0.5789036772631769\n",
            "Epoch: 260. Loss: 0.5788550776604576\n",
            "Epoch: 270. Loss: 0.5788150186944196\n",
            "Epoch: 280. Loss: 0.5787819294289809\n",
            "Epoch: 290. Loss: 0.5787545468181771\n",
            "Epoch: 300. Loss: 0.5787318505787676\n",
            "Epoch: 310. Loss: 0.5787130129362829\n",
            "Epoch: 320. Loss: 0.5786973596281703\n",
            "Epoch: 330. Loss: 0.5786843394623773\n",
            "Epoch: 340. Loss: 0.5786735004099371\n",
            "Epoch: 350. Loss: 0.5786644707151555\n",
            "Epoch: 360. Loss: 0.578656943881805\n",
            "Epoch: 370. Loss: 0.5786506666721162\n",
            "Epoch: 380. Loss: 0.5786454294625183\n",
            "Epoch: 390. Loss: 0.5786410584546864\n",
            "Epoch: 400. Loss: 0.578637409356258\n",
            "Epoch: 410. Loss: 0.5786343622327352\n",
            "Epoch: 420. Loss: 0.578631817298008\n",
            "Epoch: 430. Loss: 0.5786296914610977\n",
            "Epoch: 440. Loss: 0.5786279154851273\n",
            "Epoch: 450. Loss: 0.578626431644127\n",
            "Epoch: 460. Loss: 0.5786251917862587\n",
            "Epoch: 470. Loss: 0.5786241557299919\n",
            "Epoch: 480. Loss: 0.5786232899338858\n",
            "Epoch: 490. Loss: 0.5786225663918145\n",
            "tensor(0.9006, dtype=torch.float64)\n",
            "2021-03-14 00:00:00\n",
            "Epoch: 0. Loss: 3.319310316863527\n",
            "Epoch: 10. Loss: 1.4273842999924637\n",
            "Epoch: 20. Loss: 0.7280272421053375\n",
            "Epoch: 30. Loss: 0.6172884273053925\n",
            "Epoch: 40. Loss: 0.6046007859371921\n",
            "Epoch: 50. Loss: 0.5993993744424214\n",
            "Epoch: 60. Loss: 0.5954917915293158\n",
            "Epoch: 70. Loss: 0.592290725967262\n",
            "Epoch: 80. Loss: 0.589629231963636\n",
            "Epoch: 90. Loss: 0.5874012366708234\n",
            "Epoch: 100. Loss: 0.5855262294267833\n",
            "Epoch: 110. Loss: 0.5839412811873935\n",
            "Epoch: 120. Loss: 0.582596622605092\n",
            "Epoch: 130. Loss: 0.5814524775700005\n",
            "Epoch: 140. Loss: 0.580476721194854\n",
            "Epoch: 150. Loss: 0.5796431409253892\n",
            "Epoch: 160. Loss: 0.5789301412835491\n",
            "Epoch: 170. Loss: 0.578319773946753\n",
            "Epoch: 180. Loss: 0.5777970060986818\n",
            "Epoch: 190. Loss: 0.5773491634147507\n",
            "Epoch: 200. Loss: 0.5769655013656786\n",
            "Epoch: 210. Loss: 0.5766368712137769\n",
            "Epoch: 220. Loss: 0.5763554563247818\n",
            "Epoch: 230. Loss: 0.5761145611305095\n",
            "Epoch: 240. Loss: 0.5759084399328596\n",
            "Epoch: 250. Loss: 0.5757321562398318\n",
            "Epoch: 260. Loss: 0.5755814658393654\n",
            "Epoch: 270. Loss: 0.5754527186189643\n",
            "Epoch: 280. Loss: 0.5753427754277888\n",
            "Epoch: 290. Loss: 0.5752489371989687\n",
            "Epoch: 300. Loss: 0.5751688842092555\n",
            "Epoch: 310. Loss: 0.5751006238273167\n",
            "Epoch: 320. Loss: 0.5750424454457176\n",
            "Epoch: 330. Loss: 0.5749928815438813\n",
            "Epoch: 340. Loss: 0.5749506740173974\n",
            "Epoch: 350. Loss: 0.574914745052119\n",
            "Epoch: 360. Loss: 0.5748841719327397\n",
            "Epoch: 370. Loss: 0.5748581652641214\n",
            "Epoch: 380. Loss: 0.5748360501557541\n",
            "Epoch: 390. Loss: 0.57481724997967\n",
            "Epoch: 400. Loss: 0.5748012723627969\n",
            "Epoch: 410. Loss: 0.5747876971181735\n",
            "Epoch: 420. Loss: 0.5747761658570453\n",
            "Epoch: 430. Loss: 0.5747663730566492\n",
            "Epoch: 440. Loss: 0.574758058387202\n",
            "Epoch: 450. Loss: 0.574751000126826\n",
            "Epoch: 460. Loss: 0.5747450095152858\n",
            "Epoch: 470. Loss: 0.5747399259168889\n",
            "Epoch: 480. Loss: 0.574735612679983\n",
            "Epoch: 490. Loss: 0.5747319535954732\n",
            "tensor(0.7066, dtype=torch.float64)\n",
            "2021-03-21 00:00:00\n",
            "Epoch: 0. Loss: 2.780891394417968\n",
            "Epoch: 10. Loss: 1.3052035017824763\n",
            "Epoch: 20. Loss: 0.8817861308126665\n",
            "Epoch: 30. Loss: 0.7693999019888588\n",
            "Epoch: 40. Loss: 0.7147975899999541\n",
            "Epoch: 50. Loss: 0.6792614466815162\n",
            "Epoch: 60. Loss: 0.653909862968088\n",
            "Epoch: 70. Loss: 0.6349709738653241\n",
            "Epoch: 80. Loss: 0.6204807502956984\n",
            "Epoch: 90. Loss: 0.6093476189928713\n",
            "Epoch: 100. Loss: 0.60086635492776\n",
            "Epoch: 110. Loss: 0.5944906432288072\n",
            "Epoch: 120. Loss: 0.5897587353630799\n",
            "Epoch: 130. Loss: 0.5862821565560152\n",
            "Epoch: 140. Loss: 0.5837463860104642\n",
            "Epoch: 150. Loss: 0.5819062781227612\n",
            "Epoch: 160. Loss: 0.5805759566653329\n",
            "Epoch: 170. Loss: 0.5796169475035685\n",
            "Epoch: 180. Loss: 0.5789272104063935\n",
            "Epoch: 190. Loss: 0.5784320841717584\n",
            "Epoch: 200. Loss: 0.5780772169291672\n",
            "Epoch: 210. Loss: 0.5778231995396598\n",
            "Epoch: 220. Loss: 0.5776415528562829\n",
            "Epoch: 230. Loss: 0.5775117550167808\n",
            "Epoch: 240. Loss: 0.5774190540528983\n",
            "Epoch: 250. Loss: 0.5773528673044702\n",
            "Epoch: 260. Loss: 0.5773056158760816\n",
            "Epoch: 270. Loss: 0.5772718794752197\n",
            "Epoch: 280. Loss: 0.5772477858001885\n",
            "Epoch: 290. Loss: 0.5772305707492845\n",
            "Epoch: 300. Loss: 0.5772182624799419\n",
            "Epoch: 310. Loss: 0.5772094549211505\n",
            "Epoch: 320. Loss: 0.5772031456909502\n",
            "Epoch: 330. Loss: 0.577198620264175\n",
            "Epoch: 340. Loss: 0.5771953692830927\n",
            "Epoch: 350. Loss: 0.5771930295778859\n",
            "Epoch: 360. Loss: 0.5771913421257291\n",
            "Epoch: 370. Loss: 0.577190122098022\n",
            "Epoch: 380. Loss: 0.5771892375270421\n",
            "Epoch: 390. Loss: 0.577188594114668\n",
            "Epoch: 400. Loss: 0.5771881244157316\n",
            "Epoch: 410. Loss: 0.5771877801360633\n",
            "Epoch: 420. Loss: 0.5771875266476608\n",
            "Epoch: 430. Loss: 0.5771873390818587\n",
            "Epoch: 440. Loss: 0.5771871995455868\n",
            "Epoch: 450. Loss: 0.5771870951369855\n",
            "Epoch: 460. Loss: 0.5771870165300511\n",
            "Epoch: 470. Loss: 0.5771869569644426\n",
            "Epoch: 480. Loss: 0.577186911523866\n",
            "Epoch: 490. Loss: 0.577186876620085\n",
            "tensor(0.8431, dtype=torch.float64)\n",
            "2021-03-28 00:00:00\n",
            "Epoch: 0. Loss: 1.0718450297274817\n",
            "Epoch: 10. Loss: 0.8986105895084752\n",
            "Epoch: 20. Loss: 0.7934887545317474\n",
            "Epoch: 30. Loss: 0.7230665693802566\n",
            "Epoch: 40. Loss: 0.6742304121638626\n",
            "Epoch: 50. Loss: 0.6408538248709061\n",
            "Epoch: 60. Loss: 0.6186315417837475\n",
            "Epoch: 70. Loss: 0.6041950067410433\n",
            "Epoch: 80. Loss: 0.5950200647470599\n",
            "Epoch: 90. Loss: 0.5892993947979658\n",
            "Epoch: 100. Loss: 0.5857793348843515\n",
            "Epoch: 110. Loss: 0.5836198650562691\n",
            "Epoch: 120. Loss: 0.5822817710804016\n",
            "Epoch: 130. Loss: 0.5814332329095849\n",
            "Epoch: 140. Loss: 0.5808765160093314\n",
            "Epoch: 150. Loss: 0.5804959930087282\n",
            "Epoch: 160. Loss: 0.5802244838434729\n",
            "Epoch: 170. Loss: 0.5800227846494884\n",
            "Epoch: 180. Loss: 0.5798676885128686\n",
            "Epoch: 190. Loss: 0.5797451268595964\n",
            "Epoch: 200. Loss: 0.5796462856719737\n",
            "Epoch: 210. Loss: 0.579565414556859\n",
            "Epoch: 220. Loss: 0.5794985886521097\n",
            "Epoch: 230. Loss: 0.5794430041860571\n",
            "Epoch: 240. Loss: 0.579396572665282\n",
            "Epoch: 250. Loss: 0.579357682608526\n",
            "Epoch: 260. Loss: 0.5793250558658087\n",
            "Epoch: 270. Loss: 0.5792976578973439\n",
            "Epoch: 280. Loss: 0.579274639332573\n",
            "Epoch: 290. Loss: 0.5792552960824795\n",
            "Epoch: 300. Loss: 0.5792390408025434\n",
            "Epoch: 310. Loss: 0.5792253815766815\n",
            "Epoch: 320. Loss: 0.5792139054089228\n",
            "Epoch: 330. Loss: 0.5792042650745743\n",
            "Epoch: 340. Loss: 0.579196168430714\n",
            "Epoch: 350. Loss: 0.5791893696019369\n",
            "Epoch: 360. Loss: 0.5791836616435979\n",
            "Epoch: 370. Loss: 0.5791788703980361\n",
            "Epoch: 380. Loss: 0.579174849330824\n",
            "Epoch: 390. Loss: 0.5791714751814916\n",
            "Epoch: 400. Loss: 0.5791686442961866\n",
            "Epoch: 410. Loss: 0.5791662695339247\n",
            "Epoch: 420. Loss: 0.5791642776565568\n",
            "Epoch: 430. Loss: 0.5791626071272298\n",
            "Epoch: 440. Loss: 0.5791612062540041\n",
            "Epoch: 450. Loss: 0.5791600316251337\n",
            "Epoch: 460. Loss: 0.579159046790749\n",
            "Epoch: 470. Loss: 0.5791582211526176\n",
            "Epoch: 480. Loss: 0.5791575290295388\n",
            "Epoch: 490. Loss: 0.5791569488709013\n",
            "tensor(0.8072, dtype=torch.float64)\n",
            "2021-04-04 00:00:00\n",
            "Epoch: 0. Loss: 2.144404555079429\n",
            "Epoch: 10. Loss: 1.1597175534334407\n",
            "Epoch: 20. Loss: 0.7950591793890999\n",
            "Epoch: 30. Loss: 0.6704482858148093\n",
            "Epoch: 40. Loss: 0.6218530267712568\n",
            "Epoch: 50. Loss: 0.6022591658247985\n",
            "Epoch: 60. Loss: 0.5939189238723573\n",
            "Epoch: 70. Loss: 0.5895351172388288\n",
            "Epoch: 80. Loss: 0.5865952887547538\n",
            "Epoch: 90. Loss: 0.5843013078009872\n",
            "Epoch: 100. Loss: 0.5823846617207068\n",
            "Epoch: 110. Loss: 0.5807366501883007\n",
            "Epoch: 120. Loss: 0.5793008192303476\n",
            "Epoch: 130. Loss: 0.5780410883913291\n",
            "Epoch: 140. Loss: 0.5769313276723234\n",
            "Epoch: 150. Loss: 0.5759512843064997\n",
            "Epoch: 160. Loss: 0.5750846141915468\n",
            "Epoch: 170. Loss: 0.5743177522615136\n",
            "Epoch: 180. Loss: 0.573639194482993\n",
            "Epoch: 190. Loss: 0.5730390168696522\n",
            "Epoch: 200. Loss: 0.5725085439485487\n",
            "Epoch: 210. Loss: 0.5720401155617194\n",
            "Epoch: 220. Loss: 0.571626919542741\n",
            "Epoch: 230. Loss: 0.5712628688349208\n",
            "Epoch: 240. Loss: 0.5709425086733365\n",
            "Epoch: 250. Loss: 0.5706609441435487\n",
            "Epoch: 260. Loss: 0.5704137816040353\n",
            "Epoch: 270. Loss: 0.5701970796238176\n",
            "Epoch: 280. Loss: 0.5700073065645069\n",
            "Epoch: 290. Loss: 0.5698413029408498\n",
            "Epoch: 300. Loss: 0.5696962473704771\n",
            "Epoch: 310. Loss: 0.5695696253718368\n",
            "Epoch: 320. Loss: 0.5694592005591709\n",
            "Epoch: 330. Loss: 0.5693629879644353\n",
            "Epoch: 340. Loss: 0.5692792293235248\n",
            "Epoch: 350. Loss: 0.5692063702231472\n",
            "Epoch: 360. Loss: 0.5691430390328027\n",
            "Epoch: 370. Loss: 0.5690880275558479\n",
            "Epoch: 380. Loss: 0.5690402733328241\n",
            "Epoch: 390. Loss: 0.5689988435245587\n",
            "Epoch: 400. Loss: 0.5689629202954011\n",
            "Epoch: 410. Loss: 0.5689317876103585\n",
            "Epoch: 420. Loss: 0.5689048193548542\n",
            "Epoch: 430. Loss: 0.5688814686828024\n",
            "Epoch: 440. Loss: 0.5688612584977069\n",
            "Epoch: 450. Loss: 0.5688437729723412\n",
            "Epoch: 460. Loss: 0.5688286500150135\n",
            "Epoch: 470. Loss: 0.5688155745940792\n",
            "Epoch: 480. Loss: 0.5688042728369515\n",
            "Epoch: 490. Loss: 0.568794506825062\n",
            "tensor(0.8482, dtype=torch.float64)\n",
            "2021-04-11 00:00:00\n",
            "Epoch: 0. Loss: 1.7637477786082698\n",
            "Epoch: 10. Loss: 0.8373785165036428\n",
            "Epoch: 20. Loss: 0.6837979660020072\n",
            "Epoch: 30. Loss: 0.6278358838583517\n",
            "Epoch: 40. Loss: 0.6004789852070445\n",
            "Epoch: 50. Loss: 0.586502555233454\n",
            "Epoch: 60. Loss: 0.5787217120233394\n",
            "Epoch: 70. Loss: 0.5739497607465303\n",
            "Epoch: 80. Loss: 0.5707919324402878\n",
            "Epoch: 90. Loss: 0.5685946250093437\n",
            "Epoch: 100. Loss: 0.5670163968011095\n",
            "Epoch: 110. Loss: 0.5658584468777598\n",
            "Epoch: 120. Loss: 0.5649950957480855\n",
            "Epoch: 130. Loss: 0.5643426014523168\n",
            "Epoch: 140. Loss: 0.5638433823649184\n",
            "Epoch: 150. Loss: 0.5634570552927912\n",
            "Epoch: 160. Loss: 0.5631548923550249\n",
            "Epoch: 170. Loss: 0.5629162097798456\n",
            "Epoch: 180. Loss: 0.562725946257298\n",
            "Epoch: 190. Loss: 0.5625730119491444\n",
            "Epoch: 200. Loss: 0.5624491505410271\n",
            "Epoch: 210. Loss: 0.5623481478958336\n",
            "Epoch: 220. Loss: 0.5622652770226313\n",
            "Epoch: 230. Loss: 0.5621969053414639\n",
            "Epoch: 240. Loss: 0.5621402141925314\n",
            "Epoch: 250. Loss: 0.5620929965526116\n",
            "Epoch: 260. Loss: 0.5620535096838543\n",
            "Epoch: 270. Loss: 0.5620203667031445\n",
            "Epoch: 280. Loss: 0.5619924559821354\n",
            "Epoch: 290. Loss: 0.5619688806391349\n",
            "Epoch: 300. Loss: 0.5619489126781841\n",
            "Epoch: 310. Loss: 0.5619319579111377\n",
            "Epoch: 320. Loss: 0.5619175288950734\n",
            "Epoch: 330. Loss: 0.5619052238840311\n",
            "Epoch: 340. Loss: 0.5618947103345725\n",
            "Epoch: 350. Loss: 0.561885711889069\n",
            "Epoch: 360. Loss: 0.5618779980364815\n",
            "Epoch: 370. Loss: 0.5618713758502243\n",
            "Epoch: 380. Loss: 0.5618656833487452\n",
            "Epoch: 390. Loss: 0.5618607841322176\n",
            "Epoch: 400. Loss: 0.5618565630289089\n",
            "Epoch: 410. Loss: 0.5618529225449743\n",
            "Epoch: 420. Loss: 0.5618497799569605\n",
            "Epoch: 430. Loss: 0.561847064921007\n",
            "Epoch: 440. Loss: 0.5618447174993931\n",
            "Epoch: 450. Loss: 0.5618426865256668\n",
            "Epoch: 460. Loss: 0.5618409282456142\n",
            "Epoch: 470. Loss: 0.5618394051838465\n",
            "Epoch: 480. Loss: 0.5618380851956347\n",
            "Epoch: 490. Loss: 0.5618369406713933\n",
            "tensor(0.8231, dtype=torch.float64)\n",
            "2021-04-18 00:00:00\n",
            "Epoch: 0. Loss: 1.1888103043013862\n",
            "Epoch: 10. Loss: 0.8876618490090233\n",
            "Epoch: 20. Loss: 0.7152177180625094\n",
            "Epoch: 30. Loss: 0.6327163422797881\n",
            "Epoch: 40. Loss: 0.5993099527688306\n",
            "Epoch: 50. Loss: 0.5855321061554436\n",
            "Epoch: 60. Loss: 0.5780980716295152\n",
            "Epoch: 70. Loss: 0.5730071844375876\n",
            "Epoch: 80. Loss: 0.5691235082430465\n",
            "Epoch: 90. Loss: 0.5660259810549725\n",
            "Epoch: 100. Loss: 0.563496177070758\n",
            "Epoch: 110. Loss: 0.5613957763620736\n",
            "Epoch: 120. Loss: 0.5596290936889271\n",
            "Epoch: 130. Loss: 0.5581270951021655\n",
            "Epoch: 140. Loss: 0.556838682922811\n",
            "Epoch: 150. Loss: 0.5557252828693691\n",
            "Epoch: 160. Loss: 0.5547572609604321\n",
            "Epoch: 170. Loss: 0.5539114713407756\n",
            "Epoch: 180. Loss: 0.5531695445687609\n",
            "Epoch: 190. Loss: 0.5525166762777142\n",
            "Epoch: 200. Loss: 0.5519407603712537\n",
            "Epoch: 210. Loss: 0.551431762423928\n",
            "Epoch: 220. Loss: 0.5509812621372866\n",
            "Epoch: 230. Loss: 0.5505821157339316\n",
            "Epoch: 240. Loss: 0.5502282040758154\n",
            "Epoch: 250. Loss: 0.549914242498529\n",
            "Epoch: 260. Loss: 0.549635635405332\n",
            "Epoch: 270. Loss: 0.5493883635741427\n",
            "Epoch: 280. Loss: 0.5491688955711234\n",
            "Epoch: 290. Loss: 0.5489741170897404\n",
            "Epoch: 300. Loss: 0.548801273752988\n",
            "Epoch: 310. Loss: 0.54864792414041\n",
            "Epoch: 320. Loss: 0.5485119006768128\n",
            "Epoch: 330. Loss: 0.5483912766477875\n",
            "Epoch: 340. Loss: 0.5482843380595532\n",
            "Epoch: 350. Loss: 0.5481895593874254\n",
            "Epoch: 360. Loss: 0.5481055824939683\n",
            "Epoch: 370. Loss: 0.5480311981699965\n",
            "Epoch: 380. Loss: 0.5479653298771506\n",
            "Epoch: 390. Loss: 0.5479070193628267\n",
            "Epoch: 400. Loss: 0.5478554138861111\n",
            "Epoch: 410. Loss: 0.5478097548438051\n",
            "Epoch: 420. Loss: 0.5477693676234539\n",
            "Epoch: 430. Loss: 0.5477336525390016\n",
            "Epoch: 440. Loss: 0.5477020767267983\n",
            "Epoch: 450. Loss: 0.5476741668969614\n",
            "Epoch: 460. Loss: 0.5476495028488725\n",
            "Epoch: 470. Loss: 0.5476277116707479\n",
            "Epoch: 480. Loss: 0.5476084625524706\n",
            "Epoch: 490. Loss: 0.5475914621486436\n",
            "tensor(0.8714, dtype=torch.float64)\n",
            "2021-04-25 00:00:00\n",
            "Epoch: 0. Loss: 2.1675247760636767\n",
            "Epoch: 10. Loss: 0.8780705226402534\n",
            "Epoch: 20. Loss: 0.67845854826111\n",
            "Epoch: 30. Loss: 0.6304894606152837\n",
            "Epoch: 40. Loss: 0.6127280061739019\n",
            "Epoch: 50. Loss: 0.6024398318649841\n",
            "Epoch: 60. Loss: 0.594676534510788\n",
            "Epoch: 70. Loss: 0.5883295861020799\n",
            "Epoch: 80. Loss: 0.5830487404587996\n",
            "Epoch: 90. Loss: 0.578639630897695\n",
            "Epoch: 100. Loss: 0.5749538127479661\n",
            "Epoch: 110. Loss: 0.571868195025317\n",
            "Epoch: 120. Loss: 0.569279809132793\n",
            "Epoch: 130. Loss: 0.5671029938923302\n",
            "Epoch: 140. Loss: 0.5652669445665107\n",
            "Epoch: 150. Loss: 0.5637134176142534\n",
            "Epoch: 160. Loss: 0.5623946417440621\n",
            "Epoch: 170. Loss: 0.5612714821018835\n",
            "Epoch: 180. Loss: 0.5603118711460463\n",
            "Epoch: 190. Loss: 0.5594894948519815\n",
            "Epoch: 200. Loss: 0.55878270911699\n",
            "Epoch: 210. Loss: 0.5581736556227705\n",
            "Epoch: 220. Loss: 0.5576475458494111\n",
            "Epoch: 230. Loss: 0.5571920841269997\n",
            "Epoch: 240. Loss: 0.5567970040666216\n",
            "Epoch: 250. Loss: 0.5564536965347902\n",
            "Epoch: 260. Loss: 0.556154911029508\n",
            "Epoch: 270. Loss: 0.5558945156403856\n",
            "Epoch: 280. Loss: 0.5556673036385071\n",
            "Epoch: 290. Loss: 0.5554688371370735\n",
            "Epoch: 300. Loss: 0.5552953202272619\n",
            "Epoch: 310. Loss: 0.5551434955795466\n",
            "Epoch: 320. Loss: 0.5550105597677953\n",
            "Epoch: 330. Loss: 0.5548940935778529\n",
            "Epoch: 340. Loss: 0.554792004353981\n",
            "Epoch: 350. Loss: 0.5547024780580377\n",
            "Epoch: 360. Loss: 0.5546239392030299\n",
            "Epoch: 370. Loss: 0.5545550172033952\n",
            "Epoch: 380. Loss: 0.5544945179821561\n",
            "Epoch: 390. Loss: 0.55444139990818\n",
            "Epoch: 400. Loss: 0.5543947533195747\n",
            "Epoch: 410. Loss: 0.5543537830329469\n",
            "Epoch: 420. Loss: 0.5543177933515916\n",
            "Epoch: 430. Loss: 0.5542861751754216\n",
            "Epoch: 440. Loss: 0.5542583948868186\n",
            "Epoch: 450. Loss: 0.5542339847436194\n",
            "Epoch: 460. Loss: 0.5542125345562757\n",
            "Epoch: 470. Loss: 0.5541936844632374\n",
            "Epoch: 480. Loss: 0.5541771186486806\n",
            "Epoch: 490. Loss: 0.554162559871269\n",
            "tensor(0.7921, dtype=torch.float64)\n",
            "2021-05-02 00:00:00\n",
            "Epoch: 0. Loss: 1.3802440377710812\n",
            "Epoch: 10. Loss: 1.084501151089423\n",
            "Epoch: 20. Loss: 0.8541965668536222\n",
            "Epoch: 30. Loss: 0.6948293640166142\n",
            "Epoch: 40. Loss: 0.6106796888228989\n",
            "Epoch: 50. Loss: 0.5805586707557073\n",
            "Epoch: 60. Loss: 0.5710540877793397\n",
            "Epoch: 70. Loss: 0.5670669220389145\n",
            "Epoch: 80. Loss: 0.5646240607686915\n",
            "Epoch: 90. Loss: 0.5627800366667213\n",
            "Epoch: 100. Loss: 0.5612857019312396\n",
            "Epoch: 110. Loss: 0.560050409432731\n",
            "Epoch: 120. Loss: 0.5590233801566684\n",
            "Epoch: 130. Loss: 0.5581674863657892\n",
            "Epoch: 140. Loss: 0.5574529510525942\n",
            "Epoch: 150. Loss: 0.5568553313695525\n",
            "Epoch: 160. Loss: 0.5563544802107308\n",
            "Epoch: 170. Loss: 0.5559337945028535\n",
            "Epoch: 180. Loss: 0.555579602074226\n",
            "Epoch: 190. Loss: 0.5552806491334453\n",
            "Epoch: 200. Loss: 0.5550276720395391\n",
            "Epoch: 210. Loss: 0.5548130413835596\n",
            "Epoch: 220. Loss: 0.5546304677423691\n",
            "Epoch: 230. Loss: 0.554474759489266\n",
            "Epoch: 240. Loss: 0.5543416241320773\n",
            "Epoch: 250. Loss: 0.5542275057671868\n",
            "Epoch: 260. Loss: 0.5541294523177979\n",
            "Epoch: 270. Loss: 0.5540450072185602\n",
            "Epoch: 280. Loss: 0.5539721210926309\n",
            "Epoch: 290. Loss: 0.5539090797344045\n",
            "Epoch: 300. Loss: 0.5538544453651064\n",
            "Epoch: 310. Loss: 0.5538070086784062\n",
            "Epoch: 320. Loss: 0.5537657496509811\n",
            "Epoch: 330. Loss: 0.5537298054709849\n",
            "Epoch: 340. Loss: 0.5536984442476043\n",
            "Epoch: 350. Loss: 0.5536710434182764\n",
            "Epoch: 360. Loss: 0.5536470719763255\n",
            "Epoch: 370. Loss: 0.5536260758090719\n",
            "Epoch: 380. Loss: 0.5536076655719183\n",
            "Epoch: 390. Loss: 0.5535915066334093\n",
            "Epoch: 400. Loss: 0.5535773107146762\n",
            "Epoch: 410. Loss: 0.5535648289180267\n",
            "Epoch: 420. Loss: 0.5535538458969927\n",
            "Epoch: 430. Loss: 0.5535441749665854\n",
            "Epoch: 440. Loss: 0.5535356539899766\n",
            "Epoch: 450. Loss: 0.553528141908082\n",
            "Epoch: 460. Loss: 0.5535215158029755\n",
            "Epoch: 470. Loss: 0.5535156684058442\n",
            "Epoch: 480. Loss: 0.5535105059762182\n",
            "Epoch: 490. Loss: 0.5535059464922081\n",
            "tensor(0.8324, dtype=torch.float64)\n",
            "2021-05-09 00:00:00\n",
            "Epoch: 0. Loss: 1.5135610785426945\n",
            "Epoch: 10. Loss: 0.7264588334253413\n",
            "Epoch: 20. Loss: 0.625110712201829\n",
            "Epoch: 30. Loss: 0.5907184088174409\n",
            "Epoch: 40. Loss: 0.5741020048175884\n",
            "Epoch: 50. Loss: 0.5649882895354338\n",
            "Epoch: 60. Loss: 0.5594272201980857\n",
            "Epoch: 70. Loss: 0.5557996445075877\n",
            "Epoch: 80. Loss: 0.5533602226459708\n",
            "Epoch: 90. Loss: 0.5517012447738865\n",
            "Epoch: 100. Loss: 0.5505686500117941\n",
            "Epoch: 110. Loss: 0.5497936794495615\n",
            "Epoch: 120. Loss: 0.54926176599505\n",
            "Epoch: 130. Loss: 0.54889486283476\n",
            "Epoch: 140. Loss: 0.548639936023807\n",
            "Epoch: 150. Loss: 0.5484610728837158\n",
            "Epoch: 160. Loss: 0.5483340191905345\n",
            "Epoch: 170. Loss: 0.5482424168493548\n",
            "Epoch: 180. Loss: 0.5481752333144899\n",
            "Epoch: 190. Loss: 0.5481250177333749\n",
            "Epoch: 200. Loss: 0.5480867243491996\n",
            "Epoch: 210. Loss: 0.5480569216776784\n",
            "Epoch: 220. Loss: 0.5480332623125721\n",
            "Epoch: 230. Loss: 0.548014127992222\n",
            "Epoch: 240. Loss: 0.5479983921440004\n",
            "Epoch: 250. Loss: 0.5479852610074168\n",
            "Epoch: 260. Loss: 0.5479741672479334\n",
            "Epoch: 270. Loss: 0.5479646986109173\n",
            "Epoch: 280. Loss: 0.5479565499632701\n",
            "Epoch: 290. Loss: 0.5479494909507233\n",
            "Epoch: 300. Loss: 0.5479433440903978\n",
            "Epoch: 310. Loss: 0.5479379698465477\n",
            "Epoch: 320. Loss: 0.5479332563889178\n",
            "Epoch: 330. Loss: 0.5479291124998567\n",
            "Epoch: 340. Loss: 0.5479254626066912\n",
            "Epoch: 350. Loss: 0.5479222432555577\n",
            "Epoch: 360. Loss: 0.5479194005690317\n",
            "Epoch: 370. Loss: 0.5479168883805223\n",
            "Epoch: 380. Loss: 0.5479146668387886\n",
            "Epoch: 390. Loss: 0.5479127013429287\n",
            "Epoch: 400. Loss: 0.5479109617129581\n",
            "Epoch: 410. Loss: 0.5479094215310794\n",
            "Epoch: 420. Loss: 0.5479080576088667\n",
            "Epoch: 430. Loss: 0.5479068495491626\n",
            "Epoch: 440. Loss: 0.5479057793806577\n",
            "Epoch: 450. Loss: 0.5479048312493815\n",
            "Epoch: 460. Loss: 0.5479039911556162\n",
            "Epoch: 470. Loss: 0.5479032467277102\n",
            "Epoch: 480. Loss: 0.5479025870263491\n",
            "Epoch: 490. Loss: 0.5479020023743061\n",
            "tensor(0.7721, dtype=torch.float64)\n",
            "2021-05-16 00:00:00\n",
            "Epoch: 0. Loss: 4.341043582508285\n",
            "Epoch: 10. Loss: 1.5563195412411803\n",
            "Epoch: 20. Loss: 0.773072817083215\n",
            "Epoch: 30. Loss: 0.6439165499573345\n",
            "Epoch: 40. Loss: 0.5989517410284034\n",
            "Epoch: 50. Loss: 0.5816096661782612\n",
            "Epoch: 60. Loss: 0.574284617700221\n",
            "Epoch: 70. Loss: 0.5704655486387894\n",
            "Epoch: 80. Loss: 0.5680139180552201\n",
            "Epoch: 90. Loss: 0.5662376151705352\n",
            "Epoch: 100. Loss: 0.5648820513811967\n",
            "Epoch: 110. Loss: 0.5638275812976687\n",
            "Epoch: 120. Loss: 0.5630019158117424\n",
            "Epoch: 130. Loss: 0.5623539654473639\n",
            "Epoch: 140. Loss: 0.5618450400273267\n",
            "Epoch: 150. Loss: 0.5614450989526241\n",
            "Epoch: 160. Loss: 0.561130633981332\n",
            "Epoch: 170. Loss: 0.56088321271648\n",
            "Epoch: 180. Loss: 0.5606883808195285\n",
            "Epoch: 190. Loss: 0.5605348072663235\n",
            "Epoch: 200. Loss: 0.560413612598344\n",
            "Epoch: 210. Loss: 0.5603178401815205\n",
            "Epoch: 220. Loss: 0.5602420403510986\n",
            "Epoch: 230. Loss: 0.5601819437591277\n",
            "Epoch: 240. Loss: 0.5601342051046412\n",
            "Epoch: 250. Loss: 0.5600962022885708\n",
            "Epoch: 260. Loss: 0.5600658791353813\n",
            "Epoch: 270. Loss: 0.560041622308328\n",
            "Epoch: 280. Loss: 0.5600221650286938\n",
            "Epoch: 290. Loss: 0.560006511785706\n",
            "Epoch: 300. Loss: 0.5599938794719531\n",
            "Epoch: 310. Loss: 0.5599836513643316\n",
            "Epoch: 320. Loss: 0.5599753411463272\n",
            "Epoch: 330. Loss: 0.5599685647770735\n",
            "Epoch: 340. Loss: 0.5599630184909691\n",
            "Epoch: 350. Loss: 0.5599584615864572\n",
            "Epoch: 360. Loss: 0.5599547029559859\n",
            "Epoch: 370. Loss: 0.5599515905386616\n",
            "Epoch: 380. Loss: 0.5599490030564933\n",
            "Epoch: 390. Loss: 0.5599468435352609\n",
            "Epoch: 400. Loss: 0.5599450342204744\n",
            "Epoch: 410. Loss: 0.5599435125843243\n",
            "Epoch: 420. Loss: 0.5599422281861978\n",
            "Epoch: 430. Loss: 0.5599411402013663\n",
            "Epoch: 440. Loss: 0.5599402154730515\n",
            "Epoch: 450. Loss: 0.5599394269747484\n",
            "Epoch: 460. Loss: 0.5599387525944087\n",
            "Epoch: 470. Loss: 0.5599381741713687\n",
            "Epoch: 480. Loss: 0.5599376767319625\n",
            "Epoch: 490. Loss: 0.5599372478815118\n",
            "tensor(0.7881, dtype=torch.float64)\n",
            "2021-05-23 00:00:00\n",
            "Epoch: 0. Loss: 1.9053170095053833\n",
            "Epoch: 10. Loss: 0.919418290984469\n",
            "Epoch: 20. Loss: 0.7810301355962225\n",
            "Epoch: 30. Loss: 0.7391971863908986\n",
            "Epoch: 40. Loss: 0.7106240745314122\n",
            "Epoch: 50. Loss: 0.6870521458196093\n",
            "Epoch: 60. Loss: 0.6670492312292735\n",
            "Epoch: 70. Loss: 0.6501093914804733\n",
            "Epoch: 80. Loss: 0.6358688358708757\n",
            "Epoch: 90. Loss: 0.6239822441563828\n",
            "Epoch: 100. Loss: 0.6141139034905615\n",
            "Epoch: 110. Loss: 0.605948375846651\n",
            "Epoch: 120. Loss: 0.5992006159331833\n",
            "Epoch: 130. Loss: 0.5936215589704803\n",
            "Epoch: 140. Loss: 0.5889993420866472\n",
            "Epoch: 150. Loss: 0.585157412873498\n",
            "Epoch: 160. Loss: 0.5819508536720427\n",
            "Epoch: 170. Loss: 0.5792619680341928\n",
            "Epoch: 180. Loss: 0.5769958229089793\n",
            "Epoch: 190. Loss: 0.5750761391510835\n",
            "Epoch: 200. Loss: 0.5734417088794976\n",
            "Epoch: 210. Loss: 0.57204338446585\n",
            "Epoch: 220. Loss: 0.5708416101760122\n",
            "Epoch: 230. Loss: 0.5698044331664489\n",
            "Epoch: 240. Loss: 0.5689059196697193\n",
            "Epoch: 250. Loss: 0.5681249039460502\n",
            "Epoch: 260. Loss: 0.5674440052167343\n",
            "Epoch: 270. Loss: 0.5668488574861315\n",
            "Epoch: 280. Loss: 0.5663275068772202\n",
            "Epoch: 290. Loss: 0.5658699399032633\n",
            "Epoch: 300. Loss: 0.5654677136273847\n",
            "Epoch: 310. Loss: 0.5651136648862531\n",
            "Epoch: 320. Loss: 0.5648016807831154\n",
            "Epoch: 330. Loss: 0.5645265166543423\n",
            "Epoch: 340. Loss: 0.5642836508568841\n",
            "Epoch: 350. Loss: 0.5640691681735257\n",
            "Epoch: 360. Loss: 0.5638796655292316\n",
            "Epoch: 370. Loss: 0.5637121751727567\n",
            "Epoch: 380. Loss: 0.5635641015988384\n",
            "Epoch: 390. Loss: 0.5634331693443239\n",
            "Epoch: 400. Loss: 0.5633173794470638\n",
            "Epoch: 410. Loss: 0.5632149728566196\n",
            "Epoch: 420. Loss: 0.5631243994675208\n",
            "Epoch: 430. Loss: 0.5630442917371972\n",
            "Epoch: 440. Loss: 0.5629734420735102\n",
            "Epoch: 450. Loss: 0.5629107833475074\n",
            "Epoch: 460. Loss: 0.5628553720182411\n",
            "Epoch: 470. Loss: 0.5628063734577199\n",
            "Epoch: 480. Loss: 0.5627630491425462\n",
            "Epoch: 490. Loss: 0.562724745439977\n",
            "tensor(0.7079, dtype=torch.float64)\n",
            "2021-05-30 00:00:00\n",
            "Epoch: 0. Loss: 0.8318289477341881\n",
            "Epoch: 10. Loss: 0.718332255779239\n",
            "Epoch: 20. Loss: 0.6514538846909538\n",
            "Epoch: 30. Loss: 0.6161633922526125\n",
            "Epoch: 40. Loss: 0.5973887300712584\n",
            "Epoch: 50. Loss: 0.5860648845827139\n",
            "Epoch: 60. Loss: 0.5783216736753878\n",
            "Epoch: 70. Loss: 0.5726135260770615\n",
            "Epoch: 80. Loss: 0.5682379148806674\n",
            "Epoch: 90. Loss: 0.5648083993969578\n",
            "Epoch: 100. Loss: 0.5620782784859634\n",
            "Epoch: 110. Loss: 0.5598764079178603\n",
            "Epoch: 120. Loss: 0.5580792990057993\n",
            "Epoch: 130. Loss: 0.5565961599226626\n",
            "Epoch: 140. Loss: 0.5553594868091233\n",
            "Epoch: 150. Loss: 0.5543186221766615\n",
            "Epoch: 160. Loss: 0.5534351880440299\n",
            "Epoch: 170. Loss: 0.5526798084329818\n",
            "Epoch: 180. Loss: 0.5520297472946478\n",
            "Epoch: 190. Loss: 0.5514672020148296\n",
            "Epoch: 200. Loss: 0.5509780668462635\n",
            "Epoch: 210. Loss: 0.5505510330269834\n",
            "Epoch: 220. Loss: 0.5501769301947341\n",
            "Epoch: 230. Loss: 0.5498482410304529\n",
            "Epoch: 240. Loss: 0.5495587406638368\n",
            "Epoch: 250. Loss: 0.5493032263466415\n",
            "Epoch: 260. Loss: 0.5490773128154676\n",
            "Epoch: 270. Loss: 0.5488772757854085\n",
            "Epoch: 280. Loss: 0.5486999309817515\n",
            "Epoch: 290. Loss: 0.5485425396331234\n",
            "Epoch: 300. Loss: 0.5484027338449771\n",
            "Epoch: 310. Loss: 0.5482784570495977\n",
            "Epoch: 320. Loss: 0.5481679160002905\n",
            "Epoch: 330. Loss: 0.5480695416918883\n",
            "Epoch: 340. Loss: 0.5479819572514327\n",
            "Epoch: 350. Loss: 0.5479039513248645\n",
            "Epoch: 360. Loss: 0.5478344558390945\n",
            "Epoch: 370. Loss: 0.5477725272800876\n",
            "Epoch: 380. Loss: 0.5477173308221037\n",
            "Epoch: 390. Loss: 0.5476681267891974\n",
            "Epoch: 400. Loss: 0.5476242590404432\n",
            "Epoch: 410. Loss: 0.5475851449544674\n",
            "Epoch: 420. Loss: 0.5475502667534686\n",
            "Epoch: 430. Loss: 0.5475191639569116\n",
            "Epoch: 440. Loss: 0.5474914267940815\n",
            "Epoch: 450. Loss: 0.547466690435345\n",
            "Epoch: 460. Loss: 0.5474446299262357\n",
            "Epoch: 470. Loss: 0.5474249557278683\n",
            "Epoch: 480. Loss: 0.5474074097827518\n",
            "Epoch: 490. Loss: 0.5473917620377008\n",
            "tensor(0.6973, dtype=torch.float64)\n",
            "2021-06-06 00:00:00\n",
            "Epoch: 0. Loss: 1.9846496883939828\n",
            "Epoch: 10. Loss: 0.8593253142329665\n",
            "Epoch: 20. Loss: 0.6764172379176813\n",
            "Epoch: 30. Loss: 0.6174696648372267\n",
            "Epoch: 40. Loss: 0.5922510049831258\n",
            "Epoch: 50. Loss: 0.580155818821222\n",
            "Epoch: 60. Loss: 0.5732737412469858\n",
            "Epoch: 70. Loss: 0.5686050751371459\n",
            "Epoch: 80. Loss: 0.5650803465135367\n",
            "Epoch: 90. Loss: 0.562284395602198\n",
            "Epoch: 100. Loss: 0.5600167648452691\n",
            "Epoch: 110. Loss: 0.5581556434334313\n",
            "Epoch: 120. Loss: 0.5566153914776455\n",
            "Epoch: 130. Loss: 0.5553315707392218\n",
            "Epoch: 140. Loss: 0.5542543152406902\n",
            "Epoch: 150. Loss: 0.553344557168097\n",
            "Epoch: 160. Loss: 0.5525714773831266\n",
            "Epoch: 170. Loss: 0.5519106358276924\n",
            "Epoch: 180. Loss: 0.5513425549318796\n",
            "Epoch: 190. Loss: 0.550851632867923\n",
            "Epoch: 200. Loss: 0.5504253054908315\n",
            "Epoch: 210. Loss: 0.5500533981301489\n",
            "Epoch: 220. Loss: 0.5497276229862007\n",
            "Epoch: 230. Loss: 0.5494411884437409\n",
            "Epoch: 240. Loss: 0.5491884945563007\n",
            "Epoch: 250. Loss: 0.5489648949953697\n",
            "Epoch: 260. Loss: 0.5487665103668032\n",
            "Epoch: 270. Loss: 0.5485900813136495\n",
            "Epoch: 280. Loss: 0.5484328525088901\n",
            "Epoch: 290. Loss: 0.5482924806916185\n",
            "Epoch: 300. Loss: 0.5481669614674481\n",
            "Epoch: 310. Loss: 0.54805457079383\n",
            "Epoch: 320. Loss: 0.5479538179911921\n",
            "Epoch: 330. Loss: 0.5478634078279053\n",
            "Epoch: 340. Loss: 0.5477822097715339\n",
            "Epoch: 350. Loss: 0.5477092329189155\n",
            "Epoch: 360. Loss: 0.5476436054424473\n",
            "Epoch: 370. Loss: 0.5475845576416483\n",
            "Epoch: 380. Loss: 0.5475314078845043\n",
            "Epoch: 390. Loss: 0.5474835508751589\n",
            "Epoch: 400. Loss: 0.5474404478030527\n",
            "Epoch: 410. Loss: 0.5474016180212185\n",
            "Epoch: 420. Loss: 0.5473666319739058\n",
            "Epoch: 430. Loss: 0.547335105150539\n",
            "Epoch: 440. Loss: 0.5473066928876759\n",
            "Epoch: 450. Loss: 0.5472810858757906\n",
            "Epoch: 460. Loss: 0.5472580062554504\n",
            "Epoch: 470. Loss: 0.5472372042094089\n",
            "Epoch: 480. Loss: 0.5472184549745392\n",
            "Epoch: 490. Loss: 0.5472015562113663\n",
            "tensor(0.8241, dtype=torch.float64)\n",
            "2021-06-13 00:00:00\n",
            "Epoch: 0. Loss: 1.6293321912963605\n",
            "Epoch: 10. Loss: 1.2401878612064143\n",
            "Epoch: 20. Loss: 1.0363592470998895\n",
            "Epoch: 30. Loss: 0.8952092587898786\n",
            "Epoch: 40. Loss: 0.7878265800370257\n",
            "Epoch: 50. Loss: 0.7085938779371326\n",
            "Epoch: 60. Loss: 0.6545139427886952\n",
            "Epoch: 70. Loss: 0.619503893192461\n",
            "Epoch: 80. Loss: 0.5966615833872696\n",
            "Epoch: 90. Loss: 0.5811109263697798\n",
            "Epoch: 100. Loss: 0.570124993865417\n",
            "Epoch: 110. Loss: 0.5622126574664198\n",
            "Epoch: 120. Loss: 0.5564747216422108\n",
            "Epoch: 130. Loss: 0.5523078655012124\n",
            "Epoch: 140. Loss: 0.5492816380146646\n",
            "Epoch: 150. Loss: 0.5470822443655586\n",
            "Epoch: 160. Loss: 0.5454806006195084\n",
            "Epoch: 170. Loss: 0.5443103620410342\n",
            "Epoch: 180. Loss: 0.5434514668202647\n",
            "Epoch: 190. Loss: 0.5428176388143737\n",
            "Epoch: 200. Loss: 0.5423470166580859\n",
            "Epoch: 210. Loss: 0.5419952500184981\n",
            "Epoch: 220. Loss: 0.5417304903944351\n",
            "Epoch: 230. Loss: 0.541529796897198\n",
            "Epoch: 240. Loss: 0.5413765759912529\n",
            "Epoch: 250. Loss: 0.5412587651221163\n",
            "Epoch: 260. Loss: 0.5411675460551923\n",
            "Epoch: 270. Loss: 0.5410964330607244\n",
            "Epoch: 280. Loss: 0.5410406255009157\n",
            "Epoch: 290. Loss: 0.5409965467362604\n",
            "Epoch: 300. Loss: 0.5409615144242214\n",
            "Epoch: 310. Loss: 0.5409335036645835\n",
            "Epoch: 320. Loss: 0.5409109759537574\n",
            "Epoch: 330. Loss: 0.5408927549635633\n",
            "Epoch: 340. Loss: 0.5408779357864698\n",
            "Epoch: 350. Loss: 0.5408658182200867\n",
            "Epoch: 360. Loss: 0.540855857413226\n",
            "Epoch: 370. Loss: 0.5408476271231483\n",
            "Epoch: 380. Loss: 0.5408407921885203\n",
            "Epoch: 390. Loss: 0.5408350877784469\n",
            "Epoch: 400. Loss: 0.5408303036550076\n",
            "Epoch: 410. Loss: 0.5408262721684828\n",
            "Epoch: 420. Loss: 0.5408228590489378\n",
            "Epoch: 430. Loss: 0.5408199563054499\n",
            "Epoch: 440. Loss: 0.5408174767232576\n",
            "Epoch: 450. Loss: 0.5408153495792415\n",
            "Epoch: 460. Loss: 0.5408135172913214\n",
            "Epoch: 470. Loss: 0.5408119327874064\n",
            "Epoch: 480. Loss: 0.5408105574313758\n",
            "Epoch: 490. Loss: 0.5408093593822159\n",
            "tensor(0.6091, dtype=torch.float64)\n",
            "2021-06-20 00:00:00\n",
            "Epoch: 0. Loss: 2.5550514964694604\n",
            "Epoch: 10. Loss: 0.98128027028414\n",
            "Epoch: 20. Loss: 0.7147089599540626\n",
            "Epoch: 30. Loss: 0.6562465070062179\n",
            "Epoch: 40. Loss: 0.6267407132431405\n",
            "Epoch: 50. Loss: 0.6068433417568402\n",
            "Epoch: 60. Loss: 0.5923787379857954\n",
            "Epoch: 70. Loss: 0.5817567928194854\n",
            "Epoch: 80. Loss: 0.5740422129442917\n",
            "Epoch: 90. Loss: 0.5685223275652233\n",
            "Epoch: 100. Loss: 0.5646233943940241\n",
            "Epoch: 110. Loss: 0.5618945516085019\n",
            "Epoch: 120. Loss: 0.5599945841374113\n",
            "Epoch: 130. Loss: 0.5586736416181988\n",
            "Epoch: 140. Loss: 0.5577533432375776\n",
            "Epoch: 150. Loss: 0.5571086410536633\n",
            "Epoch: 160. Loss: 0.5566529821386277\n",
            "Epoch: 170. Loss: 0.5563269661761638\n",
            "Epoch: 180. Loss: 0.5560900464525469\n",
            "Epoch: 190. Loss: 0.5559146295157283\n",
            "Epoch: 200. Loss: 0.5557819591769908\n",
            "Epoch: 210. Loss: 0.5556792812652115\n",
            "Epoch: 220. Loss: 0.5555979069137171\n",
            "Epoch: 230. Loss: 0.555531896925095\n",
            "Epoch: 240. Loss: 0.555477171256133\n",
            "Epoch: 250. Loss: 0.5554309076171324\n",
            "Epoch: 260. Loss: 0.5553911358525971\n",
            "Epoch: 270. Loss: 0.5553564645288123\n",
            "Epoch: 280. Loss: 0.5553258966366331\n",
            "Epoch: 290. Loss: 0.5552987052965838\n",
            "Epoch: 300. Loss: 0.555274349839939\n",
            "Epoch: 310. Loss: 0.555252419053517\n",
            "Epoch: 320. Loss: 0.5552325927017813\n",
            "Epoch: 330. Loss: 0.5552146153525529\n",
            "Epoch: 340. Loss: 0.5551982784916615\n",
            "Epoch: 350. Loss: 0.5551834082285236\n",
            "Epoch: 360. Loss: 0.5551698567791776\n",
            "Epoch: 370. Loss: 0.5551574965073897\n",
            "Epoch: 380. Loss: 0.5551462157034345\n",
            "Epoch: 390. Loss: 0.5551359155481134\n",
            "Epoch: 400. Loss: 0.5551265078895772\n",
            "Epoch: 410. Loss: 0.5551179135814697\n",
            "Epoch: 420. Loss: 0.5551100612122212\n",
            "Epoch: 430. Loss: 0.5551028861100183\n",
            "Epoch: 440. Loss: 0.5550963295447959\n",
            "Epoch: 450. Loss: 0.5550903380734247\n",
            "Epoch: 460. Loss: 0.5550848629910199\n",
            "Epoch: 470. Loss: 0.5550798598626261\n",
            "Epoch: 480. Loss: 0.555075288117226\n",
            "Epoch: 490. Loss: 0.5550711106912363\n",
            "tensor(0.9144, dtype=torch.float64)\n",
            "2021-06-27 00:00:00\n",
            "Epoch: 0. Loss: 3.957748842770316\n",
            "Epoch: 10. Loss: 2.2267046456459183\n",
            "Epoch: 20. Loss: 1.372573561692149\n",
            "Epoch: 30. Loss: 0.9929323422234216\n",
            "Epoch: 40. Loss: 0.7944677398524985\n",
            "Epoch: 50. Loss: 0.6888618258007901\n",
            "Epoch: 60. Loss: 0.6373257886453378\n",
            "Epoch: 70. Loss: 0.6113014245551345\n",
            "Epoch: 80. Loss: 0.5952725349351441\n",
            "Epoch: 90. Loss: 0.5837380392310084\n",
            "Epoch: 100. Loss: 0.5749507931324948\n",
            "Epoch: 110. Loss: 0.5681806787456539\n",
            "Epoch: 120. Loss: 0.5629741778364787\n",
            "Epoch: 130. Loss: 0.5589862475444177\n",
            "Epoch: 140. Loss: 0.5559414349754286\n",
            "Epoch: 150. Loss: 0.5536205778390001\n",
            "Epoch: 160. Loss: 0.5518517749124335\n",
            "Epoch: 170. Loss: 0.5505020802142777\n",
            "Epoch: 180. Loss: 0.5494698224416837\n",
            "Epoch: 190. Loss: 0.5486778673176916\n",
            "Epoch: 200. Loss: 0.5480679921027344\n",
            "Epoch: 210. Loss: 0.5475963640000587\n",
            "Epoch: 220. Loss: 0.5472300053419229\n",
            "Epoch: 230. Loss: 0.5469440839653074\n",
            "Epoch: 240. Loss: 0.5467198638548331\n",
            "Epoch: 250. Loss: 0.5465431686173577\n",
            "Epoch: 260. Loss: 0.5464032353807449\n",
            "Epoch: 270. Loss: 0.5462918620209811\n",
            "Epoch: 280. Loss: 0.5462027729338251\n",
            "Epoch: 290. Loss: 0.5461311468510898\n",
            "Epoch: 300. Loss: 0.5460732645443771\n",
            "Epoch: 310. Loss: 0.5460262452035385\n",
            "Epoch: 320. Loss: 0.5459878484808659\n",
            "Epoch: 330. Loss: 0.5459563252715746\n",
            "Epoch: 340. Loss: 0.5459303047750503\n",
            "Epoch: 350. Loss: 0.545908708660953\n",
            "Epoch: 360. Loss: 0.5458906855645973\n",
            "Epoch: 370. Loss: 0.5458755608930419\n",
            "Epoch: 380. Loss: 0.5458627982112316\n",
            "Epoch: 390. Loss: 0.5458519694238475\n",
            "Epoch: 400. Loss: 0.5458427316659952\n",
            "Epoch: 410. Loss: 0.5458348093318142\n",
            "Epoch: 420. Loss: 0.5458279800532994\n",
            "Epoch: 430. Loss: 0.5458220637274676\n",
            "Epoch: 440. Loss: 0.5458169139041662\n",
            "Epoch: 450. Loss: 0.5458124110079917\n",
            "Epoch: 460. Loss: 0.5458084569896247\n",
            "Epoch: 470. Loss: 0.5458049710944002\n",
            "Epoch: 480. Loss: 0.5458018865064621\n",
            "Epoch: 490. Loss: 0.5457991476808508\n",
            "tensor(0.6476, dtype=torch.float64)\n",
            "2021-07-04 00:00:00\n",
            "Epoch: 0. Loss: 0.785790041846202\n",
            "Epoch: 10. Loss: 0.5843982777599986\n",
            "Epoch: 20. Loss: 0.5705976839768214\n",
            "Epoch: 30. Loss: 0.5646608372396276\n",
            "Epoch: 40. Loss: 0.5608691013200692\n",
            "Epoch: 50. Loss: 0.5580619014241063\n",
            "Epoch: 60. Loss: 0.5558289442018863\n",
            "Epoch: 70. Loss: 0.5539960423168284\n",
            "Epoch: 80. Loss: 0.5524722968493153\n",
            "Epoch: 90. Loss: 0.5511994212865036\n",
            "Epoch: 100. Loss: 0.5501343000364167\n",
            "Epoch: 110. Loss: 0.5492425528172177\n",
            "Epoch: 120. Loss: 0.5484958388813723\n",
            "Epoch: 130. Loss: 0.5478704905360543\n",
            "Epoch: 140. Loss: 0.5473466588037549\n",
            "Epoch: 150. Loss: 0.5469076865469306\n",
            "Epoch: 160. Loss: 0.5465396055290178\n",
            "Epoch: 170. Loss: 0.5462307164717705\n",
            "Epoch: 180. Loss: 0.5459712331704403\n",
            "Epoch: 190. Loss: 0.5457529797237447\n",
            "Epoch: 200. Loss: 0.5455691330866341\n",
            "Epoch: 210. Loss: 0.5454140046301271\n",
            "Epoch: 220. Loss: 0.5452828552846565\n",
            "Epoch: 230. Loss: 0.5451717395201887\n",
            "Epoch: 240. Loss: 0.5450773739979858\n",
            "Epoch: 250. Loss: 0.5449970272516844\n",
            "Epoch: 260. Loss: 0.5449284272291982\n",
            "Epoch: 270. Loss: 0.5448696839542758\n",
            "Epoch: 280. Loss: 0.544819224948594\n",
            "Epoch: 290. Loss: 0.5447757413937738\n",
            "Epoch: 300. Loss: 0.5447381433101426\n",
            "Epoch: 310. Loss: 0.5447055222884655\n",
            "Epoch: 320. Loss: 0.5446771205355943\n",
            "Epoch: 330. Loss: 0.544652305188557\n",
            "Epoch: 340. Loss: 0.544630547017458\n",
            "Epoch: 350. Loss: 0.5446114027790204\n",
            "Epoch: 360. Loss: 0.5445945006027556\n",
            "Epoch: 370. Loss: 0.5445795278934304\n",
            "Epoch: 380. Loss: 0.5445662213192665\n",
            "Epoch: 390. Loss: 0.5445543585274414\n",
            "Epoch: 400. Loss: 0.5445437512889657\n",
            "Epoch: 410. Loss: 0.5445342398256314\n",
            "Epoch: 420. Loss: 0.5445256881140065\n",
            "Epoch: 430. Loss: 0.5445179799966753\n",
            "Epoch: 440. Loss: 0.5445110159602408\n",
            "Epoch: 450. Loss: 0.5445047104639432\n",
            "Epoch: 460. Loss: 0.5444989897229545\n",
            "Epoch: 470. Loss: 0.5444937898671323\n",
            "Epoch: 480. Loss: 0.5444890554098707\n",
            "Epoch: 490. Loss: 0.5444847379731302\n",
            "tensor(0.8047, dtype=torch.float64)\n",
            "2021-07-11 00:00:00\n",
            "Epoch: 0. Loss: 2.0920530544124736\n",
            "Epoch: 10. Loss: 1.401978728607331\n",
            "Epoch: 20. Loss: 1.1253132470435934\n",
            "Epoch: 30. Loss: 0.9568655015651326\n",
            "Epoch: 40. Loss: 0.8198748160375705\n",
            "Epoch: 50. Loss: 0.714446905736546\n",
            "Epoch: 60. Loss: 0.6443141366730412\n",
            "Epoch: 70. Loss: 0.607703685937704\n",
            "Epoch: 80. Loss: 0.5920523815676203\n",
            "Epoch: 90. Loss: 0.5850383803887457\n",
            "Epoch: 100. Loss: 0.5809595406609206\n",
            "Epoch: 110. Loss: 0.5779502432121838\n",
            "Epoch: 120. Loss: 0.5754380044676162\n",
            "Epoch: 130. Loss: 0.5732267897987435\n",
            "Epoch: 140. Loss: 0.5712333344489946\n",
            "Epoch: 150. Loss: 0.5694126611100375\n",
            "Epoch: 160. Loss: 0.5677356684987002\n",
            "Epoch: 170. Loss: 0.5661815056573651\n",
            "Epoch: 180. Loss: 0.5647344399958345\n",
            "Epoch: 190. Loss: 0.563382254677888\n",
            "Epoch: 200. Loss: 0.5621152671350461\n",
            "Epoch: 210. Loss: 0.5609256610606074\n",
            "Epoch: 220. Loss: 0.5598070089948964\n",
            "Epoch: 230. Loss: 0.558753924577007\n",
            "Epoch: 240. Loss: 0.5577618077281091\n",
            "Epoch: 250. Loss: 0.5568266577419352\n",
            "Epoch: 260. Loss: 0.5559449362405082\n",
            "Epoch: 270. Loss: 0.555113466717256\n",
            "Epoch: 280. Loss: 0.5543293608509408\n",
            "Epoch: 290. Loss: 0.5535899643446278\n",
            "Epoch: 300. Loss: 0.55289281696132\n",
            "Epoch: 310. Loss: 0.5522356228543691\n",
            "Epoch: 320. Loss: 0.551616228347188\n",
            "Epoch: 330. Loss: 0.5510326050952329\n",
            "Epoch: 340. Loss: 0.5504828371341381\n",
            "Epoch: 350. Loss: 0.549965110734746\n",
            "Epoch: 360. Loss: 0.5494777062889036\n",
            "Epoch: 370. Loss: 0.5490189916695013\n",
            "Epoch: 380. Loss: 0.5485874166667147\n",
            "Epoch: 390. Loss: 0.5481815082164128\n",
            "Epoch: 400. Loss: 0.5477998662183797\n",
            "Epoch: 410. Loss: 0.5474411598003514\n",
            "Epoch: 420. Loss: 0.5471041239253712\n",
            "Epoch: 430. Loss: 0.5467875562694144\n",
            "Epoch: 440. Loss: 0.5464903143170192\n",
            "Epoch: 450. Loss: 0.546211312637307\n",
            "Epoch: 460. Loss: 0.5459495203130474\n",
            "Epoch: 470. Loss: 0.5457039585026163\n",
            "Epoch: 480. Loss: 0.5454736981197322\n",
            "Epoch: 490. Loss: 0.5452578576193686\n",
            "tensor(0.7663, dtype=torch.float64)\n",
            "2021-07-18 00:00:00\n",
            "Epoch: 0. Loss: 2.3489722364996473\n",
            "Epoch: 10. Loss: 1.3419161841998677\n",
            "Epoch: 20. Loss: 0.9143239794116913\n",
            "Epoch: 30. Loss: 0.7370605530149975\n",
            "Epoch: 40. Loss: 0.6495029371466803\n",
            "Epoch: 50. Loss: 0.6095664688748691\n",
            "Epoch: 60. Loss: 0.5922187314838365\n",
            "Epoch: 70. Loss: 0.5832199658316403\n",
            "Epoch: 80. Loss: 0.5771017576580768\n",
            "Epoch: 90. Loss: 0.5722225887543357\n",
            "Epoch: 100. Loss: 0.568104171282718\n",
            "Epoch: 110. Loss: 0.564577734523306\n",
            "Epoch: 120. Loss: 0.561555453445043\n",
            "Epoch: 130. Loss: 0.5589726696417475\n",
            "Epoch: 140. Loss: 0.5567737214536536\n",
            "Epoch: 150. Loss: 0.5549086136145237\n",
            "Epoch: 160. Loss: 0.5533322733469705\n",
            "Epoch: 170. Loss: 0.552004339605454\n",
            "Epoch: 180. Loss: 0.5508889919337814\n",
            "Epoch: 190. Loss: 0.5499547186463187\n",
            "Epoch: 200. Loss: 0.5491740222523235\n",
            "Epoch: 210. Loss: 0.5485230820816868\n",
            "Epoch: 220. Loss: 0.547981395861172\n",
            "Epoch: 230. Loss: 0.5475314184532011\n",
            "Epoch: 240. Loss: 0.5471582113903516\n",
            "Epoch: 250. Loss: 0.5468491125511614\n",
            "Epoch: 260. Loss: 0.5465934317374863\n",
            "Epoch: 270. Loss: 0.5463821751085312\n",
            "Epoch: 280. Loss: 0.546207799346697\n",
            "Epoch: 290. Loss: 0.5460639949689204\n",
            "Epoch: 300. Loss: 0.545945497234396\n",
            "Epoch: 310. Loss: 0.5458479225213894\n",
            "Epoch: 320. Loss: 0.5457676277524794\n",
            "Epoch: 330. Loss: 0.5457015903567083\n",
            "Epoch: 340. Loss: 0.5456473063035514\n",
            "Epoch: 350. Loss: 0.5456027038776419\n",
            "Epoch: 360. Loss: 0.5455660710480431\n",
            "Epoch: 370. Loss: 0.5455359944953694\n",
            "Epoch: 380. Loss: 0.5455113085761346\n",
            "Epoch: 390. Loss: 0.5454910527145361\n",
            "Epoch: 400. Loss: 0.5454744359101052\n",
            "Epoch: 410. Loss: 0.5454608072312465\n",
            "Epoch: 420. Loss: 0.5454496313277881\n",
            "Epoch: 430. Loss: 0.545440468140001\n",
            "Epoch: 440. Loss: 0.5454329561077353\n",
            "Epoch: 450. Loss: 0.5454267982926181\n",
            "Epoch: 460. Loss: 0.545421750920153\n",
            "Epoch: 470. Loss: 0.5454176139287373\n",
            "Epoch: 480. Loss: 0.5454142231806486\n",
            "Epoch: 490. Loss: 0.5454114440475833\n",
            "tensor(0.7400, dtype=torch.float64)\n",
            "2021-07-25 00:00:00\n",
            "Epoch: 0. Loss: 0.8493272016100519\n",
            "Epoch: 10. Loss: 0.7449216510738724\n",
            "Epoch: 20. Loss: 0.6902150145779861\n",
            "Epoch: 30. Loss: 0.6623303210457488\n",
            "Epoch: 40. Loss: 0.6470987808046639\n",
            "Epoch: 50. Loss: 0.6374425984580954\n",
            "Epoch: 60. Loss: 0.6303064810479972\n",
            "Epoch: 70. Loss: 0.6244570808497765\n",
            "Epoch: 80. Loss: 0.6193870619448149\n",
            "Epoch: 90. Loss: 0.6148659640766834\n",
            "Epoch: 100. Loss: 0.610771246429534\n",
            "Epoch: 110. Loss: 0.6070262162070676\n",
            "Epoch: 120. Loss: 0.6035767202990383\n",
            "Epoch: 130. Loss: 0.6003817157273444\n",
            "Epoch: 140. Loss: 0.5974089042519434\n",
            "Epoch: 150. Loss: 0.59463233485722\n",
            "Epoch: 160. Loss: 0.592030870275979\n",
            "Epoch: 170. Loss: 0.5895871030464153\n",
            "Epoch: 180. Loss: 0.5872865476350735\n",
            "Epoch: 190. Loss: 0.5851170230527285\n",
            "Epoch: 200. Loss: 0.5830681756097108\n",
            "Epoch: 210. Loss: 0.5811311079520523\n",
            "Epoch: 220. Loss: 0.5792980897981725\n",
            "Epoch: 230. Loss: 0.5775623318605089\n",
            "Epoch: 240. Loss: 0.5759178087768758\n",
            "Epoch: 250. Loss: 0.5743591201237171\n",
            "Epoch: 260. Loss: 0.5728813810607899\n",
            "Epoch: 270. Loss: 0.5714801360618584\n",
            "Epoch: 280. Loss: 0.5701512906554242\n",
            "Epoch: 290. Loss: 0.5688910572346237\n",
            "Epoch: 300. Loss: 0.5676959118730023\n",
            "Epoch: 310. Loss: 0.5665625597618867\n",
            "Epoch: 320. Loss: 0.5654879074109154\n",
            "Epoch: 330. Loss: 0.5644690401611245\n",
            "Epoch: 340. Loss: 0.5635032038766017\n",
            "Epoch: 350. Loss: 0.562587789927042\n",
            "Epoch: 360. Loss: 0.5617203227654745\n",
            "Epoch: 370. Loss: 0.5608984495552403\n",
            "Epoch: 380. Loss: 0.5601199314175228\n",
            "Epoch: 390. Loss: 0.5593826359625562\n",
            "Epoch: 400. Loss: 0.5586845308397538\n",
            "Epoch: 410. Loss: 0.5580236780986688\n",
            "Epoch: 420. Loss: 0.5573982291973242\n",
            "Epoch: 430. Loss: 0.556806420529609\n",
            "Epoch: 440. Loss: 0.556246569371149\n",
            "Epoch: 450. Loss: 0.555717070164903\n",
            "Epoch: 460. Loss: 0.5552163910849548\n",
            "Epoch: 470. Loss: 0.5547430708305093\n",
            "Epoch: 480. Loss: 0.5542957156127548\n",
            "Epoch: 490. Loss: 0.5538729963055874\n",
            "tensor(0.8477, dtype=torch.float64)\n",
            "2021-08-01 00:00:00\n",
            "Epoch: 0. Loss: 1.517759372714767\n",
            "Epoch: 10. Loss: 0.8733259192881386\n",
            "Epoch: 20. Loss: 0.6857689270296845\n",
            "Epoch: 30. Loss: 0.6058488216243754\n",
            "Epoch: 40. Loss: 0.5758399744300131\n",
            "Epoch: 50. Loss: 0.5654839743334039\n",
            "Epoch: 60. Loss: 0.5610470951369658\n",
            "Epoch: 70. Loss: 0.5583698317408082\n",
            "Epoch: 80. Loss: 0.5563736719936261\n",
            "Epoch: 90. Loss: 0.5547543318432504\n",
            "Epoch: 100. Loss: 0.553398544108435\n",
            "Epoch: 110. Loss: 0.5522467206852827\n",
            "Epoch: 120. Loss: 0.5512588948742291\n",
            "Epoch: 130. Loss: 0.5504050465322385\n",
            "Epoch: 140. Loss: 0.5496616189188743\n",
            "Epoch: 150. Loss: 0.5490098149785172\n",
            "Epoch: 160. Loss: 0.5484345226425752\n",
            "Epoch: 170. Loss: 0.5479235359752292\n",
            "Epoch: 180. Loss: 0.5474669571146599\n",
            "Epoch: 190. Loss: 0.5470567272842817\n",
            "Epoch: 200. Loss: 0.5466862563793465\n",
            "Epoch: 210. Loss: 0.5463501296861408\n",
            "Epoch: 220. Loss: 0.5460438754048909\n",
            "Epoch: 230. Loss: 0.5457637801868868\n",
            "Epoch: 240. Loss: 0.5455067425923995\n",
            "Epoch: 250. Loss: 0.5452701564984352\n",
            "Epoch: 260. Loss: 0.5450518181686507\n",
            "Epoch: 270. Loss: 0.5448498520313485\n",
            "Epoch: 280. Loss: 0.5446626512648874\n",
            "Epoch: 290. Loss: 0.5444888301195742\n",
            "Epoch: 300. Loss: 0.544327185557311\n",
            "Epoch: 310. Loss: 0.5441766663023\n",
            "Epoch: 320. Loss: 0.5440363477979145\n",
            "Epoch: 330. Loss: 0.5439054118801987\n",
            "Epoch: 340. Loss: 0.5437831302261367\n",
            "Epoch: 350. Loss: 0.5436688508295819\n",
            "Epoch: 360. Loss: 0.5435619869110625\n",
            "Epoch: 370. Loss: 0.5434620077886158\n",
            "Epoch: 380. Loss: 0.5433684313323522\n",
            "Epoch: 390. Loss: 0.5432808177010894\n",
            "Epoch: 400. Loss: 0.5431987641193915\n",
            "Epoch: 410. Loss: 0.5431219005010431\n",
            "Epoch: 420. Loss: 0.5430498857629614\n",
            "Epoch: 430. Loss: 0.5429824047038578\n",
            "Epoch: 440. Loss: 0.5429191653461972\n",
            "Epoch: 450. Loss: 0.5428598966594074\n",
            "Epoch: 460. Loss: 0.5428043465978711\n",
            "Epoch: 470. Loss: 0.5427522803997544\n",
            "Epoch: 480. Loss: 0.5427034791028026\n",
            "Epoch: 490. Loss: 0.5426577382413701\n",
            "tensor(0.8068, dtype=torch.float64)\n",
            "2021-08-08 00:00:00\n",
            "Epoch: 0. Loss: 1.7144967381742815\n",
            "Epoch: 10. Loss: 1.4365330136275807\n",
            "Epoch: 20. Loss: 1.1900316322245155\n",
            "Epoch: 30. Loss: 0.9831316134865459\n",
            "Epoch: 40. Loss: 0.8241952583216048\n",
            "Epoch: 50. Loss: 0.7166244295977743\n",
            "Epoch: 60. Loss: 0.6545387299452703\n",
            "Epoch: 70. Loss: 0.6222684441148651\n",
            "Epoch: 80. Loss: 0.6041421287758141\n",
            "Epoch: 90. Loss: 0.5918265267474812\n",
            "Epoch: 100. Loss: 0.5823254102510028\n",
            "Epoch: 110. Loss: 0.5746479541054137\n",
            "Epoch: 120. Loss: 0.5683732506496322\n",
            "Epoch: 130. Loss: 0.5632390230309401\n",
            "Epoch: 140. Loss: 0.559041726134989\n",
            "Epoch: 150. Loss: 0.5556131044998734\n",
            "Epoch: 160. Loss: 0.5528131651369323\n",
            "Epoch: 170. Loss: 0.5505261518993547\n",
            "Epoch: 180. Loss: 0.5486570152835528\n",
            "Epoch: 190. Loss: 0.5471281200645399\n",
            "Epoch: 200. Loss: 0.5458762740784497\n",
            "Epoch: 210. Loss: 0.5448501429339839\n",
            "Epoch: 220. Loss: 0.5440080608672565\n",
            "Epoch: 230. Loss: 0.5433162115680672\n",
            "Epoch: 240. Loss: 0.5427471354706145\n",
            "Epoch: 250. Loss: 0.5422785150457365\n",
            "Epoch: 260. Loss: 0.5418921914474272\n",
            "Epoch: 270. Loss: 0.5415733708290056\n",
            "Epoch: 280. Loss: 0.5413099846571178\n",
            "Epoch: 290. Loss: 0.5410921743079278\n",
            "Epoch: 300. Loss: 0.5409118756135666\n",
            "Epoch: 310. Loss: 0.5407624836529826\n",
            "Epoch: 320. Loss: 0.5406385819366676\n",
            "Epoch: 330. Loss: 0.5405357232865475\n",
            "Epoch: 340. Loss: 0.5404502522577647\n",
            "Epoch: 350. Loss: 0.5403791609892848\n",
            "Epoch: 360. Loss: 0.540319971998234\n",
            "Epoch: 370. Loss: 0.5402706427289447\n",
            "Epoch: 380. Loss: 0.5402294876987402\n",
            "Epoch: 390. Loss: 0.5401951149029247\n",
            "Epoch: 400. Loss: 0.5401663737949521\n",
            "Epoch: 410. Loss: 0.5401423126790841\n",
            "Epoch: 420. Loss: 0.540122143769468\n",
            "Epoch: 430. Loss: 0.5401052145032044\n",
            "Epoch: 440. Loss: 0.5400909839626846\n",
            "Epoch: 450. Loss: 0.5400790034777834\n",
            "Epoch: 460. Loss: 0.5400689006519704\n",
            "Epoch: 470. Loss: 0.5400603661965246\n",
            "Epoch: 480. Loss: 0.540053143070376\n",
            "Epoch: 490. Loss: 0.5400470175150122\n",
            "tensor(0.7727, dtype=torch.float64)\n",
            "2021-08-15 00:00:00\n",
            "Epoch: 0. Loss: 0.7251231883493315\n",
            "Epoch: 10. Loss: 0.6803080942535981\n",
            "Epoch: 20. Loss: 0.6554790230026335\n",
            "Epoch: 30. Loss: 0.6376193356568828\n",
            "Epoch: 40. Loss: 0.6236071879489287\n",
            "Epoch: 50. Loss: 0.6120762326046119\n",
            "Epoch: 60. Loss: 0.6023308185309247\n",
            "Epoch: 70. Loss: 0.5939877597179412\n",
            "Epoch: 80. Loss: 0.5868068861621437\n",
            "Epoch: 90. Loss: 0.5806144443066256\n",
            "Epoch: 100. Loss: 0.5752708299801071\n",
            "Epoch: 110. Loss: 0.5706576844029048\n",
            "Epoch: 120. Loss: 0.566672714428327\n",
            "Epoch: 130. Loss: 0.5632272748185639\n",
            "Epoch: 140. Loss: 0.560244799257075\n",
            "Epoch: 150. Loss: 0.5576594454517386\n",
            "Epoch: 160. Loss: 0.5554148023170541\n",
            "Epoch: 170. Loss: 0.5534626600331816\n",
            "Epoch: 180. Loss: 0.5517618737455389\n",
            "Epoch: 190. Loss: 0.5502773437447532\n",
            "Epoch: 200. Loss: 0.5489791205453788\n",
            "Epoch: 210. Loss: 0.5478416319335191\n",
            "Epoch: 220. Loss: 0.5468430223141814\n",
            "Epoch: 230. Loss: 0.5459645916473844\n",
            "Epoch: 240. Loss: 0.5451903206166089\n",
            "Epoch: 250. Loss: 0.5445064693645996\n",
            "Epoch: 260. Loss: 0.5439012384460953\n",
            "Epoch: 270. Loss: 0.54336448215713\n",
            "Epoch: 280. Loss: 0.542887465875965\n",
            "Epoch: 290. Loss: 0.5424626603841577\n",
            "Epoch: 300. Loss: 0.5420835672906973\n",
            "Epoch: 310. Loss: 0.5417445706573107\n",
            "Epoch: 320. Loss: 0.5414408107355962\n",
            "Epoch: 330. Loss: 0.5411680763991813\n",
            "Epoch: 340. Loss: 0.5409227134094992\n",
            "Epoch: 350. Loss: 0.540701546112755\n",
            "Epoch: 360. Loss: 0.5405018105458245\n",
            "Epoch: 370. Loss: 0.5403210972447767\n",
            "Epoch: 380. Loss: 0.5401573023132398\n",
            "Epoch: 390. Loss: 0.5400085855284066\n",
            "Epoch: 400. Loss: 0.5398733344477495\n",
            "Epoch: 410. Loss: 0.5397501336355707\n",
            "Epoch: 420. Loss: 0.5396377382603046\n",
            "Epoch: 430. Loss: 0.5395350514250301\n",
            "Epoch: 440. Loss: 0.5394411046882013\n",
            "Epoch: 450. Loss: 0.5393550413118737\n",
            "Epoch: 460. Loss: 0.5392761018429292\n",
            "Epoch: 470. Loss: 0.5392036116908228\n",
            "Epoch: 480. Loss: 0.5391369704147705\n",
            "Epoch: 490. Loss: 0.5390756424753548\n",
            "tensor(0.7577, dtype=torch.float64)\n",
            "2021-08-22 00:00:00\n",
            "Epoch: 0. Loss: 0.9577313184433314\n",
            "Epoch: 10. Loss: 0.8691462962877977\n",
            "Epoch: 20. Loss: 0.8185413073145202\n",
            "Epoch: 30. Loss: 0.7828022740349112\n",
            "Epoch: 40. Loss: 0.7553623484376096\n",
            "Epoch: 50. Loss: 0.7331567078916498\n",
            "Epoch: 60. Loss: 0.7144800353545068\n",
            "Epoch: 70. Loss: 0.6983564729031829\n",
            "Epoch: 80. Loss: 0.6842127091733076\n",
            "Epoch: 90. Loss: 0.6716888206434071\n",
            "Epoch: 100. Loss: 0.660535803706079\n",
            "Epoch: 110. Loss: 0.6505640311682862\n",
            "Epoch: 120. Loss: 0.6416187467660005\n",
            "Epoch: 130. Loss: 0.6335687478483863\n",
            "Epoch: 140. Loss: 0.6263010140857508\n",
            "Epoch: 150. Loss: 0.6197178054631978\n",
            "Epoch: 160. Loss: 0.6137347019188684\n",
            "Epoch: 170. Loss: 0.6082789854453092\n",
            "Epoch: 180. Loss: 0.6032881694970613\n",
            "Epoch: 190. Loss: 0.598708635870482\n",
            "Epoch: 200. Loss: 0.5944943865164275\n",
            "Epoch: 210. Loss: 0.5906059234865473\n",
            "Epoch: 220. Loss: 0.5870092632900394\n",
            "Epoch: 230. Loss: 0.5836750835849166\n",
            "Epoch: 240. Loss: 0.580577993877913\n",
            "Epoch: 250. Loss: 0.5776959182670784\n",
            "Epoch: 260. Loss: 0.5750095767419644\n",
            "Epoch: 270. Loss: 0.5725020514858207\n",
            "Epoch: 280. Loss: 0.5701584254264209\n",
            "Epoch: 290. Loss: 0.5679654815350117\n",
            "Epoch: 300. Loss: 0.5659114527993409\n",
            "Epoch: 310. Loss: 0.5639858142254959\n",
            "Epoch: 320. Loss: 0.5621791095600536\n",
            "Epoch: 330. Loss: 0.5604828066218666\n",
            "Epoch: 340. Loss: 0.5588891761766023\n",
            "Epoch: 350. Loss: 0.5573911901779154\n",
            "Epoch: 360. Loss: 0.555982435948817\n",
            "Epoch: 370. Loss: 0.5546570435003751\n",
            "Epoch: 380. Loss: 0.5534096236996598\n",
            "Epoch: 390. Loss: 0.552235215420786\n",
            "Epoch: 400. Loss: 0.5511292401574798\n",
            "Epoch: 410. Loss: 0.5500874628555709\n",
            "Epoch: 420. Loss: 0.5491059579511334\n",
            "Epoch: 430. Loss: 0.5481810797839521\n",
            "Epoch: 440. Loss: 0.5473094367049274\n",
            "Epoch: 450. Loss: 0.5464878683164883\n",
            "Epoch: 460. Loss: 0.5457134253826242\n",
            "Epoch: 470. Loss: 0.5449833520242241\n",
            "Epoch: 480. Loss: 0.5442950698795902\n",
            "Epoch: 490. Loss: 0.543646163962294\n",
            "tensor(0.7814, dtype=torch.float64)\n",
            "2021-08-29 00:00:00\n",
            "Epoch: 0. Loss: 1.4065173096883687\n",
            "Epoch: 10. Loss: 1.1207334642923754\n",
            "Epoch: 20. Loss: 0.8633335459844432\n",
            "Epoch: 30. Loss: 0.691869854545409\n",
            "Epoch: 40. Loss: 0.6071650708819339\n",
            "Epoch: 50. Loss: 0.5739669996120657\n",
            "Epoch: 60. Loss: 0.5610810772087217\n",
            "Epoch: 70. Loss: 0.5553034356948476\n",
            "Epoch: 80. Loss: 0.5521128091451928\n",
            "Epoch: 90. Loss: 0.5499512322632879\n",
            "Epoch: 100. Loss: 0.5482609876928936\n",
            "Epoch: 110. Loss: 0.546831356899611\n",
            "Epoch: 120. Loss: 0.5455749298113176\n",
            "Epoch: 130. Loss: 0.5444497288944958\n",
            "Epoch: 140. Loss: 0.5434316757145677\n",
            "Epoch: 150. Loss: 0.5425045953755229\n",
            "Epoch: 160. Loss: 0.5416563970594762\n",
            "Epoch: 170. Loss: 0.5408774741028657\n",
            "Epoch: 180. Loss: 0.5401599349011276\n",
            "Epoch: 190. Loss: 0.5394971694132713\n",
            "Epoch: 200. Loss: 0.5388835687008964\n",
            "Epoch: 210. Loss: 0.5383143257292019\n",
            "Epoch: 220. Loss: 0.5377852860075846\n",
            "Epoch: 230. Loss: 0.5372928321726883\n",
            "Epoch: 240. Loss: 0.5368337931927213\n",
            "Epoch: 250. Loss: 0.5364053720657004\n",
            "Epoch: 260. Loss: 0.5360050876853701\n",
            "Epoch: 270. Loss: 0.5356307276969945\n",
            "Epoch: 280. Loss: 0.5352803099583752\n",
            "Epoch: 290. Loss: 0.5349520507941128\n",
            "Epoch: 300. Loss: 0.534644338654303\n",
            "Epoch: 310. Loss: 0.5343557121054966\n",
            "Epoch: 320. Loss: 0.5340848413205089\n",
            "Epoch: 330. Loss: 0.5338305124147397\n",
            "Epoch: 340. Loss: 0.5335916141147548\n",
            "Epoch: 350. Loss: 0.5333671263507661\n",
            "Epoch: 360. Loss: 0.5331561104463325\n",
            "Epoch: 370. Loss: 0.5329577006420279\n",
            "Epoch: 380. Loss: 0.5327710967394123\n",
            "Epoch: 390. Loss: 0.532595557690681\n",
            "Epoch: 400. Loss: 0.5324303959903485\n",
            "Epoch: 410. Loss: 0.5322749727500834\n",
            "Epoch: 420. Loss: 0.5321286933577449\n",
            "Epoch: 430. Loss: 0.5319910036378424\n",
            "Epoch: 440. Loss: 0.5318613864438425\n",
            "Epoch: 450. Loss: 0.5317393586236073\n",
            "Epoch: 460. Loss: 0.5316244683082098\n",
            "Epoch: 470. Loss: 0.531516292481845\n",
            "Epoch: 480. Loss: 0.5314144347967814\n",
            "Epoch: 490. Loss: 0.5313185236025263\n",
            "tensor(0.8670, dtype=torch.float64)\n",
            "2021-09-05 00:00:00\n",
            "Epoch: 0. Loss: 1.4579226721418792\n",
            "Epoch: 10. Loss: 1.1222815513514888\n",
            "Epoch: 20. Loss: 0.9638331077224389\n",
            "Epoch: 30. Loss: 0.8477026833537029\n",
            "Epoch: 40. Loss: 0.7521987470845678\n",
            "Epoch: 50. Loss: 0.6761368267416713\n",
            "Epoch: 60. Loss: 0.6205472369735636\n",
            "Epoch: 70. Loss: 0.584132801987575\n",
            "Epoch: 80. Loss: 0.5623793966649563\n",
            "Epoch: 90. Loss: 0.5497135467397012\n",
            "Epoch: 100. Loss: 0.5419778393596669\n",
            "Epoch: 110. Loss: 0.5368701762474462\n",
            "Epoch: 120. Loss: 0.5332629673741514\n",
            "Epoch: 130. Loss: 0.5305958613159076\n",
            "Epoch: 140. Loss: 0.5285632262063139\n",
            "Epoch: 150. Loss: 0.526979272488466\n",
            "Epoch: 160. Loss: 0.5257212380574788\n",
            "Epoch: 170. Loss: 0.5247037828931415\n",
            "Epoch: 180. Loss: 0.5238659483462282\n",
            "Epoch: 190. Loss: 0.5231635832012959\n",
            "Epoch: 200. Loss: 0.5225644714311148\n",
            "Epoch: 210. Loss: 0.5220449945527782\n",
            "Epoch: 220. Loss: 0.5215877684576952\n",
            "Epoch: 230. Loss: 0.5211799438147771\n",
            "Epoch: 240. Loss: 0.5208119753053729\n",
            "Epoch: 250. Loss: 0.5204767278764697\n",
            "Epoch: 260. Loss: 0.5201688270476525\n",
            "Epoch: 270. Loss: 0.5198841864437056\n",
            "Epoch: 280. Loss: 0.5196196641327834\n",
            "Epoch: 290. Loss: 0.5193728125896104\n",
            "Epoch: 300. Loss: 0.5191416967051424\n",
            "Epoch: 310. Loss: 0.518924761246746\n",
            "Epoch: 320. Loss: 0.5187207342529853\n",
            "Epoch: 330. Loss: 0.5185285565418428\n",
            "Epoch: 340. Loss: 0.5183473301972162\n",
            "Epoch: 350. Loss: 0.5181762808505124\n",
            "Epoch: 360. Loss: 0.5180147299923641\n",
            "Epoch: 370. Loss: 0.517862074579722\n",
            "Epoch: 380. Loss: 0.5177177719519123\n",
            "Epoch: 390. Loss: 0.5175813286128067\n",
            "Epoch: 400. Loss: 0.5174522918310402\n",
            "Epoch: 410. Loss: 0.5173302432969474\n",
            "Epoch: 420. Loss: 0.517214794283132\n",
            "Epoch: 430. Loss: 0.5171055819067977\n",
            "Epoch: 440. Loss: 0.5170022662017877\n",
            "Epoch: 450. Loss: 0.5169045277879956\n",
            "Epoch: 460. Loss: 0.5168120659837006\n",
            "Epoch: 470. Loss: 0.5167245972483873\n",
            "Epoch: 480. Loss: 0.5166418538741184\n",
            "Epoch: 490. Loss: 0.5165635828656603\n",
            "tensor(0.7905, dtype=torch.float64)\n",
            "2021-09-12 00:00:00\n",
            "Epoch: 0. Loss: 2.586531947185252\n",
            "Epoch: 10. Loss: 0.6685227245323728\n",
            "Epoch: 20. Loss: 0.5856927613058421\n",
            "Epoch: 30. Loss: 0.5631398693156484\n",
            "Epoch: 40. Loss: 0.549633054964158\n",
            "Epoch: 50. Loss: 0.5406439742299066\n",
            "Epoch: 60. Loss: 0.5343699406280668\n",
            "Epoch: 70. Loss: 0.5298526509427496\n",
            "Epoch: 80. Loss: 0.5265420237280645\n",
            "Epoch: 90. Loss: 0.5240941345860665\n",
            "Epoch: 100. Loss: 0.522276680458712\n",
            "Epoch: 110. Loss: 0.5209243059110142\n",
            "Epoch: 120. Loss: 0.5199159390154676\n",
            "Epoch: 130. Loss: 0.5191618798838126\n",
            "Epoch: 140. Loss: 0.5185954950634741\n",
            "Epoch: 150. Loss: 0.5181673708820387\n",
            "Epoch: 160. Loss: 0.5178409884468471\n",
            "Epoch: 170. Loss: 0.5175894599025059\n",
            "Epoch: 180. Loss: 0.517393056648528\n",
            "Epoch: 190. Loss: 0.5172373443932564\n",
            "Epoch: 200. Loss: 0.5171117850387891\n",
            "Epoch: 210. Loss: 0.5170086956520994\n",
            "Epoch: 220. Loss: 0.5169224781842082\n",
            "Epoch: 230. Loss: 0.5168490526315966\n",
            "Epoch: 240. Loss: 0.5167854418261091\n",
            "Epoch: 250. Loss: 0.5167294684517342\n",
            "Epoch: 260. Loss: 0.5166795346448586\n",
            "Epoch: 270. Loss: 0.5166344620749147\n",
            "Epoch: 280. Loss: 0.5165933761450839\n",
            "Epoch: 290. Loss: 0.5165556222753633\n",
            "Epoch: 300. Loss: 0.5165207054535758\n",
            "Epoch: 310. Loss: 0.5164882466254256\n",
            "Epoch: 320. Loss: 0.5164579512496269\n",
            "Epoch: 330. Loss: 0.5164295866289462\n",
            "Epoch: 340. Loss: 0.516402965564948\n",
            "Epoch: 350. Loss: 0.5163779345653411\n",
            "Epoch: 360. Loss: 0.5163543653266501\n",
            "Epoch: 370. Loss: 0.5163321485722044\n",
            "Epoch: 380. Loss: 0.5163111895834603\n",
            "Epoch: 390. Loss: 0.516291404948714\n",
            "Epoch: 400. Loss: 0.5162727201872671\n",
            "Epoch: 410. Loss: 0.5162550680034969\n",
            "Epoch: 420. Loss: 0.5162383869945787\n",
            "Epoch: 430. Loss: 0.5162226206853716\n",
            "Epoch: 440. Loss: 0.5162077167997036\n",
            "Epoch: 450. Loss: 0.5161936267029207\n",
            "Epoch: 460. Loss: 0.5161803049689432\n",
            "Epoch: 470. Loss: 0.516167709038248\n",
            "Epoch: 480. Loss: 0.5161557989426411\n",
            "Epoch: 490. Loss: 0.5161445370794537\n",
            "tensor(0.7873, dtype=torch.float64)\n",
            "2021-09-19 00:00:00\n",
            "Epoch: 0. Loss: 2.8906131577284033\n",
            "Epoch: 10. Loss: 0.7324639707297479\n",
            "Epoch: 20. Loss: 0.5899015930824465\n",
            "Epoch: 30. Loss: 0.5587339882337915\n",
            "Epoch: 40. Loss: 0.545574564605529\n",
            "Epoch: 50. Loss: 0.5396143551280778\n",
            "Epoch: 60. Loss: 0.5364871075450188\n",
            "Epoch: 70. Loss: 0.5344754101496166\n",
            "Epoch: 80. Loss: 0.5329621905385432\n",
            "Epoch: 90. Loss: 0.5317201819489354\n",
            "Epoch: 100. Loss: 0.5306540620265102\n",
            "Epoch: 110. Loss: 0.5297154710730861\n",
            "Epoch: 120. Loss: 0.5288751889524381\n",
            "Epoch: 130. Loss: 0.5281134255742458\n",
            "Epoch: 140. Loss: 0.5274159344885759\n",
            "Epoch: 150. Loss: 0.5267721329870793\n",
            "Epoch: 160. Loss: 0.526174014148049\n",
            "Epoch: 170. Loss: 0.525615435899057\n",
            "Epoch: 180. Loss: 0.5250916252702945\n",
            "Epoch: 190. Loss: 0.5245988219775776\n",
            "Epoch: 200. Loss: 0.5241340186564529\n",
            "Epoch: 210. Loss: 0.5236947703876036\n",
            "Epoch: 220. Loss: 0.5232790546387688\n",
            "Epoch: 230. Loss: 0.5228851681262879\n",
            "Epoch: 240. Loss: 0.5225116507849358\n",
            "Epoch: 250. Loss: 0.5221572296615846\n",
            "Epoch: 260. Loss: 0.5218207774553794\n",
            "Epoch: 270. Loss: 0.5215012818234531\n",
            "Epoch: 280. Loss: 0.5211978225973932\n",
            "Epoch: 290. Loss: 0.5209095548109643\n",
            "Epoch: 300. Loss: 0.520635695995792\n",
            "Epoch: 310. Loss: 0.520375516611231\n",
            "Epoch: 320. Loss: 0.5201283327760776\n",
            "Epoch: 330. Loss: 0.5198935006915243\n",
            "Epoch: 340. Loss: 0.5196704123077758\n",
            "Epoch: 350. Loss: 0.5194584919064902\n",
            "Epoch: 360. Loss: 0.5192571933591144\n",
            "Epoch: 370. Loss: 0.5190659978856481\n",
            "Epoch: 380. Loss: 0.5188844121856022\n",
            "Epoch: 390. Loss: 0.518711966847497\n",
            "Epoch: 400. Loss: 0.5185482149685272\n",
            "Epoch: 410. Loss: 0.5183927309344947\n",
            "Epoch: 420. Loss: 0.5182451093235799\n",
            "Epoch: 430. Loss: 0.5181049639073507\n",
            "Epoch: 440. Loss: 0.5179719267295524\n",
            "Epoch: 450. Loss: 0.517845647248418\n",
            "Epoch: 460. Loss: 0.5177257915320127\n",
            "Epoch: 470. Loss: 0.5176120414988588\n",
            "Epoch: 480. Loss: 0.5175040941980641\n",
            "Epoch: 490. Loss: 0.5174016611246138\n",
            "tensor(0.7636, dtype=torch.float64)\n",
            "2021-09-26 00:00:00\n",
            "Epoch: 0. Loss: 1.7676900772553734\n",
            "Epoch: 10. Loss: 1.285360892297811\n",
            "Epoch: 20. Loss: 1.0951574956895407\n",
            "Epoch: 30. Loss: 0.9333504115458873\n",
            "Epoch: 40. Loss: 0.8074828568988313\n",
            "Epoch: 50. Loss: 0.7117050182832562\n",
            "Epoch: 60. Loss: 0.6422386687625732\n",
            "Epoch: 70. Loss: 0.5961049116777151\n",
            "Epoch: 80. Loss: 0.5677490277017615\n",
            "Epoch: 90. Loss: 0.5508102244378267\n",
            "Epoch: 100. Loss: 0.5404445232309857\n",
            "Epoch: 110. Loss: 0.5337560891123777\n",
            "Epoch: 120. Loss: 0.5291895065959146\n",
            "Epoch: 130. Loss: 0.5259222256361795\n",
            "Epoch: 140. Loss: 0.5235029982299425\n",
            "Epoch: 150. Loss: 0.5216685431136409\n",
            "Epoch: 160. Loss: 0.5202544523559253\n",
            "Epoch: 170. Loss: 0.5191515179472467\n",
            "Epoch: 180. Loss: 0.518283540723709\n",
            "Epoch: 190. Loss: 0.5175954274756298\n",
            "Epoch: 200. Loss: 0.5170463688443906\n",
            "Epoch: 210. Loss: 0.516605645557409\n",
            "Epoch: 220. Loss: 0.5162498798948933\n",
            "Epoch: 230. Loss: 0.5159611399232948\n",
            "Epoch: 240. Loss: 0.5157255835495318\n",
            "Epoch: 250. Loss: 0.5155324654525443\n",
            "Epoch: 260. Loss: 0.5153733990865816\n",
            "Epoch: 270. Loss: 0.5152418033607895\n",
            "Epoch: 280. Loss: 0.5151324854467975\n",
            "Epoch: 290. Loss: 0.5150413249577838\n",
            "Epoch: 300. Loss: 0.514965034044003\n",
            "Epoch: 310. Loss: 0.5149009745275519\n",
            "Epoch: 320. Loss: 0.5148470179897283\n",
            "Epoch: 330. Loss: 0.5148014382696663\n",
            "Epoch: 340. Loss: 0.5147628284765091\n",
            "Epoch: 350. Loss: 0.5147300365939499\n",
            "Epoch: 360. Loss: 0.5147021152343769\n",
            "Epoch: 370. Loss: 0.5146782822050233\n",
            "Epoch: 380. Loss: 0.5146578893741377\n",
            "Epoch: 390. Loss: 0.5146403979417563\n",
            "Epoch: 400. Loss: 0.5146253586802322\n",
            "Epoch: 410. Loss: 0.5146123960540386\n",
            "Epoch: 420. Loss: 0.5146011953862825\n",
            "Epoch: 430. Loss: 0.5145914924329908\n",
            "Epoch: 440. Loss: 0.5145830648720756\n",
            "Epoch: 450. Loss: 0.514575725324135\n",
            "Epoch: 460. Loss: 0.5145693156059923\n",
            "Epoch: 470. Loss: 0.5145637019818016\n",
            "Epoch: 480. Loss: 0.5145587712256104\n",
            "Epoch: 490. Loss: 0.5145544273471762\n",
            "tensor(0.8282, dtype=torch.float64)\n",
            "2021-10-03 00:00:00\n",
            "Epoch: 0. Loss: 1.1329474654013643\n",
            "Epoch: 10. Loss: 0.9491053519084816\n",
            "Epoch: 20. Loss: 0.804516766579669\n",
            "Epoch: 30. Loss: 0.7033711517923786\n",
            "Epoch: 40. Loss: 0.6429863539909824\n",
            "Epoch: 50. Loss: 0.6111763715717079\n",
            "Epoch: 60. Loss: 0.5945094735728357\n",
            "Epoch: 70. Loss: 0.5848274643443021\n",
            "Epoch: 80. Loss: 0.5783795000709545\n",
            "Epoch: 90. Loss: 0.5735431477550476\n",
            "Epoch: 100. Loss: 0.569588924621594\n",
            "Epoch: 110. Loss: 0.5661670755312199\n",
            "Epoch: 120. Loss: 0.5630986012242399\n",
            "Epoch: 130. Loss: 0.5602857967846749\n",
            "Epoch: 140. Loss: 0.5576716972448573\n",
            "Epoch: 150. Loss: 0.5552207838402072\n",
            "Epoch: 160. Loss: 0.552909422802766\n",
            "Epoch: 170. Loss: 0.5507209383853172\n",
            "Epoch: 180. Loss: 0.5486429636428642\n",
            "Epoch: 190. Loss: 0.5466659452051801\n",
            "Epoch: 200. Loss: 0.5447822531077108\n",
            "Epoch: 210. Loss: 0.5429856213879786\n",
            "Epoch: 220. Loss: 0.5412707787097519\n",
            "Epoch: 230. Loss: 0.5396331942944173\n",
            "Epoch: 240. Loss: 0.5380688977154466\n",
            "Epoch: 250. Loss: 0.5365743483368505\n",
            "Epoch: 260. Loss: 0.5351463394223314\n",
            "Epoch: 270. Loss: 0.533781927142666\n",
            "Epoch: 280. Loss: 0.5324783777993983\n",
            "Epoch: 290. Loss: 0.5312331285282158\n",
            "Epoch: 300. Loss: 0.5300437580370911\n",
            "Epoch: 310. Loss: 0.5289079648311177\n",
            "Epoch: 320. Loss: 0.5278235510198392\n",
            "Epoch: 330. Loss: 0.5267884102762734\n",
            "Epoch: 340. Loss: 0.5258005188700484\n",
            "Epoch: 350. Loss: 0.5248579289632637\n",
            "Epoch: 360. Loss: 0.5239587635592045\n",
            "Epoch: 370. Loss: 0.5231012126470173\n",
            "Epoch: 380. Loss: 0.5222835302016412\n",
            "Epoch: 390. Loss: 0.5215040317864026\n",
            "Epoch: 400. Loss: 0.5207610925724226\n",
            "Epoch: 410. Loss: 0.5200531456393608\n",
            "Epoch: 420. Loss: 0.5193786804599106\n",
            "Epoch: 430. Loss: 0.5187362414988173\n",
            "Epoch: 440. Loss: 0.5181244268783008\n",
            "Epoch: 450. Loss: 0.5175418870773592\n",
            "Epoch: 460. Loss: 0.5169873236438388\n",
            "Epoch: 470. Loss: 0.5164594879064366\n",
            "Epoch: 480. Loss: 0.5159571796796879\n",
            "Epoch: 490. Loss: 0.5154792459591272\n",
            "tensor(0.9667, dtype=torch.float64)\n",
            "2021-10-10 00:00:00\n",
            "Epoch: 0. Loss: 1.5950925183303197\n",
            "Epoch: 10. Loss: 0.7655567822096038\n",
            "Epoch: 20. Loss: 0.6334772830543588\n",
            "Epoch: 30. Loss: 0.5797149365230418\n",
            "Epoch: 40. Loss: 0.5542587378825883\n",
            "Epoch: 50. Loss: 0.5421818451019909\n",
            "Epoch: 60. Loss: 0.5356162884733853\n",
            "Epoch: 70. Loss: 0.5314104127955653\n",
            "Epoch: 80. Loss: 0.5284023014071468\n",
            "Epoch: 90. Loss: 0.5261168879763234\n",
            "Epoch: 100. Loss: 0.5243204220541806\n",
            "Epoch: 110. Loss: 0.522875879980934\n",
            "Epoch: 120. Loss: 0.5216928172437186\n",
            "Epoch: 130. Loss: 0.5207075026113478\n",
            "Epoch: 140. Loss: 0.5198735612494496\n",
            "Epoch: 150. Loss: 0.5191567364983327\n",
            "Epoch: 160. Loss: 0.5185315414939459\n",
            "Epoch: 170. Loss: 0.5179789375510925\n",
            "Epoch: 180. Loss: 0.5174846554655486\n",
            "Epoch: 190. Loss: 0.5170379589158933\n",
            "Epoch: 200. Loss: 0.5166307276240009\n",
            "Epoch: 210. Loss: 0.516256777100257\n",
            "Epoch: 220. Loss: 0.5159113547947842\n",
            "Epoch: 230. Loss: 0.5155907678557387\n",
            "Epoch: 240. Loss: 0.515292108823495\n",
            "Epoch: 250. Loss: 0.5150130539411878\n",
            "Epoch: 260. Loss: 0.5147517151065538\n",
            "Epoch: 270. Loss: 0.5145065313112194\n",
            "Epoch: 280. Loss: 0.5142761890605626\n",
            "Epoch: 290. Loss: 0.5140595640093558\n",
            "Epoch: 300. Loss: 0.51385567809746\n",
            "Epoch: 310. Loss: 0.5136636679924643\n",
            "Epoch: 320. Loss: 0.5134827617720267\n",
            "Epoch: 330. Loss: 0.5133122616076307\n",
            "Epoch: 340. Loss: 0.5131515308196276\n",
            "Epoch: 350. Loss: 0.5129999841182323\n",
            "Epoch: 360. Loss: 0.5128570801696266\n",
            "Epoch: 370. Loss: 0.5127223158625197\n",
            "Epoch: 380. Loss: 0.5125952218221382\n",
            "Epoch: 390. Loss: 0.5124753588431331\n",
            "Epoch: 400. Loss: 0.5123623150031161\n",
            "Epoch: 410. Loss: 0.5122557032838629\n",
            "Epoch: 420. Loss: 0.5121551595744747\n",
            "Epoch: 430. Loss: 0.5120603409649663\n",
            "Epoch: 440. Loss: 0.5119709242634641\n",
            "Epoch: 450. Loss: 0.5118866046880606\n",
            "Epoch: 460. Loss: 0.5118070946973106\n",
            "Epoch: 470. Loss: 0.5117321229327114\n",
            "Epoch: 480. Loss: 0.5116614332533006\n",
            "Epoch: 490. Loss: 0.511594783847436\n",
            "tensor(0.6659, dtype=torch.float64)\n",
            "2021-10-17 00:00:00\n",
            "Epoch: 0. Loss: 2.9533576717317205\n",
            "Epoch: 10. Loss: 1.2688767787298005\n",
            "Epoch: 20. Loss: 0.8319669126490229\n",
            "Epoch: 30. Loss: 0.6676141617893294\n",
            "Epoch: 40. Loss: 0.5823425003444079\n",
            "Epoch: 50. Loss: 0.544555737034734\n",
            "Epoch: 60. Loss: 0.5305794262859082\n",
            "Epoch: 70. Loss: 0.5250966903283463\n",
            "Epoch: 80. Loss: 0.5222536931257374\n",
            "Epoch: 90. Loss: 0.5203224718188526\n",
            "Epoch: 100. Loss: 0.5188037802850137\n",
            "Epoch: 110. Loss: 0.5175332056554426\n",
            "Epoch: 120. Loss: 0.5164420294943602\n",
            "Epoch: 130. Loss: 0.5154927132347958\n",
            "Epoch: 140. Loss: 0.514660190689996\n",
            "Epoch: 150. Loss: 0.5139257311259862\n",
            "Epoch: 160. Loss: 0.5132745388073339\n",
            "Epoch: 170. Loss: 0.5126945979307062\n",
            "Epoch: 180. Loss: 0.5121760000939984\n",
            "Epoch: 190. Loss: 0.5117104947555668\n",
            "Epoch: 200. Loss: 0.5112911623489309\n",
            "Epoch: 210. Loss: 0.5109121651064544\n",
            "Epoch: 220. Loss: 0.510568552081193\n",
            "Epoch: 230. Loss: 0.510256104218395\n",
            "Epoch: 240. Loss: 0.509971210007942\n",
            "Epoch: 250. Loss: 0.5097107649279898\n",
            "Epoch: 260. Loss: 0.5094720896103061\n",
            "Epoch: 270. Loss: 0.5092528628558475\n",
            "Epoch: 280. Loss: 0.5090510665059251\n",
            "Epoch: 290. Loss: 0.50886493983391\n",
            "Epoch: 300. Loss: 0.5086929416259488\n",
            "Epoch: 310. Loss: 0.508533718506575\n",
            "Epoch: 320. Loss: 0.5083860783646807\n",
            "Epoch: 330. Loss: 0.5082489679678457\n",
            "Epoch: 340. Loss: 0.5081214540342261\n",
            "Epoch: 350. Loss: 0.5080027071729899\n",
            "Epoch: 360. Loss: 0.5078919882157517\n",
            "Epoch: 370. Loss: 0.5077886365495672\n",
            "Epoch: 380. Loss: 0.5076920601320792\n",
            "Epoch: 390. Loss: 0.5076017269254168\n",
            "Epoch: 400. Loss: 0.5075171575305281\n",
            "Epoch: 410. Loss: 0.5074379188401369\n",
            "Epoch: 420. Loss: 0.5073636185582617\n",
            "Epoch: 430. Loss: 0.5072939004586313\n",
            "Epoch: 440. Loss: 0.5072284402744336\n",
            "Epoch: 450. Loss: 0.5071669421285082\n",
            "Epoch: 460. Loss: 0.5071091354269632\n",
            "Epoch: 470. Loss: 0.5070547721508091\n",
            "Epoch: 480. Loss: 0.5070036244899419\n",
            "Epoch: 490. Loss: 0.5069554827720181\n",
            "tensor(0.7480, dtype=torch.float64)\n",
            "2021-10-24 00:00:00\n",
            "Epoch: 0. Loss: 1.279127819939253\n",
            "Epoch: 10. Loss: 0.8768717406801075\n",
            "Epoch: 20. Loss: 0.7157610386185158\n",
            "Epoch: 30. Loss: 0.6175448987329761\n",
            "Epoch: 40. Loss: 0.5654708222350185\n",
            "Epoch: 50. Loss: 0.5450419958365806\n",
            "Epoch: 60. Loss: 0.5382347693325938\n",
            "Epoch: 70. Loss: 0.5354363144203511\n",
            "Epoch: 80. Loss: 0.5336794898927629\n",
            "Epoch: 90. Loss: 0.5322326720646581\n",
            "Epoch: 100. Loss: 0.5309215573786201\n",
            "Epoch: 110. Loss: 0.529701233502032\n",
            "Epoch: 120. Loss: 0.5285568975349196\n",
            "Epoch: 130. Loss: 0.5274811070288451\n",
            "Epoch: 140. Loss: 0.5264685146648779\n",
            "Epoch: 150. Loss: 0.5255146052978316\n",
            "Epoch: 160. Loss: 0.5246153594725524\n",
            "Epoch: 170. Loss: 0.5237671378066966\n",
            "Epoch: 180. Loss: 0.5229666224399272\n",
            "Epoch: 190. Loss: 0.5222107764783043\n",
            "Epoch: 200. Loss: 0.5214968114688044\n",
            "Epoch: 210. Loss: 0.5208221599211825\n",
            "Epoch: 220. Loss: 0.5201844516733362\n",
            "Epoch: 230. Loss: 0.5195814934137966\n",
            "Epoch: 240. Loss: 0.5190112508681384\n",
            "Epoch: 250. Loss: 0.5184718332558516\n",
            "Epoch: 260. Loss: 0.5179614796909067\n",
            "Epoch: 270. Loss: 0.5174785472504376\n",
            "Epoch: 280. Loss: 0.5170215004776411\n",
            "Epoch: 290. Loss: 0.5165889021197739\n",
            "Epoch: 300. Loss: 0.5161794049314586\n",
            "Epoch: 310. Loss: 0.5157917443983406\n",
            "Epoch: 320. Loss: 0.5154247322572387\n",
            "Epoch: 330. Loss: 0.515077250706856\n",
            "Epoch: 340. Loss: 0.514748247218379\n",
            "Epoch: 350. Loss: 0.5144367298682843\n",
            "Epoch: 360. Loss: 0.5141417631267402\n",
            "Epoch: 370. Loss: 0.5138624640444305\n",
            "Epoch: 380. Loss: 0.5135979987886755\n",
            "Epoch: 390. Loss: 0.5133475794865984\n",
            "Epoch: 400. Loss: 0.5131104613389497\n",
            "Epoch: 410. Loss: 0.512885939973222\n",
            "Epoch: 420. Loss: 0.5126733490089674\n",
            "Epoch: 430. Loss: 0.5124720578119034\n",
            "Epoch: 440. Loss: 0.5122814694165271\n",
            "Epoch: 450. Loss: 0.5121010185996498\n",
            "Epoch: 460. Loss: 0.5119301700895658\n",
            "Epoch: 470. Loss: 0.5117684168975438\n",
            "Epoch: 480. Loss: 0.511615278760026\n",
            "Epoch: 490. Loss: 0.5114703006813744\n",
            "tensor(0.8469, dtype=torch.float64)\n",
            "2021-10-31 00:00:00\n",
            "Epoch: 0. Loss: 0.9757340806493117\n",
            "Epoch: 10. Loss: 0.8045837174916568\n",
            "Epoch: 20. Loss: 0.7057206371005671\n",
            "Epoch: 30. Loss: 0.6372284036183888\n",
            "Epoch: 40. Loss: 0.5937037447981001\n",
            "Epoch: 50. Loss: 0.5688397548018667\n",
            "Epoch: 60. Loss: 0.5550882792487788\n",
            "Epoch: 70. Loss: 0.5470108383983726\n",
            "Epoch: 80. Loss: 0.5417031394745293\n",
            "Epoch: 90. Loss: 0.537805365808433\n",
            "Epoch: 100. Loss: 0.5346983159966056\n",
            "Epoch: 110. Loss: 0.5320907032453424\n",
            "Epoch: 120. Loss: 0.5298349860845252\n",
            "Epoch: 130. Loss: 0.5278483130249251\n",
            "Epoch: 140. Loss: 0.5260785884109492\n",
            "Epoch: 150. Loss: 0.5244896057533633\n",
            "Epoch: 160. Loss: 0.5230542696286133\n",
            "Epoch: 170. Loss: 0.5217513002772287\n",
            "Epoch: 180. Loss: 0.5205634800837858\n",
            "Epoch: 190. Loss: 0.5194766159555855\n",
            "Epoch: 200. Loss: 0.5184788596316691\n",
            "Epoch: 210. Loss: 0.5175602255548567\n",
            "Epoch: 220. Loss: 0.516712230244001\n",
            "Epoch: 230. Loss: 0.5159276138316655\n",
            "Epoch: 240. Loss: 0.5152001210942313\n",
            "Epoch: 250. Loss: 0.5145243274078629\n",
            "Epoch: 260. Loss: 0.5138954994298923\n",
            "Epoch: 270. Loss: 0.5133094829507173\n",
            "Epoch: 280. Loss: 0.5127626121433194\n",
            "Epoch: 290. Loss: 0.512251635731107\n",
            "Epoch: 300. Loss: 0.5117736565752959\n",
            "Epoch: 310. Loss: 0.51132608194188\n",
            "Epoch: 320. Loss: 0.5109065823002806\n",
            "Epoch: 330. Loss: 0.5105130569684755\n",
            "Epoch: 340. Loss: 0.5101436052806815\n",
            "Epoch: 350. Loss: 0.5097965022353065\n",
            "Epoch: 360. Loss: 0.5094701778001387\n",
            "Epoch: 370. Loss: 0.5091631992223145\n",
            "Epoch: 380. Loss: 0.508874255823369\n",
            "Epoch: 390. Loss: 0.5086021458631309\n",
            "Epoch: 400. Loss: 0.5083457651370554\n",
            "Epoch: 410. Loss: 0.5081040970349544\n",
            "Epoch: 420. Loss: 0.5078762038389696\n",
            "Epoch: 430. Loss: 0.5076612190781309\n",
            "Epoch: 440. Loss: 0.5074583407882843\n",
            "Epoch: 450. Loss: 0.5072668255513726\n",
            "Epoch: 460. Loss: 0.5070859832083966\n",
            "Epoch: 470. Loss: 0.5069151721569164\n",
            "Epoch: 480. Loss: 0.506753795157488\n",
            "Epoch: 490. Loss: 0.506601295584598\n",
            "tensor(0.9043, dtype=torch.float64)\n",
            "2021-11-07 00:00:00\n",
            "Epoch: 0. Loss: 2.760513192760416\n",
            "Epoch: 10. Loss: 0.6861564048598148\n",
            "Epoch: 20. Loss: 0.6162562483856966\n",
            "Epoch: 30. Loss: 0.5983273206397736\n",
            "Epoch: 40. Loss: 0.5863835869980752\n",
            "Epoch: 50. Loss: 0.577084779339619\n",
            "Epoch: 60. Loss: 0.5695241963616146\n",
            "Epoch: 70. Loss: 0.5632012341002552\n",
            "Epoch: 80. Loss: 0.5577936802901436\n",
            "Epoch: 90. Loss: 0.553083566765255\n",
            "Epoch: 100. Loss: 0.5489182284559161\n",
            "Epoch: 110. Loss: 0.5451875642446024\n",
            "Epoch: 120. Loss: 0.5418101889860635\n",
            "Epoch: 130. Loss: 0.5387247196346823\n",
            "Epoch: 140. Loss: 0.5358841087700694\n",
            "Epoch: 150. Loss: 0.5332518305467099\n",
            "Epoch: 160. Loss: 0.5307992248352693\n",
            "Epoch: 170. Loss: 0.5285035909498881\n",
            "Epoch: 180. Loss: 0.5263467854856304\n",
            "Epoch: 190. Loss: 0.5243141721299739\n",
            "Epoch: 200. Loss: 0.5223938253197391\n",
            "Epoch: 210. Loss: 0.5205759216383812\n",
            "Epoch: 220. Loss: 0.5188522725629187\n",
            "Epoch: 230. Loss: 0.5172159648823594\n",
            "Epoch: 240. Loss: 0.515661083712647\n",
            "Epoch: 250. Loss: 0.514182499113795\n",
            "Epoch: 260. Loss: 0.5127757017635346\n",
            "Epoch: 270. Loss: 0.5114366764779348\n",
            "Epoch: 280. Loss: 0.5101618049123182\n",
            "Epoch: 290. Loss: 0.5089477907333051\n",
            "Epoch: 300. Loss: 0.507791602068118\n",
            "Epoch: 310. Loss: 0.5066904272134602\n",
            "Epoch: 320. Loss: 0.5056416405001224\n",
            "Epoch: 330. Loss: 0.504642775919366\n",
            "Epoch: 340. Loss: 0.5036915066681995\n",
            "Epoch: 350. Loss: 0.5027856291978713\n",
            "Epoch: 360. Loss: 0.5019230506806329\n",
            "Epoch: 370. Loss: 0.5011017790653933\n",
            "Epoch: 380. Loss: 0.5003199150900242\n",
            "Epoch: 390. Loss: 0.49957564576979313\n",
            "Epoch: 400. Loss: 0.49886723899793556\n",
            "Epoch: 410. Loss: 0.49819303898362777\n",
            "Epoch: 420. Loss: 0.4975514623208242\n",
            "Epoch: 430. Loss: 0.4969409945333554\n",
            "Epoch: 440. Loss: 0.4963601869811265\n",
            "Epoch: 450. Loss: 0.4958076540420793\n",
            "Epoch: 460. Loss: 0.49528207050705636\n",
            "Epoch: 470. Loss: 0.4947821691415562\n",
            "Epoch: 480. Loss: 0.4943067383809479\n",
            "Epoch: 490. Loss: 0.4938546201350292\n",
            "tensor(0.9318, dtype=torch.float64)\n",
            "2021-11-14 00:00:00\n",
            "Epoch: 0. Loss: 3.5185018103963057\n",
            "Epoch: 10. Loss: 0.5567495772707709\n",
            "Epoch: 20. Loss: 0.523181409630191\n",
            "Epoch: 30. Loss: 0.5141792832015237\n",
            "Epoch: 40. Loss: 0.5075139934979161\n",
            "Epoch: 50. Loss: 0.5024557478826718\n",
            "Epoch: 60. Loss: 0.49865944253876476\n",
            "Epoch: 70. Loss: 0.49584403984364206\n",
            "Epoch: 80. Loss: 0.4937789634743293\n",
            "Epoch: 90. Loss: 0.4922788049594823\n",
            "Epoch: 100. Loss: 0.4911978689796499\n",
            "Epoch: 110. Loss: 0.4904241492883427\n",
            "Epoch: 120. Loss: 0.4898731914767716\n",
            "Epoch: 130. Loss: 0.4894823547482067\n",
            "Epoch: 140. Loss: 0.4892058059884056\n",
            "Epoch: 150. Loss: 0.4890103792913937\n",
            "Epoch: 160. Loss: 0.4888722876568557\n",
            "Epoch: 170. Loss: 0.48877459115482236\n",
            "Epoch: 180. Loss: 0.4887052931963868\n",
            "Epoch: 190. Loss: 0.4886559349020727\n",
            "Epoch: 200. Loss: 0.4886205717077777\n",
            "Epoch: 210. Loss: 0.48859503632503337\n",
            "Epoch: 220. Loss: 0.4885764124086909\n",
            "Epoch: 230. Loss: 0.48856266117763797\n",
            "Epoch: 240. Loss: 0.4885523579158693\n",
            "Epoch: 250. Loss: 0.4885445067782984\n",
            "Epoch: 260. Loss: 0.48853841105011697\n",
            "Epoch: 270. Loss: 0.48853358248369244\n",
            "Epoch: 280. Loss: 0.4885296780658033\n",
            "Epoch: 290. Loss: 0.4885264559800891\n",
            "Epoch: 300. Loss: 0.48852374496910417\n",
            "Epoch: 310. Loss: 0.4885214230322481\n",
            "Epoch: 320. Loss: 0.4885194026185659\n",
            "Epoch: 330. Loss: 0.48851762033290774\n",
            "Epoch: 340. Loss: 0.48851602977599223\n",
            "Epoch: 350. Loss: 0.48851459655948226\n",
            "Epoch: 360. Loss: 0.4885132948302903\n",
            "Epoch: 370. Loss: 0.4885121048422522\n",
            "Epoch: 380. Loss: 0.4885110112549654\n",
            "Epoch: 390. Loss: 0.48851000193787814\n",
            "Epoch: 400. Loss: 0.4885090671258636\n",
            "Epoch: 410. Loss: 0.48850819881971075\n",
            "Epoch: 420. Loss: 0.48850739035765695\n",
            "Epoch: 430. Loss: 0.48850663610671163\n",
            "Epoch: 440. Loss: 0.4885059312381791\n",
            "Epoch: 450. Loss: 0.4885052715626352\n",
            "Epoch: 460. Loss: 0.48850465340711285\n",
            "Epoch: 470. Loss: 0.48850407352245906\n",
            "Epoch: 480. Loss: 0.48850352901242705\n",
            "Epoch: 490. Loss: 0.4885030172785745\n",
            "tensor(0.8733, dtype=torch.float64)\n",
            "2021-11-21 00:00:00\n",
            "Epoch: 0. Loss: 1.6084239448262776\n",
            "Epoch: 10. Loss: 0.8461101411268845\n",
            "Epoch: 20. Loss: 0.7283255565745648\n",
            "Epoch: 30. Loss: 0.6718383300359828\n",
            "Epoch: 40. Loss: 0.6418072726338573\n",
            "Epoch: 50. Loss: 0.6259531799527102\n",
            "Epoch: 60. Loss: 0.6162958516801686\n",
            "Epoch: 70. Loss: 0.6091517735939549\n",
            "Epoch: 80. Loss: 0.6031163541796893\n",
            "Epoch: 90. Loss: 0.5976695711331185\n",
            "Epoch: 100. Loss: 0.5926065824253415\n",
            "Epoch: 110. Loss: 0.5878362725501048\n",
            "Epoch: 120. Loss: 0.5833112239411525\n",
            "Epoch: 130. Loss: 0.579002571604849\n",
            "Epoch: 140. Loss: 0.5748903830878537\n",
            "Epoch: 150. Loss: 0.5709596337647151\n",
            "Epoch: 160. Loss: 0.567198329651853\n",
            "Epoch: 170. Loss: 0.5635965242491175\n",
            "Epoch: 180. Loss: 0.5601457440510628\n",
            "Epoch: 190. Loss: 0.556838620146231\n",
            "Epoch: 200. Loss: 0.5536686342862304\n",
            "Epoch: 210. Loss: 0.5506299345389695\n",
            "Epoch: 220. Loss: 0.5477171967383617\n",
            "Epoch: 230. Loss: 0.544925518100976\n",
            "Epoch: 240. Loss: 0.5422503345742313\n",
            "Epoch: 250. Loss: 0.5396873563030519\n",
            "Epoch: 260. Loss: 0.537232517238506\n",
            "Epoch: 270. Loss: 0.5348819359298196\n",
            "Epoch: 280. Loss: 0.5326318852192288\n",
            "Epoch: 290. Loss: 0.5304787690395663\n",
            "Epoch: 300. Loss: 0.5284191048723476\n",
            "Epoch: 310. Loss: 0.5264495107001381\n",
            "Epoch: 320. Loss: 0.5245666955054561\n",
            "Epoch: 330. Loss: 0.522767452544073\n",
            "Epoch: 340. Loss: 0.5210486547634334\n",
            "Epoch: 350. Loss: 0.5194072518538738\n",
            "Epoch: 360. Loss: 0.5178402685167284\n",
            "Epoch: 370. Loss: 0.5163448036131106\n",
            "Epoch: 380. Loss: 0.5149180299232746\n",
            "Epoch: 390. Loss: 0.5135571943014104\n",
            "Epoch: 400. Loss: 0.5122596180563883\n",
            "Epoch: 410. Loss: 0.5110226974269069\n",
            "Epoch: 420. Loss: 0.5098439040509373\n",
            "Epoch: 430. Loss: 0.5087207853553024\n",
            "Epoch: 440. Loss: 0.5076509648124932\n",
            "Epoch: 450. Loss: 0.5066321420291698\n",
            "Epoch: 460. Loss: 0.5056620926447175\n",
            "Epoch: 470. Loss: 0.504738668029323\n",
            "Epoch: 480. Loss: 0.5038597947796918\n",
            "Epoch: 490. Loss: 0.5030234740171423\n",
            "tensor(0.8859, dtype=torch.float64)\n",
            "2021-11-28 00:00:00\n",
            "Epoch: 0. Loss: 2.6724835568345995\n",
            "Epoch: 10. Loss: 0.839221161956609\n",
            "Epoch: 20. Loss: 0.6885263916116062\n",
            "Epoch: 30. Loss: 0.6195171503650331\n",
            "Epoch: 40. Loss: 0.5818927029811733\n",
            "Epoch: 50. Loss: 0.5641303165444305\n",
            "Epoch: 60. Loss: 0.5554824093949615\n",
            "Epoch: 70. Loss: 0.550215442599706\n",
            "Epoch: 80. Loss: 0.5462073499069433\n",
            "Epoch: 90. Loss: 0.5427602844795475\n",
            "Epoch: 100. Loss: 0.5396409996224817\n",
            "Epoch: 110. Loss: 0.5367624823484728\n",
            "Epoch: 120. Loss: 0.5340849000557927\n",
            "Epoch: 130. Loss: 0.5315847865171881\n",
            "Epoch: 140. Loss: 0.5292451819032004\n",
            "Epoch: 150. Loss: 0.5270522951124882\n",
            "Epoch: 160. Loss: 0.5249942603418283\n",
            "Epoch: 170. Loss: 0.5230606011089793\n",
            "Epoch: 180. Loss: 0.5212419519793501\n",
            "Epoch: 190. Loss: 0.519529884521452\n",
            "Epoch: 200. Loss: 0.5179167815020881\n",
            "Epoch: 210. Loss: 0.5163957371870406\n",
            "Epoch: 220. Loss: 0.5149604741509407\n",
            "Epoch: 230. Loss: 0.5136052719690273\n",
            "Epoch: 240. Loss: 0.5123249052661384\n",
            "Epoch: 250. Loss: 0.511114589546731\n",
            "Epoch: 260. Loss: 0.5099699336889939\n",
            "Epoch: 270. Loss: 0.5088868982300309\n",
            "Epoch: 280. Loss: 0.5078617587151677\n",
            "Epoch: 290. Loss: 0.5068910734846032\n",
            "Epoch: 300. Loss: 0.5059716553479409\n",
            "Epoch: 310. Loss: 0.5051005466619178\n",
            "Epoch: 320. Loss: 0.5042749973833814\n",
            "Epoch: 330. Loss: 0.5034924457202571\n",
            "Epoch: 340. Loss: 0.5027505010488045\n",
            "Epoch: 350. Loss: 0.5020469288063311\n",
            "Epoch: 360. Loss: 0.5013796371050874\n",
            "Epoch: 370. Loss: 0.5007466648455708\n",
            "Epoch: 380. Loss: 0.5001461711362363\n",
            "Epoch: 390. Loss: 0.4995764258519616\n",
            "Epoch: 400. Loss: 0.49903580118584795\n",
            "Epoch: 410. Loss: 0.4985227640683686\n",
            "Epoch: 420. Loss: 0.49803586934481814\n",
            "Epoch: 430. Loss: 0.49757375361672657\n",
            "Epoch: 440. Loss: 0.49713512966566076\n",
            "Epoch: 450. Loss: 0.49671878138887754\n",
            "Epoch: 460. Loss: 0.496323559185831\n",
            "Epoch: 470. Loss: 0.495948375742766\n",
            "Epoch: 480. Loss: 0.49559220216972194\n",
            "Epoch: 490. Loss: 0.4952540644503838\n",
            "tensor(0.8876, dtype=torch.float64)\n",
            "2021-12-05 00:00:00\n",
            "Epoch: 0. Loss: 1.4004001039218186\n",
            "Epoch: 10. Loss: 0.9363548887774304\n",
            "Epoch: 20. Loss: 0.8009087153732188\n",
            "Epoch: 30. Loss: 0.7161293062571467\n",
            "Epoch: 40. Loss: 0.6602191534658971\n",
            "Epoch: 50. Loss: 0.6267441833859227\n",
            "Epoch: 60. Loss: 0.607738774695073\n",
            "Epoch: 70. Loss: 0.5962592054388149\n",
            "Epoch: 80. Loss: 0.5883027658749708\n",
            "Epoch: 90. Loss: 0.5820341413786639\n",
            "Epoch: 100. Loss: 0.5766820782961625\n",
            "Epoch: 110. Loss: 0.5719208116259024\n",
            "Epoch: 120. Loss: 0.5676021634894476\n",
            "Epoch: 130. Loss: 0.5636490948231746\n",
            "Epoch: 140. Loss: 0.5600141830241382\n",
            "Epoch: 150. Loss: 0.5566632622918102\n",
            "Epoch: 160. Loss: 0.5535688314593195\n",
            "Epoch: 170. Loss: 0.5507073122253124\n",
            "Epoch: 180. Loss: 0.5480578514566575\n",
            "Epoch: 190. Loss: 0.5456017509117331\n",
            "Epoch: 200. Loss: 0.5433221541513339\n",
            "Epoch: 210. Loss: 0.5412038400051519\n",
            "Epoch: 220. Loss: 0.5392330616562293\n",
            "Epoch: 230. Loss: 0.5373974072810987\n",
            "Epoch: 240. Loss: 0.5356856732355564\n",
            "Epoch: 250. Loss: 0.5340877467464163\n",
            "Epoch: 260. Loss: 0.5325944972767073\n",
            "Epoch: 270. Loss: 0.5311976764131067\n",
            "Epoch: 280. Loss: 0.5298898262205138\n",
            "Epoch: 290. Loss: 0.5286641959097041\n",
            "Epoch: 300. Loss: 0.5275146665261284\n",
            "Epoch: 310. Loss: 0.5264356832484363\n",
            "Epoch: 320. Loss: 0.5254221948004509\n",
            "Epoch: 330. Loss: 0.5244695994302977\n",
            "Epoch: 340. Loss: 0.5235736968896306\n",
            "Epoch: 350. Loss: 0.5227306458476773\n",
            "Epoch: 360. Loss: 0.5219369261928021\n",
            "Epoch: 370. Loss: 0.5211893057031836\n",
            "Epoch: 380. Loss: 0.5204848106038076\n",
            "Epoch: 390. Loss: 0.5198206995661225\n",
            "Epoch: 400. Loss: 0.5191944407470389\n",
            "Epoch: 410. Loss: 0.5186036915038347\n",
            "Epoch: 420. Loss: 0.5180462804598317\n",
            "Epoch: 430. Loss: 0.5175201916317169\n",
            "Epoch: 440. Loss: 0.5170235503626989\n",
            "Epoch: 450. Loss: 0.5165546108361107\n",
            "Epoch: 460. Loss: 0.5161117449715749\n",
            "Epoch: 470. Loss: 0.5156934325304959\n",
            "Epoch: 480. Loss: 0.5152982522795967\n",
            "Epoch: 490. Loss: 0.5149248740806345\n",
            "tensor(0.8716, dtype=torch.float64)\n",
            "2021-12-12 00:00:00\n",
            "Epoch: 0. Loss: 2.1120883348987674\n",
            "Epoch: 10. Loss: 0.6489994210512344\n",
            "Epoch: 20. Loss: 0.5871161248950805\n",
            "Epoch: 30. Loss: 0.5645449140829163\n",
            "Epoch: 40. Loss: 0.5528456005527055\n",
            "Epoch: 50. Loss: 0.5455660051458565\n",
            "Epoch: 60. Loss: 0.5402273211670484\n",
            "Epoch: 70. Loss: 0.5359376394717492\n",
            "Epoch: 80. Loss: 0.5323513475060295\n",
            "Epoch: 90. Loss: 0.5293059856367526\n",
            "Epoch: 100. Loss: 0.5267049007962142\n",
            "Epoch: 110. Loss: 0.5244790632164581\n",
            "Epoch: 120. Loss: 0.5225737953139185\n",
            "Epoch: 130. Loss: 0.5209435732861183\n",
            "Epoch: 140. Loss: 0.5195496299805495\n",
            "Epoch: 150. Loss: 0.5183586290860813\n",
            "Epoch: 160. Loss: 0.5173417985822722\n",
            "Epoch: 170. Loss: 0.5164742871123429\n",
            "Epoch: 180. Loss: 0.5157346441450487\n",
            "Epoch: 190. Loss: 0.515104379280514\n",
            "Epoch: 200. Loss: 0.5145675792041248\n",
            "Epoch: 210. Loss: 0.5141105710510245\n",
            "Epoch: 220. Loss: 0.513721625571586\n",
            "Epoch: 230. Loss: 0.5133906955768054\n",
            "Epoch: 240. Loss: 0.5131091860841213\n",
            "Epoch: 250. Loss: 0.5128697530247547\n",
            "Epoch: 260. Loss: 0.5126661276139206\n",
            "Epoch: 270. Loss: 0.512492963660837\n",
            "Epoch: 280. Loss: 0.5123457052626221\n",
            "Epoch: 290. Loss: 0.5122204725035567\n",
            "Epoch: 300. Loss: 0.5121139629706395\n",
            "Epoch: 310. Loss: 0.512023367093131\n",
            "Epoch: 320. Loss: 0.5119462955114952\n",
            "Epoch: 330. Loss: 0.5118807168739379\n",
            "Epoch: 340. Loss: 0.5118249046420986\n",
            "Epoch: 350. Loss: 0.5117773916582826\n",
            "Epoch: 360. Loss: 0.5117369313831887\n",
            "Epoch: 370. Loss: 0.5117024648546317\n",
            "Epoch: 380. Loss: 0.5116730925443312\n",
            "Epoch: 390. Loss: 0.5116480504020133\n",
            "Epoch: 400. Loss: 0.5116266894747381\n",
            "Epoch: 410. Loss: 0.5116084585756284\n",
            "Epoch: 420. Loss: 0.5115928895512145\n",
            "Epoch: 430. Loss: 0.5115795847616128\n",
            "Epoch: 440. Loss: 0.5115682064438505\n",
            "Epoch: 450. Loss: 0.5115584676769556\n",
            "Epoch: 460. Loss: 0.5115501247088761\n",
            "Epoch: 470. Loss: 0.5115429704408315\n",
            "Epoch: 480. Loss: 0.5115368288950851\n",
            "Epoch: 490. Loss: 0.5115315505180839\n",
            "tensor(0.6753, dtype=torch.float64)\n",
            "2021-12-19 00:00:00\n",
            "Epoch: 0. Loss: 1.1913475787763639\n",
            "Epoch: 10. Loss: 0.9676605220903446\n",
            "Epoch: 20. Loss: 0.798137990088941\n",
            "Epoch: 30. Loss: 0.6837808356445165\n",
            "Epoch: 40. Loss: 0.6154855542400994\n",
            "Epoch: 50. Loss: 0.5778469443787467\n",
            "Epoch: 60. Loss: 0.5585670339529976\n",
            "Epoch: 70. Loss: 0.5491050301693027\n",
            "Epoch: 80. Loss: 0.5442745221658923\n",
            "Epoch: 90. Loss: 0.541462873113104\n",
            "Epoch: 100. Loss: 0.5395278253423305\n",
            "Epoch: 110. Loss: 0.5380057009805902\n",
            "Epoch: 120. Loss: 0.5367111888797449\n",
            "Epoch: 130. Loss: 0.5355669985827394\n",
            "Epoch: 140. Loss: 0.5345371345596235\n",
            "Epoch: 150. Loss: 0.5336017426893973\n",
            "Epoch: 160. Loss: 0.5327477395620596\n",
            "Epoch: 170. Loss: 0.5319652797154402\n",
            "Epoch: 180. Loss: 0.5312463633282444\n",
            "Epoch: 190. Loss: 0.530584233944968\n",
            "Epoch: 200. Loss: 0.5299730761830005\n",
            "Epoch: 210. Loss: 0.5294078348736072\n",
            "Epoch: 220. Loss: 0.5288840893447939\n",
            "Epoch: 230. Loss: 0.5283979571181159\n",
            "Epoch: 240. Loss: 0.5279460161459394\n",
            "Epoch: 250. Loss: 0.5275252403313282\n",
            "Epoch: 260. Loss: 0.5271329453348895\n",
            "Epoch: 270. Loss: 0.5267667426880632\n",
            "Epoch: 280. Loss: 0.526424500760451\n",
            "Epoch: 290. Loss: 0.5261043114494357\n",
            "Epoch: 300. Loss: 0.5258044616805573\n",
            "Epoch: 310. Loss: 0.5255234089708852\n",
            "Epoch: 320. Loss: 0.5252597604352208\n",
            "Epoch: 330. Loss: 0.5250122547170653\n",
            "Epoch: 340. Loss: 0.5247797464093321\n",
            "Epoch: 350. Loss: 0.5245611925981006\n",
            "Epoch: 360. Loss: 0.5243556412193497\n",
            "Epoch: 370. Loss: 0.5241622209658946\n",
            "Epoch: 380. Loss: 0.5239801325213904\n",
            "Epoch: 390. Loss: 0.5238086409316638\n",
            "Epoch: 400. Loss: 0.5236470689518227\n",
            "Epoch: 410. Loss: 0.5234947912314855\n",
            "Epoch: 420. Loss: 0.5233512292207098\n",
            "Epoch: 430. Loss: 0.5232158466964205\n",
            "Epoch: 440. Loss: 0.5230881458237574\n",
            "Epoch: 450. Loss: 0.5229676636792169\n",
            "Epoch: 460. Loss: 0.5228539691730657\n",
            "Epoch: 470. Loss: 0.5227466603175324\n",
            "Epoch: 480. Loss: 0.5226453617949786\n",
            "Epoch: 490. Loss: 0.522549722786817\n",
            "tensor(0.6986, dtype=torch.float64)\n",
            "2021-12-26 00:00:00\n",
            "Epoch: 0. Loss: 1.261305534413906\n",
            "Epoch: 10. Loss: 0.9455874583110019\n",
            "Epoch: 20. Loss: 0.7408285308531816\n",
            "Epoch: 30. Loss: 0.6177262312025589\n",
            "Epoch: 40. Loss: 0.5645897744344903\n",
            "Epoch: 50. Loss: 0.5450538762571391\n",
            "Epoch: 60. Loss: 0.5371305821595308\n",
            "Epoch: 70. Loss: 0.5333746761695158\n",
            "Epoch: 80. Loss: 0.5313190558358252\n",
            "Epoch: 90. Loss: 0.5300403196948459\n",
            "Epoch: 100. Loss: 0.529151850197924\n",
            "Epoch: 110. Loss: 0.5284770205560142\n",
            "Epoch: 120. Loss: 0.5279289716408743\n",
            "Epoch: 130. Loss: 0.5274620579695221\n",
            "Epoch: 140. Loss: 0.5270508154533852\n",
            "Epoch: 150. Loss: 0.5266802694600913\n",
            "Epoch: 160. Loss: 0.5263411929490542\n",
            "Epoch: 170. Loss: 0.5260276504740586\n",
            "Epoch: 180. Loss: 0.5257356602040549\n",
            "Epoch: 190. Loss: 0.5254624340814752\n",
            "Epoch: 200. Loss: 0.5252059321297631\n",
            "Epoch: 210. Loss: 0.5249645945345122\n",
            "Epoch: 220. Loss: 0.5247371775093576\n",
            "Epoch: 230. Loss: 0.5245226511641077\n",
            "Epoch: 240. Loss: 0.5243201350461558\n",
            "Epoch: 250. Loss: 0.5241288568676825\n",
            "Epoch: 260. Loss: 0.5239481256510702\n",
            "Epoch: 270. Loss: 0.5237773139236932\n",
            "Epoch: 280. Loss: 0.5236158456448936\n",
            "Epoch: 290. Loss: 0.5234631878005389\n",
            "Epoch: 300. Loss: 0.5233188443716772\n",
            "Epoch: 310. Loss: 0.5231823518616171\n",
            "Epoch: 320. Loss: 0.5230532758634132\n",
            "Epoch: 330. Loss: 0.522931208336102\n",
            "Epoch: 340. Loss: 0.5228157653752777\n",
            "Epoch: 350. Loss: 0.522706585337773\n",
            "Epoch: 360. Loss: 0.5226033272274062\n",
            "Epoch: 370. Loss: 0.522505669279032\n",
            "Epoch: 380. Loss: 0.5224133076977063\n",
            "Epoch: 390. Loss: 0.5223259555225764\n",
            "Epoch: 400. Loss: 0.5222433415935883\n",
            "Epoch: 410. Loss: 0.5221652096048107\n",
            "Epoch: 420. Loss: 0.5220913172320774\n",
            "Epoch: 430. Loss: 0.5220214353253835\n",
            "Epoch: 440. Loss: 0.5219553471584225\n",
            "Epoch: 450. Loss: 0.5218928477290734\n",
            "Epoch: 460. Loss: 0.5218337431057155\n",
            "Epoch: 470. Loss: 0.521777849815065\n",
            "Epoch: 480. Loss: 0.5217249942678612\n",
            "Epoch: 490. Loss: 0.521675012219235\n",
            "tensor(0.7087, dtype=torch.float64)\n",
            "2022-01-02 00:00:00\n",
            "Epoch: 0. Loss: 0.9469568329772552\n",
            "Epoch: 10. Loss: 0.7551459837329794\n",
            "Epoch: 20. Loss: 0.6698659751696311\n",
            "Epoch: 30. Loss: 0.6242656035560112\n",
            "Epoch: 40. Loss: 0.5997893638828656\n",
            "Epoch: 50. Loss: 0.5852131103113118\n",
            "Epoch: 60. Loss: 0.5751554440257071\n",
            "Epoch: 70. Loss: 0.5673616420736584\n",
            "Epoch: 80. Loss: 0.5609033541899475\n",
            "Epoch: 90. Loss: 0.5553773685797606\n",
            "Epoch: 100. Loss: 0.5505858978145681\n",
            "Epoch: 110. Loss: 0.5464125969180381\n",
            "Epoch: 120. Loss: 0.5427749949095183\n",
            "Epoch: 130. Loss: 0.539606437596074\n",
            "Epoch: 140. Loss: 0.5368493175121717\n",
            "Epoch: 150. Loss: 0.5344525358166499\n",
            "Epoch: 160. Loss: 0.5323704877361378\n",
            "Epoch: 170. Loss: 0.5305625528256401\n",
            "Epoch: 180. Loss: 0.528992723597091\n",
            "Epoch: 190. Loss: 0.5276292536537458\n",
            "Epoch: 200. Loss: 0.526444297028989\n",
            "Epoch: 210. Loss: 0.5254135407801384\n",
            "Epoch: 220. Loss: 0.5245158407368352\n",
            "Epoch: 230. Loss: 0.523732870238789\n",
            "Epoch: 240. Loss: 0.523048789286736\n",
            "Epoch: 250. Loss: 0.5224499388249708\n",
            "Epoch: 260. Loss: 0.5219245625584222\n",
            "Epoch: 270. Loss: 0.5214625569424657\n",
            "Epoch: 280. Loss: 0.5210552487383638\n",
            "Epoch: 290. Loss: 0.5206951987105218\n",
            "Epoch: 300. Loss: 0.5203760295546879\n",
            "Epoch: 310. Loss: 0.5200922759006471\n",
            "Epoch: 320. Loss: 0.519839254156978\n",
            "Epoch: 330. Loss: 0.5196129500033217\n",
            "Epoch: 340. Loss: 0.5194099214457489\n",
            "Epoch: 350. Loss: 0.5192272155029904\n",
            "Epoch: 360. Loss: 0.5190622967643144\n",
            "Epoch: 370. Loss: 0.518912986239159\n",
            "Epoch: 380. Loss: 0.5187774090947848\n",
            "Epoch: 390. Loss: 0.5186539500452682\n",
            "Epoch: 400. Loss: 0.5185412153097632\n",
            "Epoch: 410. Loss: 0.5184380001984776\n",
            "Epoch: 420. Loss: 0.518343261510823\n",
            "Epoch: 430. Loss: 0.5182560940419941\n",
            "Epoch: 440. Loss: 0.5181757105926192\n",
            "Epoch: 450. Loss: 0.5181014249620992\n",
            "Epoch: 460. Loss: 0.5180326374810131\n",
            "Epoch: 470. Loss: 0.5179688227026511\n",
            "Epoch: 480. Loss: 0.5179095189295235\n",
            "Epoch: 490. Loss: 0.51785431929865\n",
            "tensor(0.7139, dtype=torch.float64)\n",
            "2022-01-09 00:00:00\n",
            "Epoch: 0. Loss: 1.879130018732385\n",
            "Epoch: 10. Loss: 0.8555777829497581\n",
            "Epoch: 20. Loss: 0.6596371214149308\n",
            "Epoch: 30. Loss: 0.5788902059773731\n",
            "Epoch: 40. Loss: 0.5481647036321607\n",
            "Epoch: 50. Loss: 0.5354767776565232\n",
            "Epoch: 60. Loss: 0.5294235529437779\n",
            "Epoch: 70. Loss: 0.5261673147942298\n",
            "Epoch: 80. Loss: 0.5242354205877988\n",
            "Epoch: 90. Loss: 0.5230032988681471\n",
            "Epoch: 100. Loss: 0.5221793217177327\n",
            "Epoch: 110. Loss: 0.5216117688243448\n",
            "Epoch: 120. Loss: 0.5212131543575037\n",
            "Epoch: 130. Loss: 0.5209289623611156\n",
            "Epoch: 140. Loss: 0.5207235428739297\n",
            "Epoch: 150. Loss: 0.5205729578900224\n",
            "Epoch: 160. Loss: 0.5204609078240195\n",
            "Epoch: 170. Loss: 0.5203762040679645\n",
            "Epoch: 180. Loss: 0.5203111194072062\n",
            "Epoch: 190. Loss: 0.5202602842001856\n",
            "Epoch: 200. Loss: 0.5202199399757234\n",
            "Epoch: 210. Loss: 0.5201874328553616\n",
            "Epoch: 220. Loss: 0.520160869349321\n",
            "Epoch: 230. Loss: 0.5201388822980201\n",
            "Epoch: 240. Loss: 0.520120471476636\n",
            "Epoch: 250. Loss: 0.520104894751209\n",
            "Epoch: 260. Loss: 0.5200915934407256\n",
            "Epoch: 270. Loss: 0.5200801408353645\n",
            "Epoch: 280. Loss: 0.520070206418064\n",
            "Epoch: 290. Loss: 0.5200615307692771\n",
            "Epoch: 300. Loss: 0.5200539077740333\n",
            "Epoch: 310. Loss: 0.5200471718520125\n",
            "Epoch: 320. Loss: 0.52004118867036\n",
            "Epoch: 330. Loss: 0.520035848294465\n",
            "Epoch: 340. Loss: 0.520031060064336\n",
            "Epoch: 350. Loss: 0.5200267487075547\n",
            "Epoch: 360. Loss: 0.520022851350334\n",
            "Epoch: 370. Loss: 0.520019315190074\n",
            "Epoch: 380. Loss: 0.520016095662145\n",
            "Epoch: 390. Loss: 0.5200131549811502\n",
            "Epoch: 400. Loss: 0.520010460969772\n",
            "Epoch: 410. Loss: 0.5200079861112442\n",
            "Epoch: 420. Loss: 0.5200057067776992\n",
            "Epoch: 430. Loss: 0.5200036025982343\n",
            "Epoch: 440. Loss: 0.5200016559389443\n",
            "Epoch: 450. Loss: 0.5199998514733601\n",
            "Epoch: 460. Loss: 0.519998175826345\n",
            "Epoch: 470. Loss: 0.5199966172779951\n",
            "Epoch: 480. Loss: 0.5199951655167768\n",
            "Epoch: 490. Loss: 0.5199938114332122\n",
            "tensor(0.8294, dtype=torch.float64)\n",
            "2022-01-16 00:00:00\n",
            "Epoch: 0. Loss: 0.8968666669339814\n",
            "Epoch: 10. Loss: 0.7916270419086738\n",
            "Epoch: 20. Loss: 0.7202288069812137\n",
            "Epoch: 30. Loss: 0.671395040351263\n",
            "Epoch: 40. Loss: 0.6377231740218551\n",
            "Epoch: 50. Loss: 0.6134729909482148\n",
            "Epoch: 60. Loss: 0.5950518257682323\n",
            "Epoch: 70. Loss: 0.5805335870937637\n",
            "Epoch: 80. Loss: 0.56889775447882\n",
            "Epoch: 90. Loss: 0.5595287427019429\n",
            "Epoch: 100. Loss: 0.5519861152734397\n",
            "Epoch: 110. Loss: 0.5459191981754109\n",
            "Epoch: 120. Loss: 0.5410386299777596\n",
            "Epoch: 130. Loss: 0.5371057468811509\n",
            "Epoch: 140. Loss: 0.5339260983515598\n",
            "Epoch: 150. Loss: 0.5313434010956579\n",
            "Epoch: 160. Loss: 0.5292334694182905\n",
            "Epoch: 170. Loss: 0.5274984276939121\n",
            "Epoch: 180. Loss: 0.5260615219612081\n",
            "Epoch: 190. Loss: 0.5248626944044013\n",
            "Epoch: 200. Loss: 0.523854945782088\n",
            "Epoch: 210. Loss: 0.5230014242799043\n",
            "Epoch: 220. Loss: 0.5222731387703834\n",
            "Epoch: 230. Loss: 0.5216471846659888\n",
            "Epoch: 240. Loss: 0.5211053777327037\n",
            "Epoch: 250. Loss: 0.5206332058990116\n",
            "Epoch: 260. Loss: 0.520219025605782\n",
            "Epoch: 270. Loss: 0.5198534446962216\n",
            "Epoch: 280. Loss: 0.5195288470411576\n",
            "Epoch: 290. Loss: 0.5192390247715111\n",
            "Epoch: 300. Loss: 0.518978892338164\n",
            "Epoch: 310. Loss: 0.5187442630045765\n",
            "Epoch: 320. Loss: 0.5185316731929548\n",
            "Epoch: 330. Loss: 0.5183382437062273\n",
            "Epoch: 340. Loss: 0.5181615695306987\n",
            "Epoch: 350. Loss: 0.5179996319208234\n",
            "Epoch: 360. Loss: 0.517850727956078\n",
            "Epoch: 370. Loss: 0.5177134138737159\n",
            "Epoch: 380. Loss: 0.5175864593188235\n",
            "Epoch: 390. Loss: 0.5174688102868422\n",
            "Epoch: 400. Loss: 0.5173595590164093\n",
            "Epoch: 410. Loss: 0.5172579194605387\n",
            "Epoch: 420. Loss: 0.517163207250033\n",
            "Epoch: 430. Loss: 0.5170748232852488\n",
            "Epoch: 440. Loss: 0.5169922402662174\n",
            "Epoch: 450. Loss: 0.5169149916079444\n",
            "Epoch: 460. Loss: 0.5168426622959816\n",
            "Epoch: 470. Loss: 0.5167748813234104\n",
            "Epoch: 480. Loss: 0.5167113154190875\n",
            "Epoch: 490. Loss: 0.5166516638320406\n",
            "tensor(0.8840, dtype=torch.float64)\n",
            "2022-01-23 00:00:00\n",
            "Epoch: 0. Loss: 1.5559852026605312\n",
            "Epoch: 10. Loss: 0.6461338598320676\n",
            "Epoch: 20. Loss: 0.6052915427699797\n",
            "Epoch: 30. Loss: 0.5827949403966481\n",
            "Epoch: 40. Loss: 0.5685272462970848\n",
            "Epoch: 50. Loss: 0.5589780819314712\n",
            "Epoch: 60. Loss: 0.5523872203726696\n",
            "Epoch: 70. Loss: 0.5477282070683195\n",
            "Epoch: 80. Loss: 0.5443570344142927\n",
            "Epoch: 90. Loss: 0.5418599545272398\n",
            "Epoch: 100. Loss: 0.539968605919236\n",
            "Epoch: 110. Loss: 0.5385070031790178\n",
            "Epoch: 120. Loss: 0.5373578398621723\n",
            "Epoch: 130. Loss: 0.5364412500889809\n",
            "Epoch: 140. Loss: 0.5357015234712367\n",
            "Epoch: 150. Loss: 0.5350988003816518\n",
            "Epoch: 160. Loss: 0.5346038479433092\n",
            "Epoch: 170. Loss: 0.5341947339304242\n",
            "Epoch: 180. Loss: 0.5338546728523133\n",
            "Epoch: 190. Loss: 0.5335706016169355\n",
            "Epoch: 200. Loss: 0.5333322148356737\n",
            "Epoch: 210. Loss: 0.5331312944099806\n",
            "Epoch: 220. Loss: 0.5329612312901413\n",
            "Epoch: 230. Loss: 0.5328166756333017\n",
            "Epoch: 240. Loss: 0.532693274939793\n",
            "Epoch: 250. Loss: 0.5325874740776586\n",
            "Epoch: 260. Loss: 0.5324963599896568\n",
            "Epoch: 270. Loss: 0.5324175394575372\n",
            "Epoch: 280. Loss: 0.5323490418615922\n",
            "Epoch: 290. Loss: 0.5322892411941011\n",
            "Epoch: 300. Loss: 0.5322367931317061\n",
            "Epoch: 310. Loss: 0.5321905840287906\n",
            "Epoch: 320. Loss: 0.5321496894360249\n",
            "Epoch: 330. Loss: 0.5321133402832529\n",
            "Epoch: 340. Loss: 0.5320808952614184\n",
            "Epoch: 350. Loss: 0.5320518182372558\n",
            "Epoch: 360. Loss: 0.5320256597649048\n",
            "Epoch: 370. Loss: 0.5320020419389925\n",
            "Epoch: 380. Loss: 0.531980645976667\n",
            "Epoch: 390. Loss: 0.5319612020304273\n",
            "Epoch: 400. Loss: 0.5319434808257184\n",
            "Epoch: 410. Loss: 0.5319272867918646\n",
            "Epoch: 420. Loss: 0.5319124524155369\n",
            "Epoch: 430. Loss: 0.531898833595357\n",
            "Epoch: 440. Loss: 0.5318863058165467\n",
            "Epoch: 450. Loss: 0.5318747609974813\n",
            "Epoch: 460. Loss: 0.5318641048869316\n",
            "Epoch: 470. Loss: 0.531854254912816\n",
            "Epoch: 480. Loss: 0.5318451384013045\n",
            "Epoch: 490. Loss: 0.5318366910998589\n",
            "tensor(0.5176, dtype=torch.float64)\n",
            "2022-01-30 00:00:00\n",
            "Epoch: 0. Loss: 1.077490973587081\n",
            "Epoch: 10. Loss: 0.7375335996151094\n",
            "Epoch: 20. Loss: 0.6618972829318485\n",
            "Epoch: 30. Loss: 0.6167965559390117\n",
            "Epoch: 40. Loss: 0.5914629508541931\n",
            "Epoch: 50. Loss: 0.5776748166205309\n",
            "Epoch: 60. Loss: 0.5697993647100729\n",
            "Epoch: 70. Loss: 0.5648551992171337\n",
            "Epoch: 80. Loss: 0.5614604515044231\n",
            "Epoch: 90. Loss: 0.5589770788944771\n",
            "Epoch: 100. Loss: 0.5570839988191828\n",
            "Epoch: 110. Loss: 0.5555993780937581\n",
            "Epoch: 120. Loss: 0.5544093255048993\n",
            "Epoch: 130. Loss: 0.5534375689693654\n",
            "Epoch: 140. Loss: 0.552630931100056\n",
            "Epoch: 150. Loss: 0.5519513893177784\n",
            "Epoch: 160. Loss: 0.5513712609274755\n",
            "Epoch: 170. Loss: 0.5508700870509495\n",
            "Epoch: 180. Loss: 0.5504325399161074\n",
            "Epoch: 190. Loss: 0.5500469861238024\n",
            "Epoch: 200. Loss: 0.5497044850522331\n",
            "Epoch: 210. Loss: 0.549398081689498\n",
            "Epoch: 220. Loss: 0.5491223014429832\n",
            "Epoch: 230. Loss: 0.548872785134156\n",
            "Epoch: 240. Loss: 0.5486460223933265\n",
            "Epoch: 250. Loss: 0.5484391549065937\n",
            "Epoch: 260. Loss: 0.5482498298078098\n",
            "Epoch: 270. Loss: 0.5480760894620254\n",
            "Epoch: 280. Loss: 0.5479162879324644\n",
            "Epoch: 290. Loss: 0.5477690271997989\n",
            "Epoch: 300. Loss: 0.5476331081293837\n",
            "Epoch: 310. Loss: 0.5475074925348509\n",
            "Epoch: 320. Loss: 0.5473912736474245\n",
            "Epoch: 330. Loss: 0.5472836529908915\n",
            "Epoch: 340. Loss: 0.5471839221639458\n",
            "Epoch: 350. Loss: 0.5470914483999268\n",
            "Epoch: 360. Loss: 0.5470056630468076\n",
            "Epoch: 370. Loss: 0.5469260523140073\n",
            "Epoch: 380. Loss: 0.5468521497857991\n",
            "Epoch: 390. Loss: 0.5467835303169661\n",
            "Epoch: 400. Loss: 0.5467198050144425\n",
            "Epoch: 410. Loss: 0.546660617075934\n",
            "Epoch: 420. Loss: 0.546605638308023\n",
            "Epoch: 430. Loss: 0.5465545661858499\n",
            "Epoch: 440. Loss: 0.5465071213469433\n",
            "Epoch: 450. Loss: 0.5464630454353063\n",
            "Epoch: 460. Loss: 0.5464220992300544\n",
            "Epoch: 470. Loss: 0.5463840610069954\n",
            "Epoch: 480. Loss: 0.5463487250924736\n",
            "Epoch: 490. Loss: 0.5463159005772849\n",
            "tensor(0.6373, dtype=torch.float64)\n",
            "2022-02-06 00:00:00\n",
            "Epoch: 0. Loss: 2.281788502364055\n",
            "Epoch: 10. Loss: 0.6356113843039981\n",
            "Epoch: 20. Loss: 0.6189389537093337\n",
            "Epoch: 30. Loss: 0.611516092863426\n",
            "Epoch: 40. Loss: 0.6058098117868943\n",
            "Epoch: 50. Loss: 0.6010478904921898\n",
            "Epoch: 60. Loss: 0.5969369162028919\n",
            "Epoch: 70. Loss: 0.5933059340011018\n",
            "Epoch: 80. Loss: 0.5900414735648928\n",
            "Epoch: 90. Loss: 0.5870657604805298\n",
            "Epoch: 100. Loss: 0.5843249353627333\n",
            "Epoch: 110. Loss: 0.5817813570581678\n",
            "Epoch: 120. Loss: 0.5794083505266443\n",
            "Epoch: 130. Loss: 0.5771866139573092\n",
            "Epoch: 140. Loss: 0.5751017784681998\n",
            "Epoch: 150. Loss: 0.5731427654367268\n",
            "Epoch: 160. Loss: 0.5713006906021653\n",
            "Epoch: 170. Loss: 0.5695681392653891\n",
            "Epoch: 180. Loss: 0.5679386910170248\n",
            "Epoch: 190. Loss: 0.5664066107946236\n",
            "Epoch: 200. Loss: 0.5649666498819773\n",
            "Epoch: 210. Loss: 0.5636139189647418\n",
            "Epoch: 220. Loss: 0.5623438079870753\n",
            "Epoch: 230. Loss: 0.5611519360983862\n",
            "Epoch: 240. Loss: 0.560034120713281\n",
            "Epoch: 250. Loss: 0.5589863585279792\n",
            "Epoch: 260. Loss: 0.558004813864677\n",
            "Epoch: 270. Loss: 0.5570858113778917\n",
            "Epoch: 280. Loss: 0.5562258312434134\n",
            "Epoch: 290. Loss: 0.5554215056562392\n",
            "Epoch: 300. Loss: 0.5546696159192388\n",
            "Epoch: 310. Loss: 0.5539670896960466\n",
            "Epoch: 320. Loss: 0.5533109981869131\n",
            "Epoch: 330. Loss: 0.5526985531026402\n",
            "Epoch: 340. Loss: 0.5521271033837092\n",
            "Epoch: 350. Loss: 0.5515941316553014\n",
            "Epoch: 360. Loss: 0.5510972504343573\n",
            "Epoch: 370. Loss: 0.550634198118833\n",
            "Epoch: 380. Loss: 0.5502028347961123\n",
            "Epoch: 390. Loss: 0.5498011379098903\n",
            "Epoch: 400. Loss: 0.5494271978244856\n",
            "Epoch: 410. Loss: 0.5490792133235943\n",
            "Epoch: 420. Loss: 0.5487554870776568\n",
            "Epoch: 430. Loss: 0.5484544211107354\n",
            "Epoch: 440. Loss: 0.5481745122943653\n",
            "Epoch: 450. Loss: 0.5479143478924207\n",
            "Epoch: 460. Loss: 0.5476726011777455\n",
            "Epoch: 470. Loss: 0.5474480271381862\n",
            "Epoch: 480. Loss: 0.5472394582867807\n",
            "Epoch: 490. Loss: 0.5470458005882005\n",
            "tensor(0.6573, dtype=torch.float64)\n",
            "2022-02-13 00:00:00\n",
            "Epoch: 0. Loss: 2.3848071079749538\n",
            "Epoch: 10. Loss: 1.340148748084672\n",
            "Epoch: 20. Loss: 1.016522938202531\n",
            "Epoch: 30. Loss: 0.855968237663359\n",
            "Epoch: 40. Loss: 0.7704621143448868\n",
            "Epoch: 50. Loss: 0.7192613569774868\n",
            "Epoch: 60. Loss: 0.6827551933332274\n",
            "Epoch: 70. Loss: 0.654229320919197\n",
            "Epoch: 80. Loss: 0.63160124821665\n",
            "Epoch: 90. Loss: 0.6138805599202444\n",
            "Epoch: 100. Loss: 0.6002575755308137\n",
            "Epoch: 110. Loss: 0.5899452050598606\n",
            "Epoch: 120. Loss: 0.5822017451944974\n",
            "Epoch: 130. Loss: 0.5763797333035566\n",
            "Epoch: 140. Loss: 0.5719543953608153\n",
            "Epoch: 150. Loss: 0.5685250962640983\n",
            "Epoch: 160. Loss: 0.5657992423061814\n",
            "Epoch: 170. Loss: 0.5635697382967421\n",
            "Epoch: 180. Loss: 0.56169309754475\n",
            "Epoch: 190. Loss: 0.5600712606348843\n",
            "Epoch: 200. Loss: 0.558637727940523\n",
            "Epoch: 210. Loss: 0.5573475135053965\n",
            "Epoch: 220. Loss: 0.556170104301655\n",
            "Epoch: 230. Loss: 0.5550846345035887\n",
            "Epoch: 240. Loss: 0.5540766291478032\n",
            "Epoch: 250. Loss: 0.5531358315905003\n",
            "Epoch: 260. Loss: 0.5522547663735049\n",
            "Epoch: 270. Loss: 0.5514277948311178\n",
            "Epoch: 280. Loss: 0.5506504977231887\n",
            "Epoch: 290. Loss: 0.549919273302633\n",
            "Epoch: 300. Loss: 0.5492310764471264\n",
            "Epoch: 310. Loss: 0.5485832496873454\n",
            "Epoch: 320. Loss: 0.5479734138355802\n",
            "Epoch: 330. Loss: 0.547399397114852\n",
            "Epoch: 340. Loss: 0.5468591890673522\n",
            "Epoch: 350. Loss: 0.54635091035605\n",
            "Epoch: 360. Loss: 0.5458727927261595\n",
            "Epoch: 370. Loss: 0.5454231654404494\n",
            "Epoch: 380. Loss: 0.5450004458267932\n",
            "Epoch: 390. Loss: 0.5446031324302423\n",
            "Epoch: 400. Loss: 0.5442297998107405\n",
            "Epoch: 410. Loss: 0.5438790943792842\n",
            "Epoch: 420. Loss: 0.5435497308900914\n",
            "Epoch: 430. Loss: 0.5432404893495105\n",
            "Epoch: 440. Loss: 0.5429502121933397\n",
            "Epoch: 450. Loss: 0.5426778016417522\n",
            "Epoch: 460. Loss: 0.5424222171772363\n",
            "Epoch: 470. Loss: 0.5421824731136249\n",
            "Epoch: 480. Loss: 0.541957636238324\n",
            "Epoch: 490. Loss: 0.5417468235184365\n",
            "tensor(0.8031, dtype=torch.float64)\n",
            "2022-02-20 00:00:00\n",
            "Epoch: 0. Loss: 1.3609328133804472\n",
            "Epoch: 10. Loss: 0.9383687339857728\n",
            "Epoch: 20. Loss: 0.7256706524774582\n",
            "Epoch: 30. Loss: 0.6535728599781001\n",
            "Epoch: 40. Loss: 0.6226178538792215\n",
            "Epoch: 50. Loss: 0.6028240958790422\n",
            "Epoch: 60. Loss: 0.5879144695507093\n",
            "Epoch: 70. Loss: 0.5761316850251419\n",
            "Epoch: 80. Loss: 0.5667402457844709\n",
            "Epoch: 90. Loss: 0.5592825449499729\n",
            "Epoch: 100. Loss: 0.553400276694538\n",
            "Epoch: 110. Loss: 0.5487917118432437\n",
            "Epoch: 120. Loss: 0.5452017497915436\n",
            "Epoch: 130. Loss: 0.5424180526565017\n",
            "Epoch: 140. Loss: 0.5402670495770486\n",
            "Epoch: 150. Loss: 0.5386090987218326\n",
            "Epoch: 160. Loss: 0.537333294079185\n",
            "Epoch: 170. Loss: 0.5363524402789854\n",
            "Epoch: 180. Loss: 0.5355985202688222\n",
            "Epoch: 190. Loss: 0.5350187973411701\n",
            "Epoch: 200. Loss: 0.5345725715031108\n",
            "Epoch: 210. Loss: 0.5342285429228734\n",
            "Epoch: 220. Loss: 0.5339627049785207\n",
            "Epoch: 230. Loss: 0.5337566814679673\n",
            "Epoch: 240. Loss: 0.5335964265024862\n",
            "Epoch: 250. Loss: 0.5334712150406795\n",
            "Epoch: 260. Loss: 0.5333728631996482\n",
            "Epoch: 270. Loss: 0.5332951284332051\n",
            "Epoch: 280. Loss: 0.5332332494764244\n",
            "Epoch: 290. Loss: 0.5331835943000381\n",
            "Epoch: 300. Loss: 0.5331433911881197\n",
            "Epoch: 310. Loss: 0.5331105235858392\n",
            "Epoch: 320. Loss: 0.5330833737530893\n",
            "Epoch: 330. Loss: 0.5330607037030772\n",
            "Epoch: 340. Loss: 0.5330415645847446\n",
            "Epoch: 350. Loss: 0.5330252277410922\n",
            "Epoch: 360. Loss: 0.5330111322722975\n",
            "Epoch: 370. Loss: 0.5329988451583176\n",
            "Epoch: 380. Loss: 0.5329880309342416\n",
            "Epoch: 390. Loss: 0.532978428628927\n",
            "Epoch: 400. Loss: 0.532969834224767\n",
            "Epoch: 410. Loss: 0.5329620873135963\n",
            "Epoch: 420. Loss: 0.5329550609414035\n",
            "Epoch: 430. Loss: 0.5329486538762572\n",
            "Epoch: 440. Loss: 0.5329427847177021\n",
            "Epoch: 450. Loss: 0.5329373874056605\n",
            "Epoch: 460. Loss: 0.5329324077931016\n",
            "Epoch: 470. Loss: 0.5329278010274469\n",
            "Epoch: 480. Loss: 0.532923529547004\n",
            "Epoch: 490. Loss: 0.5329195615452846\n",
            "tensor(0.5985, dtype=torch.float64)\n",
            "2022-02-27 00:00:00\n",
            "Epoch: 0. Loss: 1.1716158767751421\n",
            "Epoch: 10. Loss: 0.9325027563182892\n",
            "Epoch: 20. Loss: 0.7779602601791594\n",
            "Epoch: 30. Loss: 0.6907982263844883\n",
            "Epoch: 40. Loss: 0.6399518185411217\n",
            "Epoch: 50. Loss: 0.6057766993368239\n",
            "Epoch: 60. Loss: 0.5821971180257622\n",
            "Epoch: 70. Loss: 0.5664273593162986\n",
            "Epoch: 80. Loss: 0.5562392022178806\n",
            "Epoch: 90. Loss: 0.5498020370287384\n",
            "Epoch: 100. Loss: 0.5457710639672678\n",
            "Epoch: 110. Loss: 0.5432435619558185\n",
            "Epoch: 120. Loss: 0.541645492738656\n",
            "Epoch: 130. Loss: 0.5406217787688816\n",
            "Epoch: 140. Loss: 0.5399551789139383\n",
            "Epoch: 150. Loss: 0.5395129130666676\n",
            "Epoch: 160. Loss: 0.5392134188485594\n",
            "Epoch: 170. Loss: 0.5390061575138497\n",
            "Epoch: 180. Loss: 0.5388594619901347\n",
            "Epoch: 190. Loss: 0.5387532318674274\n",
            "Epoch: 200. Loss: 0.5386745256758431\n",
            "Epoch: 210. Loss: 0.5386148836858701\n",
            "Epoch: 220. Loss: 0.5385686878146237\n",
            "Epoch: 230. Loss: 0.5385321467130982\n",
            "Epoch: 240. Loss: 0.5385026605630187\n",
            "Epoch: 250. Loss: 0.5384784185385005\n",
            "Epoch: 260. Loss: 0.5384581402642117\n",
            "Epoch: 270. Loss: 0.5384409073889945\n",
            "Epoch: 280. Loss: 0.5384260522458438\n",
            "Epoch: 290. Loss: 0.5384130831526053\n",
            "Epoch: 300. Loss: 0.5384016335593402\n",
            "Epoch: 310. Loss: 0.5383914269406505\n",
            "Epoch: 320. Loss: 0.5383822522362549\n",
            "Epoch: 330. Loss: 0.5383739464606495\n",
            "Epoch: 340. Loss: 0.5383663822530992\n",
            "Epoch: 350. Loss: 0.5383594588766278\n",
            "Epoch: 360. Loss: 0.5383530956537567\n",
            "Epoch: 370. Loss: 0.5383472271423897\n",
            "Epoch: 380. Loss: 0.5383417995662266\n",
            "Epoch: 390. Loss: 0.5383367681571042\n",
            "Epoch: 400. Loss: 0.5383320951649809\n",
            "Epoch: 410. Loss: 0.5383277483597319\n",
            "Epoch: 420. Loss: 0.5383236998971517\n",
            "Epoch: 430. Loss: 0.5383199254559251\n",
            "Epoch: 440. Loss: 0.5383164035770203\n",
            "Epoch: 450. Loss: 0.5383131151548741\n",
            "Epoch: 460. Loss: 0.538310043042801\n",
            "Epoch: 470. Loss: 0.5383071717446609\n",
            "Epoch: 480. Loss: 0.5383044871719027\n",
            "Epoch: 490. Loss: 0.538301976450343\n",
            "tensor(0.8085, dtype=torch.float64)\n",
            "2022-03-06 00:00:00\n",
            "Epoch: 0. Loss: 8.012107357763966\n",
            "Epoch: 10. Loss: 0.7674584709733866\n",
            "Epoch: 20. Loss: 0.5914018348975277\n",
            "Epoch: 30. Loss: 0.5788199912388842\n",
            "Epoch: 40. Loss: 0.5730007705846435\n",
            "Epoch: 50. Loss: 0.5690527647171114\n",
            "Epoch: 60. Loss: 0.5660263720919445\n",
            "Epoch: 70. Loss: 0.5635932807237878\n",
            "Epoch: 80. Loss: 0.5615798308199049\n",
            "Epoch: 90. Loss: 0.5598743600735334\n",
            "Epoch: 100. Loss: 0.5584001733983098\n",
            "Epoch: 110. Loss: 0.5571033587350781\n",
            "Epoch: 120. Loss: 0.5559455607100939\n",
            "Epoch: 130. Loss: 0.5548992069708167\n",
            "Epoch: 140. Loss: 0.5539442486682985\n",
            "Epoch: 150. Loss: 0.5530659130797045\n",
            "Epoch: 160. Loss: 0.5522531479596434\n",
            "Epoch: 170. Loss: 0.5514975412580347\n",
            "Epoch: 180. Loss: 0.5507925681852592\n",
            "Epoch: 190. Loss: 0.5501330641759721\n",
            "Epoch: 200. Loss: 0.5495148542036755\n",
            "Epoch: 210. Loss: 0.548934490715657\n",
            "Epoch: 220. Loss: 0.5483890673559646\n",
            "Epoch: 230. Loss: 0.5478760858164242\n",
            "Epoch: 240. Loss: 0.5473933601115556\n",
            "Epoch: 250. Loss: 0.5469389473429214\n",
            "Epoch: 260. Loss: 0.5465110973014551\n",
            "Epoch: 270. Loss: 0.5461082155263577\n",
            "Epoch: 280. Loss: 0.5457288360167055\n",
            "Epoch: 290. Loss: 0.545371600894089\n",
            "Epoch: 300. Loss: 0.5450352450888498\n",
            "Epoch: 310. Loss: 0.5447185846692707\n",
            "Epoch: 320. Loss: 0.5444205078212234\n",
            "Epoch: 330. Loss: 0.5441399677626152\n",
            "Epoch: 340. Loss: 0.5438759770753103\n",
            "Epoch: 350. Loss: 0.5436276030798063\n",
            "Epoch: 360. Loss: 0.5433939639808584\n",
            "Epoch: 370. Loss: 0.5431742255866842\n",
            "Epoch: 380. Loss: 0.542967598458367\n",
            "Epoch: 390. Loss: 0.5427733353852752\n",
            "Epoch: 400. Loss: 0.5425907291108116\n",
            "Epoch: 410. Loss: 0.5424191102535303\n",
            "Epoch: 420. Loss: 0.5422578453837262\n",
            "Epoch: 430. Loss: 0.5421063352265446\n",
            "Epoch: 440. Loss: 0.5419640129705972\n",
            "Epoch: 450. Loss: 0.5418303426668134\n",
            "Epoch: 460. Loss: 0.5417048177063939\n",
            "Epoch: 470. Loss: 0.5415869593697095\n",
            "Epoch: 480. Loss: 0.5414763154401104\n",
            "Epoch: 490. Loss: 0.541372458878117\n",
            "tensor(0.9582, dtype=torch.float64)\n",
            "2022-03-13 00:00:00\n",
            "Epoch: 0. Loss: 4.504172787285761\n",
            "Epoch: 10. Loss: 0.6895250778808842\n",
            "Epoch: 20. Loss: 0.6310395340460861\n",
            "Epoch: 30. Loss: 0.6100470725362229\n",
            "Epoch: 40. Loss: 0.5957268337629785\n",
            "Epoch: 50. Loss: 0.5849659410803911\n",
            "Epoch: 60. Loss: 0.5768624450225284\n",
            "Epoch: 70. Loss: 0.5708002350847241\n",
            "Epoch: 80. Loss: 0.5662886461319218\n",
            "Epoch: 90. Loss: 0.5629423032708073\n",
            "Epoch: 100. Loss: 0.560465150803924\n",
            "Epoch: 110. Loss: 0.558633290420104\n",
            "Epoch: 120. Loss: 0.5572791165800799\n",
            "Epoch: 130. Loss: 0.5562779733184025\n",
            "Epoch: 140. Loss: 0.5555375173389994\n",
            "Epoch: 150. Loss: 0.5549895029690723\n",
            "Epoch: 160. Loss: 0.5545835587054704\n",
            "Epoch: 170. Loss: 0.5542825281492141\n",
            "Epoch: 180. Loss: 0.5540590074069379\n",
            "Epoch: 190. Loss: 0.5538927829878136\n",
            "Epoch: 200. Loss: 0.5537689408434795\n",
            "Epoch: 210. Loss: 0.5536764726617524\n",
            "Epoch: 220. Loss: 0.5536072492945913\n",
            "Epoch: 230. Loss: 0.5535552647227344\n",
            "Epoch: 240. Loss: 0.5535160791836744\n",
            "Epoch: 250. Loss: 0.5534864088697101\n",
            "Epoch: 260. Loss: 0.5534638234963496\n",
            "Epoch: 270. Loss: 0.5534465232817029\n",
            "Epoch: 280. Loss: 0.5534331744099487\n",
            "Epoch: 290. Loss: 0.5534227875872376\n",
            "Epoch: 300. Loss: 0.5534146283649067\n",
            "Epoch: 310. Loss: 0.553408150892794\n",
            "Epoch: 320. Loss: 0.5534029489616835\n",
            "Epoch: 330. Loss: 0.553398719809126\n",
            "Epoch: 340. Loss: 0.5533952373514838\n",
            "Epoch: 350. Loss: 0.5533923323802401\n",
            "Epoch: 360. Loss: 0.553389877905455\n",
            "Epoch: 370. Loss: 0.5533877783046036\n",
            "Epoch: 380. Loss: 0.5533859612856703\n",
            "Epoch: 390. Loss: 0.5533843719321013\n",
            "Epoch: 400. Loss: 0.5533829682882576\n",
            "Epoch: 410. Loss: 0.5533817180850855\n",
            "Epoch: 420. Loss: 0.5533805963099663\n",
            "Epoch: 430. Loss: 0.5533795834017446\n",
            "Epoch: 440. Loss: 0.5533786639088931\n",
            "Epoch: 450. Loss: 0.5533778254908841\n",
            "Epoch: 460. Loss: 0.5533770581739943\n",
            "Epoch: 470. Loss: 0.5533763537958122\n",
            "Epoch: 480. Loss: 0.5533757055897764\n",
            "Epoch: 490. Loss: 0.5533751078736819\n",
            "tensor(0.4587, dtype=torch.float64)\n",
            "2022-03-20 00:00:00\n",
            "Epoch: 0. Loss: 1.436910348660716\n",
            "Epoch: 10. Loss: 1.0913759678502442\n",
            "Epoch: 20. Loss: 0.9352744628233667\n",
            "Epoch: 30. Loss: 0.8281641574056445\n",
            "Epoch: 40. Loss: 0.7460409046125809\n",
            "Epoch: 50. Loss: 0.682397877714396\n",
            "Epoch: 60. Loss: 0.6355157612710978\n",
            "Epoch: 70. Loss: 0.6034588339844106\n",
            "Epoch: 80. Loss: 0.5830595396219808\n",
            "Epoch: 90. Loss: 0.5707636992869389\n",
            "Epoch: 100. Loss: 0.5635941720566052\n",
            "Epoch: 110. Loss: 0.5594804198851111\n",
            "Epoch: 120. Loss: 0.5571309146919327\n",
            "Epoch: 130. Loss: 0.5557857829452689\n",
            "Epoch: 140. Loss: 0.5550104257057528\n",
            "Epoch: 150. Loss: 0.5545590926518725\n",
            "Epoch: 160. Loss: 0.5542931308835775\n",
            "Epoch: 170. Loss: 0.554134102758346\n",
            "Epoch: 180. Loss: 0.5540373933489045\n",
            "Epoch: 190. Loss: 0.5539774418130844\n",
            "Epoch: 200. Loss: 0.5539394758809794\n",
            "Epoch: 210. Loss: 0.5539148710091976\n",
            "Epoch: 220. Loss: 0.5538985321900618\n",
            "Epoch: 230. Loss: 0.5538874083924635\n",
            "Epoch: 240. Loss: 0.5538796441595906\n",
            "Epoch: 250. Loss: 0.5538740915017947\n",
            "Epoch: 260. Loss: 0.5538700266903138\n",
            "Epoch: 270. Loss: 0.5538669843161992\n",
            "Epoch: 280. Loss: 0.5538646589417499\n",
            "Epoch: 290. Loss: 0.553862846036064\n",
            "Epoch: 300. Loss: 0.5538614059640078\n",
            "Epoch: 310. Loss: 0.5538602416580028\n",
            "Epoch: 320. Loss: 0.5538592845186157\n",
            "Epoch: 330. Loss: 0.5538584853389884\n",
            "Epoch: 340. Loss: 0.5538578083483799\n",
            "Epoch: 350. Loss: 0.5538572272278274\n",
            "Epoch: 360. Loss: 0.5538567223967362\n",
            "Epoch: 370. Loss: 0.5538562791344719\n",
            "Epoch: 380. Loss: 0.5538558862609599\n",
            "Epoch: 390. Loss: 0.5538555351981957\n",
            "Epoch: 400. Loss: 0.5538552192955123\n",
            "Epoch: 410. Loss: 0.5538549333400881\n",
            "Epoch: 420. Loss: 0.5538546731991445\n",
            "Epoch: 430. Loss: 0.5538544355567271\n",
            "Epoch: 440. Loss: 0.5538542177189948\n",
            "Epoch: 450. Loss: 0.5538540174694824\n",
            "Epoch: 460. Loss: 0.5538538329610172\n",
            "Epoch: 470. Loss: 0.5538536626346539\n",
            "Epoch: 480. Loss: 0.5538535051585964\n",
            "Epoch: 490. Loss: 0.5538533593819625\n",
            "tensor(0.7710, dtype=torch.float64)\n",
            "2022-03-27 00:00:00\n",
            "Epoch: 0. Loss: 1.1337704619856892\n",
            "Epoch: 10. Loss: 0.9156593051982066\n",
            "Epoch: 20. Loss: 0.7963555836742165\n",
            "Epoch: 30. Loss: 0.7153313749925725\n",
            "Epoch: 40. Loss: 0.6572293052929776\n",
            "Epoch: 50. Loss: 0.6176041955486518\n",
            "Epoch: 60. Loss: 0.5926757300635136\n",
            "Epoch: 70. Loss: 0.5780431308112371\n",
            "Epoch: 80. Loss: 0.5698117119969517\n",
            "Epoch: 90. Loss: 0.5652623541053126\n",
            "Epoch: 100. Loss: 0.562749036982878\n",
            "Epoch: 110. Loss: 0.561345168751885\n",
            "Epoch: 120. Loss: 0.5605452727325665\n",
            "Epoch: 130. Loss: 0.5600763182455657\n",
            "Epoch: 140. Loss: 0.5597907401108783\n",
            "Epoch: 150. Loss: 0.5596083294050462\n",
            "Epoch: 160. Loss: 0.559485121904587\n",
            "Epoch: 170. Loss: 0.5593967700446948\n",
            "Epoch: 180. Loss: 0.559329622268082\n",
            "Epoch: 190. Loss: 0.5592759082619226\n",
            "Epoch: 200. Loss: 0.5592311221375657\n",
            "Epoch: 210. Loss: 0.5591925895676346\n",
            "Epoch: 220. Loss: 0.5591586769378705\n",
            "Epoch: 230. Loss: 0.5591283510130391\n",
            "Epoch: 240. Loss: 0.5591009313177655\n",
            "Epoch: 250. Loss: 0.5590759492714359\n",
            "Epoch: 260. Loss: 0.5590530669540477\n",
            "Epoch: 270. Loss: 0.5590320295000751\n",
            "Epoch: 280. Loss: 0.5590126366685072\n",
            "Epoch: 290. Loss: 0.5589947254915935\n",
            "Epoch: 300. Loss: 0.5589781594223152\n",
            "Epoch: 310. Loss: 0.5589628213613073\n",
            "Epoch: 320. Loss: 0.5589486090457536\n",
            "Epoch: 330. Loss: 0.5589354319077972\n",
            "Epoch: 340. Loss: 0.55892320886856\n",
            "Epoch: 350. Loss: 0.5589118667422679\n",
            "Epoch: 360. Loss: 0.5589013390479486\n",
            "Epoch: 370. Loss: 0.5588915650999869\n",
            "Epoch: 380. Loss: 0.5588824892939626\n",
            "Epoch: 390. Loss: 0.5588740605323568\n",
            "Epoch: 400. Loss: 0.558866231752638\n",
            "Epoch: 410. Loss: 0.5588589595318916\n",
            "Epoch: 420. Loss: 0.5588522037498531\n",
            "Epoch: 430. Loss: 0.5588459272974227\n",
            "Epoch: 440. Loss: 0.5588400958212836\n",
            "Epoch: 450. Loss: 0.5588346774977359\n",
            "Epoch: 460. Loss: 0.5588296428305971\n",
            "Epoch: 470. Loss: 0.5588249644692679\n",
            "Epoch: 480. Loss: 0.5588206170439531\n",
            "Epoch: 490. Loss: 0.5588165770156923\n",
            "tensor(0.7642, dtype=torch.float64)\n",
            "2022-04-03 00:00:00\n",
            "Epoch: 0. Loss: 1.3429928781076965\n",
            "Epoch: 10. Loss: 0.6650023816834127\n",
            "Epoch: 20. Loss: 0.6191543317344078\n",
            "Epoch: 30. Loss: 0.5973214216772341\n",
            "Epoch: 40. Loss: 0.5857040003345766\n",
            "Epoch: 50. Loss: 0.579026101686692\n",
            "Epoch: 60. Loss: 0.5750153062471425\n",
            "Epoch: 70. Loss: 0.5725290106887944\n",
            "Epoch: 80. Loss: 0.5709366392124867\n",
            "Epoch: 90. Loss: 0.5698778544917562\n",
            "Epoch: 100. Loss: 0.5691434559037485\n",
            "Epoch: 110. Loss: 0.5686104395600623\n",
            "Epoch: 120. Loss: 0.5682055272293804\n",
            "Epoch: 130. Loss: 0.5678844450681568\n",
            "Epoch: 140. Loss: 0.5676200355083272\n",
            "Epoch: 150. Loss: 0.5673953641517108\n",
            "Epoch: 160. Loss: 0.5671996775364948\n",
            "Epoch: 170. Loss: 0.567026005262958\n",
            "Epoch: 180. Loss: 0.5668697212458914\n",
            "Epoch: 190. Loss: 0.5667276707907832\n",
            "Epoch: 200. Loss: 0.5665976352273152\n",
            "Epoch: 210. Loss: 0.5664780001230494\n",
            "Epoch: 220. Loss: 0.5663675475654191\n",
            "Epoch: 230. Loss: 0.5662653248116059\n",
            "Epoch: 240. Loss: 0.566170560390556\n",
            "Epoch: 250. Loss: 0.5660826099532895\n",
            "Epoch: 260. Loss: 0.566000920929617\n",
            "Epoch: 270. Loss: 0.5659250091686187\n",
            "Epoch: 280. Loss: 0.565854443273664\n",
            "Epoch: 290. Loss: 0.565788833914978\n",
            "Epoch: 300. Loss: 0.5657278263867109\n",
            "Epoch: 310. Loss: 0.5656710952960566\n",
            "Epoch: 320. Loss: 0.5656183406661633\n",
            "Epoch: 330. Loss: 0.5655692849865677\n",
            "Epoch: 340. Loss: 0.5655236709068989\n",
            "Epoch: 350. Loss: 0.5654812593742937\n",
            "Epoch: 360. Loss: 0.5654418280829079\n",
            "Epoch: 370. Loss: 0.5654051701482076\n",
            "Epoch: 380. Loss: 0.5653710929476761\n",
            "Epoch: 390. Loss: 0.5653394170885804\n",
            "Epoch: 400. Loss: 0.5653099754759494\n",
            "Epoch: 410. Loss: 0.5652826124621781\n",
            "Epoch: 420. Loss: 0.5652571830651416\n",
            "Epoch: 430. Loss: 0.5652335522453549\n",
            "Epoch: 440. Loss: 0.5652115942351437\n",
            "Epoch: 450. Loss: 0.565191191914444\n",
            "Epoch: 460. Loss: 0.5651722362289608\n",
            "Epoch: 470. Loss: 0.5651546256471969\n",
            "Epoch: 480. Loss: 0.5651382656533959\n",
            "Epoch: 490. Loss: 0.5651230682738444\n",
            "tensor(0.6823, dtype=torch.float64)\n",
            "2022-04-10 00:00:00\n",
            "Epoch: 0. Loss: 5.899595110001541\n",
            "Epoch: 10. Loss: 1.2832275262481576\n",
            "Epoch: 20. Loss: 0.7950038128258442\n",
            "Epoch: 30. Loss: 0.6926754146127951\n",
            "Epoch: 40. Loss: 0.6566060478024688\n",
            "Epoch: 50. Loss: 0.6393387711165038\n",
            "Epoch: 60. Loss: 0.6284696208383433\n",
            "Epoch: 70. Loss: 0.6204653400632792\n",
            "Epoch: 80. Loss: 0.6141168144865092\n",
            "Epoch: 90. Loss: 0.60889017208781\n",
            "Epoch: 100. Loss: 0.6044868907512015\n",
            "Epoch: 110. Loss: 0.6007129380006216\n",
            "Epoch: 120. Loss: 0.5974321834914106\n",
            "Epoch: 130. Loss: 0.5945455110978329\n",
            "Epoch: 140. Loss: 0.5919792806349916\n",
            "Epoch: 150. Loss: 0.5896780196792072\n",
            "Epoch: 160. Loss: 0.5875994398995169\n",
            "Epoch: 170. Loss: 0.5857109099455509\n",
            "Epoch: 180. Loss: 0.583986912997095\n",
            "Epoch: 190. Loss: 0.5824071981476805\n",
            "Epoch: 200. Loss: 0.5809554315133977\n",
            "Epoch: 210. Loss: 0.5796182111014434\n",
            "Epoch: 220. Loss: 0.5783843475192172\n",
            "Epoch: 230. Loss: 0.577244338980731\n",
            "Epoch: 240. Loss: 0.576189988027612\n",
            "Epoch: 250. Loss: 0.5752141212898388\n",
            "Epoch: 260. Loss: 0.5743103839069165\n",
            "Epoch: 270. Loss: 0.5734730878683005\n",
            "Epoch: 280. Loss: 0.572697099187349\n",
            "Epoch: 290. Loss: 0.5719777529927876\n",
            "Epoch: 300. Loss: 0.571310788679319\n",
            "Epoch: 310. Loss: 0.5706922994878487\n",
            "Epoch: 320. Loss: 0.5701186925006458\n",
            "Epoch: 330. Loss: 0.5695866561996407\n",
            "Epoch: 340. Loss: 0.5690931335685535\n",
            "Epoch: 350. Loss: 0.5686352993121118\n",
            "Epoch: 360. Loss: 0.5682105401850897\n",
            "Epoch: 370. Loss: 0.5678164377193177\n",
            "Epoch: 380. Loss: 0.5674507528438336\n",
            "Epoch: 390. Loss: 0.5671114120378015\n",
            "Epoch: 400. Loss: 0.5667964947562367\n",
            "Epoch: 410. Loss: 0.5665042219381694\n",
            "Epoch: 420. Loss: 0.5662329454550388\n",
            "Epoch: 430. Loss: 0.5659811383904485\n",
            "Epoch: 440. Loss: 0.5657473860655595\n",
            "Epoch: 450. Loss: 0.5655303777405664\n",
            "Epoch: 460. Loss: 0.5653288989341418\n",
            "Epoch: 470. Loss: 0.5651418243109579\n",
            "Epoch: 480. Loss: 0.5649681110934605\n",
            "Epoch: 490. Loss: 0.5648067929586729\n",
            "tensor(0.6109, dtype=torch.float64)\n",
            "2022-04-17 00:00:00\n",
            "Epoch: 0. Loss: 1.0669886269014528\n",
            "Epoch: 10. Loss: 0.7048255515125467\n",
            "Epoch: 20. Loss: 0.5955177417783712\n",
            "Epoch: 30. Loss: 0.5773693464432982\n",
            "Epoch: 40. Loss: 0.5743617932592741\n",
            "Epoch: 50. Loss: 0.5735617149888103\n",
            "Epoch: 60. Loss: 0.5731335345737066\n",
            "Epoch: 70. Loss: 0.5728003976350998\n",
            "Epoch: 80. Loss: 0.5725117356582964\n",
            "Epoch: 90. Loss: 0.5722532915326943\n",
            "Epoch: 100. Loss: 0.5720183924804073\n",
            "Epoch: 110. Loss: 0.5718029129247723\n",
            "Epoch: 120. Loss: 0.5716040121092628\n",
            "Epoch: 130. Loss: 0.5714196251672491\n",
            "Epoch: 140. Loss: 0.5712481868780637\n",
            "Epoch: 150. Loss: 0.571088464158284\n",
            "Epoch: 160. Loss: 0.5709394505113644\n",
            "Epoch: 170. Loss: 0.5708002982655331\n",
            "Epoch: 180. Loss: 0.5706702744560155\n",
            "Epoch: 190. Loss: 0.5705487317084872\n",
            "Epoch: 200. Loss: 0.5704350887389518\n",
            "Epoch: 210. Loss: 0.5703288170733405\n",
            "Epoch: 220. Loss: 0.5702294318232347\n",
            "Epoch: 230. Loss: 0.5701364851282426\n",
            "Epoch: 240. Loss: 0.5700495613664736\n",
            "Epoch: 250. Loss: 0.5699682735485242\n",
            "Epoch: 260. Loss: 0.5698922605126383\n",
            "Epoch: 270. Loss: 0.5698211846697724\n",
            "Epoch: 280. Loss: 0.5697547301326531\n",
            "Epoch: 290. Loss: 0.5696926011187265\n",
            "Epoch: 300. Loss: 0.5696345205535248\n",
            "Epoch: 310. Loss: 0.5695802288250715\n",
            "Epoch: 320. Loss: 0.5695294826558482\n",
            "Epoch: 330. Loss: 0.5694820540693544\n",
            "Epoch: 340. Loss: 0.5694377294352678\n",
            "Epoch: 350. Loss: 0.5693963085818472\n",
            "Epoch: 360. Loss: 0.5693576039673083\n",
            "Epoch: 370. Loss: 0.5693214399039839\n",
            "Epoch: 380. Loss: 0.5692876518304715\n",
            "Epoch: 390. Loss: 0.569256085627937\n",
            "Epoch: 400. Loss: 0.5692265969773826\n",
            "Epoch: 410. Loss: 0.5691990507551687\n",
            "Epoch: 420. Loss: 0.5691733204643945\n",
            "Epoch: 430. Loss: 0.5691492876999917\n",
            "Epoch: 440. Loss: 0.5691268416455769\n",
            "Epoch: 450. Loss: 0.5691058786002438\n",
            "Epoch: 460. Loss: 0.569086301533609\n",
            "Epoch: 470. Loss: 0.569068019667519\n",
            "Epoch: 480. Loss: 0.5690509480829221\n",
            "Epoch: 490. Loss: 0.5690350073504861\n",
            "tensor(0.4727, dtype=torch.float64)\n",
            "2022-04-24 00:00:00\n",
            "Epoch: 0. Loss: 2.805660418583853\n",
            "Epoch: 10. Loss: 1.054216747031184\n",
            "Epoch: 20. Loss: 0.7133727283626913\n",
            "Epoch: 30. Loss: 0.6497123062676228\n",
            "Epoch: 40. Loss: 0.6319582662209654\n",
            "Epoch: 50. Loss: 0.6227850297681612\n",
            "Epoch: 60. Loss: 0.6167514727504835\n",
            "Epoch: 70. Loss: 0.6123124613192494\n",
            "Epoch: 80. Loss: 0.6087851064775517\n",
            "Epoch: 90. Loss: 0.6058111649023812\n",
            "Epoch: 100. Loss: 0.6031922326415537\n",
            "Epoch: 110. Loss: 0.6008166140633552\n",
            "Epoch: 120. Loss: 0.5986208241839929\n",
            "Epoch: 130. Loss: 0.5965682135685116\n",
            "Epoch: 140. Loss: 0.5946370016407359\n",
            "Epoch: 150. Loss: 0.592813608083372\n",
            "Epoch: 160. Loss: 0.5910889632494936\n",
            "Epoch: 170. Loss: 0.5894564813379435\n",
            "Epoch: 180. Loss: 0.5879109545846056\n",
            "Epoch: 190. Loss: 0.5864479541106712\n",
            "Epoch: 200. Loss: 0.5850635077526476\n",
            "Epoch: 210. Loss: 0.5837539284086606\n",
            "Epoch: 220. Loss: 0.5825157236644255\n",
            "Epoch: 230. Loss: 0.5813455489879037\n",
            "Epoch: 240. Loss: 0.580240184050859\n",
            "Epoch: 250. Loss: 0.5791965211488139\n",
            "Epoch: 260. Loss: 0.5782115597996668\n",
            "Epoch: 270. Loss: 0.57728240436313\n",
            "Epoch: 280. Loss: 0.5764062630112108\n",
            "Epoch: 290. Loss: 0.5755804471792301\n",
            "Epoch: 300. Loss: 0.5748023710549597\n",
            "Epoch: 310. Loss: 0.5740695508919987\n",
            "Epoch: 320. Loss: 0.5733796040549825\n",
            "Epoch: 330. Loss: 0.572730247768255\n",
            "Epoch: 340. Loss: 0.5721192975728863\n",
            "Epoch: 350. Loss: 0.5715446655135853\n",
            "Epoch: 360. Loss: 0.5710043580848296\n",
            "Epoch: 370. Loss: 0.570496473968459\n",
            "Epoch: 380. Loss: 0.5700192015953057\n",
            "Epoch: 390. Loss: 0.5695708165623452\n",
            "Epoch: 400. Loss: 0.5691496789350233\n",
            "Epoch: 410. Loss: 0.5687542304622051\n",
            "Epoch: 420. Loss: 0.5683829917288353\n",
            "Epoch: 430. Loss: 0.568034559268992\n",
            "Epoch: 440. Loss: 0.5677076026596604\n",
            "Epoch: 450. Loss: 0.5674008616132804\n",
            "Epoch: 460. Loss: 0.5671131430849553\n",
            "Epoch: 470. Loss: 0.5668433184081832\n",
            "Epoch: 480. Loss: 0.5665903204710793\n",
            "Epoch: 490. Loss: 0.5663531409433057\n",
            "tensor(0.2271, dtype=torch.float64)\n",
            "2022-05-01 00:00:00\n",
            "Epoch: 0. Loss: 2.645890457041781\n",
            "Epoch: 10. Loss: 2.0133877520921155\n",
            "Epoch: 20. Loss: 1.5386144730562359\n",
            "Epoch: 30. Loss: 1.1902941953763773\n",
            "Epoch: 40. Loss: 0.9775795594780399\n",
            "Epoch: 50. Loss: 0.8584434169784197\n",
            "Epoch: 60. Loss: 0.7718633264599772\n",
            "Epoch: 70. Loss: 0.7049959198739052\n",
            "Epoch: 80. Loss: 0.655514097161064\n",
            "Epoch: 90. Loss: 0.6211375395767316\n",
            "Epoch: 100. Loss: 0.59882824585015\n",
            "Epoch: 110. Loss: 0.5852028467245854\n",
            "Epoch: 120. Loss: 0.5772082860199078\n",
            "Epoch: 130. Loss: 0.5725852981394431\n",
            "Epoch: 140. Loss: 0.5698915059347579\n",
            "Epoch: 150. Loss: 0.5682843424256556\n",
            "Epoch: 160. Loss: 0.5672923392747105\n",
            "Epoch: 170. Loss: 0.5666550548048392\n",
            "Epoch: 180. Loss: 0.5662277723641151\n",
            "Epoch: 190. Loss: 0.5659286650479719\n",
            "Epoch: 200. Loss: 0.5657103280112553\n",
            "Epoch: 210. Loss: 0.5655445267559724\n",
            "Epoch: 220. Loss: 0.5654139598398394\n",
            "Epoch: 230. Loss: 0.5653077330100554\n",
            "Epoch: 240. Loss: 0.5652188137639667\n",
            "Epoch: 250. Loss: 0.5651425603975275\n",
            "Epoch: 260. Loss: 0.5650758474180934\n",
            "Epoch: 270. Loss: 0.5650165309656378\n",
            "Epoch: 280. Loss: 0.5649631137627066\n",
            "Epoch: 290. Loss: 0.5649145305582496\n",
            "Epoch: 300. Loss: 0.5648700082913289\n",
            "Epoch: 310. Loss: 0.5648289736701017\n",
            "Epoch: 320. Loss: 0.564790991417133\n",
            "Epoch: 330. Loss: 0.5647557226492474\n",
            "Epoch: 340. Loss: 0.5647228966305039\n",
            "Epoch: 350. Loss: 0.5646922914848281\n",
            "Epoch: 360. Loss: 0.5646637209504415\n",
            "Epoch: 370. Loss: 0.5646370252285229\n",
            "Epoch: 380. Loss: 0.5646120646170925\n",
            "Epoch: 390. Loss: 0.5645887150458279\n",
            "Epoch: 400. Loss: 0.564566864912264\n",
            "Epoch: 410. Loss: 0.5645464128117753\n",
            "Epoch: 420. Loss: 0.5645272658836739\n",
            "Epoch: 430. Loss: 0.5645093385839268\n",
            "Epoch: 440. Loss: 0.5644925517549797\n",
            "Epoch: 450. Loss: 0.5644768319040118\n",
            "Epoch: 460. Loss: 0.5644621106287949\n",
            "Epoch: 470. Loss: 0.5644483241493331\n",
            "Epoch: 480. Loss: 0.5644354129164378\n",
            "Epoch: 490. Loss: 0.56442332127726\n",
            "tensor(0.4287, dtype=torch.float64)\n",
            "2022-05-08 00:00:00\n",
            "Epoch: 0. Loss: 1.1703441949229791\n",
            "Epoch: 10. Loss: 0.8636765890721051\n",
            "Epoch: 20. Loss: 0.7563282197996106\n",
            "Epoch: 30. Loss: 0.6960629236547496\n",
            "Epoch: 40. Loss: 0.656050566870691\n",
            "Epoch: 50. Loss: 0.6304438369641954\n",
            "Epoch: 60. Loss: 0.6146986628414205\n",
            "Epoch: 70. Loss: 0.6051368453931427\n",
            "Epoch: 80. Loss: 0.5991952990803808\n",
            "Epoch: 90. Loss: 0.5952979620221904\n",
            "Epoch: 100. Loss: 0.5925471285257902\n",
            "Epoch: 110. Loss: 0.5904509575313762\n",
            "Epoch: 120. Loss: 0.5887437863673339\n",
            "Epoch: 130. Loss: 0.5872817807830943\n",
            "Epoch: 140. Loss: 0.5859858521196981\n",
            "Epoch: 150. Loss: 0.5848112881691591\n",
            "Epoch: 160. Loss: 0.583731774765976\n",
            "Epoch: 170. Loss: 0.5827309991353566\n",
            "Epoch: 180. Loss: 0.5817982118591031\n",
            "Epoch: 190. Loss: 0.5809258534410973\n",
            "Epoch: 200. Loss: 0.5801082626960835\n",
            "Epoch: 210. Loss: 0.5793409575964958\n",
            "Epoch: 220. Loss: 0.5786202236046453\n",
            "Epoch: 230. Loss: 0.5779428705120401\n",
            "Epoch: 240. Loss: 0.5773060839368999\n",
            "Epoch: 250. Loss: 0.5767073315236356\n",
            "Epoch: 260. Loss: 0.5761443017229461\n",
            "Epoch: 270. Loss: 0.5756148625680825\n",
            "Epoch: 280. Loss: 0.5751170330717196\n",
            "Epoch: 290. Loss: 0.5746489627875822\n",
            "Epoch: 300. Loss: 0.5742089167664284\n",
            "Epoch: 310. Loss: 0.5737952641396225\n",
            "Epoch: 320. Loss: 0.5734064691795798\n",
            "Epoch: 330. Loss: 0.573041084075091\n",
            "Epoch: 340. Loss: 0.5726977429106596\n",
            "Epoch: 350. Loss: 0.5723751565042903\n",
            "Epoch: 360. Loss: 0.5720721078685403\n",
            "Epoch: 370. Loss: 0.5717874481340876\n",
            "Epoch: 380. Loss: 0.5715200928256142\n",
            "Epoch: 390. Loss: 0.5712690184142661\n",
            "Epoch: 400. Loss: 0.5710332590944674\n",
            "Epoch: 410. Loss: 0.5708119037489308\n",
            "Epoch: 420. Loss: 0.57060409307665\n",
            "Epoch: 430. Loss: 0.5704090168660809\n",
            "Epoch: 440. Loss: 0.5702259114007411\n",
            "Epoch: 450. Loss: 0.5700540569878216\n",
            "Epoch: 460. Loss: 0.5698927756026421\n",
            "Epoch: 470. Loss: 0.5697414286432511\n",
            "Epoch: 480. Loss: 0.5695994147904273\n",
            "Epoch: 490. Loss: 0.5694661679689483\n",
            "tensor(0.6289, dtype=torch.float64)\n",
            "2022-05-15 00:00:00\n",
            "Epoch: 0. Loss: 1.8232712790111811\n",
            "Epoch: 10. Loss: 1.0931689850477153\n",
            "Epoch: 20. Loss: 0.8699478156710192\n",
            "Epoch: 30. Loss: 0.770303139697702\n",
            "Epoch: 40. Loss: 0.7061080404425394\n",
            "Epoch: 50. Loss: 0.6617364893242949\n",
            "Epoch: 60. Loss: 0.6320800793718252\n",
            "Epoch: 70. Loss: 0.6129049845629745\n",
            "Epoch: 80. Loss: 0.6006902978639506\n",
            "Epoch: 90. Loss: 0.5929014162836196\n",
            "Epoch: 100. Loss: 0.5878842991879122\n",
            "Epoch: 110. Loss: 0.5846077194121124\n",
            "Epoch: 120. Loss: 0.5824355062446299\n",
            "Epoch: 130. Loss: 0.5809725317702998\n",
            "Epoch: 140. Loss: 0.5799702716648526\n",
            "Epoch: 150. Loss: 0.5792703945836232\n",
            "Epoch: 160. Loss: 0.5787709042770898\n",
            "Epoch: 170. Loss: 0.5784054934908784\n",
            "Epoch: 180. Loss: 0.5781307316674278\n",
            "Epoch: 190. Loss: 0.5779179894606511\n",
            "Epoch: 200. Loss: 0.5777482840705122\n",
            "Epoch: 210. Loss: 0.5776089561991435\n",
            "Epoch: 220. Loss: 0.5774915112784028\n",
            "Epoch: 230. Loss: 0.5773902086609853\n",
            "Epoch: 240. Loss: 0.5773011352960303\n",
            "Epoch: 250. Loss: 0.5772215952345964\n",
            "Epoch: 260. Loss: 0.5771497060507172\n",
            "Epoch: 270. Loss: 0.5770841313568593\n",
            "Epoch: 280. Loss: 0.5770239031131161\n",
            "Epoch: 290. Loss: 0.5769683033309218\n",
            "Epoch: 300. Loss: 0.5769167851446775\n",
            "Epoch: 310. Loss: 0.5768689200223385\n",
            "Epoch: 320. Loss: 0.5768243623573306\n",
            "Epoch: 330. Loss: 0.5767828256340743\n",
            "Epoch: 340. Loss: 0.576744066310145\n",
            "Epoch: 350. Loss: 0.5767078728506339\n",
            "Epoch: 360. Loss: 0.576674058207967\n",
            "Epoch: 370. Loss: 0.5766424546103059\n",
            "Epoch: 380. Loss: 0.5766129099006468\n",
            "Epoch: 390. Loss: 0.5765852849209933\n",
            "Epoch: 400. Loss: 0.5765594516039846\n",
            "Epoch: 410. Loss: 0.5765352915463211\n",
            "Epoch: 420. Loss: 0.5765126949129634\n",
            "Epoch: 430. Loss: 0.5764915595708635\n",
            "Epoch: 440. Loss: 0.5764717903842025\n",
            "Epoch: 450. Loss: 0.5764532986252784\n",
            "Epoch: 460. Loss: 0.5764360014699952\n",
            "Epoch: 470. Loss: 0.5764198215568098\n",
            "Epoch: 480. Loss: 0.576404686594604\n",
            "Epoch: 490. Loss: 0.5763905290094041\n",
            "tensor(0.6524, dtype=torch.float64)\n",
            "2022-05-22 00:00:00\n",
            "Epoch: 0. Loss: 2.327038821234024\n",
            "Epoch: 10. Loss: 1.5992522741636421\n",
            "Epoch: 20. Loss: 1.1502897959431975\n",
            "Epoch: 30. Loss: 0.9284789781911035\n",
            "Epoch: 40. Loss: 0.8065484815664029\n",
            "Epoch: 50. Loss: 0.7261556042227554\n",
            "Epoch: 60. Loss: 0.6764727760140934\n",
            "Epoch: 70. Loss: 0.64817761455995\n",
            "Epoch: 80. Loss: 0.6323831785309311\n",
            "Epoch: 90. Loss: 0.6231648621373599\n",
            "Epoch: 100. Loss: 0.6173244288399091\n",
            "Epoch: 110. Loss: 0.6132702298637792\n",
            "Epoch: 120. Loss: 0.6102158671923035\n",
            "Epoch: 130. Loss: 0.6077611821742208\n",
            "Epoch: 140. Loss: 0.6056928319863661\n",
            "Epoch: 150. Loss: 0.6038908315762315\n",
            "Epoch: 160. Loss: 0.6022839616645327\n",
            "Epoch: 170. Loss: 0.6008277491035613\n",
            "Epoch: 180. Loss: 0.5994931133325763\n",
            "Epoch: 190. Loss: 0.5982602288783939\n",
            "Epoch: 200. Loss: 0.5971150475240176\n",
            "Epoch: 210. Loss: 0.5960472406304698\n",
            "Epoch: 220. Loss: 0.5950489361653623\n",
            "Epoch: 230. Loss: 0.5941139204563987\n",
            "Epoch: 240. Loss: 0.5932371222966746\n",
            "Epoch: 250. Loss: 0.5924142739881364\n",
            "Epoch: 260. Loss: 0.5916416859058392\n",
            "Epoch: 270. Loss: 0.5909160951433494\n",
            "Epoch: 280. Loss: 0.5902345630703988\n",
            "Epoch: 290. Loss: 0.5895944054333901\n",
            "Epoch: 300. Loss: 0.5889931442103585\n",
            "Epoch: 310. Loss: 0.5884284740475526\n",
            "Epoch: 320. Loss: 0.5878982384829027\n",
            "Epoch: 330. Loss: 0.5874004127421387\n",
            "Epoch: 340. Loss: 0.5869330909508068\n",
            "Epoch: 350. Loss: 0.5864944763158191\n",
            "Epoch: 360. Loss: 0.5860828733083275\n",
            "Epoch: 370. Loss: 0.5856966812017089\n",
            "Epoch: 380. Loss: 0.585334388535082\n",
            "Epoch: 390. Loss: 0.5849945682182628\n",
            "Epoch: 400. Loss: 0.5846758730914694\n",
            "Epoch: 410. Loss: 0.5843770318180176\n",
            "Epoch: 420. Loss: 0.5840968450313081\n",
            "Epoch: 430. Loss: 0.5838341816857385\n",
            "Epoch: 440. Loss: 0.5835879755796447\n",
            "Epoch: 450. Loss: 0.5833572220302673\n",
            "Epoch: 460. Loss: 0.5831409746882493\n",
            "Epoch: 470. Loss: 0.5829383424838201\n",
            "Epoch: 480. Loss: 0.5827484866995752\n",
            "Epoch: 490. Loss: 0.5825706181663265\n",
            "tensor(0.5472, dtype=torch.float64)\n",
            "2022-05-29 00:00:00\n",
            "Epoch: 0. Loss: 0.9339009199626619\n",
            "Epoch: 10. Loss: 0.7212621633953875\n",
            "Epoch: 20. Loss: 0.6801685268243525\n",
            "Epoch: 30. Loss: 0.6541249039595163\n",
            "Epoch: 40. Loss: 0.6344416495162848\n",
            "Epoch: 50. Loss: 0.6197575454340227\n",
            "Epoch: 60. Loss: 0.6090368413578494\n",
            "Epoch: 70. Loss: 0.6013567712414959\n",
            "Epoch: 80. Loss: 0.5959400437121144\n",
            "Epoch: 90. Loss: 0.5921660648048469\n",
            "Epoch: 100. Loss: 0.5895602633582622\n",
            "Epoch: 110. Loss: 0.5877718398333293\n",
            "Epoch: 120. Loss: 0.5865482241147582\n",
            "Epoch: 130. Loss: 0.5857112146216046\n",
            "Epoch: 140. Loss: 0.5851370133089968\n",
            "Epoch: 150. Loss: 0.5847406264481296\n",
            "Epoch: 160. Loss: 0.5844642221654482\n",
            "Epoch: 170. Loss: 0.5842687143975772\n",
            "Epoch: 180. Loss: 0.584127817119346\n",
            "Epoch: 190. Loss: 0.5840239138128567\n",
            "Epoch: 200. Loss: 0.5839452236962058\n",
            "Epoch: 210. Loss: 0.5838838758747255\n",
            "Epoch: 220. Loss: 0.583834609899719\n",
            "Epoch: 230. Loss: 0.5837939038065988\n",
            "Epoch: 240. Loss: 0.5837593914778781\n",
            "Epoch: 250. Loss: 0.5837294745938577\n",
            "Epoch: 260. Loss: 0.5837030648198328\n",
            "Epoch: 270. Loss: 0.5836794128318961\n",
            "Epoch: 280. Loss: 0.5836579950751846\n",
            "Epoch: 290. Loss: 0.5836384388168907\n",
            "Epoch: 300. Loss: 0.583620472556349\n",
            "Epoch: 310. Loss: 0.583603893203334\n",
            "Epoch: 320. Loss: 0.583588544334411\n",
            "Epoch: 330. Loss: 0.5835743017636199\n",
            "Epoch: 340. Loss: 0.5835610639411082\n",
            "Epoch: 350. Loss: 0.5835487455387202\n",
            "Epoch: 360. Loss: 0.5835372731402603\n",
            "Epoch: 370. Loss: 0.5835265823229672\n",
            "Epoch: 380. Loss: 0.5835166156599911\n",
            "Epoch: 390. Loss: 0.5835073213340009\n",
            "Epoch: 400. Loss: 0.5834986521576586\n",
            "Epoch: 410. Loss: 0.5834905648662566\n",
            "Epoch: 420. Loss: 0.5834830195936039\n",
            "Epoch: 430. Loss: 0.5834759794723966\n",
            "Epoch: 440. Loss: 0.5834694103201569\n",
            "Epoch: 450. Loss: 0.5834632803848967\n",
            "Epoch: 460. Loss: 0.583457560133281\n",
            "Epoch: 470. Loss: 0.5834522220697379\n",
            "Epoch: 480. Loss: 0.5834472405787218\n",
            "Epoch: 490. Loss: 0.5834425917848112\n",
            "tensor(0.7742, dtype=torch.float64)\n",
            "2022-06-05 00:00:00\n",
            "Epoch: 0. Loss: 1.8736554066901887\n",
            "Epoch: 10. Loss: 1.3251475663239956\n",
            "Epoch: 20. Loss: 0.9212709147478058\n",
            "Epoch: 30. Loss: 0.7270831072027161\n",
            "Epoch: 40. Loss: 0.6647354956592971\n",
            "Epoch: 50. Loss: 0.6402710159332445\n",
            "Epoch: 60. Loss: 0.6279778618674154\n",
            "Epoch: 70. Loss: 0.6211945849726194\n",
            "Epoch: 80. Loss: 0.6170699149944197\n",
            "Epoch: 90. Loss: 0.6142521653817989\n",
            "Epoch: 100. Loss: 0.6121110799182552\n",
            "Epoch: 110. Loss: 0.6103519907711433\n",
            "Epoch: 120. Loss: 0.6088330347193767\n",
            "Epoch: 130. Loss: 0.6074822193499464\n",
            "Epoch: 140. Loss: 0.6062602404196077\n",
            "Epoch: 150. Loss: 0.6051436855249175\n",
            "Epoch: 160. Loss: 0.604117283308335\n",
            "Epoch: 170. Loss: 0.6031702047947269\n",
            "Epoch: 180. Loss: 0.60229421763232\n",
            "Epoch: 190. Loss: 0.6014827145883366\n",
            "Epoch: 200. Loss: 0.6007301721794649\n",
            "Epoch: 210. Loss: 0.6000318318141623\n",
            "Epoch: 220. Loss: 0.5993835024061513\n",
            "Epoch: 230. Loss: 0.5987814328205585\n",
            "Epoch: 240. Loss: 0.5982222263146286\n",
            "Epoch: 250. Loss: 0.5977027811658425\n",
            "Epoch: 260. Loss: 0.5972202480962653\n",
            "Epoch: 270. Loss: 0.5967719987101362\n",
            "Epoch: 280. Loss: 0.5963556012884884\n",
            "Epoch: 290. Loss: 0.5959688015860684\n",
            "Epoch: 300. Loss: 0.5956095070944909\n",
            "Epoch: 310. Loss: 0.5952757737602815\n",
            "Epoch: 320. Loss: 0.5949657944869059\n",
            "Epoch: 330. Loss: 0.5946778889724388\n",
            "Epoch: 340. Loss: 0.5944104945806669\n",
            "Epoch: 350. Loss: 0.5941621580396312\n",
            "Epoch: 360. Loss: 0.5939315278250774\n",
            "Epoch: 370. Loss: 0.5937173471281698\n",
            "Epoch: 380. Loss: 0.5935184473345606\n",
            "Epoch: 390. Loss: 0.5933337419602859\n",
            "Epoch: 400. Loss: 0.593162221002227\n",
            "Epoch: 410. Loss: 0.5930029456691117\n",
            "Epoch: 420. Loss: 0.59285504346464\n",
            "Epoch: 430. Loss: 0.5927177035982122\n",
            "Epoch: 440. Loss: 0.592590172701501\n",
            "Epoch: 450. Loss: 0.5924717508311683\n",
            "Epoch: 460. Loss: 0.592361787739587\n",
            "Epoch: 470. Loss: 0.5922596793967125\n",
            "Epoch: 480. Loss: 0.5921648647473047\n",
            "Epoch: 490. Loss: 0.5920768226886496\n",
            "tensor(0.6332, dtype=torch.float64)\n",
            "2022-06-12 00:00:00\n",
            "Epoch: 0. Loss: 3.2203368833663837\n",
            "Epoch: 10. Loss: 1.5023243020223982\n",
            "Epoch: 20. Loss: 0.8445229039247073\n",
            "Epoch: 30. Loss: 0.7156116234337119\n",
            "Epoch: 40. Loss: 0.6804146956108794\n",
            "Epoch: 50. Loss: 0.6566164742889801\n",
            "Epoch: 60. Loss: 0.6393198416308318\n",
            "Epoch: 70. Loss: 0.6269190424001994\n",
            "Epoch: 80. Loss: 0.6181779688564961\n",
            "Epoch: 90. Loss: 0.6121070186157508\n",
            "Epoch: 100. Loss: 0.6079425825855629\n",
            "Epoch: 110. Loss: 0.605114957294549\n",
            "Epoch: 120. Loss: 0.6032107116755812\n",
            "Epoch: 130. Loss: 0.6019365276256083\n",
            "Epoch: 140. Loss: 0.6010880729154123\n",
            "Epoch: 150. Loss: 0.600525066536091\n",
            "Epoch: 160. Loss: 0.6001523031512421\n",
            "Epoch: 170. Loss: 0.5999057483384288\n",
            "Epoch: 180. Loss: 0.5997426332860053\n",
            "Epoch: 190. Loss: 0.599634546647506\n",
            "Epoch: 200. Loss: 0.5995626930624992\n",
            "Epoch: 210. Loss: 0.5995146778925605\n",
            "Epoch: 220. Loss: 0.5994823468257298\n",
            "Epoch: 230. Loss: 0.5994603443938581\n",
            "Epoch: 240. Loss: 0.5994451573171642\n",
            "Epoch: 250. Loss: 0.599434482226083\n",
            "Epoch: 260. Loss: 0.5994268091035342\n",
            "Epoch: 270. Loss: 0.5994211475253072\n",
            "Epoch: 280. Loss: 0.5994168470903253\n",
            "Epoch: 290. Loss: 0.5994134798071497\n",
            "Epoch: 300. Loss: 0.5994107631464809\n",
            "Epoch: 310. Loss: 0.5994085097407106\n",
            "Epoch: 320. Loss: 0.5994065945215725\n",
            "Epoch: 330. Loss: 0.5994049332578906\n",
            "Epoch: 340. Loss: 0.5994034685403119\n",
            "Epoch: 350. Loss: 0.5994021606278731\n",
            "Epoch: 360. Loss: 0.5994009814673575\n",
            "Epoch: 370. Loss: 0.5993999107826538\n",
            "Epoch: 380. Loss: 0.5993989335144955\n",
            "Epoch: 390. Loss: 0.5993980381411791\n",
            "Epoch: 400. Loss: 0.5993972155741656\n",
            "Epoch: 410. Loss: 0.5993964584290011\n",
            "Epoch: 420. Loss: 0.5993957605414573\n",
            "Epoch: 430. Loss: 0.5993951166440727\n",
            "Epoch: 440. Loss: 0.599394522147796\n",
            "Epoch: 450. Loss: 0.599393972992658\n",
            "Epoch: 460. Loss: 0.5993934655439407\n",
            "Epoch: 470. Loss: 0.5993929965184698\n",
            "Epoch: 480. Loss: 0.5993925629309885\n",
            "Epoch: 490. Loss: 0.5993921620540317\n",
            "tensor(0.6288, dtype=torch.float64)\n",
            "2022-06-19 00:00:00\n",
            "Epoch: 0. Loss: 2.0948462735996958\n",
            "Epoch: 10. Loss: 1.3695596779836243\n",
            "Epoch: 20. Loss: 1.0923618001470947\n",
            "Epoch: 30. Loss: 0.9507935011028634\n",
            "Epoch: 40. Loss: 0.8487742653854073\n",
            "Epoch: 50. Loss: 0.7703345745528715\n",
            "Epoch: 60. Loss: 0.7132826219179491\n",
            "Epoch: 70. Loss: 0.6752438627959614\n",
            "Epoch: 80. Loss: 0.651840625203723\n",
            "Epoch: 90. Loss: 0.638078501268889\n",
            "Epoch: 100. Loss: 0.629971385134984\n",
            "Epoch: 110. Loss: 0.6249835374588887\n",
            "Epoch: 120. Loss: 0.6217033706119919\n",
            "Epoch: 130. Loss: 0.6193928636534742\n",
            "Epoch: 140. Loss: 0.6176671593558283\n",
            "Epoch: 150. Loss: 0.6163169904057026\n",
            "Epoch: 160. Loss: 0.6152212719653801\n",
            "Epoch: 170. Loss: 0.6143056092776358\n",
            "Epoch: 180. Loss: 0.6135221039745149\n",
            "Epoch: 190. Loss: 0.6128388674092197\n",
            "Epoch: 200. Loss: 0.6122341328829071\n",
            "Epoch: 210. Loss: 0.6116927187685901\n",
            "Epoch: 220. Loss: 0.6112038021705197\n",
            "Epoch: 230. Loss: 0.6107594784619682\n",
            "Epoch: 240. Loss: 0.6103538157832724\n",
            "Epoch: 250. Loss: 0.6099822300401399\n",
            "Epoch: 260. Loss: 0.609641070247629\n",
            "Epoch: 270. Loss: 0.6093273426733828\n",
            "Epoch: 280. Loss: 0.6090385266991121\n",
            "Epoch: 290. Loss: 0.6087724512754534\n",
            "Epoch: 300. Loss: 0.608527211384716\n",
            "Epoch: 310. Loss: 0.6083011109152398\n",
            "Epoch: 320. Loss: 0.6080926229848914\n",
            "Epoch: 330. Loss: 0.607900361817205\n",
            "Epoch: 340. Loss: 0.6077230622970545\n",
            "Epoch: 350. Loss: 0.6075595646645742\n",
            "Epoch: 360. Loss: 0.6074088026805975\n",
            "Epoch: 370. Loss: 0.6072697941699928\n",
            "Epoch: 380. Loss: 0.6071416332241877\n",
            "Epoch: 390. Loss: 0.6070234835891125\n",
            "Epoch: 400. Loss: 0.6069145729246676\n",
            "Epoch: 410. Loss: 0.606814187726112\n",
            "Epoch: 420. Loss: 0.6067216687658203\n",
            "Epoch: 430. Loss: 0.6066364069582848\n",
            "Epoch: 440. Loss: 0.6065578395803037\n",
            "Epoch: 450. Loss: 0.6064854467973737\n",
            "Epoch: 460. Loss: 0.6064187484598885\n",
            "Epoch: 470. Loss: 0.60635730114112\n",
            "Epoch: 480. Loss: 0.6063006953945931\n",
            "Epoch: 490. Loss: 0.6062485532123292\n",
            "tensor(0.5873, dtype=torch.float64)\n",
            "2022-06-26 00:00:00\n",
            "Epoch: 0. Loss: 2.672388311466349\n",
            "Epoch: 10. Loss: 0.9858026557238728\n",
            "Epoch: 20. Loss: 0.7631929088121812\n",
            "Epoch: 30. Loss: 0.6767070444136368\n",
            "Epoch: 40. Loss: 0.6361978809908481\n",
            "Epoch: 50. Loss: 0.6183382765599978\n",
            "Epoch: 60. Loss: 0.6108153891650173\n",
            "Epoch: 70. Loss: 0.607486154895245\n",
            "Epoch: 80. Loss: 0.6058540217520135\n",
            "Epoch: 90. Loss: 0.6049612051191262\n",
            "Epoch: 100. Loss: 0.6044263011726465\n",
            "Epoch: 110. Loss: 0.6040839251181251\n",
            "Epoch: 120. Loss: 0.6038542729273008\n",
            "Epoch: 130. Loss: 0.6036946106507325\n",
            "Epoch: 140. Loss: 0.6035800847952366\n",
            "Epoch: 150. Loss: 0.6034954122463717\n",
            "Epoch: 160. Loss: 0.6034308705353049\n",
            "Epoch: 170. Loss: 0.6033801497989789\n",
            "Epoch: 180. Loss: 0.6033391034818961\n",
            "Epoch: 190. Loss: 0.6033049811425013\n",
            "Epoch: 200. Loss: 0.6032759421314274\n",
            "Epoch: 210. Loss: 0.6032507420274112\n",
            "Epoch: 220. Loss: 0.6032285287137766\n",
            "Epoch: 230. Loss: 0.6032087091953783\n",
            "Epoch: 240. Loss: 0.6031908624266336\n",
            "Epoch: 250. Loss: 0.6031746821749261\n",
            "Epoch: 260. Loss: 0.6031599395193504\n",
            "Epoch: 270. Loss: 0.6031464581923752\n",
            "Epoch: 280. Loss: 0.6031340983232983\n",
            "Epoch: 290. Loss: 0.6031227456793925\n",
            "Epoch: 300. Loss: 0.6031123045062199\n",
            "Epoch: 310. Loss: 0.6031026927263937\n",
            "Epoch: 320. Loss: 0.6030938386861766\n",
            "Epoch: 330. Loss: 0.6030856789203441\n",
            "Epoch: 340. Loss: 0.6030781565892945\n",
            "Epoch: 350. Loss: 0.60307122036221\n",
            "Epoch: 360. Loss: 0.6030648235982589\n",
            "Epoch: 370. Loss: 0.6030589237288623\n",
            "Epoch: 380. Loss: 0.6030534817773247\n",
            "Epoch: 390. Loss: 0.6030484619738685\n",
            "Epoch: 400. Loss: 0.6030438314382937\n",
            "Epoch: 410. Loss: 0.6030395599117637\n",
            "Epoch: 420. Loss: 0.6030356195252813\n",
            "Epoch: 430. Loss: 0.6030319845964067\n",
            "Epoch: 440. Loss: 0.6030286314483837\n",
            "Epoch: 450. Loss: 0.603025538247571\n",
            "Epoch: 460. Loss: 0.6030226848562257\n",
            "Epoch: 470. Loss: 0.6030200526984539\n",
            "Epoch: 480. Loss: 0.603017624637663\n",
            "Epoch: 490. Loss: 0.6030153848642115\n",
            "tensor(0.6191, dtype=torch.float64)\n",
            "2022-07-03 00:00:00\n",
            "Epoch: 0. Loss: 1.0876225853664756\n",
            "Epoch: 10. Loss: 0.7434435490354323\n",
            "Epoch: 20. Loss: 0.661006854212226\n",
            "Epoch: 30. Loss: 0.6360754226702929\n",
            "Epoch: 40. Loss: 0.6241264633882887\n",
            "Epoch: 50. Loss: 0.617880027724897\n",
            "Epoch: 60. Loss: 0.6143684541662063\n",
            "Epoch: 70. Loss: 0.6122211122586974\n",
            "Epoch: 80. Loss: 0.6108035858361259\n",
            "Epoch: 90. Loss: 0.6098067617966121\n",
            "Epoch: 100. Loss: 0.609068222669262\n",
            "Epoch: 110. Loss: 0.6084962761644226\n",
            "Epoch: 120. Loss: 0.6080362085989072\n",
            "Epoch: 130. Loss: 0.607654073306856\n",
            "Epoch: 140. Loss: 0.6073282113074986\n",
            "Epoch: 150. Loss: 0.6070444879985359\n",
            "Epoch: 160. Loss: 0.6067934787298364\n",
            "Epoch: 170. Loss: 0.6065687515532698\n",
            "Epoch: 180. Loss: 0.6063657987577423\n",
            "Epoch: 190. Loss: 0.6061813640470094\n",
            "Epoch: 200. Loss: 0.6060130154629255\n",
            "Epoch: 210. Loss: 0.6058588726177898\n",
            "Epoch: 220. Loss: 0.6057174314678282\n",
            "Epoch: 230. Loss: 0.6055874510163215\n",
            "Epoch: 240. Loss: 0.6054678794675491\n",
            "Epoch: 250. Loss: 0.605357805587118\n",
            "Epoch: 260. Loss: 0.6052564262186614\n",
            "Epoch: 270. Loss: 0.605163024196002\n",
            "Epoch: 280. Loss: 0.605076952977653\n",
            "Epoch: 290. Loss: 0.6049976256580102\n",
            "Epoch: 300. Loss: 0.6049245068546648\n",
            "Epoch: 310. Loss: 0.6048571065097746\n",
            "Epoch: 320. Loss: 0.6047949749868431\n",
            "Epoch: 330. Loss: 0.604737699063446\n",
            "Epoch: 340. Loss: 0.6046848985604562\n",
            "Epoch: 350. Loss: 0.6046362234378541\n",
            "Epoch: 360. Loss: 0.6045913512445688\n",
            "Epoch: 370. Loss: 0.6045499848466028\n",
            "Epoch: 380. Loss: 0.6045118503814142\n",
            "Epoch: 390. Loss: 0.6044766954018731\n",
            "Epoch: 400. Loss: 0.6044442871831197\n",
            "Epoch: 410. Loss: 0.6044144111722409\n",
            "Epoch: 420. Loss: 0.6043868695650871\n",
            "Epoch: 430. Loss: 0.6043614799975543\n",
            "Epoch: 440. Loss: 0.6043380743407489\n",
            "Epoch: 450. Loss: 0.6043164975909698\n",
            "Epoch: 460. Loss: 0.6042966068465622\n",
            "Epoch: 470. Loss: 0.6042782703645764\n",
            "Epoch: 480. Loss: 0.604261366690866\n",
            "Epoch: 490. Loss: 0.604245783857839\n",
            "tensor(0.9951, dtype=torch.float64)\n",
            "2022-07-10 00:00:00\n",
            "Epoch: 0. Loss: 3.8757892161754883\n",
            "Epoch: 10. Loss: 0.6862188951444899\n",
            "Epoch: 20. Loss: 0.6330423175214037\n",
            "Epoch: 30. Loss: 0.6285645100935574\n",
            "Epoch: 40. Loss: 0.6256962445516681\n",
            "Epoch: 50. Loss: 0.6234661778143522\n",
            "Epoch: 60. Loss: 0.6216205503360716\n",
            "Epoch: 70. Loss: 0.620042981803697\n",
            "Epoch: 80. Loss: 0.6186707906478877\n",
            "Epoch: 90. Loss: 0.6174645878433568\n",
            "Epoch: 100. Loss: 0.6163966023032512\n",
            "Epoch: 110. Loss: 0.6154458051445857\n",
            "Epoch: 120. Loss: 0.6145955939449582\n",
            "Epoch: 130. Loss: 0.6138325224059341\n",
            "Epoch: 140. Loss: 0.6131455112771953\n",
            "Epoch: 150. Loss: 0.6125253129676345\n",
            "Epoch: 160. Loss: 0.6119641270931264\n",
            "Epoch: 170. Loss: 0.6114553143210036\n",
            "Epoch: 180. Loss: 0.6109931782533207\n",
            "Epoch: 190. Loss: 0.6105727963305846\n",
            "Epoch: 200. Loss: 0.6101898870201291\n",
            "Epoch: 210. Loss: 0.6098407043787559\n",
            "Epoch: 220. Loss: 0.6095219535616317\n",
            "Epoch: 230. Loss: 0.6092307225370324\n",
            "Epoch: 240. Loss: 0.6089644264538843\n",
            "Epoch: 250. Loss: 0.6087207619662122\n",
            "Epoch: 260. Loss: 0.6084976694493999\n",
            "Epoch: 270. Loss: 0.6082933015141664\n",
            "Epoch: 280. Loss: 0.60810599657968\n",
            "Epoch: 290. Loss: 0.6079342565378383\n",
            "Epoch: 300. Loss: 0.6077767277480614\n",
            "Epoch: 310. Loss: 0.6076321847616443\n",
            "Epoch: 320. Loss: 0.6074995162983033\n",
            "Epoch: 330. Loss: 0.607377713093621\n",
            "Epoch: 340. Loss: 0.60726585731108\n",
            "Epoch: 350. Loss: 0.60716311327117\n",
            "Epoch: 360. Loss: 0.6070687192963387\n",
            "Epoch: 370. Loss: 0.6069819805071792\n",
            "Epoch: 380. Loss: 0.6069022624343615\n",
            "Epoch: 390. Loss: 0.6068289853340701\n",
            "Epoch: 400. Loss: 0.6067616191133937\n",
            "Epoch: 410. Loss: 0.6066996787871995\n",
            "Epoch: 420. Loss: 0.6066427204002823\n",
            "Epoch: 430. Loss: 0.6065903373585803\n",
            "Epoch: 440. Loss: 0.6065421571214792\n",
            "Epoch: 450. Loss: 0.6064978382140213\n",
            "Epoch: 460. Loss: 0.6064570675234775\n",
            "Epoch: 470. Loss: 0.6064195578494757\n",
            "Epoch: 480. Loss: 0.6063850456808332\n",
            "Epoch: 490. Loss: 0.6063532891756146\n",
            "tensor(0.6012, dtype=torch.float64)\n",
            "2022-07-17 00:00:00\n",
            "Epoch: 0. Loss: 2.3255798861314414\n",
            "Epoch: 10. Loss: 1.0987658640411775\n",
            "Epoch: 20. Loss: 0.657129467230092\n",
            "Epoch: 30. Loss: 0.6236762900055857\n",
            "Epoch: 40. Loss: 0.621199462628721\n",
            "Epoch: 50. Loss: 0.6200710945031038\n",
            "Epoch: 60. Loss: 0.6192391097840044\n",
            "Epoch: 70. Loss: 0.6185666697692679\n",
            "Epoch: 80. Loss: 0.6179999543778181\n",
            "Epoch: 90. Loss: 0.6175102400691181\n",
            "Epoch: 100. Loss: 0.6170799224719602\n",
            "Epoch: 110. Loss: 0.6166972735351476\n",
            "Epoch: 120. Loss: 0.6163540487114114\n",
            "Epoch: 130. Loss: 0.6160442159180135\n",
            "Epoch: 140. Loss: 0.6157632079719785\n",
            "Epoch: 150. Loss: 0.6155074565215313\n",
            "Epoch: 160. Loss: 0.6152740919533841\n",
            "Epoch: 170. Loss: 0.6150607462363239\n",
            "Epoch: 180. Loss: 0.6148654213036735\n",
            "Epoch: 190. Loss: 0.6146863997833932\n",
            "Epoch: 200. Loss: 0.6145221833727005\n",
            "Epoch: 210. Loss: 0.6143714494271324\n",
            "Epoch: 220. Loss: 0.6142330196721197\n",
            "Epoch: 230. Loss: 0.6141058370784334\n",
            "Epoch: 240. Loss: 0.6139889483136457\n",
            "Epoch: 250. Loss: 0.6138814900662133\n",
            "Epoch: 260. Loss: 0.6137826781117269\n",
            "Epoch: 270. Loss: 0.6136917983636251\n",
            "Epoch: 280. Loss: 0.6136081993944363\n",
            "Epoch: 290. Loss: 0.6135312860740018\n",
            "Epoch: 300. Loss: 0.6134605140774297\n",
            "Epoch: 310. Loss: 0.61339538508662\n",
            "Epoch: 320. Loss: 0.6133354425572096\n",
            "Epoch: 330. Loss: 0.613280267955642\n",
            "Epoch: 340. Loss: 0.6132294773938426\n",
            "Epoch: 350. Loss: 0.6131827186050457\n",
            "Epoch: 360. Loss: 0.6131396682158473\n",
            "Epoch: 370. Loss: 0.6131000292779955\n",
            "Epoch: 380. Loss: 0.6130635290297298\n",
            "Epoch: 390. Loss: 0.6130299168612964\n",
            "Epoch: 400. Loss: 0.6129989624630038\n",
            "Epoch: 410. Loss: 0.6129704541371647\n",
            "Epoch: 420. Loss: 0.6129441972576759\n",
            "Epoch: 430. Loss: 0.6129200128629724\n",
            "Epoch: 440. Loss: 0.6128977363697498\n",
            "Epoch: 450. Loss: 0.6128772163962508\n",
            "Epoch: 460. Loss: 0.612858313685114\n",
            "Epoch: 470. Loss: 0.6128409001168197\n",
            "Epoch: 480. Loss: 0.6128248578056789\n",
            "Epoch: 490. Loss: 0.6128100782710949\n",
            "tensor(0.5894, dtype=torch.float64)\n",
            "2022-07-24 00:00:00\n",
            "Epoch: 0. Loss: 3.3894638152119207\n",
            "Epoch: 10. Loss: 0.8897852844934899\n",
            "Epoch: 20. Loss: 0.6897646424130072\n",
            "Epoch: 30. Loss: 0.6508599378907268\n",
            "Epoch: 40. Loss: 0.6354167011291397\n",
            "Epoch: 50. Loss: 0.6280182224044123\n",
            "Epoch: 60. Loss: 0.6241444375540544\n",
            "Epoch: 70. Loss: 0.6219182095141152\n",
            "Epoch: 80. Loss: 0.6205452870025421\n",
            "Epoch: 90. Loss: 0.6196624065712192\n",
            "Epoch: 100. Loss: 0.6190809995764729\n",
            "Epoch: 110. Loss: 0.6186918698768262\n",
            "Epoch: 120. Loss: 0.6184274927403026\n",
            "Epoch: 130. Loss: 0.618244779783405\n",
            "Epoch: 140. Loss: 0.6181158750532438\n",
            "Epoch: 150. Loss: 0.6180226785679036\n",
            "Epoch: 160. Loss: 0.6179534017089539\n",
            "Epoch: 170. Loss: 0.6179003504640461\n",
            "Epoch: 180. Loss: 0.6178584881731698\n",
            "Epoch: 190. Loss: 0.617824502504137\n",
            "Epoch: 200. Loss: 0.6177962002592221\n",
            "Epoch: 210. Loss: 0.6177721153060246\n",
            "Epoch: 220. Loss: 0.6177512548288383\n",
            "Epoch: 230. Loss: 0.6177329351838813\n",
            "Epoch: 240. Loss: 0.6177166757078912\n",
            "Epoch: 250. Loss: 0.6177021299659888\n",
            "Epoch: 260. Loss: 0.6176890411689858\n",
            "Epoch: 270. Loss: 0.6176772131894109\n",
            "Epoch: 280. Loss: 0.6176664916466235\n",
            "Epoch: 290. Loss: 0.6176567514959875\n",
            "Epoch: 300. Loss: 0.6176478888245592\n",
            "Epoch: 310. Loss: 0.617639815372674\n",
            "Epoch: 320. Loss: 0.6176324548270494\n",
            "Epoch: 330. Loss: 0.6176257402698452\n",
            "Epoch: 340. Loss: 0.6176196123862435\n",
            "Epoch: 350. Loss: 0.6176140181735773\n",
            "Epoch: 360. Loss: 0.6176089099854637\n",
            "Epoch: 370. Loss: 0.6176042448026978\n",
            "Epoch: 380. Loss: 0.6175999836602449\n",
            "Epoch: 390. Loss: 0.6175960911839413\n",
            "Epoch: 400. Loss: 0.6175925352062105\n",
            "Epoch: 410. Loss: 0.6175892864402871\n",
            "Epoch: 420. Loss: 0.6175863181990444\n",
            "Epoch: 430. Loss: 0.6175836061488632\n",
            "Epoch: 440. Loss: 0.6175811280918072\n",
            "Epoch: 450. Loss: 0.6175788637712556\n",
            "Epoch: 460. Loss: 0.6175767946974035\n",
            "Epoch: 470. Loss: 0.6175749039898927\n",
            "Epoch: 480. Loss: 0.6175731762354232\n",
            "Epoch: 490. Loss: 0.6175715973586089\n",
            "tensor(0.6217, dtype=torch.float64)\n",
            "2022-07-31 00:00:00\n",
            "Epoch: 0. Loss: 1.9747503288576738\n",
            "Epoch: 10. Loss: 1.2729714698167007\n",
            "Epoch: 20. Loss: 0.895284747505507\n",
            "Epoch: 30. Loss: 0.7790923042126049\n",
            "Epoch: 40. Loss: 0.7277384396449427\n",
            "Epoch: 50. Loss: 0.6957181538134589\n",
            "Epoch: 60. Loss: 0.6746977246288981\n",
            "Epoch: 70. Loss: 0.6605848745768965\n",
            "Epoch: 80. Loss: 0.650824344983236\n",
            "Epoch: 90. Loss: 0.6438948018650275\n",
            "Epoch: 100. Loss: 0.6388817319551936\n",
            "Epoch: 110. Loss: 0.63520208769368\n",
            "Epoch: 120. Loss: 0.6324624667527294\n",
            "Epoch: 130. Loss: 0.6303890728587429\n",
            "Epoch: 140. Loss: 0.6287895505282023\n",
            "Epoch: 150. Loss: 0.6275289374204601\n",
            "Epoch: 160. Loss: 0.6265129521799822\n",
            "Epoch: 170. Loss: 0.625675960504083\n",
            "Epoch: 180. Loss: 0.6249723061123865\n",
            "Epoch: 190. Loss: 0.624370141063246\n",
            "Epoch: 200. Loss: 0.623847097106381\n",
            "Epoch: 210. Loss: 0.623387287172011\n",
            "Epoch: 220. Loss: 0.622979249487743\n",
            "Epoch: 230. Loss: 0.6226145489196928\n",
            "Epoch: 240. Loss: 0.622286830651903\n",
            "Epoch: 250. Loss: 0.6219911820735204\n",
            "Epoch: 260. Loss: 0.6217237030555992\n",
            "Epoch: 270. Loss: 0.621481216313498\n",
            "Epoch: 280. Loss: 0.6212610715467408\n",
            "Epoch: 290. Loss: 0.621061012185867\n",
            "Epoch: 300. Loss: 0.6208790838820931\n",
            "Epoch: 310. Loss: 0.6207135708342904\n",
            "Epoch: 320. Loss: 0.6205629507154883\n",
            "Epoch: 330. Loss: 0.620425862075866\n",
            "Epoch: 340. Loss: 0.6203010801690344\n",
            "Epoch: 350. Loss: 0.6201874985193477\n",
            "Epoch: 360. Loss: 0.6200841144536741\n",
            "Epoch: 370. Loss: 0.6199900174182117\n",
            "Epoch: 380. Loss: 0.6199043792941777\n",
            "Epoch: 390. Loss: 0.6198264461849736\n",
            "Epoch: 400. Loss: 0.6197555313177652\n",
            "Epoch: 410. Loss: 0.6196910088146391\n",
            "Epoch: 420. Loss: 0.6196323081626305\n",
            "Epoch: 430. Loss: 0.6195789092610511\n",
            "Epoch: 440. Loss: 0.6195303379573304\n",
            "Epoch: 450. Loss: 0.6194861620046296\n",
            "Epoch: 460. Loss: 0.6194459873895034\n",
            "Epoch: 470. Loss: 0.6194094549882664\n",
            "Epoch: 480. Loss: 0.6193762375180539\n",
            "Epoch: 490. Loss: 0.6193460367538767\n",
            "tensor(0.5822, dtype=torch.float64)\n",
            "2022-08-07 00:00:00\n",
            "Epoch: 0. Loss: 2.83013404209706\n",
            "Epoch: 10. Loss: 0.894884682435004\n",
            "Epoch: 20. Loss: 0.780457269196382\n",
            "Epoch: 30. Loss: 0.7397623877775374\n",
            "Epoch: 40. Loss: 0.7082595305088178\n",
            "Epoch: 50. Loss: 0.683701570710167\n",
            "Epoch: 60. Loss: 0.6649644431912307\n",
            "Epoch: 70. Loss: 0.6510147513450466\n",
            "Epoch: 80. Loss: 0.6408692687592663\n",
            "Epoch: 90. Loss: 0.6336367143600659\n",
            "Epoch: 100. Loss: 0.6285601444801656\n",
            "Epoch: 110. Loss: 0.6250345122770039\n",
            "Epoch: 120. Loss: 0.6225997908958187\n",
            "Epoch: 130. Loss: 0.6209196188973803\n",
            "Epoch: 140. Loss: 0.6197552232009653\n",
            "Epoch: 150. Loss: 0.6189407803415043\n",
            "Epoch: 160. Loss: 0.61836295047769\n",
            "Epoch: 170. Loss: 0.6179451372378522\n",
            "Epoch: 180. Loss: 0.6176359701079825\n",
            "Epoch: 190. Loss: 0.6174011553799762\n",
            "Epoch: 200. Loss: 0.6172178437037483\n",
            "Epoch: 210. Loss: 0.6170708010997643\n",
            "Epoch: 220. Loss: 0.6169498368749555\n",
            "Epoch: 230. Loss: 0.616848090768238\n",
            "Epoch: 240. Loss: 0.6167608994523641\n",
            "Epoch: 250. Loss: 0.6166850497999661\n",
            "Epoch: 260. Loss: 0.6166182884512966\n",
            "Epoch: 270. Loss: 0.6165590003024527\n",
            "Epoch: 280. Loss: 0.6165059978728656\n",
            "Epoch: 290. Loss: 0.6164583832385625\n",
            "Epoch: 300. Loss: 0.6164154573590255\n",
            "Epoch: 310. Loss: 0.6163766603186729\n",
            "Epoch: 320. Loss: 0.6163415317243548\n",
            "Epoch: 330. Loss: 0.6163096842491949\n",
            "Epoch: 340. Loss: 0.6162807857622753\n",
            "Epoch: 350. Loss: 0.6162545470797924\n",
            "Epoch: 360. Loss: 0.6162307134115091\n",
            "Epoch: 370. Loss: 0.6162090582506735\n",
            "Epoch: 380. Loss: 0.6161893788930882\n",
            "Epoch: 390. Loss: 0.6161714930547094\n",
            "Epoch: 400. Loss: 0.6161552362410326\n",
            "Epoch: 410. Loss: 0.6161404596407254\n",
            "Epoch: 420. Loss: 0.6161270283932819\n",
            "Epoch: 430. Loss: 0.6161148201306862\n",
            "Epoch: 440. Loss: 0.6161037237257394\n",
            "Epoch: 450. Loss: 0.6160936382010249\n",
            "Epoch: 460. Loss: 0.6160844717664593\n",
            "Epoch: 470. Loss: 0.6160761409625951\n",
            "Epoch: 480. Loss: 0.6160685698929593\n",
            "Epoch: 490. Loss: 0.6160616895328452\n",
            "tensor(0.7345, dtype=torch.float64)\n",
            "2022-08-14 00:00:00\n",
            "Epoch: 0. Loss: 1.5521977392645236\n",
            "Epoch: 10. Loss: 0.9114391452564751\n",
            "Epoch: 20. Loss: 0.7119528820357102\n",
            "Epoch: 30. Loss: 0.6568389446394912\n",
            "Epoch: 40. Loss: 0.6350998203327731\n",
            "Epoch: 50. Loss: 0.6248782983592799\n",
            "Epoch: 60. Loss: 0.6193264377505184\n",
            "Epoch: 70. Loss: 0.6160407024836634\n",
            "Epoch: 80. Loss: 0.6140157384546909\n",
            "Epoch: 90. Loss: 0.6127456177650294\n",
            "Epoch: 100. Loss: 0.6119426832782205\n",
            "Epoch: 110. Loss: 0.6114330807409115\n",
            "Epoch: 120. Loss: 0.6111088691777561\n",
            "Epoch: 130. Loss: 0.6109022394235933\n",
            "Epoch: 140. Loss: 0.610770352944569\n",
            "Epoch: 150. Loss: 0.6106860592809781\n",
            "Epoch: 160. Loss: 0.6106321127418537\n",
            "Epoch: 170. Loss: 0.6105975401189305\n",
            "Epoch: 180. Loss: 0.6105753493122925\n",
            "Epoch: 190. Loss: 0.6105610795709431\n",
            "Epoch: 200. Loss: 0.6105518821145233\n",
            "Epoch: 210. Loss: 0.61054593598464\n",
            "Epoch: 220. Loss: 0.6105420762893521\n",
            "Epoch: 230. Loss: 0.6105395572902407\n",
            "Epoch: 240. Loss: 0.6105379012473864\n",
            "Epoch: 250. Loss: 0.6105368018863255\n",
            "Epoch: 260. Loss: 0.6105360626990733\n",
            "Epoch: 270. Loss: 0.6105355574830216\n",
            "Epoch: 280. Loss: 0.610535205088601\n",
            "Epoch: 290. Loss: 0.6105349532519756\n",
            "Epoch: 300. Loss: 0.6105347682400433\n",
            "Epoch: 310. Loss: 0.6105346282157263\n",
            "Epoch: 320. Loss: 0.610534518985452\n",
            "Epoch: 330. Loss: 0.610534431272504\n",
            "Epoch: 340. Loss: 0.6105343589680267\n",
            "Epoch: 350. Loss: 0.6105342980085867\n",
            "Epoch: 360. Loss: 0.6105342456553802\n",
            "Epoch: 370. Loss: 0.6105342000309764\n",
            "Epoch: 380. Loss: 0.6105341598212413\n",
            "Epoch: 390. Loss: 0.6105341240832424\n",
            "Epoch: 400. Loss: 0.6105340921211834\n",
            "Epoch: 410. Loss: 0.6105340634060306\n",
            "Epoch: 420. Loss: 0.6105340375232297\n",
            "Epoch: 430. Loss: 0.6105340141384947\n",
            "Epoch: 440. Loss: 0.6105339929752513\n",
            "Epoch: 450. Loss: 0.610533973799603\n",
            "Epoch: 460. Loss: 0.6105339564101762\n",
            "Epoch: 470. Loss: 0.6105339406311406\n",
            "Epoch: 480. Loss: 0.6105339263073044\n",
            "Epoch: 490. Loss: 0.6105339133005827\n",
            "tensor(0.6465, dtype=torch.float64)\n",
            "2022-08-21 00:00:00\n",
            "Epoch: 0. Loss: 2.3083157201838205\n",
            "Epoch: 10. Loss: 1.496606472346709\n",
            "Epoch: 20. Loss: 0.9489876790967221\n",
            "Epoch: 30. Loss: 0.790054271429451\n",
            "Epoch: 40. Loss: 0.7303489423624553\n",
            "Epoch: 50. Loss: 0.692297512094898\n",
            "Epoch: 60. Loss: 0.66693361196334\n",
            "Epoch: 70. Loss: 0.6500693159046286\n",
            "Epoch: 80. Loss: 0.6389076771732964\n",
            "Epoch: 90. Loss: 0.6315345278727905\n",
            "Epoch: 100. Loss: 0.6266515233226913\n",
            "Epoch: 110. Loss: 0.6233930171727964\n",
            "Epoch: 120. Loss: 0.6211909290756421\n",
            "Epoch: 130. Loss: 0.619676497491349\n",
            "Epoch: 140. Loss: 0.6186117512381972\n",
            "Epoch: 150. Loss: 0.6178434214044908\n",
            "Epoch: 160. Loss: 0.6172727027156034\n",
            "Epoch: 170. Loss: 0.6168357033211511\n",
            "Epoch: 180. Loss: 0.6164909025142539\n",
            "Epoch: 190. Loss: 0.6162111314226814\n",
            "Epoch: 200. Loss: 0.6159784496438476\n",
            "Epoch: 210. Loss: 0.6157808698632562\n",
            "Epoch: 220. Loss: 0.6156102608546221\n",
            "Epoch: 230. Loss: 0.6154610023752042\n",
            "Epoch: 240. Loss: 0.6153291204574546\n",
            "Epoch: 250. Loss: 0.6152117301153486\n",
            "Epoch: 260. Loss: 0.6151066750917502\n",
            "Epoch: 270. Loss: 0.6150122941059875\n",
            "Epoch: 280. Loss: 0.6149272684469421\n",
            "Epoch: 290. Loss: 0.6148505219658676\n",
            "Epoch: 300. Loss: 0.6147811548904317\n",
            "Epoch: 310. Loss: 0.6147183995224744\n",
            "Epoch: 320. Loss: 0.6146615901413142\n",
            "Epoch: 330. Loss: 0.6146101421689689\n",
            "Epoch: 340. Loss: 0.6145635374106081\n",
            "Epoch: 350. Loss: 0.6145213133130617\n",
            "Epoch: 360. Loss: 0.6144830549107181\n",
            "Epoch: 370. Loss: 0.6144483885956374\n",
            "Epoch: 380. Loss: 0.6144169771497058\n",
            "Epoch: 390. Loss: 0.6143885156705797\n",
            "Epoch: 400. Loss: 0.6143627281482502\n",
            "Epoch: 410. Loss: 0.6143393645298616\n",
            "Epoch: 420. Loss: 0.6143181981627523\n",
            "Epoch: 430. Loss: 0.6142990235397074\n",
            "Epoch: 440. Loss: 0.6142816542926418\n",
            "Epoch: 450. Loss: 0.6142659213955862\n",
            "Epoch: 460. Loss: 0.6142516715475992\n",
            "Epoch: 470. Loss: 0.6142387657128247\n",
            "Epoch: 480. Loss: 0.6142270777994588\n",
            "Epoch: 490. Loss: 0.6142164934625977\n",
            "tensor(0.6171, dtype=torch.float64)\n",
            "2022-08-28 00:00:00\n",
            "Epoch: 0. Loss: 1.817452318487132\n",
            "Epoch: 10. Loss: 0.8226247263098074\n",
            "Epoch: 20. Loss: 0.7104378274373563\n",
            "Epoch: 30. Loss: 0.6816369780953527\n",
            "Epoch: 40. Loss: 0.6621763603825188\n",
            "Epoch: 50. Loss: 0.6478807618683224\n",
            "Epoch: 60. Loss: 0.6376416395190856\n",
            "Epoch: 70. Loss: 0.6304897169972494\n",
            "Epoch: 80. Loss: 0.6255940916858281\n",
            "Epoch: 90. Loss: 0.6222936285229336\n",
            "Epoch: 100. Loss: 0.6200920136085116\n",
            "Epoch: 110. Loss: 0.6186326170149286\n",
            "Epoch: 120. Loss: 0.6176673679180422\n",
            "Epoch: 130. Loss: 0.6170277809433883\n",
            "Epoch: 140. Loss: 0.616601402213093\n",
            "Epoch: 150. Loss: 0.616314117651694\n",
            "Epoch: 160. Loss: 0.616117519258604\n",
            "Epoch: 170. Loss: 0.6159801839257998\n",
            "Epoch: 180. Loss: 0.6158817927035115\n",
            "Epoch: 190. Loss: 0.6158092307224334\n",
            "Epoch: 200. Loss: 0.6157540314572184\n",
            "Epoch: 210. Loss: 0.615710716511128\n",
            "Epoch: 220. Loss: 0.6156757240368529\n",
            "Epoch: 230. Loss: 0.6156467203383061\n",
            "Epoch: 240. Loss: 0.6156221591280795\n",
            "Epoch: 250. Loss: 0.6156009999943847\n",
            "Epoch: 260. Loss: 0.6155825288087476\n",
            "Epoch: 270. Loss: 0.6155662432110057\n",
            "Epoch: 280. Loss: 0.6155517795485684\n",
            "Epoch: 290. Loss: 0.6155388661831788\n",
            "Epoch: 300. Loss: 0.6155272935550704\n",
            "Epoch: 310. Loss: 0.6155168948950058\n",
            "Epoch: 320. Loss: 0.6155075337057022\n",
            "Epoch: 330. Loss: 0.6154990955528743\n",
            "Epoch: 340. Loss: 0.6154914826067128\n",
            "Epoch: 350. Loss: 0.6154846099455533\n",
            "Epoch: 360. Loss: 0.6154784029950732\n",
            "Epoch: 370. Loss: 0.6154727957052132\n",
            "Epoch: 380. Loss: 0.61546772921181\n",
            "Epoch: 390. Loss: 0.6154631508215358\n",
            "Epoch: 400. Loss: 0.6154590132167176\n",
            "Epoch: 410. Loss: 0.6154552738133389\n",
            "Epoch: 420. Loss: 0.6154518942288212\n",
            "Epoch: 430. Loss: 0.6154488398310005\n",
            "Epoch: 440. Loss: 0.6154460793491614\n",
            "Epoch: 450. Loss: 0.6154435845340558\n",
            "Epoch: 460. Loss: 0.6154413298577436\n",
            "Epoch: 470. Loss: 0.6154392922466434\n",
            "Epoch: 480. Loss: 0.6154374508428684\n",
            "Epoch: 490. Loss: 0.6154357867900545\n",
            "tensor(0.4806, dtype=torch.float64)\n",
            "2022-09-04 00:00:00\n",
            "Epoch: 0. Loss: 6.333710176167022\n",
            "Epoch: 10. Loss: 1.474432596403346\n",
            "Epoch: 20. Loss: 0.9711302829677516\n",
            "Epoch: 30. Loss: 0.8376774515208232\n",
            "Epoch: 40. Loss: 0.7515151658001477\n",
            "Epoch: 50. Loss: 0.696616809634726\n",
            "Epoch: 60. Loss: 0.6638554242740804\n",
            "Epoch: 70. Loss: 0.6447407271162944\n",
            "Epoch: 80. Loss: 0.6334820369697702\n",
            "Epoch: 90. Loss: 0.6267376562690269\n",
            "Epoch: 100. Loss: 0.6226388821525202\n",
            "Epoch: 110. Loss: 0.6201182177700338\n",
            "Epoch: 120. Loss: 0.6185505357158779\n",
            "Epoch: 130. Loss: 0.6175635653437489\n",
            "Epoch: 140. Loss: 0.6169332056004343\n",
            "Epoch: 150. Loss: 0.6165234920980003\n",
            "Epoch: 160. Loss: 0.6162514004862447\n",
            "Epoch: 170. Loss: 0.6160659387857984\n",
            "Epoch: 180. Loss: 0.6159356152716683\n",
            "Epoch: 190. Loss: 0.615840872635218\n",
            "Epoch: 200. Loss: 0.6157694922788751\n",
            "Epoch: 210. Loss: 0.6157137878106469\n",
            "Epoch: 220. Loss: 0.6156688832028745\n",
            "Epoch: 230. Loss: 0.6156316521688869\n",
            "Epoch: 240. Loss: 0.6156000625597357\n",
            "Epoch: 250. Loss: 0.615572769863199\n",
            "Epoch: 260. Loss: 0.6155488644348798\n",
            "Epoch: 270. Loss: 0.6155277138762306\n",
            "Epoch: 280. Loss: 0.6155088644428923\n",
            "Epoch: 290. Loss: 0.615491979153138\n",
            "Epoch: 300. Loss: 0.6154767987572966\n",
            "Epoch: 310. Loss: 0.615463116974814\n",
            "Epoch: 320. Loss: 0.6154507646544785\n",
            "Epoch: 330. Loss: 0.6154395995294015\n",
            "Epoch: 340. Loss: 0.6154294994913639\n",
            "Epoch: 350. Loss: 0.615420358088844\n",
            "Epoch: 360. Loss: 0.6154120814387132\n",
            "Epoch: 370. Loss: 0.615404586044345\n",
            "Epoch: 380. Loss: 0.6153977972017475\n",
            "Epoch: 390. Loss: 0.6153916477932473\n",
            "Epoch: 400. Loss: 0.6153860773419222\n",
            "Epoch: 410. Loss: 0.6153810312460612\n",
            "Epoch: 420. Loss: 0.6153764601418044\n",
            "Epoch: 430. Loss: 0.615372319360236\n",
            "Epoch: 440. Loss: 0.6153685684566204\n",
            "Epoch: 450. Loss: 0.6153651707967002\n",
            "Epoch: 460. Loss: 0.6153620931895706\n",
            "Epoch: 470. Loss: 0.6153593055596144\n",
            "Epoch: 480. Loss: 0.6153567806519045\n",
            "Epoch: 490. Loss: 0.6153544937667687\n",
            "tensor(0.4596, dtype=torch.float64)\n",
            "2022-09-11 00:00:00\n",
            "Epoch: 0. Loss: 1.7398571713938993\n",
            "Epoch: 10. Loss: 1.1622305684624985\n",
            "Epoch: 20. Loss: 0.9698716609446867\n",
            "Epoch: 30. Loss: 0.8375935409503222\n",
            "Epoch: 40. Loss: 0.7444752081067195\n",
            "Epoch: 50. Loss: 0.6864392053053071\n",
            "Epoch: 60. Loss: 0.6553582271043583\n",
            "Epoch: 70. Loss: 0.6405782229540674\n",
            "Epoch: 80. Loss: 0.6337037601672316\n",
            "Epoch: 90. Loss: 0.6301972750004196\n",
            "Epoch: 100. Loss: 0.6281257445827234\n",
            "Epoch: 110. Loss: 0.6267351596904288\n",
            "Epoch: 120. Loss: 0.625717377202042\n",
            "Epoch: 130. Loss: 0.6249292045495153\n",
            "Epoch: 140. Loss: 0.6242944155557026\n",
            "Epoch: 150. Loss: 0.6237681826863063\n",
            "Epoch: 160. Loss: 0.6233223912770607\n",
            "Epoch: 170. Loss: 0.6229385879076342\n",
            "Epoch: 180. Loss: 0.6226041813097624\n",
            "Epoch: 190. Loss: 0.6223102522719645\n",
            "Epoch: 200. Loss: 0.6220502442426523\n",
            "Epoch: 210. Loss: 0.621819163087747\n",
            "Epoch: 220. Loss: 0.6216130794144585\n",
            "Epoch: 230. Loss: 0.6214288135017367\n",
            "Epoch: 240. Loss: 0.6212637317235373\n",
            "Epoch: 250. Loss: 0.6211156118354191\n",
            "Epoch: 260. Loss: 0.6209825513635343\n",
            "Epoch: 270. Loss: 0.6208629034057235\n",
            "Epoch: 280. Loss: 0.6207552302017569\n",
            "Epoch: 290. Loss: 0.6206582684819455\n",
            "Epoch: 300. Loss: 0.6205709028234239\n",
            "Epoch: 310. Loss: 0.620492144603499\n",
            "Epoch: 320. Loss: 0.620421114980463\n",
            "Epoch: 330. Loss: 0.620357030858107\n",
            "Epoch: 340. Loss: 0.6202991931232876\n",
            "Epoch: 350. Loss: 0.6202469766601733\n",
            "Epoch: 360. Loss: 0.6201998217850959\n",
            "Epoch: 370. Loss: 0.6201572268396339\n",
            "Epoch: 380. Loss: 0.6201187417435335\n",
            "Epoch: 390. Loss: 0.6200839623537971\n",
            "Epoch: 400. Loss: 0.6200525255083169\n",
            "Epoch: 410. Loss: 0.6200241046559507\n",
            "Epoch: 420. Loss: 0.6199984059926297\n",
            "Epoch: 430. Loss: 0.6199751650366871\n",
            "Epoch: 440. Loss: 0.6199541435872669\n",
            "Epoch: 450. Loss: 0.6199351270181906\n",
            "Epoch: 460. Loss: 0.6199179218665809\n",
            "Epoch: 470. Loss: 0.6199023536812223\n",
            "Epoch: 480. Loss: 0.6198882651003655\n",
            "Epoch: 490. Loss: 0.6198755141326617\n",
            "tensor(0.5999, dtype=torch.float64)\n",
            "2022-09-18 00:00:00\n",
            "Epoch: 0. Loss: 5.494877063147597\n",
            "Epoch: 10. Loss: 0.909119269443196\n",
            "Epoch: 20. Loss: 0.7206239042836844\n",
            "Epoch: 30. Loss: 0.6612519404725685\n",
            "Epoch: 40. Loss: 0.6353491093232014\n",
            "Epoch: 50. Loss: 0.6258837883463075\n",
            "Epoch: 60. Loss: 0.6224317496462414\n",
            "Epoch: 70. Loss: 0.6208955242918707\n",
            "Epoch: 80. Loss: 0.619991462328017\n",
            "Epoch: 90. Loss: 0.6193378095106823\n",
            "Epoch: 100. Loss: 0.6188112800136092\n",
            "Epoch: 110. Loss: 0.6183640876220292\n",
            "Epoch: 120. Loss: 0.6179733494267599\n",
            "Epoch: 130. Loss: 0.6176261146956803\n",
            "Epoch: 140. Loss: 0.6173142097975471\n",
            "Epoch: 150. Loss: 0.6170320810352907\n",
            "Epoch: 160. Loss: 0.6167757268684798\n",
            "Epoch: 170. Loss: 0.6165421105308186\n",
            "Epoch: 180. Loss: 0.6163288184346131\n",
            "Epoch: 190. Loss: 0.6161338555880244\n",
            "Epoch: 200. Loss: 0.61595552066541\n",
            "Epoch: 210. Loss: 0.615792328305961\n",
            "Epoch: 220. Loss: 0.6156429597038369\n",
            "Epoch: 230. Loss: 0.6155062302696187\n",
            "Epoch: 240. Loss: 0.6153810676723094\n",
            "Epoch: 250. Loss: 0.6152664962594172\n",
            "Epoch: 260. Loss: 0.6151616254556358\n",
            "Epoch: 270. Loss: 0.6150656406981163\n",
            "Epoch: 280. Loss: 0.6149777960385598\n",
            "Epoch: 290. Loss: 0.6148974078843303\n",
            "Epoch: 300. Loss: 0.614823849555165\n",
            "Epoch: 310. Loss: 0.6147565464542211\n",
            "Epoch: 320. Loss: 0.6146949717253155\n",
            "Epoch: 330. Loss: 0.614638642312071\n",
            "Epoch: 340. Loss: 0.6145871153611454\n",
            "Epoch: 350. Loss: 0.6145399849278149\n",
            "Epoch: 360. Loss: 0.6144968789521379\n",
            "Epoch: 370. Loss: 0.6144574564802175\n",
            "Epoch: 380. Loss: 0.6144214051092168\n",
            "Epoch: 390. Loss: 0.6143884386376025\n",
            "Epoch: 400. Loss: 0.6143582949041574\n",
            "Epoch: 410. Loss: 0.6143307338008763\n",
            "Epoch: 420. Loss: 0.614305535446147\n",
            "Epoch: 430. Loss: 0.614282498505716\n",
            "Epoch: 440. Loss: 0.6142614386498982\n",
            "Epoch: 450. Loss: 0.6142421871363634\n",
            "Epoch: 460. Loss: 0.6142245895086246\n",
            "Epoch: 470. Loss: 0.6142085044010962\n",
            "Epoch: 480. Loss: 0.6141938024422647\n",
            "Epoch: 490. Loss: 0.6141803652481563\n",
            "tensor(0.5152, dtype=torch.float64)\n",
            "2022-09-25 00:00:00\n",
            "Epoch: 0. Loss: 7.905061696613583\n",
            "Epoch: 10. Loss: 2.393383554780323\n",
            "Epoch: 20. Loss: 0.7266006600911047\n",
            "Epoch: 30. Loss: 0.668628069053419\n",
            "Epoch: 40. Loss: 0.6636058150648025\n",
            "Epoch: 50. Loss: 0.6599733812055465\n",
            "Epoch: 60. Loss: 0.6567993024696289\n",
            "Epoch: 70. Loss: 0.6538977476887365\n",
            "Epoch: 80. Loss: 0.6512107359973384\n",
            "Epoch: 90. Loss: 0.6487140820867734\n",
            "Epoch: 100. Loss: 0.6463931901226952\n",
            "Epoch: 110. Loss: 0.6442365193579799\n",
            "Epoch: 120. Loss: 0.6422337596487552\n",
            "Epoch: 130. Loss: 0.6403752927387003\n",
            "Epoch: 140. Loss: 0.6386520172166672\n",
            "Epoch: 150. Loss: 0.6370552831983389\n",
            "Epoch: 160. Loss: 0.6355768636254927\n",
            "Epoch: 170. Loss: 0.6342089391971621\n",
            "Epoch: 180. Loss: 0.6329440886096374\n",
            "Epoch: 190. Loss: 0.6317752805713487\n",
            "Epoch: 200. Loss: 0.630695865917369\n",
            "Epoch: 210. Loss: 0.6296995690178494\n",
            "Epoch: 220. Loss: 0.6287804781394845\n",
            "Epoch: 230. Loss: 0.6279330346823995\n",
            "Epoch: 240. Loss: 0.6271520213634766\n",
            "Epoch: 250. Loss: 0.6264325494962174\n",
            "Epoch: 260. Loss: 0.6257700455533086\n",
            "Epoch: 270. Loss: 0.6251602372077598\n",
            "Epoch: 280. Loss: 0.6245991390424438\n",
            "Epoch: 290. Loss: 0.6240830381029487\n",
            "Epoch: 300. Loss: 0.6236084794492072\n",
            "Epoch: 310. Loss: 0.6231722518402054\n",
            "Epoch: 320. Loss: 0.6227713736648611\n",
            "Epoch: 330. Loss: 0.6224030792119724\n",
            "Epoch: 340. Loss: 0.622064805353506\n",
            "Epoch: 350. Loss: 0.6217541786987337\n",
            "Epoch: 360. Loss: 0.6214690032619131\n",
            "Epoch: 370. Loss: 0.6212072486733277\n",
            "Epoch: 380. Loss: 0.6209670389524707\n",
            "Epoch: 390. Loss: 0.6207466418528195\n",
            "Epoch: 400. Loss: 0.6205444587798662\n",
            "Epoch: 410. Loss: 0.6203590152776832\n",
            "Epoch: 420. Loss: 0.6201889520741284\n",
            "Epoch: 430. Loss: 0.6200330166707053\n",
            "Epoch: 440. Loss: 0.619890055459928\n",
            "Epoch: 450. Loss: 0.6197590063506636\n",
            "Epoch: 460. Loss: 0.6196388918802356\n",
            "Epoch: 470. Loss: 0.6195288127909344\n",
            "Epoch: 480. Loss: 0.6194279420479266\n",
            "Epoch: 490. Loss: 0.6193355192752833\n",
            "tensor(0.5407, dtype=torch.float64)\n",
            "2022-10-02 00:00:00\n",
            "Epoch: 0. Loss: 1.5035755494585659\n",
            "Epoch: 10. Loss: 0.6463991568103788\n",
            "Epoch: 20. Loss: 0.6313950648341705\n",
            "Epoch: 30. Loss: 0.6292982905427595\n",
            "Epoch: 40. Loss: 0.6279193496578087\n",
            "Epoch: 50. Loss: 0.6268957698905998\n",
            "Epoch: 60. Loss: 0.6260922136933141\n",
            "Epoch: 70. Loss: 0.6254348290806309\n",
            "Epoch: 80. Loss: 0.6248802113650521\n",
            "Epoch: 90. Loss: 0.6244016802669179\n",
            "Epoch: 100. Loss: 0.6239821807151273\n",
            "Epoch: 110. Loss: 0.6236103456878738\n",
            "Epoch: 120. Loss: 0.6232782448447935\n",
            "Epoch: 130. Loss: 0.6229800772064038\n",
            "Epoch: 140. Loss: 0.6227114028957071\n",
            "Epoch: 150. Loss: 0.6224686853893172\n",
            "Epoch: 160. Loss: 0.622249013794875\n",
            "Epoch: 170. Loss: 0.6220499303171528\n",
            "Epoch: 180. Loss: 0.6218693198379809\n",
            "Epoch: 190. Loss: 0.6217053367006898\n",
            "Epoch: 200. Loss: 0.621556354198101\n",
            "Epoch: 210. Loss: 0.6214209282449351\n",
            "Epoch: 220. Loss: 0.6212977701693565\n",
            "Epoch: 230. Loss: 0.621185725565394\n",
            "Epoch: 240. Loss: 0.6210837573240654\n",
            "Epoch: 250. Loss: 0.6209909316575496\n",
            "Epoch: 260. Loss: 0.6209064063487177\n",
            "Epoch: 270. Loss: 0.6208294207132443\n",
            "Epoch: 280. Loss: 0.6207592869200401\n",
            "Epoch: 290. Loss: 0.6206953824166206\n",
            "Epoch: 300. Loss: 0.6206371432719257\n",
            "Epoch: 310. Loss: 0.6205840582934373\n",
            "Epoch: 320. Loss: 0.6205356638061872\n",
            "Epoch: 330. Loss: 0.6204915390032755\n",
            "Epoch: 340. Loss: 0.620451301793763\n",
            "Epoch: 350. Loss: 0.6204146050861383\n",
            "Epoch: 360. Loss: 0.6203811334551735\n",
            "Epoch: 370. Loss: 0.6203506001476239\n",
            "Epoch: 380. Loss: 0.6203227443884345\n",
            "Epoch: 390. Loss: 0.62029732895422\n",
            "Epoch: 400. Loss: 0.6202741379850509\n",
            "Epoch: 410. Loss: 0.6202529750091698\n",
            "Epoch: 420. Loss: 0.6202336611583198\n",
            "Epoch: 430. Loss: 0.6202160335539888\n",
            "Epoch: 440. Loss: 0.6201999438471322\n",
            "Epoch: 450. Loss: 0.6201852568958977\n",
            "Epoch: 460. Loss: 0.6201718495675812\n",
            "Epoch: 470. Loss: 0.6201596096525407\n",
            "Epoch: 480. Loss: 0.6201484348790977\n",
            "Epoch: 490. Loss: 0.6201382320196207\n",
            "tensor(0.6481, dtype=torch.float64)\n",
            "2022-10-09 00:00:00\n",
            "Epoch: 0. Loss: 1.491163075171727\n",
            "Epoch: 10. Loss: 0.7934441853381945\n",
            "Epoch: 20. Loss: 0.6898265209456386\n",
            "Epoch: 30. Loss: 0.6633446463280379\n",
            "Epoch: 40. Loss: 0.6487596100444507\n",
            "Epoch: 50. Loss: 0.6400056850459154\n",
            "Epoch: 60. Loss: 0.634689064983123\n",
            "Epoch: 70. Loss: 0.6314826359367629\n",
            "Epoch: 80. Loss: 0.6295717098231192\n",
            "Epoch: 90. Loss: 0.6284450805142323\n",
            "Epoch: 100. Loss: 0.6277856803909189\n",
            "Epoch: 110. Loss: 0.627400814644339\n",
            "Epoch: 120. Loss: 0.6271756118343396\n",
            "Epoch: 130. Loss: 0.6270426460993781\n",
            "Epoch: 140. Loss: 0.6269627949009176\n",
            "Epoch: 150. Loss: 0.6269135424477631\n",
            "Epoch: 160. Loss: 0.6268819993290895\n",
            "Epoch: 170. Loss: 0.6268608079816947\n",
            "Epoch: 180. Loss: 0.6268457705434635\n",
            "Epoch: 190. Loss: 0.6268344866872126\n",
            "Epoch: 200. Loss: 0.6268255763201181\n",
            "Epoch: 210. Loss: 0.6268182379711148\n",
            "Epoch: 220. Loss: 0.6268119986335717\n",
            "Epoch: 230. Loss: 0.6268065723130865\n",
            "Epoch: 240. Loss: 0.6268017801026052\n",
            "Epoch: 250. Loss: 0.6267975050081295\n",
            "Epoch: 260. Loss: 0.6267936663756103\n",
            "Epoch: 270. Loss: 0.6267902053670862\n",
            "Epoch: 280. Loss: 0.6267870766657\n",
            "Epoch: 290. Loss: 0.6267842436951416\n",
            "Epoch: 300. Loss: 0.6267816758256445\n",
            "Epoch: 310. Loss: 0.6267793467065765\n",
            "Epoch: 320. Loss: 0.6267772332413536\n",
            "Epoch: 330. Loss: 0.6267753149316767\n",
            "Epoch: 340. Loss: 0.6267735734368917\n",
            "Epoch: 350. Loss: 0.6267719922610924\n",
            "Epoch: 360. Loss: 0.6267705565182081\n",
            "Epoch: 370. Loss: 0.6267692527465107\n",
            "Epoch: 380. Loss: 0.6267680687559474\n",
            "Epoch: 390. Loss: 0.6267669934984892\n",
            "Epoch: 400. Loss: 0.6267660169555372\n",
            "Epoch: 410. Loss: 0.6267651300386485\n",
            "Epoch: 420. Loss: 0.62676432450112\n",
            "Epoch: 430. Loss: 0.6267635928587257\n",
            "Epoch: 440. Loss: 0.626762928318365\n",
            "Epoch: 450. Loss: 0.6267623247136539\n",
            "Epoch: 460. Loss: 0.6267617764466854\n",
            "Epoch: 470. Loss: 0.6267612784353088\n",
            "Epoch: 480. Loss: 0.6267608260653688\n",
            "Epoch: 490. Loss: 0.6267604151474158\n",
            "tensor(0.4444, dtype=torch.float64)\n",
            "2022-10-16 00:00:00\n",
            "Epoch: 0. Loss: 2.7042154832006466\n",
            "Epoch: 10. Loss: 1.4707686385206418\n",
            "Epoch: 20. Loss: 1.1200698421822666\n",
            "Epoch: 30. Loss: 0.9406882390861012\n",
            "Epoch: 40. Loss: 0.8180058137839441\n",
            "Epoch: 50. Loss: 0.7438501388611903\n",
            "Epoch: 60. Loss: 0.7037943158620403\n",
            "Epoch: 70. Loss: 0.6823468056303145\n",
            "Epoch: 80. Loss: 0.6701565768954469\n",
            "Epoch: 90. Loss: 0.6627070701847965\n",
            "Epoch: 100. Loss: 0.6578255233065853\n",
            "Epoch: 110. Loss: 0.6544021751326912\n",
            "Epoch: 120. Loss: 0.6518414626192502\n",
            "Epoch: 130. Loss: 0.6498135994755574\n",
            "Epoch: 140. Loss: 0.6481318869347941\n",
            "Epoch: 150. Loss: 0.6466884474542794\n",
            "Epoch: 160. Loss: 0.645419442515274\n",
            "Epoch: 170. Loss: 0.6442859006193691\n",
            "Epoch: 180. Loss: 0.6432630314199433\n",
            "Epoch: 190. Loss: 0.6423342254804256\n",
            "Epoch: 200. Loss: 0.64148766701153\n",
            "Epoch: 210. Loss: 0.6407144133750056\n",
            "Epoch: 220. Loss: 0.640007301465759\n",
            "Epoch: 230. Loss: 0.6393603214309483\n",
            "Epoch: 240. Loss: 0.638768254855653\n",
            "Epoch: 250. Loss: 0.6382264626752131\n",
            "Epoch: 260. Loss: 0.6377307578661718\n",
            "Epoch: 270. Loss: 0.6372773261703941\n",
            "Epoch: 280. Loss: 0.6368626740969092\n",
            "Epoch: 290. Loss: 0.6364835925085593\n",
            "Epoch: 300. Loss: 0.6361371292288729\n",
            "Epoch: 310. Loss: 0.6358205669988167\n",
            "Epoch: 320. Loss: 0.6355314047401482\n",
            "Epoch: 330. Loss: 0.6352673409920354\n",
            "Epoch: 340. Loss: 0.6350262588930078\n",
            "Epoch: 350. Loss: 0.6348062123585009\n",
            "Epoch: 360. Loss: 0.6346054132555553\n",
            "Epoch: 370. Loss: 0.6344222194572448\n",
            "Epoch: 380. Loss: 0.6342551237018442\n",
            "Epoch: 390. Loss: 0.6341027432033784\n",
            "Epoch: 400. Loss: 0.6339638099707811\n",
            "Epoch: 410. Loss: 0.633837161797861\n",
            "Epoch: 420. Loss: 0.6337217338885068\n",
            "Epoch: 430. Loss: 0.6336165510825923\n",
            "Epoch: 440. Loss: 0.6335207206486686\n",
            "Epoch: 450. Loss: 0.6334334256101131\n",
            "Epoch: 460. Loss: 0.633353918572116\n",
            "Epoch: 470. Loss: 0.6332815160177603\n",
            "Epoch: 480. Loss: 0.6332155930425108\n",
            "Epoch: 490. Loss: 0.6331555784976138\n",
            "tensor(0.6523, dtype=torch.float64)\n",
            "2022-10-23 00:00:00\n",
            "Epoch: 0. Loss: 2.078417695788574\n",
            "Epoch: 10. Loss: 1.1713234828496708\n",
            "Epoch: 20. Loss: 0.9187585391502218\n",
            "Epoch: 30. Loss: 0.8114260641868011\n",
            "Epoch: 40. Loss: 0.7480036716210078\n",
            "Epoch: 50. Loss: 0.7098560879833333\n",
            "Epoch: 60. Loss: 0.6872335839881286\n",
            "Epoch: 70. Loss: 0.6738703314128913\n",
            "Epoch: 80. Loss: 0.6657087077086298\n",
            "Epoch: 90. Loss: 0.6603858069703211\n",
            "Epoch: 100. Loss: 0.6566376785279558\n",
            "Epoch: 110. Loss: 0.6538101612830336\n",
            "Epoch: 120. Loss: 0.6515639521091929\n",
            "Epoch: 130. Loss: 0.6497173125381757\n",
            "Epoch: 140. Loss: 0.6481667531008342\n",
            "Epoch: 150. Loss: 0.6468482182226153\n",
            "Epoch: 160. Loss: 0.6457183297771041\n",
            "Epoch: 170. Loss: 0.6447452959361863\n",
            "Epoch: 180. Loss: 0.6439044126724309\n",
            "Epoch: 190. Loss: 0.6431757397118374\n",
            "Epoch: 200. Loss: 0.6425428132668176\n",
            "Epoch: 210. Loss: 0.6419918639739403\n",
            "Epoch: 220. Loss: 0.6415112920496712\n",
            "Epoch: 230. Loss: 0.6410912833048494\n",
            "Epoch: 240. Loss: 0.640723510364037\n",
            "Epoch: 250. Loss: 0.6404008913057365\n",
            "Epoch: 260. Loss: 0.6401173907381746\n",
            "Epoch: 270. Loss: 0.6398678542779164\n",
            "Epoch: 280. Loss: 0.6396478702779262\n",
            "Epoch: 290. Loss: 0.639453654166132\n",
            "Epoch: 300. Loss: 0.6392819516643264\n",
            "Epoch: 310. Loss: 0.6391299577895242\n",
            "Epoch: 320. Loss: 0.6389952490337194\n",
            "Epoch: 330. Loss: 0.6388757265295454\n",
            "Epoch: 340. Loss: 0.6387695683610434\n",
            "Epoch: 350. Loss: 0.6386751894805868\n",
            "Epoch: 360. Loss: 0.638591207950633\n",
            "Epoch: 370. Loss: 0.6385164164470981\n",
            "Epoch: 380. Loss: 0.6384497581443133\n",
            "Epoch: 390. Loss: 0.638390306254213\n",
            "Epoch: 400. Loss: 0.63833724661898\n",
            "Epoch: 410. Loss: 0.6382898628608441\n",
            "Epoch: 420. Loss: 0.6382475236787016\n",
            "Epoch: 430. Loss: 0.6382096719518365\n",
            "Epoch: 440. Loss: 0.6381758153689919\n",
            "Epoch: 450. Loss: 0.6381455183486019\n",
            "Epoch: 460. Loss: 0.6381183950550707\n",
            "Epoch: 470. Loss: 0.638094103348105\n",
            "Epoch: 480. Loss: 0.6380723395285739\n",
            "Epoch: 490. Loss: 0.6380528337662106\n",
            "tensor(0.4442, dtype=torch.float64)\n",
            "2022-10-30 00:00:00\n",
            "Epoch: 0. Loss: 3.070078786634817\n",
            "Epoch: 10. Loss: 1.5971092962600157\n",
            "Epoch: 20. Loss: 0.737984225822455\n",
            "Epoch: 30. Loss: 0.6530524738776733\n",
            "Epoch: 40. Loss: 0.6486128950609404\n",
            "Epoch: 50. Loss: 0.647259760041314\n",
            "Epoch: 60. Loss: 0.64657095117718\n",
            "Epoch: 70. Loss: 0.6460910176978054\n",
            "Epoch: 80. Loss: 0.6457048858304547\n",
            "Epoch: 90. Loss: 0.6453749896287377\n",
            "Epoch: 100. Loss: 0.6450849584368742\n",
            "Epoch: 110. Loss: 0.6448260007781754\n",
            "Epoch: 120. Loss: 0.6445927387165696\n",
            "Epoch: 130. Loss: 0.6443815556907885\n",
            "Epoch: 140. Loss: 0.64418981514043\n",
            "Epoch: 150. Loss: 0.6440154574904546\n",
            "Epoch: 160. Loss: 0.6438567837413918\n",
            "Epoch: 170. Loss: 0.6437123363016546\n",
            "Epoch: 180. Loss: 0.6435808316365252\n",
            "Epoch: 190. Loss: 0.6434611208246395\n",
            "Epoch: 200. Loss: 0.6433521652731546\n",
            "Epoch: 210. Loss: 0.6432530207604394\n",
            "Epoch: 220. Loss: 0.6431628261376027\n",
            "Epoch: 230. Loss: 0.6430807947143322\n",
            "Epoch: 240. Loss: 0.6430062072623923\n",
            "Epoch: 250. Loss: 0.6429384060564075\n",
            "Epoch: 260. Loss: 0.6428767896318579\n",
            "Epoch: 270. Loss: 0.6428208080795258\n",
            "Epoch: 280. Loss: 0.6427699587702626\n",
            "Epoch: 290. Loss: 0.6427237824440656\n",
            "Epoch: 300. Loss: 0.6426818596192205\n",
            "Epoch: 310. Loss: 0.6426438072892541\n",
            "Epoch: 320. Loss: 0.6426092758822787\n",
            "Epoch: 330. Loss: 0.6425779464613917\n",
            "Epoch: 340. Loss: 0.6425495281474238\n",
            "Epoch: 350. Loss: 0.6425237557471793\n",
            "Epoch: 360. Loss: 0.6425003875717311\n",
            "Epoch: 370. Loss: 0.6424792034305159\n",
            "Epoch: 380. Loss: 0.6424600027879982\n",
            "Epoch: 390. Loss: 0.6424426030706094\n",
            "Epoch: 400. Loss: 0.6424268381125184\n",
            "Epoch: 410. Loss: 0.6424125567295939\n",
            "Epoch: 420. Loss: 0.6423996214116627\n",
            "Epoch: 430. Loss: 0.6423879071238637\n",
            "Epoch: 440. Loss: 0.6423773002085559\n",
            "Epoch: 450. Loss: 0.6423676973798458\n",
            "Epoch: 460. Loss: 0.6423590048033841\n",
            "Epoch: 470. Loss: 0.642351137254605\n",
            "Epoch: 480. Loss: 0.6423440173490935\n",
            "Epoch: 490. Loss: 0.6423375748392329\n",
            "tensor(0.5529, dtype=torch.float64)\n",
            "2022-11-06 00:00:00\n",
            "Epoch: 0. Loss: 1.1704151349313687\n",
            "Epoch: 10. Loss: 0.7094222586282045\n",
            "Epoch: 20. Loss: 0.6764219351872927\n",
            "Epoch: 30. Loss: 0.6633325829515818\n",
            "Epoch: 40. Loss: 0.6576895158121924\n",
            "Epoch: 50. Loss: 0.6550740810322723\n",
            "Epoch: 60. Loss: 0.6537420233117037\n",
            "Epoch: 70. Loss: 0.6529838823473543\n",
            "Epoch: 80. Loss: 0.6524990704198498\n",
            "Epoch: 90. Loss: 0.6521547567883175\n",
            "Epoch: 100. Loss: 0.6518896453482352\n",
            "Epoch: 110. Loss: 0.6516740226207187\n",
            "Epoch: 120. Loss: 0.6514925722979995\n",
            "Epoch: 130. Loss: 0.6513367605454622\n",
            "Epoch: 140. Loss: 0.6512013755107091\n",
            "Epoch: 150. Loss: 0.6510829170708061\n",
            "Epoch: 160. Loss: 0.6509788281843645\n",
            "Epoch: 170. Loss: 0.6508871161295833\n",
            "Epoch: 180. Loss: 0.6508061576313511\n",
            "Epoch: 190. Loss: 0.6507345925178231\n",
            "Epoch: 200. Loss: 0.6506712611600605\n",
            "Epoch: 210. Loss: 0.6506151644001243\n",
            "Epoch: 220. Loss: 0.6505654356585372\n",
            "Epoch: 230. Loss: 0.6505213201114791\n",
            "Epoch: 240. Loss: 0.650482158317269\n",
            "Epoch: 250. Loss: 0.6504473728810527\n",
            "Epoch: 260. Loss: 0.650416457346768\n",
            "Epoch: 270. Loss: 0.6503889668128131\n",
            "Epoch: 280. Loss: 0.6503645099326695\n",
            "Epoch: 290. Loss: 0.6503427420557643\n",
            "Epoch: 300. Loss: 0.6503233593217208\n",
            "Epoch: 310. Loss: 0.6503060935596406\n",
            "Epoch: 320. Loss: 0.6502907078715733\n",
            "Epoch: 330. Loss: 0.650276992800125\n",
            "Epoch: 340. Loss: 0.6502647629965078\n",
            "Epoch: 350. Loss: 0.6502538543185243\n",
            "Epoch: 360. Loss: 0.6502441212988236\n",
            "Epoch: 370. Loss: 0.650235434932739\n",
            "Epoch: 380. Loss: 0.6502276807425316\n",
            "Epoch: 390. Loss: 0.6502207570811467\n",
            "Epoch: 400. Loss: 0.6502145736439104\n",
            "Epoch: 410. Loss: 0.6502090501610561\n",
            "Epoch: 420. Loss: 0.6502041152477746\n",
            "Epoch: 430. Loss: 0.6501997053916997\n",
            "Epoch: 440. Loss: 0.6501957640604847\n",
            "Epoch: 450. Loss: 0.6501922409144585\n",
            "Epoch: 460. Loss: 0.6501890911113556\n",
            "Epoch: 470. Loss: 0.6501862746918258\n",
            "Epoch: 480. Loss: 0.6501837560358964\n",
            "Epoch: 490. Loss: 0.650181503381832\n",
            "tensor(0.5794, dtype=torch.float64)\n",
            "2022-11-13 00:00:00\n",
            "Epoch: 0. Loss: 2.441882613604195\n",
            "Epoch: 10. Loss: 1.5130556519875193\n",
            "Epoch: 20. Loss: 1.1367633095261827\n",
            "Epoch: 30. Loss: 0.9806212420478726\n",
            "Epoch: 40. Loss: 0.8851092474971317\n",
            "Epoch: 50. Loss: 0.8165324789886164\n",
            "Epoch: 60. Loss: 0.7655112569786445\n",
            "Epoch: 70. Loss: 0.7282654765176352\n",
            "Epoch: 80. Loss: 0.7022071062692948\n",
            "Epoch: 90. Loss: 0.6848281768402524\n",
            "Epoch: 100. Loss: 0.6737137714968007\n",
            "Epoch: 110. Loss: 0.6668099008136251\n",
            "Epoch: 120. Loss: 0.6625744877063233\n",
            "Epoch: 130. Loss: 0.6599590742804394\n",
            "Epoch: 140. Loss: 0.6583006174409763\n",
            "Epoch: 150. Loss: 0.657200457619385\n",
            "Epoch: 160. Loss: 0.6564268610373184\n",
            "Epoch: 170. Loss: 0.6558479238989567\n",
            "Epoch: 180. Loss: 0.6553893420441577\n",
            "Epoch: 190. Loss: 0.655009266564688\n",
            "Epoch: 200. Loss: 0.6546838615553221\n",
            "Epoch: 210. Loss: 0.6543992056718605\n",
            "Epoch: 220. Loss: 0.6541468241673215\n",
            "Epoch: 230. Loss: 0.6539212504670964\n",
            "Epoch: 240. Loss: 0.6537187041559334\n",
            "Epoch: 250. Loss: 0.6535363761804337\n",
            "Epoch: 260. Loss: 0.6533720417213357\n",
            "Epoch: 270. Loss: 0.653223848964109\n",
            "Epoch: 280. Loss: 0.6530902020282864\n",
            "Epoch: 290. Loss: 0.6529696942885467\n",
            "Epoch: 300. Loss: 0.6528610687480225\n",
            "Epoch: 310. Loss: 0.6527631930489887\n",
            "Epoch: 320. Loss: 0.652675042523312\n",
            "Epoch: 330. Loss: 0.6525956877729338\n",
            "Epoch: 340. Loss: 0.652524284906441\n",
            "Epoch: 350. Loss: 0.6524600674234997\n",
            "Epoch: 360. Loss: 0.6524023391972715\n",
            "Epoch: 370. Loss: 0.6523504682480594\n",
            "Epoch: 380. Loss: 0.652303881130974\n",
            "Epoch: 390. Loss: 0.65226205782993\n",
            "Epoch: 400. Loss: 0.6522245270880823\n",
            "Epoch: 410. Loss: 0.6521908621257426\n",
            "Epoch: 420. Loss: 0.6521606767087627\n",
            "Epoch: 430. Loss: 0.6521336215374568\n",
            "Epoch: 440. Loss: 0.6521093809305994\n",
            "Epoch: 450. Loss: 0.6520876697820029\n",
            "Epoch: 460. Loss: 0.652068230769341\n",
            "Epoch: 470. Loss: 0.6520508317965392\n",
            "Epoch: 480. Loss: 0.6520352636524162\n",
            "Epoch: 490. Loss: 0.6520213378694405\n",
            "tensor(0.5211, dtype=torch.float64)\n",
            "2022-11-20 00:00:00\n",
            "Epoch: 0. Loss: 4.542407334602148\n",
            "Epoch: 10. Loss: 1.5903374250247362\n",
            "Epoch: 20. Loss: 0.7837201609099167\n",
            "Epoch: 30. Loss: 0.70417570348148\n",
            "Epoch: 40. Loss: 0.6738518434646011\n",
            "Epoch: 50. Loss: 0.6633018527276769\n",
            "Epoch: 60. Loss: 0.6592130922247507\n",
            "Epoch: 70. Loss: 0.6569639791361659\n",
            "Epoch: 80. Loss: 0.6553245848207934\n",
            "Epoch: 90. Loss: 0.6539863488828448\n",
            "Epoch: 100. Loss: 0.6528567878874189\n",
            "Epoch: 110. Loss: 0.6518939656825544\n",
            "Epoch: 120. Loss: 0.6510701435410965\n",
            "Epoch: 130. Loss: 0.6503635811024858\n",
            "Epoch: 140. Loss: 0.6497563335410496\n",
            "Epoch: 150. Loss: 0.6492333799553781\n",
            "Epoch: 160. Loss: 0.6487820981323463\n",
            "Epoch: 170. Loss: 0.6483918669924942\n",
            "Epoch: 180. Loss: 0.6480537410582053\n",
            "Epoch: 190. Loss: 0.6477601781139718\n",
            "Epoch: 200. Loss: 0.6475048105141217\n",
            "Epoch: 210. Loss: 0.6472822534195859\n",
            "Epoch: 220. Loss: 0.6470879444252166\n",
            "Epoch: 230. Loss: 0.6469180097733075\n",
            "Epoch: 240. Loss: 0.6467691529549723\n",
            "Epoch: 250. Loss: 0.6466385620572648\n",
            "Epoch: 260. Loss: 0.6465238327311678\n",
            "Epoch: 270. Loss: 0.6464229041283359\n",
            "Epoch: 280. Loss: 0.6463340055767886\n",
            "Epoch: 290. Loss: 0.6462556121350017\n",
            "Epoch: 300. Loss: 0.6461864074810751\n",
            "Epoch: 310. Loss: 0.6461252528622988\n",
            "Epoch: 320. Loss: 0.6460711610554818\n",
            "Epoch: 330. Loss: 0.6460232744752921\n",
            "Epoch: 340. Loss: 0.6459808467221081\n",
            "Epoch: 350. Loss: 0.6459432269875941\n",
            "Epoch: 360. Loss: 0.6459098468399991\n",
            "Epoch: 370. Loss: 0.6458802089959957\n",
            "Epoch: 380. Loss: 0.6458538777551573\n",
            "Epoch: 390. Loss: 0.6458304708297162\n",
            "Epoch: 400. Loss: 0.6458096523484543\n",
            "Epoch: 410. Loss: 0.6457911268513423\n",
            "Epoch: 420. Loss: 0.6457746341224903\n",
            "Epoch: 430. Loss: 0.6457599447343383\n",
            "Epoch: 440. Loss: 0.6457468561968913\n",
            "Epoch: 450. Loss: 0.6457351896229817\n",
            "Epoch: 460. Loss: 0.6457247868347565\n",
            "Epoch: 470. Loss: 0.6457155078483381\n",
            "Epoch: 480. Loss: 0.64570722868338\n",
            "Epoch: 490. Loss: 0.6456998394523704\n",
            "tensor(0.6529, dtype=torch.float64)\n",
            "2022-11-27 00:00:00\n",
            "Epoch: 0. Loss: 1.7515980855153082\n",
            "Epoch: 10. Loss: 1.134680649604403\n",
            "Epoch: 20. Loss: 0.9246241886667524\n",
            "Epoch: 30. Loss: 0.8277246891149663\n",
            "Epoch: 40. Loss: 0.7646987768392485\n",
            "Epoch: 50. Loss: 0.7243199956529464\n",
            "Epoch: 60. Loss: 0.6991955344565592\n",
            "Epoch: 70. Loss: 0.6835663794692906\n",
            "Epoch: 80. Loss: 0.6736203840250146\n",
            "Epoch: 90. Loss: 0.6670168106275282\n",
            "Epoch: 100. Loss: 0.6623859629934531\n",
            "Epoch: 110. Loss: 0.6589541336574567\n",
            "Epoch: 120. Loss: 0.6562902546568663\n",
            "Epoch: 130. Loss: 0.6541511145139076\n",
            "Epoch: 140. Loss: 0.6523939066067865\n",
            "Epoch: 150. Loss: 0.6509293685066649\n",
            "Epoch: 160. Loss: 0.6496974662659123\n",
            "Epoch: 170. Loss: 0.6486549398906862\n",
            "Epoch: 180. Loss: 0.6477688722289493\n",
            "Epoch: 190. Loss: 0.64701325693635\n",
            "Epoch: 200. Loss: 0.6463670546635492\n",
            "Epoch: 210. Loss: 0.6458130000868195\n",
            "Epoch: 220. Loss: 0.6453368037784207\n",
            "Epoch: 230. Loss: 0.6449265763858985\n",
            "Epoch: 240. Loss: 0.6445723895446391\n",
            "Epoch: 250. Loss: 0.6442659289613204\n",
            "Epoch: 260. Loss: 0.6440002146119534\n",
            "Epoch: 270. Loss: 0.6437693725343991\n",
            "Epoch: 280. Loss: 0.6435684476191778\n",
            "Epoch: 290. Loss: 0.6433932495720084\n",
            "Epoch: 300. Loss: 0.6432402259551367\n",
            "Epoch: 310. Loss: 0.643106357419435\n",
            "Epoch: 320. Loss: 0.6429890711470866\n",
            "Epoch: 330. Loss: 0.6428861692440363\n",
            "Epoch: 340. Loss: 0.6427957694065237\n",
            "Epoch: 350. Loss: 0.6427162556672007\n",
            "Epoch: 360. Loss: 0.6426462374231225\n",
            "Epoch: 370. Loss: 0.6425845152746705\n",
            "Epoch: 380. Loss: 0.642530052472898\n",
            "Epoch: 390. Loss: 0.6424819509926003\n",
            "Epoch: 400. Loss: 0.6424394314279652\n",
            "Epoch: 410. Loss: 0.6424018160540014\n",
            "Epoch: 420. Loss: 0.6423685145160697\n",
            "Epoch: 430. Loss: 0.6423390117067086\n",
            "Epoch: 440. Loss: 0.6423128574677396\n",
            "Epoch: 450. Loss: 0.6422896578197194\n",
            "Epoch: 460. Loss: 0.6422690674729881\n",
            "Epoch: 470. Loss: 0.6422507834171094\n",
            "Epoch: 480. Loss: 0.6422345394202372\n",
            "Epoch: 490. Loss: 0.6422201012983625\n",
            "tensor(0.5873, dtype=torch.float64)\n",
            "2022-12-04 00:00:00\n",
            "Epoch: 0. Loss: 4.632523566195652\n",
            "Epoch: 10. Loss: 1.100006822108657\n",
            "Epoch: 20. Loss: 0.6497276850354842\n",
            "Epoch: 30. Loss: 0.640807618710411\n",
            "Epoch: 40. Loss: 0.6383192702942341\n",
            "Epoch: 50. Loss: 0.6369243159230341\n",
            "Epoch: 60. Loss: 0.6359895950514802\n",
            "Epoch: 70. Loss: 0.6353087331045354\n",
            "Epoch: 80. Loss: 0.634785733206579\n",
            "Epoch: 90. Loss: 0.6343667061892911\n",
            "Epoch: 100. Loss: 0.6340191336069811\n",
            "Epoch: 110. Loss: 0.6337228337951326\n",
            "Epoch: 120. Loss: 0.6334650347591532\n",
            "Epoch: 130. Loss: 0.6332374583754454\n",
            "Epoch: 140. Loss: 0.633034562606291\n",
            "Epoch: 150. Loss: 0.6328524819193728\n",
            "Epoch: 160. Loss: 0.6326883907498776\n",
            "Epoch: 170. Loss: 0.6325401218824072\n",
            "Epoch: 180. Loss: 0.6324059374326135\n",
            "Epoch: 190. Loss: 0.632284390695313\n",
            "Epoch: 200. Loss: 0.6321742419170217\n",
            "Epoch: 210. Loss: 0.6320744060314963\n",
            "Epoch: 220. Loss: 0.6319839193669208\n",
            "Epoch: 230. Loss: 0.6319019176657484\n",
            "Epoch: 240. Loss: 0.6318276209105214\n",
            "Epoch: 250. Loss: 0.6317603223046995\n",
            "Epoch: 260. Loss: 0.6316993798466931\n",
            "Epoch: 270. Loss: 0.6316442095732931\n",
            "Epoch: 280. Loss: 0.6315942799220776\n",
            "Epoch: 290. Loss: 0.631549106880972\n",
            "Epoch: 300. Loss: 0.6315082497213286\n",
            "Epoch: 310. Loss: 0.6314713071863244\n",
            "Epoch: 320. Loss: 0.6314379140511519\n",
            "Epoch: 330. Loss: 0.6314077379981688\n",
            "Epoch: 340. Loss: 0.6313804767663567\n",
            "Epoch: 350. Loss: 0.6313558555444535\n",
            "Epoch: 360. Loss: 0.6313336245834816\n",
            "Epoch: 370. Loss: 0.6313135570085998\n",
            "Epoch: 380. Loss: 0.631295446813084\n",
            "Epoch: 390. Loss: 0.6312791070193452\n",
            "Epoch: 400. Loss: 0.631264367993469\n",
            "Epoch: 410. Loss: 0.6312510759010405\n",
            "Epoch: 420. Loss: 0.6312390912930667\n",
            "Epoch: 430. Loss: 0.6312282878117162\n",
            "Epoch: 440. Loss: 0.6312185510063958\n",
            "Epoch: 450. Loss: 0.6312097772513964\n",
            "Epoch: 460. Loss: 0.6312018727570013\n",
            "Epoch: 470. Loss: 0.631194752666539\n",
            "Epoch: 480. Loss: 0.631188340232422\n",
            "Epoch: 490. Loss: 0.6311825660647294\n",
            "tensor(0.7230, dtype=torch.float64)\n",
            "2022-12-11 00:00:00\n",
            "Epoch: 0. Loss: 4.877916400466924\n",
            "Epoch: 10. Loss: 1.6453572476011578\n",
            "Epoch: 20. Loss: 0.9736441684166757\n",
            "Epoch: 30. Loss: 0.7442793756355794\n",
            "Epoch: 40. Loss: 0.6764901911722432\n",
            "Epoch: 50. Loss: 0.6591944903628498\n",
            "Epoch: 60. Loss: 0.6530317380111926\n",
            "Epoch: 70. Loss: 0.6501906179866374\n",
            "Epoch: 80. Loss: 0.6487038648706481\n",
            "Epoch: 90. Loss: 0.6478538576963387\n",
            "Epoch: 100. Loss: 0.6473230782778187\n",
            "Epoch: 110. Loss: 0.6469600391396363\n",
            "Epoch: 120. Loss: 0.6466899659811113\n",
            "Epoch: 130. Loss: 0.6464750576164918\n",
            "Epoch: 140. Loss: 0.6462957009863758\n",
            "Epoch: 150. Loss: 0.6461413537967314\n",
            "Epoch: 160. Loss: 0.6460060553194396\n",
            "Epoch: 170. Loss: 0.6458861948572572\n",
            "Epoch: 180. Loss: 0.6457793942025422\n",
            "Epoch: 190. Loss: 0.645683944023867\n",
            "Epoch: 200. Loss: 0.6455985171919084\n",
            "Epoch: 210. Loss: 0.6455220211251559\n",
            "Epoch: 220. Loss: 0.6454535201653254\n",
            "Epoch: 230. Loss: 0.6453921933680469\n",
            "Epoch: 240. Loss: 0.6453373103088782\n",
            "Epoch: 250. Loss: 0.6452882161475681\n",
            "Epoch: 260. Loss: 0.6452443215388566\n",
            "Epoch: 270. Loss: 0.6452050951638115\n",
            "Epoch: 280. Loss: 0.64517005775483\n",
            "Epoch: 290. Loss: 0.6451387770397332\n",
            "Epoch: 300. Loss: 0.6451108633076159\n",
            "Epoch: 310. Loss: 0.6450859654381537\n",
            "Epoch: 320. Loss: 0.645063767305798\n",
            "Epoch: 330. Loss: 0.6450439845053484\n",
            "Epoch: 340. Loss: 0.6450263613631607\n",
            "Epoch: 350. Loss: 0.6450106682074219\n",
            "Epoch: 360. Loss: 0.6449966988758586\n",
            "Epoch: 370. Loss: 0.6449842684420762\n",
            "Epoch: 380. Loss: 0.6449732111435514\n",
            "Epoch: 390. Loss: 0.6449633784955991\n",
            "Epoch: 400. Loss: 0.6449546375767187\n",
            "Epoch: 410. Loss: 0.6449468694716439\n",
            "Epoch: 420. Loss: 0.6449399678593092\n",
            "Epoch: 430. Loss: 0.644933837733755\n",
            "Epoch: 440. Loss: 0.6449283942467953\n",
            "Epoch: 450. Loss: 0.6449235616620281\n",
            "Epoch: 460. Loss: 0.644919272410499\n",
            "Epoch: 470. Loss: 0.6449154662390301\n",
            "Epoch: 480. Loss: 0.6449120894428948\n",
            "Epoch: 490. Loss: 0.644909094175151\n",
            "tensor(0.7638, dtype=torch.float64)\n",
            "2022-12-18 00:00:00\n",
            "Epoch: 0. Loss: 5.279639658011116\n",
            "Epoch: 10. Loss: 1.9804940380867404\n",
            "Epoch: 20. Loss: 0.956387694886642\n",
            "Epoch: 30. Loss: 0.7278682739624468\n",
            "Epoch: 40. Loss: 0.6724180194798006\n",
            "Epoch: 50. Loss: 0.6623835223799506\n",
            "Epoch: 60. Loss: 0.6596145749405453\n",
            "Epoch: 70. Loss: 0.6581642521118835\n",
            "Epoch: 80. Loss: 0.6571222460412749\n",
            "Epoch: 90. Loss: 0.6563061981249804\n",
            "Epoch: 100. Loss: 0.6556521447122562\n",
            "Epoch: 110. Loss: 0.6551227976512407\n",
            "Epoch: 120. Loss: 0.6546915062705676\n",
            "Epoch: 130. Loss: 0.654338108171913\n",
            "Epoch: 140. Loss: 0.6540470583319814\n",
            "Epoch: 150. Loss: 0.6538062474677415\n",
            "Epoch: 160. Loss: 0.6536061658098798\n",
            "Epoch: 170. Loss: 0.6534392901904809\n",
            "Epoch: 180. Loss: 0.6532996281367988\n",
            "Epoch: 190. Loss: 0.65318237553257\n",
            "Epoch: 200. Loss: 0.6530836575190924\n",
            "Epoch: 210. Loss: 0.6530003309445188\n",
            "Epoch: 220. Loss: 0.6529298326578558\n",
            "Epoch: 230. Loss: 0.652870062187054\n",
            "Epoch: 240. Loss: 0.6528192903812379\n",
            "Epoch: 250. Loss: 0.6527760877923728\n",
            "Epoch: 260. Loss: 0.6527392681659729\n",
            "Epoch: 270. Loss: 0.6527078435746713\n",
            "Epoch: 280. Loss: 0.6526809885833114\n",
            "Epoch: 290. Loss: 0.6526580114654595\n",
            "Epoch: 300. Loss: 0.6526383309600933\n",
            "Epoch: 310. Loss: 0.6526214574076009\n",
            "Epoch: 320. Loss: 0.6526069773676677\n",
            "Epoch: 330. Loss: 0.6525945410209445\n",
            "Epoch: 340. Loss: 0.6525838518081484\n",
            "Epoch: 350. Loss: 0.6525746578764833\n",
            "Epoch: 360. Loss: 0.6525667449928708\n",
            "Epoch: 370. Loss: 0.6525599306529425\n",
            "Epoch: 380. Loss: 0.6525540591689218\n",
            "Epoch: 390. Loss: 0.6525489975620095\n",
            "Epoch: 400. Loss: 0.6525446321183935\n",
            "Epoch: 410. Loss: 0.6525408654945599\n",
            "Epoch: 420. Loss: 0.652537614278745\n",
            "Epoch: 430. Loss: 0.6525348069323101\n",
            "Epoch: 440. Loss: 0.6525323820484421\n",
            "Epoch: 450. Loss: 0.6525302868765952\n",
            "Epoch: 460. Loss: 0.6525284760700175\n",
            "Epoch: 470. Loss: 0.6525269106209783\n",
            "Epoch: 480. Loss: 0.6525255569542607\n",
            "Epoch: 490. Loss: 0.6525243861543631\n",
            "tensor(0.5255, dtype=torch.float64)\n",
            "2022-12-25 00:00:00\n",
            "Epoch: 0. Loss: 1.8943618589387872\n",
            "Epoch: 10. Loss: 1.121629639984421\n",
            "Epoch: 20. Loss: 0.8630890906201493\n",
            "Epoch: 30. Loss: 0.8027176669703446\n",
            "Epoch: 40. Loss: 0.7705588918615305\n",
            "Epoch: 50. Loss: 0.7476909291432504\n",
            "Epoch: 60. Loss: 0.7295612768666881\n",
            "Epoch: 70. Loss: 0.714627114263105\n",
            "Epoch: 80. Loss: 0.7023560385794044\n",
            "Epoch: 90. Loss: 0.6924789649383245\n",
            "Epoch: 100. Loss: 0.6846815832775244\n",
            "Epoch: 110. Loss: 0.6785951050616575\n",
            "Epoch: 120. Loss: 0.6738686894137452\n",
            "Epoch: 130. Loss: 0.6702057089486935\n",
            "Epoch: 140. Loss: 0.6673674357344895\n",
            "Epoch: 150. Loss: 0.6651654344690578\n",
            "Epoch: 160. Loss: 0.6634525132770653\n",
            "Epoch: 170. Loss: 0.6621147133851657\n",
            "Epoch: 180. Loss: 0.6610645300571322\n",
            "Epoch: 190. Loss: 0.6602352210972251\n",
            "Epoch: 200. Loss: 0.6595761032465953\n",
            "Epoch: 210. Loss: 0.6590487565367676\n",
            "Epoch: 220. Loss: 0.6586240364519843\n",
            "Epoch: 230. Loss: 0.6582797718154866\n",
            "Epoch: 240. Loss: 0.6579990199032514\n",
            "Epoch: 250. Loss: 0.6577687588269481\n",
            "Epoch: 260. Loss: 0.6575789142755627\n",
            "Epoch: 270. Loss: 0.6574216373313923\n",
            "Epoch: 280. Loss: 0.6572907686061464\n",
            "Epoch: 290. Loss: 0.6571814397024895\n",
            "Epoch: 300. Loss: 0.6570897755923666\n",
            "Epoch: 310. Loss: 0.6570126711595977\n",
            "Epoch: 320. Loss: 0.6569476223721386\n",
            "Epoch: 330. Loss: 0.6568925978557046\n",
            "Epoch: 340. Loss: 0.6568459405022318\n",
            "Epoch: 350. Loss: 0.6568062915421331\n",
            "Epoch: 360. Loss: 0.6567725315290621\n",
            "Epoch: 370. Loss: 0.656743734146166\n",
            "Epoch: 380. Loss: 0.6567191298012766\n",
            "Epoch: 390. Loss: 0.6566980767487532\n",
            "Epoch: 400. Loss: 0.6566800380390008\n",
            "Epoch: 410. Loss: 0.6566645630109992\n",
            "Epoch: 420. Loss: 0.6566512723497517\n",
            "Epoch: 430. Loss: 0.6566398459588989\n",
            "Epoch: 440. Loss: 0.6566300130699096\n",
            "Epoch: 450. Loss: 0.6566215441384353\n",
            "Epoch: 460. Loss: 0.6566142441765408\n",
            "Epoch: 470. Loss: 0.6566079472445482\n",
            "Epoch: 480. Loss: 0.6566025118839572\n",
            "Epoch: 490. Loss: 0.6565978173176132\n",
            "tensor(0.5928, dtype=torch.float64)\n",
            "2023-01-01 00:00:00\n",
            "Epoch: 0. Loss: 4.342895006753936\n",
            "Epoch: 10. Loss: 1.1173169496311026\n",
            "Epoch: 20. Loss: 0.8660096809761072\n",
            "Epoch: 30. Loss: 0.7595496860005452\n",
            "Epoch: 40. Loss: 0.7022396090011319\n",
            "Epoch: 50. Loss: 0.675693068601653\n",
            "Epoch: 60. Loss: 0.6644318897274277\n",
            "Epoch: 70. Loss: 0.6596952706747171\n",
            "Epoch: 80. Loss: 0.6575945773109465\n",
            "Epoch: 90. Loss: 0.6565596073380913\n",
            "Epoch: 100. Loss: 0.6559684539691207\n",
            "Epoch: 110. Loss: 0.6555728012683033\n",
            "Epoch: 120. Loss: 0.6552717086496668\n",
            "Epoch: 130. Loss: 0.6550230299981173\n",
            "Epoch: 140. Loss: 0.654808371540611\n",
            "Epoch: 150. Loss: 0.6546190652811587\n",
            "Epoch: 160. Loss: 0.6544504991645599\n",
            "Epoch: 170. Loss: 0.6542998069277862\n",
            "Epoch: 180. Loss: 0.6541649194831982\n",
            "Epoch: 190. Loss: 0.6540441710946949\n",
            "Epoch: 200. Loss: 0.6539361325017256\n",
            "Epoch: 210. Loss: 0.6538395372168677\n",
            "Epoch: 220. Loss: 0.6537532462845738\n",
            "Epoch: 230. Loss: 0.6536762290969075\n",
            "Epoch: 240. Loss: 0.6536075510842584\n",
            "Epoch: 250. Loss: 0.6535463645118419\n",
            "Epoch: 260. Loss: 0.6534919008274567\n",
            "Epoch: 270. Loss: 0.6534434639111564\n",
            "Epoch: 280. Loss: 0.6534004239471549\n",
            "Epoch: 290. Loss: 0.6533622117893761\n",
            "Epoch: 300. Loss: 0.6533283137541754\n",
            "Epoch: 310. Loss: 0.653298266799774\n",
            "Epoch: 320. Loss: 0.6532716540632991\n",
            "Epoch: 330. Loss: 0.6532481007317159\n",
            "Epoch: 340. Loss: 0.6532272702258273\n",
            "Epoch: 350. Loss: 0.6532088606783274\n",
            "Epoch: 360. Loss: 0.6531926016881762\n",
            "Epoch: 370. Loss: 0.6531782513345392\n",
            "Epoch: 380. Loss: 0.653165593434354\n",
            "Epoch: 390. Loss: 0.6531544350282554\n",
            "Epoch: 400. Loss: 0.6531446040802072\n",
            "Epoch: 410. Loss: 0.6531359473767322\n",
            "Epoch: 420. Loss: 0.6531283286121595\n",
            "Epoch: 430. Loss: 0.6531216266468275\n",
            "Epoch: 440. Loss: 0.6531157339256879\n",
            "Epoch: 450. Loss: 0.6531105550452942\n",
            "Epoch: 460. Loss: 0.653106005457689\n",
            "Epoch: 470. Loss: 0.6531020103002682\n",
            "Epoch: 480. Loss: 0.6530985033412582\n",
            "Epoch: 490. Loss: 0.6530954260310294\n",
            "tensor(0.6298, dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backtest_returns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QJznmoa50iU",
        "outputId": "a690aeb8-db3e-4100-b26c-e7fc838ed3d0"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Timestamp('2003-09-21 00:00:00', freq='W-SUN'): -0.028196412799152443,\n",
              " Timestamp('2003-09-28 00:00:00', freq='W-SUN'): 0.030807536466374772,\n",
              " Timestamp('2003-10-05 00:00:00', freq='W-SUN'): 0.010533407116348816,\n",
              " Timestamp('2003-10-12 00:00:00', freq='W-SUN'): -0.004297555193367887,\n",
              " Timestamp('2003-10-19 00:00:00', freq='W-SUN'): -0.008329296553258906,\n",
              " Timestamp('2003-10-26 00:00:00', freq='W-SUN'): 0.015037642472289269,\n",
              " Timestamp('2003-11-02 00:00:00', freq='W-SUN'): -0.0013238676122931735,\n",
              " Timestamp('2003-11-09 00:00:00', freq='W-SUN'): -0.002647995132362341,\n",
              " Timestamp('2003-11-16 00:00:00', freq='W-SUN'): -0.0066724332600349955,\n",
              " Timestamp('2003-11-23 00:00:00', freq='W-SUN'): 0.016811490747702815,\n",
              " Timestamp('2003-11-30 00:00:00', freq='W-SUN'): 0.0,\n",
              " Timestamp('2003-12-07 00:00:00', freq='W-SUN'): 0.013115992376166272,\n",
              " Timestamp('2003-12-14 00:00:00', freq='W-SUN'): -0.002473170330185461,\n",
              " Timestamp('2003-12-21 00:00:00', freq='W-SUN'): 0.008364702561221527,\n",
              " Timestamp('2003-12-28 00:00:00', freq='W-SUN'): 0.010263442511597476,\n",
              " Timestamp('2004-01-04 00:00:00', freq='W-SUN'): 0.0062673201492108145,\n",
              " Timestamp('2004-01-11 00:00:00', freq='W-SUN'): 0.014926698846911559,\n",
              " Timestamp('2004-01-18 00:00:00', freq='W-SUN'): -0.0008731249530526656,\n",
              " Timestamp('2004-01-25 00:00:00', freq='W-SUN'): -0.007955205944184042,\n",
              " Timestamp('2004-02-01 00:00:00', freq='W-SUN'): 0.006596306242646603,\n",
              " Timestamp('2004-02-08 00:00:00', freq='W-SUN'): 0.004011502642565636,\n",
              " Timestamp('2004-02-15 00:00:00', freq='W-SUN'): -0.00837290476258788,\n",
              " Timestamp('2004-02-22 00:00:00', freq='W-SUN'): -0.001735844456380388,\n",
              " Timestamp('2004-02-29 00:00:00', freq='W-SUN'): 0.008230070172398823,\n",
              " Timestamp('2004-03-07 00:00:00', freq='W-SUN'): -0.03231901434825566,\n",
              " Timestamp('2004-03-14 00:00:00', freq='W-SUN'): -0.01077758111991408,\n",
              " Timestamp('2004-03-21 00:00:00', freq='W-SUN'): 0.004432766379294677,\n",
              " Timestamp('2004-03-28 00:00:00', freq='W-SUN'): 0.02696409639785263,\n",
              " Timestamp('2004-04-04 00:00:00', freq='W-SUN'): -0.0007862659513040822,\n",
              " Timestamp('2004-04-11 00:00:00', freq='W-SUN'): -0.006545644849962562,\n",
              " Timestamp('2004-04-18 00:00:00', freq='W-SUN'): 0.007133403598412878,\n",
              " Timestamp('2004-04-25 00:00:00', freq='W-SUN'): -0.030917039301310078,\n",
              " Timestamp('2004-05-02 00:00:00', freq='W-SUN'): -0.012660536607869184,\n",
              " Timestamp('2004-05-09 00:00:00', freq='W-SUN'): 0.005482446902733032,\n",
              " Timestamp('2004-05-16 00:00:00', freq='W-SUN'): 0.008448884272650144,\n",
              " Timestamp('2004-05-23 00:00:00', freq='W-SUN'): 0.021080267991316938,\n",
              " Timestamp('2004-05-30 00:00:00', freq='W-SUN'): 0.004623901872878374,\n",
              " Timestamp('2004-06-06 00:00:00', freq='W-SUN'): 0.00811071145199676,\n",
              " Timestamp('2004-06-13 00:00:00', freq='W-SUN'): -0.001669328764716132,\n",
              " Timestamp('2004-06-20 00:00:00', freq='W-SUN'): 0.0007911736263736202,\n",
              " Timestamp('2004-06-27 00:00:00', freq='W-SUN'): -0.014320643057648704,\n",
              " Timestamp('2004-07-04 00:00:00', freq='W-SUN'): -0.005695470169205216,\n",
              " Timestamp('2004-07-11 00:00:00', freq='W-SUN'): -0.007263253423509393,\n",
              " Timestamp('2004-07-18 00:00:00', freq='W-SUN'): -0.016162537246049696,\n",
              " Timestamp('2004-07-25 00:00:00', freq='W-SUN'): 0.015111218699309047,\n",
              " Timestamp('2004-08-01 00:00:00', freq='W-SUN'): -0.030311316266243532,\n",
              " Timestamp('2004-08-08 00:00:00', freq='W-SUN'): 0.0015885348978285179,\n",
              " Timestamp('2004-08-15 00:00:00', freq='W-SUN'): 0.03117420226968635,\n",
              " Timestamp('2004-08-22 00:00:00', freq='W-SUN'): 0.008141058123716129,\n",
              " Timestamp('2004-08-29 00:00:00', freq='W-SUN'): 0.008092087681243598,\n",
              " Timestamp('2004-09-05 00:00:00', freq='W-SUN'): 0.004620552651318968,\n",
              " Timestamp('2004-09-12 00:00:00', freq='W-SUN'): -0.0014120201467128478,\n",
              " Timestamp('2004-09-19 00:00:00', freq='W-SUN'): -0.010739318553995274,\n",
              " Timestamp('2004-09-26 00:00:00', freq='W-SUN'): 0.022952331646306612,\n",
              " Timestamp('2004-10-03 00:00:00', freq='W-SUN'): -0.013935109797285003,\n",
              " Timestamp('2004-10-10 00:00:00', freq='W-SUN'): -0.013477540463535592,\n",
              " Timestamp('2004-10-17 00:00:00', freq='W-SUN'): -0.008116160231906965,\n",
              " Timestamp('2004-10-24 00:00:00', freq='W-SUN'): 0.03143505239179951,\n",
              " Timestamp('2004-10-31 00:00:00', freq='W-SUN'): 0.03275802276784129,\n",
              " Timestamp('2004-11-07 00:00:00', freq='W-SUN'): 0.015472712887518112,\n",
              " Timestamp('2004-11-14 00:00:00', freq='W-SUN'): -0.009113940928269984,\n",
              " Timestamp('2004-11-21 00:00:00', freq='W-SUN'): 0.010070837416929823,\n",
              " Timestamp('2004-11-28 00:00:00', freq='W-SUN'): 0.0038723713791365003,\n",
              " Timestamp('2004-12-05 00:00:00', freq='W-SUN'): 0.0010066521349437892,\n",
              " Timestamp('2004-12-12 00:00:00', freq='W-SUN'): -0.002672010643419939,\n",
              " Timestamp('2004-12-19 00:00:00', freq='W-SUN'): 0.00851772025052195,\n",
              " Timestamp('2004-12-26 00:00:00', freq='W-SUN'): -0.002722722839671351,\n",
              " Timestamp('2005-01-02 00:00:00', freq='W-SUN'): -0.025666305127777202,\n",
              " Timestamp('2005-01-09 00:00:00', freq='W-SUN'): -0.000845005943721676,\n",
              " Timestamp('2005-01-16 00:00:00', freq='W-SUN'): -0.010758186935412447,\n",
              " Timestamp('2005-01-23 00:00:00', freq='W-SUN'): 0.0029037835136659115,\n",
              " Timestamp('2005-01-30 00:00:00', freq='W-SUN'): 0.01933027603213928,\n",
              " Timestamp('2005-02-06 00:00:00', freq='W-SUN'): 0.004324299376299406,\n",
              " Timestamp('2005-02-13 00:00:00', freq='W-SUN'): -0.0024857319995736167,\n",
              " Timestamp('2005-02-20 00:00:00', freq='W-SUN'): 0.012760616968129877,\n",
              " Timestamp('2005-02-27 00:00:00', freq='W-SUN'): 0.013041691901911779,\n",
              " Timestamp('2005-03-06 00:00:00', freq='W-SUN'): -0.018506480727002075,\n",
              " Timestamp('2005-03-13 00:00:00', freq='W-SUN'): -0.017162755848082557,\n",
              " Timestamp('2005-03-20 00:00:00', freq='W-SUN'): -0.013225507650791854,\n",
              " Timestamp('2005-03-27 00:00:00', freq='W-SUN'): 8.518140155308184e-05,\n",
              " Timestamp('2005-04-03 00:00:00', freq='W-SUN'): 0.00545329749954589,\n",
              " Timestamp('2005-04-10 00:00:00', freq='W-SUN'): -0.03499872318033037,\n",
              " Timestamp('2005-04-17 00:00:00', freq='W-SUN'): 0.012705896967072427,\n",
              " Timestamp('2005-04-24 00:00:00', freq='W-SUN'): -0.0009494303387758206,\n",
              " Timestamp('2005-05-01 00:00:00', freq='W-SUN'): 0.008787766003273939,\n",
              " Timestamp('2005-05-08 00:00:00', freq='W-SUN'): -0.01271220896435636,\n",
              " Timestamp('2005-05-15 00:00:00', freq='W-SUN'): 0.029559257464803573,\n",
              " Timestamp('2005-05-22 00:00:00', freq='W-SUN'): 0.008724108788894493,\n",
              " Timestamp('2005-05-29 00:00:00', freq='W-SUN'): 0.0005829446938217689,\n",
              " Timestamp('2005-06-05 00:00:00', freq='W-SUN'): 0.0020842018028562354,\n",
              " Timestamp('2005-06-12 00:00:00', freq='W-SUN'): 0.011839244424891622,\n",
              " Timestamp('2005-06-19 00:00:00', freq='W-SUN'): -0.017343896310804463,\n",
              " Timestamp('2005-06-26 00:00:00', freq='W-SUN'): 0.004707052158468145,\n",
              " Timestamp('2005-07-03 00:00:00', freq='W-SUN'): 0.01735849056603768,\n",
              " Timestamp('2005-07-10 00:00:00', freq='W-SUN'): 0.012445347194505166,\n",
              " Timestamp('2005-07-17 00:00:00', freq='W-SUN'): 0.008489804081632683,\n",
              " Timestamp('2005-07-24 00:00:00', freq='W-SUN'): 0.002673964746002271,\n",
              " Timestamp('2005-07-31 00:00:00', freq='W-SUN'): -0.0076718483780690745,\n",
              " Timestamp('2005-08-07 00:00:00', freq='W-SUN'): -0.0007308485467991103,\n",
              " Timestamp('2005-08-14 00:00:00', freq='W-SUN'): -0.006086674191797807,\n",
              " Timestamp('2005-08-21 00:00:00', freq='W-SUN'): -0.014847446323259102,\n",
              " Timestamp('2005-08-28 00:00:00', freq='W-SUN'): 0.015447163343670372,\n",
              " Timestamp('2005-09-04 00:00:00', freq='W-SUN'): 0.015816027529234375,\n",
              " Timestamp('2005-09-11 00:00:00', freq='W-SUN'): -0.007633563864208018,\n",
              " Timestamp('2005-09-18 00:00:00', freq='W-SUN'): -0.016441232554942554,\n",
              " Timestamp('2005-09-25 00:00:00', freq='W-SUN'): 0.008359318350089781,\n",
              " Timestamp('2005-10-02 00:00:00', freq='W-SUN'): -0.02724461635690156,\n",
              " Timestamp('2005-10-09 00:00:00', freq='W-SUN'): -0.008439187834224598,\n",
              " Timestamp('2005-10-16 00:00:00', freq='W-SUN'): -0.005639781002362439,\n",
              " Timestamp('2005-10-23 00:00:00', freq='W-SUN'): 0.011482615476484008,\n",
              " Timestamp('2005-10-30 00:00:00', freq='W-SUN'): 0.01513010212710858,\n",
              " Timestamp('2005-11-06 00:00:00', freq='W-SUN'): 0.011358984766879536,\n",
              " Timestamp('2005-11-13 00:00:00', freq='W-SUN'): 0.010824751507999416,\n",
              " Timestamp('2005-11-20 00:00:00', freq='W-SUN'): 0.01582097457737158,\n",
              " Timestamp('2005-11-27 00:00:00', freq='W-SUN'): -0.00314343418467584,\n",
              " Timestamp('2005-12-04 00:00:00', freq='W-SUN'): -0.0029202447416001357,\n",
              " Timestamp('2005-12-11 00:00:00', freq='W-SUN'): -0.0027621971648819866,\n",
              " Timestamp('2005-12-18 00:00:00', freq='W-SUN'): 0.00023671584699641853,\n",
              " Timestamp('2005-12-25 00:00:00', freq='W-SUN'): -0.01929739303164295,\n",
              " Timestamp('2006-01-01 00:00:00', freq='W-SUN'): 0.02596053956449322,\n",
              " Timestamp('2006-01-08 00:00:00', freq='W-SUN'): 0.00202456785585687,\n",
              " Timestamp('2006-01-15 00:00:00', freq='W-SUN'): -0.017394664993634904,\n",
              " Timestamp('2006-01-22 00:00:00', freq='W-SUN'): 0.01846124727407702,\n",
              " Timestamp('2006-01-29 00:00:00', freq='W-SUN'): -0.01689508693716767,\n",
              " Timestamp('2006-02-05 00:00:00', freq='W-SUN'): 0.0015817541666916155,\n",
              " Timestamp('2006-02-12 00:00:00', freq='W-SUN'): 0.017456556357923543,\n",
              " Timestamp('2006-02-19 00:00:00', freq='W-SUN'): 0.002323623248984216,\n",
              " Timestamp('2006-02-26 00:00:00', freq='W-SUN'): -0.004945896674461893,\n",
              " Timestamp('2006-03-05 00:00:00', freq='W-SUN'): -0.004258967045523792,\n",
              " Timestamp('2006-03-12 00:00:00', freq='W-SUN'): 0.013815577889337835,\n",
              " Timestamp('2006-03-19 00:00:00', freq='W-SUN'): -0.00329142684699499,\n",
              " Timestamp('2006-03-26 00:00:00', freq='W-SUN'): -0.0015380835310165326,\n",
              " Timestamp('2006-04-02 00:00:00', freq='W-SUN'): -0.0040748364071356916,\n",
              " Timestamp('2006-04-09 00:00:00', freq='W-SUN'): -0.007938939111340455,\n",
              " Timestamp('2006-04-16 00:00:00', freq='W-SUN'): 0.018008165520326427,\n",
              " Timestamp('2006-04-23 00:00:00', freq='W-SUN'): 0.00443121708634139,\n",
              " Timestamp('2006-04-30 00:00:00', freq='W-SUN'): 0.00798663567363937,\n",
              " Timestamp('2006-05-07 00:00:00', freq='W-SUN'): -0.02467730830417741,\n",
              " Timestamp('2006-05-14 00:00:00', freq='W-SUN'): -0.01312209870218729,\n",
              " Timestamp('2006-05-21 00:00:00', freq='W-SUN'): 0.016629759396814752,\n",
              " Timestamp('2006-05-28 00:00:00', freq='W-SUN'): 0.008048753551232711,\n",
              " Timestamp('2006-06-04 00:00:00', freq='W-SUN'): -0.027163429080476784,\n",
              " Timestamp('2006-06-11 00:00:00', freq='W-SUN'): -0.009771171189335208,\n",
              " Timestamp('2006-06-18 00:00:00', freq='W-SUN'): -0.007655502270247123,\n",
              " Timestamp('2006-06-25 00:00:00', freq='W-SUN'): 0.022000947310093565,\n",
              " Timestamp('2006-07-02 00:00:00', freq='W-SUN'): -0.006434897590834261,\n",
              " Timestamp('2006-07-09 00:00:00', freq='W-SUN'): -0.0269419012613534,\n",
              " Timestamp('2006-07-16 00:00:00', freq='W-SUN'): 0.003481217701130551,\n",
              " Timestamp('2006-07-23 00:00:00', freq='W-SUN'): 0.028447452130384805,\n",
              " Timestamp('2006-07-30 00:00:00', freq='W-SUN'): 0.0042299309343590144,\n",
              " Timestamp('2006-08-06 00:00:00', freq='W-SUN'): -0.0069585612672625335,\n",
              " Timestamp('2006-08-13 00:00:00', freq='W-SUN'): 0.023975594076054,\n",
              " Timestamp('2006-08-20 00:00:00', freq='W-SUN'): -0.002842180211209481,\n",
              " Timestamp('2006-08-27 00:00:00', freq='W-SUN'): 0.013652171862036494,\n",
              " Timestamp('2006-09-03 00:00:00', freq='W-SUN'): -0.009352870859739595,\n",
              " Timestamp('2006-09-10 00:00:00', freq='W-SUN'): 0.016171307437460893,\n",
              " Timestamp('2006-09-17 00:00:00', freq='W-SUN'): -0.0024280447454004595,\n",
              " Timestamp('2006-09-24 00:00:00', freq='W-SUN'): 0.014043923602639506,\n",
              " Timestamp('2006-10-01 00:00:00', freq='W-SUN'): 0.01100795325037941,\n",
              " Timestamp('2006-10-08 00:00:00', freq='W-SUN'): 0.013199843684100418,\n",
              " Timestamp('2006-10-15 00:00:00', freq='W-SUN'): 0.002343920236041111,\n",
              " Timestamp('2006-10-22 00:00:00', freq='W-SUN'): 0.009885808580635591,\n",
              " Timestamp('2006-10-29 00:00:00', freq='W-SUN'): -0.00813606688548387,\n",
              " Timestamp('2006-11-05 00:00:00', freq='W-SUN'): 0.009345779312058638,\n",
              " Timestamp('2006-11-12 00:00:00', freq='W-SUN'): 0.01621077662089617,\n",
              " Timestamp('2006-11-19 00:00:00', freq='W-SUN'): 0.0003564005625859024,\n",
              " Timestamp('2006-11-26 00:00:00', freq='W-SUN'): -0.0004277017424273529,\n",
              " Timestamp('2006-12-03 00:00:00', freq='W-SUN'): 0.008342231729055205,\n",
              " Timestamp('2006-12-10 00:00:00', freq='W-SUN'): 0.006505430724161239,\n",
              " Timestamp('2006-12-17 00:00:00', freq='W-SUN'): -0.01255782999792914,\n",
              " Timestamp('2006-12-24 00:00:00', freq='W-SUN'): 0.0057524111320559875,\n",
              " Timestamp('2006-12-31 00:00:00', freq='W-SUN'): -0.012021138840070231,\n",
              " Timestamp('2007-01-07 00:00:00', freq='W-SUN'): 0.017185043883714567,\n",
              " Timestamp('2007-01-14 00:00:00', freq='W-SUN'): -0.0017473962938996711,\n",
              " Timestamp('2007-01-21 00:00:00', freq='W-SUN'): -0.006570224044233063,\n",
              " Timestamp('2007-01-28 00:00:00', freq='W-SUN'): 0.018426021261326198,\n",
              " Timestamp('2007-02-04 00:00:00', freq='W-SUN'): -0.005252211580902822,\n",
              " Timestamp('2007-02-11 00:00:00', freq='W-SUN'): 0.012435695255860892,\n",
              " Timestamp('2007-02-18 00:00:00', freq='W-SUN'): -0.0017861706758199015,\n",
              " Timestamp('2007-02-25 00:00:00', freq='W-SUN'): -0.04909829185903745,\n",
              " Timestamp('2007-03-04 00:00:00', freq='W-SUN'): 0.020662699518878447,\n",
              " Timestamp('2007-03-11 00:00:00', freq='W-SUN'): -0.013459614206802573,\n",
              " Timestamp('2007-03-18 00:00:00', freq='W-SUN'): 0.029656786932959357,\n",
              " Timestamp('2007-03-25 00:00:00', freq='W-SUN'): -0.010452961672473868,\n",
              " Timestamp('2007-04-01 00:00:00', freq='W-SUN'): 0.014631407860680774,\n",
              " Timestamp('2007-04-08 00:00:00', freq='W-SUN'): 0.004631960095345815,\n",
              " Timestamp('2007-04-15 00:00:00', freq='W-SUN'): 0.019131817607737404,\n",
              " Timestamp('2007-04-22 00:00:00', freq='W-SUN'): 0.0078183193306707,\n",
              " Timestamp('2007-04-29 00:00:00', freq='W-SUN'): 0.008553855978039693,\n",
              " Timestamp('2007-05-06 00:00:00', freq='W-SUN'): -0.00013258218012386817,\n",
              " Timestamp('2007-05-13 00:00:00', freq='W-SUN'): 0.011666405861948639,\n",
              " Timestamp('2007-05-20 00:00:00', freq='W-SUN'): -0.0058330055599292415,\n",
              " Timestamp('2007-05-27 00:00:00', freq='W-SUN'): 0.014084506856857979,\n",
              " Timestamp('2007-06-03 00:00:00', freq='W-SUN'): -0.016282402722266633,\n",
              " Timestamp('2007-06-10 00:00:00', freq='W-SUN'): 0.014178851780639835,\n",
              " Timestamp('2007-06-17 00:00:00', freq='W-SUN'): -0.01845091868395758,\n",
              " Timestamp('2007-06-24 00:00:00', freq='W-SUN'): 0.0012645633231974374,\n",
              " Timestamp('2007-07-01 00:00:00', freq='W-SUN'): 0.013985557565637961,\n",
              " Timestamp('2007-07-08 00:00:00', freq='W-SUN'): 0.011034225358207885,\n",
              " Timestamp('2007-07-15 00:00:00', freq='W-SUN'): -0.009613555403137103,\n",
              " Timestamp('2007-07-22 00:00:00', freq='W-SUN'): -0.058827295445525056,\n",
              " Timestamp('2007-07-29 00:00:00', freq='W-SUN'): -0.014595971371012074,\n",
              " Timestamp('2007-08-05 00:00:00', freq='W-SUN'): 0.0034671657702644728,\n",
              " Timestamp('2007-08-12 00:00:00', freq='W-SUN'): -0.012218382252559794,\n",
              " Timestamp('2007-08-19 00:00:00', freq='W-SUN'): 0.021767610687712588,\n",
              " Timestamp('2007-08-26 00:00:00', freq='W-SUN'): 0.008026811932109678,\n",
              " Timestamp('2007-09-02 00:00:00', freq='W-SUN'): -0.00935903715209972,\n",
              " Timestamp('2007-09-09 00:00:00', freq='W-SUN'): 0.01624344755000138,\n",
              " Timestamp('2007-09-16 00:00:00', freq='W-SUN'): 0.024678059802819154,\n",
              " Timestamp('2007-09-23 00:00:00', freq='W-SUN'): 0.0010497572634793953,\n",
              " Timestamp('2007-09-30 00:00:00', freq='W-SUN'): 0.021297508992234246,\n",
              " Timestamp('2007-10-07 00:00:00', freq='W-SUN'): 0.006049314666640925,\n",
              " Timestamp('2007-10-14 00:00:00', freq='W-SUN'): -0.04223463128598888,\n",
              " Timestamp('2007-10-21 00:00:00', freq='W-SUN'): 0.0319763130997156,\n",
              " Timestamp('2007-10-28 00:00:00', freq='W-SUN'): -0.017735309063516946,\n",
              " Timestamp('2007-11-04 00:00:00', freq='W-SUN'): -0.030072173416681194,\n",
              " Timestamp('2007-11-11 00:00:00', freq='W-SUN'): 0.003994118669796769,\n",
              " Timestamp('2007-11-18 00:00:00', freq='W-SUN'): -0.007915707653604763,\n",
              " Timestamp('2007-11-25 00:00:00', freq='W-SUN'): 0.004934021688261035,\n",
              " Timestamp('2007-12-02 00:00:00', freq='W-SUN'): 0.018354828013296024,\n",
              " Timestamp('2007-12-09 00:00:00', freq='W-SUN'): -0.02716817178191554,\n",
              " Timestamp('2007-12-16 00:00:00', freq='W-SUN'): 0.010367669256069374,\n",
              " Timestamp('2007-12-23 00:00:00', freq='W-SUN'): 0.006157051436871524,\n",
              " Timestamp('2007-12-30 00:00:00', freq='W-SUN'): -0.03936103170519245,\n",
              " Timestamp('2008-01-06 00:00:00', freq='W-SUN'): -0.011705831911795209,\n",
              " Timestamp('2008-01-13 00:00:00', freq='W-SUN'): -0.06446589502788609,\n",
              " Timestamp('2008-01-20 00:00:00', freq='W-SUN'): 0.045829683561274245,\n",
              " Timestamp('2008-01-27 00:00:00', freq='W-SUN'): 0.04742613865474034,\n",
              " Timestamp('2008-02-03 00:00:00', freq='W-SUN'): -0.044106024648069925,\n",
              " Timestamp('2008-02-10 00:00:00', freq='W-SUN'): 0.015326768655442293,\n",
              " Timestamp('2008-02-17 00:00:00', freq='W-SUN'): -0.008045684552035717,\n",
              " Timestamp('2008-02-24 00:00:00', freq='W-SUN'): -0.012689878182301556,\n",
              " Timestamp('2008-03-02 00:00:00', freq='W-SUN'): -0.025762295521723707,\n",
              " Timestamp('2008-03-09 00:00:00', freq='W-SUN'): -0.0017713725129813033,\n",
              " Timestamp('2008-03-16 00:00:00', freq='W-SUN'): 0.04353323852413696,\n",
              " Timestamp('2008-03-23 00:00:00', freq='W-SUN'): -0.013502385620019316,\n",
              " Timestamp('2008-03-30 00:00:00', freq='W-SUN'): 0.04265371542825795,\n",
              " Timestamp('2008-04-06 00:00:00', freq='W-SUN'): -0.032566839507029634,\n",
              " Timestamp('2008-04-13 00:00:00', freq='W-SUN'): 0.039717650878930144,\n",
              " Timestamp('2008-04-20 00:00:00', freq='W-SUN'): 0.009911090498765606,\n",
              " Timestamp('2008-04-27 00:00:00', freq='W-SUN'): 0.011652773389591973,\n",
              " Timestamp('2008-05-04 00:00:00', freq='W-SUN'): -0.015242885177393518,\n",
              " Timestamp('2008-05-11 00:00:00', freq='W-SUN'): 0.02448835906642719,\n",
              " Timestamp('2008-05-18 00:00:00', freq='W-SUN'): -0.036201940147075826,\n",
              " Timestamp('2008-05-25 00:00:00', freq='W-SUN'): 0.01850510119364804,\n",
              " Timestamp('2008-06-01 00:00:00', freq='W-SUN'): -0.025316519697968665,\n",
              " Timestamp('2008-06-08 00:00:00', freq='W-SUN'): -0.005187834245303116,\n",
              " Timestamp('2008-06-15 00:00:00', freq='W-SUN'): -0.029288092306423603,\n",
              " Timestamp('2008-06-22 00:00:00', freq='W-SUN'): -0.03452189520847596,\n",
              " Timestamp('2008-06-29 00:00:00', freq='W-SUN'): -0.012354374949991281,\n",
              " Timestamp('2008-07-06 00:00:00', freq='W-SUN'): -0.023266858401554902,\n",
              " Timestamp('2008-07-13 00:00:00', freq='W-SUN'): 0.005748051959954434,\n",
              " Timestamp('2008-07-20 00:00:00', freq='W-SUN'): -0.008141640848286474,\n",
              " Timestamp('2008-07-27 00:00:00', freq='W-SUN'): 0.0065135411607006154,\n",
              " Timestamp('2008-08-03 00:00:00', freq='W-SUN'): 0.02642013625499721,\n",
              " Timestamp('2008-08-10 00:00:00', freq='W-SUN'): 0.0054066346998792114,\n",
              " Timestamp('2008-08-17 00:00:00', freq='W-SUN'): -0.005980211928708788,\n",
              " Timestamp('2008-08-24 00:00:00', freq='W-SUN'): -7.771738949411421e-05,\n",
              " Timestamp('2008-08-31 00:00:00', freq='W-SUN'): -0.0431438978939006,\n",
              " Timestamp('2008-09-07 00:00:00', freq='W-SUN'): -0.015229593147509858,\n",
              " Timestamp('2008-09-14 00:00:00', freq='W-SUN'): 0.020471972880176867,\n",
              " Timestamp('2008-09-21 00:00:00', freq='W-SUN'): -0.028927272694108597,\n",
              " Timestamp('2008-09-28 00:00:00', freq='W-SUN'): -0.07386270835876038,\n",
              " Timestamp('2008-10-05 00:00:00', freq='W-SUN'): -0.17405507841241105,\n",
              " Timestamp('2008-10-12 00:00:00', freq='W-SUN'): -0.007031042707008337,\n",
              " Timestamp('2008-10-19 00:00:00', freq='W-SUN'): 0.021716779556904358,\n",
              " Timestamp('2008-10-26 00:00:00', freq='W-SUN'): 0.12632314614024487,\n",
              " Timestamp('2008-11-02 00:00:00', freq='W-SUN'): 0.010718381210435012,\n",
              " Timestamp('2008-11-09 00:00:00', freq='W-SUN'): -0.09022157431174849,\n",
              " Timestamp('2008-11-16 00:00:00', freq='W-SUN'): -0.0794165343626951,\n",
              " Timestamp('2008-11-23 00:00:00', freq='W-SUN'): 0.0997314233332866,\n",
              " Timestamp('2008-11-30 00:00:00', freq='W-SUN'): 0.004799428527038621,\n",
              " Timestamp('2008-12-07 00:00:00', freq='W-SUN'): 0.01319373821989529,\n",
              " Timestamp('2008-12-14 00:00:00', freq='W-SUN'): -0.009323691619535739,\n",
              " Timestamp('2008-12-21 00:00:00', freq='W-SUN'): 0.0008035456167848656,\n",
              " Timestamp('2008-12-28 00:00:00', freq='W-SUN'): -0.02342879909790243,\n",
              " Timestamp('2009-01-04 00:00:00', freq='W-SUN'): 0.009409616476161899,\n",
              " Timestamp('2009-01-11 00:00:00', freq='W-SUN'): -0.04254838102424055,\n",
              " Timestamp('2009-01-18 00:00:00', freq='W-SUN'): -0.013296948356988655,\n",
              " Timestamp('2009-01-25 00:00:00', freq='W-SUN'): -0.009091925306468565,\n",
              " Timestamp('2009-02-01 00:00:00', freq='W-SUN'): 0.06632343999019252,\n",
              " Timestamp('2009-02-08 00:00:00', freq='W-SUN'): -0.04829803413406199,\n",
              " Timestamp('2009-02-15 00:00:00', freq='W-SUN'): -0.034181709871172083,\n",
              " Timestamp('2009-02-22 00:00:00', freq='W-SUN'): -0.05544905029190172,\n",
              " Timestamp('2009-03-01 00:00:00', freq='W-SUN'): -0.04964146647717038,\n",
              " Timestamp('2009-03-08 00:00:00', freq='W-SUN'): 0.11979395672379504,\n",
              " Timestamp('2009-03-15 00:00:00', freq='W-SUN'): -0.0032484407906502185,\n",
              " Timestamp('2009-03-22 00:00:00', freq='W-SUN'): 0.036449111924031254,\n",
              " Timestamp('2009-03-29 00:00:00', freq='W-SUN'): 0.055889709678331664,\n",
              " Timestamp('2009-04-05 00:00:00', freq='W-SUN'): -0.0023165315118823296,\n",
              " Timestamp('2009-04-12 00:00:00', freq='W-SUN'): 0.02543575189438872,\n",
              " Timestamp('2009-04-19 00:00:00', freq='W-SUN'): 0.013093324607279312,\n",
              " Timestamp('2009-04-26 00:00:00', freq='W-SUN'): 0.025793639122315547,\n",
              " Timestamp('2009-05-03 00:00:00', freq='W-SUN'): 0.05002823094201355,\n",
              " Timestamp('2009-05-10 00:00:00', freq='W-SUN'): -0.03260630422921388,\n",
              " Timestamp('2009-05-17 00:00:00', freq='W-SUN'): -0.005918548098764443,\n",
              " Timestamp('2009-05-24 00:00:00', freq='W-SUN'): 0.04719327696702954,\n",
              " Timestamp('2009-05-31 00:00:00', freq='W-SUN'): -0.018391357890729945,\n",
              " Timestamp('2009-06-07 00:00:00', freq='W-SUN'): 0.0132140457465492,\n",
              " Timestamp('2009-06-14 00:00:00', freq='W-SUN'): -0.020434206262603224,\n",
              " Timestamp('2009-06-21 00:00:00', freq='W-SUN'): 0.0076804587193378855,\n",
              " Timestamp('2009-06-28 00:00:00', freq='W-SUN'): -0.02497017669123686,\n",
              " Timestamp('2009-07-05 00:00:00', freq='W-SUN'): -0.011018697750872667,\n",
              " Timestamp('2009-07-12 00:00:00', freq='W-SUN'): -0.02429235467186156,\n",
              " Timestamp('2009-07-19 00:00:00', freq='W-SUN'): 0.035699176172369944,\n",
              " Timestamp('2009-07-26 00:00:00', freq='W-SUN'): 0.009501440830652968,\n",
              " Timestamp('2009-08-02 00:00:00', freq='W-SUN'): 0.013520270676420011,\n",
              " Timestamp('2009-08-09 00:00:00', freq='W-SUN'): 0.0004963569683613037,\n",
              " Timestamp('2009-08-16 00:00:00', freq='W-SUN'): 0.041679343281322036,\n",
              " Timestamp('2009-08-23 00:00:00', freq='W-SUN'): -9.674049808241188e-05,\n",
              " Timestamp('2009-08-30 00:00:00', freq='W-SUN'): -0.003028279680718617,\n",
              " Timestamp('2009-09-06 00:00:00', freq='W-SUN'): 0.017184436893203918,\n",
              " Timestamp('2009-09-13 00:00:00', freq='W-SUN'): 0.027339276877337542,\n",
              " Timestamp('2009-09-20 00:00:00', freq='W-SUN'): -0.013599036864661854,\n",
              " Timestamp('2009-09-27 00:00:00', freq='W-SUN'): -0.022508345684470108,\n",
              " Timestamp('2009-10-04 00:00:00', freq='W-SUN'): 0.04237123338442694,\n",
              " Timestamp('2009-10-11 00:00:00', freq='W-SUN'): 0.010486237741532364,\n",
              " Timestamp('2009-10-18 00:00:00', freq='W-SUN'): -0.009076721371596222,\n",
              " Timestamp('2009-10-25 00:00:00', freq='W-SUN'): -0.042883540930227594,\n",
              " Timestamp('2009-11-01 00:00:00', freq='W-SUN'): 0.028810141999715988,\n",
              " Timestamp('2009-11-08 00:00:00', freq='W-SUN'): 0.015470181069111107,\n",
              " Timestamp('2009-11-15 00:00:00', freq='W-SUN'): -0.008606604691246696,\n",
              " Timestamp('2009-11-22 00:00:00', freq='W-SUN'): -0.01038656963162422,\n",
              " Timestamp('2009-11-29 00:00:00', freq='W-SUN'): 0.01397514576246407,\n",
              " Timestamp('2009-12-06 00:00:00', freq='W-SUN'): 0.001803236793680002,\n",
              " Timestamp('2009-12-13 00:00:00', freq='W-SUN'): -0.014838687364654855,\n",
              " Timestamp('2009-12-20 00:00:00', freq='W-SUN'): 0.015529080615220613,\n",
              " Timestamp('2009-12-27 00:00:00', freq='W-SUN'): -0.012931797822288734,\n",
              " Timestamp('2010-01-03 00:00:00', freq='W-SUN'): 0.019578152009126458,\n",
              " Timestamp('2010-01-10 00:00:00', freq='W-SUN'): -0.012513060262199076,\n",
              " Timestamp('2010-01-17 00:00:00', freq='W-SUN'): -0.03881362333708089,\n",
              " Timestamp('2010-01-24 00:00:00', freq='W-SUN'): -0.02558751497674901,\n",
              " Timestamp('2010-01-31 00:00:00', freq='W-SUN'): -0.013777142602364446,\n",
              " Timestamp('2010-02-07 00:00:00', freq='W-SUN'): 0.012179155184170079,\n",
              " Timestamp('2010-02-14 00:00:00', freq='W-SUN'): 0.020944313605141398,\n",
              " Timestamp('2010-02-21 00:00:00', freq='W-SUN'): -0.007261362422374868,\n",
              " Timestamp('2010-02-28 00:00:00', freq='W-SUN'): 0.027428085272340464,\n",
              " Timestamp('2010-03-07 00:00:00', freq='W-SUN'): 0.010502336591942264,\n",
              " Timestamp('2010-03-14 00:00:00', freq='W-SUN'): 0.006159977335415943,\n",
              " Timestamp('2010-03-21 00:00:00', freq='W-SUN'): 0.01101382379696165,\n",
              " Timestamp('2010-03-28 00:00:00', freq='W-SUN'): 0.005376845700722783,\n",
              " Timestamp('2010-04-04 00:00:00', freq='W-SUN'): 0.010993682875264303,\n",
              " Timestamp('2010-04-11 00:00:00', freq='W-SUN'): -0.0028404010736942566,\n",
              " Timestamp('2010-04-18 00:00:00', freq='W-SUN'): 0.02352740066334923,\n",
              " Timestamp('2010-04-25 00:00:00', freq='W-SUN'): -0.02494870783666329,\n",
              " Timestamp('2010-05-02 00:00:00', freq='W-SUN'): -0.06801805330921563,\n",
              " Timestamp('2010-05-09 00:00:00', freq='W-SUN'): -0.016578870850166065,\n",
              " Timestamp('2010-05-16 00:00:00', freq='W-SUN'): -0.044570894340741525,\n",
              " Timestamp('2010-05-23 00:00:00', freq='W-SUN'): 0.007832713080520942,\n",
              " Timestamp('2010-05-30 00:00:00', freq='W-SUN'): -0.014120886278189006,\n",
              " Timestamp('2010-06-06 00:00:00', freq='W-SUN'): 0.023134356990700388,\n",
              " Timestamp('2010-06-13 00:00:00', freq='W-SUN'): 0.010948299247601254,\n",
              " Timestamp('2010-06-20 00:00:00', freq='W-SUN'): -0.04641088985826848,\n",
              " Timestamp('2010-06-27 00:00:00', freq='W-SUN'): -0.05396650980252261,\n",
              " Timestamp('2010-07-04 00:00:00', freq='W-SUN'): 0.04168274837594309,\n",
              " Timestamp('2010-07-11 00:00:00', freq='W-SUN'): -0.008736003879851361,\n",
              " Timestamp('2010-07-18 00:00:00', freq='W-SUN'): 0.031387210703768,\n",
              " Timestamp('2010-07-25 00:00:00', freq='W-SUN'): -0.0029837342311705628,\n",
              " Timestamp('2010-08-01 00:00:00', freq='W-SUN'): 0.003571756470609127,\n",
              " Timestamp('2010-08-08 00:00:00', freq='W-SUN'): -0.040825363811997355,\n",
              " Timestamp('2010-08-15 00:00:00', freq='W-SUN'): -0.000371860184066092,\n",
              " Timestamp('2010-08-22 00:00:00', freq='W-SUN'): -0.010921880683803462,\n",
              " Timestamp('2010-08-29 00:00:00', freq='W-SUN'): 0.040439077867534756,\n",
              " Timestamp('2010-09-05 00:00:00', freq='W-SUN'): 0.010057080455094302,\n",
              " Timestamp('2010-09-12 00:00:00', freq='W-SUN'): -0.0007994670314537152,\n",
              " Timestamp('2010-09-19 00:00:00', freq='W-SUN'): 0.01718641966299831,\n",
              " Timestamp('2010-09-26 00:00:00', freq='W-SUN'): -0.0021765627531206448,\n",
              " Timestamp('2010-10-03 00:00:00', freq='W-SUN'): 0.01897348905376882,\n",
              " Timestamp('2010-10-10 00:00:00', freq='W-SUN'): 0.008396127412644555,\n",
              " Timestamp('2010-10-17 00:00:00', freq='W-SUN'): 0.005180907171410004,\n",
              " Timestamp('2010-10-24 00:00:00', freq='W-SUN'): -0.0054557747646111964,\n",
              " Timestamp('2010-10-31 00:00:00', freq='W-SUN'): 0.03065424540186448,\n",
              " Timestamp('2010-11-07 00:00:00', freq='W-SUN'): -0.017492227153579464,\n",
              " Timestamp('2010-11-14 00:00:00', freq='W-SUN'): -0.0024050505489292455,\n",
              " Timestamp('2010-11-21 00:00:00', freq='W-SUN'): -0.007435867533864717,\n",
              " Timestamp('2010-11-28 00:00:00', freq='W-SUN'): 0.03704640506329117,\n",
              " Timestamp('2010-12-05 00:00:00', freq='W-SUN'): 0.015086080447347588,\n",
              " Timestamp('2010-12-12 00:00:00', freq='W-SUN'): -0.005997600815731288,\n",
              " Timestamp('2010-12-19 00:00:00', freq='W-SUN'): 0.007702174323669533,\n",
              " Timestamp('2010-12-26 00:00:00', freq='W-SUN'): 0.0049548710530217385,\n",
              " Timestamp('2011-01-02 00:00:00', freq='W-SUN'): 0.003393575908717408,\n",
              " Timestamp('2011-01-09 00:00:00', freq='W-SUN'): 0.021488394351581782,\n",
              " Timestamp('2011-01-16 00:00:00', freq='W-SUN'): -0.0062703053405491925,\n",
              " Timestamp('2011-01-23 00:00:00', freq='W-SUN'): -0.0044429965788525165,\n",
              " Timestamp('2011-01-30 00:00:00', freq='W-SUN'): 0.024049245191342796,\n",
              " Timestamp('2011-02-06 00:00:00', freq='W-SUN'): 0.012705409118907489,\n",
              " Timestamp('2011-02-13 00:00:00', freq='W-SUN'): 0.011275652193307164,\n",
              " Timestamp('2011-02-20 00:00:00', freq='W-SUN'): -0.0059344428310711805,\n",
              " Timestamp('2011-02-27 00:00:00', freq='W-SUN'): -0.002635190344478807,\n",
              " Timestamp('2011-03-06 00:00:00', freq='W-SUN'): -0.01520401162724662,\n",
              " Timestamp('2011-03-13 00:00:00', freq='W-SUN'): -0.017155188200815873,\n",
              " Timestamp('2011-03-20 00:00:00', freq='W-SUN'): 0.015075352992252633,\n",
              " Timestamp('2011-03-27 00:00:00', freq='W-SUN'): 0.011931843563887351,\n",
              " Timestamp('2011-04-03 00:00:00', freq='W-SUN'): -0.004271843137996605,\n",
              " Timestamp('2011-04-10 00:00:00', freq='W-SUN'): -0.00721809774436083,\n",
              " Timestamp('2011-04-17 00:00:00', freq='W-SUN'): 0.024427621546140407,\n",
              " Timestamp('2011-04-24 00:00:00', freq='W-SUN'): 0.020571515140638885,\n",
              " Timestamp('2011-05-01 00:00:00', freq='W-SUN'): -0.020938278641803875,\n",
              " Timestamp('2011-05-08 00:00:00', freq='W-SUN'): -0.0011178850716462689,\n",
              " Timestamp('2011-05-15 00:00:00', freq='W-SUN'): 0.00037438604933195485,\n",
              " Timestamp('2011-05-22 00:00:00', freq='W-SUN'): 0.011592658329827527,\n",
              " Timestamp('2011-05-29 00:00:00', freq='W-SUN'): -0.032277256591904585,\n",
              " Timestamp('2011-06-05 00:00:00', freq='W-SUN'): -0.019140580187272924,\n",
              " Timestamp('2011-06-12 00:00:00', freq='W-SUN'): -0.006568113273657929,\n",
              " Timestamp('2011-06-19 00:00:00', freq='W-SUN'): 0.0015005133114709857,\n",
              " Timestamp('2011-06-26 00:00:00', freq='W-SUN'): 0.055402309523227194,\n",
              " Timestamp('2011-07-03 00:00:00', freq='W-SUN'): 0.0046344371702378975,\n",
              " Timestamp('2011-07-10 00:00:00', freq='W-SUN'): -0.007984919020715686,\n",
              " Timestamp('2011-07-17 00:00:00', freq='W-SUN'): 0.026701250736935446,\n",
              " Timestamp('2011-07-24 00:00:00', freq='W-SUN'): -0.029782452443005543,\n",
              " Timestamp('2011-07-31 00:00:00', freq='W-SUN'): -0.08223780440959368,\n",
              " Timestamp('2011-08-07 00:00:00', freq='W-SUN'): 0.010349832850916644,\n",
              " Timestamp('2011-08-14 00:00:00', freq='W-SUN'): -0.05495429893524126,\n",
              " Timestamp('2011-08-21 00:00:00', freq='W-SUN'): 0.024311913246711954,\n",
              " Timestamp('2011-08-28 00:00:00', freq='W-SUN'): -0.014302442527642012,\n",
              " Timestamp('2011-09-04 00:00:00', freq='W-SUN'): 0.013375286418177201,\n",
              " Timestamp('2011-09-11 00:00:00', freq='W-SUN'): 0.06158815356348261,\n",
              " Timestamp('2011-09-18 00:00:00', freq='W-SUN'): -0.05011292604461579,\n",
              " Timestamp('2011-09-25 00:00:00', freq='W-SUN'): -0.012738844666793052,\n",
              " Timestamp('2011-10-02 00:00:00', freq='W-SUN'): 0.028624776044533277,\n",
              " Timestamp('2011-10-09 00:00:00', freq='W-SUN'): 0.0415533650577837,\n",
              " Timestamp('2011-10-16 00:00:00', freq='W-SUN'): 0.01623086345160852,\n",
              " Timestamp('2011-10-23 00:00:00', freq='W-SUN'): 0.03567695958245889,\n",
              " Timestamp('2011-10-30 00:00:00', freq='W-SUN'): -0.013211709241531672,\n",
              " Timestamp('2011-11-06 00:00:00', freq='W-SUN'): 0.010128439350254701,\n",
              " Timestamp('2011-11-13 00:00:00', freq='W-SUN'): -0.0333623815934325,\n",
              " Timestamp('2011-11-20 00:00:00', freq='W-SUN'): -0.032113153879695995,\n",
              " Timestamp('2011-11-27 00:00:00', freq='W-SUN'): 0.04450393136603699,\n",
              " Timestamp('2011-12-04 00:00:00', freq='W-SUN'): -0.006228264151001672,\n",
              " Timestamp('2011-12-11 00:00:00', freq='W-SUN'): -0.026890764951358878,\n",
              " Timestamp('2011-12-18 00:00:00', freq='W-SUN'): 0.035474365647622,\n",
              " Timestamp('2011-12-25 00:00:00', freq='W-SUN'): -0.005310279865424161,\n",
              " Timestamp('2012-01-01 00:00:00', freq='W-SUN'): -0.00039138227314683194,\n",
              " Timestamp('2012-01-08 00:00:00', freq='W-SUN'): 0.0065624687500001055,\n",
              " Timestamp('2012-01-15 00:00:00', freq='W-SUN'): 0.01437573009877405,\n",
              " Timestamp('2012-01-22 00:00:00', freq='W-SUN'): 0.002357326528679439,\n",
              " Timestamp('2012-01-29 00:00:00', freq='W-SUN'): 0.03087884571599291,\n",
              " Timestamp('2012-02-05 00:00:00', freq='W-SUN'): -0.0002849719849427151,\n",
              " Timestamp('2012-02-12 00:00:00', freq='W-SUN'): 0.008054958199935524,\n",
              " Timestamp('2012-02-19 00:00:00', freq='W-SUN'): 0.0014627148822559477,\n",
              " Timestamp('2012-02-26 00:00:00', freq='W-SUN'): 0.009483855036498949,\n",
              " Timestamp('2012-03-04 00:00:00', freq='W-SUN'): 0.0034281617755727617,\n",
              " Timestamp('2012-03-11 00:00:00', freq='W-SUN'): 0.019992729480347592,\n",
              " Timestamp('2012-03-18 00:00:00', freq='W-SUN'): -0.003994101505179997,\n",
              " Timestamp('2012-03-25 00:00:00', freq='W-SUN'): 0.001137604030043648,\n",
              " Timestamp('2012-04-01 00:00:00', freq='W-SUN'): -0.00604384247755846,\n",
              " Timestamp('2012-04-08 00:00:00', freq='W-SUN'): -0.006447873697369329,\n",
              " Timestamp('2012-04-15 00:00:00', freq='W-SUN'): 0.0007980339755667338,\n",
              " Timestamp('2012-04-22 00:00:00', freq='W-SUN'): 0.02819691077617075,\n",
              " Timestamp('2012-04-29 00:00:00', freq='W-SUN'): -0.022196852314632493,\n",
              " Timestamp('2012-05-06 00:00:00', freq='W-SUN'): -0.006592879883996716,\n",
              " Timestamp('2012-05-13 00:00:00', freq='W-SUN'): -0.03402570968692897,\n",
              " Timestamp('2012-05-20 00:00:00', freq='W-SUN'): 0.014904747544414806,\n",
              " Timestamp('2012-05-27 00:00:00', freq='W-SUN'): -0.037548812329564064,\n",
              " Timestamp('2012-06-03 00:00:00', freq='W-SUN'): 0.03668515489278896,\n",
              " Timestamp('2012-06-10 00:00:00', freq='W-SUN'): -0.00022358947937081778,\n",
              " Timestamp('2012-06-17 00:00:00', freq='W-SUN'): -0.0008983006303594543,\n",
              " Timestamp('2012-06-24 00:00:00', freq='W-SUN'): 0.030670222703440633,\n",
              " Timestamp('2012-07-01 00:00:00', freq='W-SUN'): -0.007253744350930399,\n",
              " Timestamp('2012-07-08 00:00:00', freq='W-SUN'): 0.002733010683519983,\n",
              " Timestamp('2012-07-15 00:00:00', freq='W-SUN'): 0.007604835977483253,\n",
              " Timestamp('2012-07-22 00:00:00', freq='W-SUN'): 0.03130803873497406,\n",
              " Timestamp('2012-07-29 00:00:00', freq='W-SUN'): 0.00599192879029954,\n",
              " Timestamp('2012-08-05 00:00:00', freq='W-SUN'): 0.008015996220899092,\n",
              " Timestamp('2012-08-12 00:00:00', freq='W-SUN'): 0.011237460402384254,\n",
              " Timestamp('2012-08-19 00:00:00', freq='W-SUN'): -0.0033103325344508135,\n",
              " Timestamp('2012-08-26 00:00:00', freq='W-SUN'): -0.00514479530019591,\n",
              " Timestamp('2012-09-02 00:00:00', freq='W-SUN'): 0.023326780794721093,\n",
              " Timestamp('2012-09-09 00:00:00', freq='W-SUN'): 0.021152666327031496,\n",
              " Timestamp('2012-09-16 00:00:00', freq='W-SUN'): -0.007281931301457339,\n",
              " Timestamp('2012-09-23 00:00:00', freq='W-SUN'): -0.008129473295052262,\n",
              " Timestamp('2012-09-30 00:00:00', freq='W-SUN'): 0.011209486265998088,\n",
              " Timestamp('2012-10-07 00:00:00', freq='W-SUN'): -0.01861268467255433,\n",
              " Timestamp('2012-10-14 00:00:00', freq='W-SUN'): 0.0011171053862208376,\n",
              " Timestamp('2012-10-21 00:00:00', freq='W-SUN'): -0.012574139542052547,\n",
              " Timestamp('2012-10-28 00:00:00', freq='W-SUN'): -0.0020444694235684435,\n",
              " Timestamp('2012-11-04 00:00:00', freq='W-SUN'): -0.022568106576521977,\n",
              " Timestamp('2012-11-11 00:00:00', freq='W-SUN'): -0.01601847942906373,\n",
              " Timestamp('2012-11-18 00:00:00', freq='W-SUN'): 0.02501821718715967,\n",
              " Timestamp('2012-11-25 00:00:00', freq='W-SUN'): 0.010664771162379147,\n",
              " Timestamp('2012-12-02 00:00:00', freq='W-SUN'): -0.0027310853767980475,\n",
              " Timestamp('2012-12-09 00:00:00', freq='W-SUN'): -0.0007735109667773429,\n",
              " Timestamp('2012-12-16 00:00:00', freq='W-SUN'): 0.002246030727549538,\n",
              " Timestamp('2012-12-23 00:00:00', freq='W-SUN'): -0.017195375272189062,\n",
              " Timestamp('2012-12-30 00:00:00', freq='W-SUN'): 0.04804518693841655,\n",
              " Timestamp('2013-01-06 00:00:00', freq='W-SUN'): 0.008364764825583869,\n",
              " Timestamp('2013-01-13 00:00:00', freq='W-SUN'): 0.009803274625932966,\n",
              " Timestamp('2013-01-20 00:00:00', freq='W-SUN'): 0.01294409744564011,\n",
              " Timestamp('2013-01-27 00:00:00', freq='W-SUN'): 0.00632119265585425,\n",
              " Timestamp('2013-02-03 00:00:00', freq='W-SUN'): 0.009845635518098398,\n",
              " Timestamp('2013-02-10 00:00:00', freq='W-SUN'): 0.002438355000713323,\n",
              " Timestamp('2013-02-17 00:00:00', freq='W-SUN'): -0.0031502002740106403,\n",
              " Timestamp('2013-02-24 00:00:00', freq='W-SUN'): -0.003406957891405429,\n",
              " Timestamp('2013-03-03 00:00:00', freq='W-SUN'): 0.02424886084109313,\n",
              " Timestamp('2013-03-10 00:00:00', freq='W-SUN'): 0.0032835113122291035,\n",
              " Timestamp('2013-03-17 00:00:00', freq='W-SUN'): 0.008163859224150777,\n",
              " Timestamp('2013-03-24 00:00:00', freq='W-SUN'): 0.004230517410118428,\n",
              " Timestamp('2013-03-31 00:00:00', freq='W-SUN'): -0.009132077632852273,\n",
              " Timestamp('2013-04-07 00:00:00', freq='W-SUN'): 0.022734584330918184,\n",
              " Timestamp('2013-04-14 00:00:00', freq='W-SUN'): -0.01594939240506329,\n",
              " Timestamp('2013-04-21 00:00:00', freq='W-SUN'): 0.01579153945173663,\n",
              " Timestamp('2013-04-28 00:00:00', freq='W-SUN'): 0.01701643054158226,\n",
              " Timestamp('2013-05-05 00:00:00', freq='W-SUN'): 0.011889274509589556,\n",
              " Timestamp('2013-05-12 00:00:00', freq='W-SUN'): 0.022916697725184374,\n",
              " Timestamp('2013-05-19 00:00:00', freq='W-SUN'): -0.008814012524367483,\n",
              " Timestamp('2013-05-26 00:00:00', freq='W-SUN'): -0.021491835191827464,\n",
              " Timestamp('2013-06-02 00:00:00', freq='W-SUN'): 0.005920777563074169,\n",
              " Timestamp('2013-06-09 00:00:00', freq='W-SUN'): -0.012884913349282184,\n",
              " Timestamp('2013-06-16 00:00:00', freq='W-SUN'): -0.031773000319015206,\n",
              " Timestamp('2013-06-23 00:00:00', freq='W-SUN'): 0.019121999387027563,\n",
              " Timestamp('2013-06-30 00:00:00', freq='W-SUN'): 0.010914107990639566,\n",
              " Timestamp('2013-07-07 00:00:00', freq='W-SUN'): 0.022275076148693493,\n",
              " Timestamp('2013-07-14 00:00:00', freq='W-SUN'): 0.007144114978007271,\n",
              " Timestamp('2013-07-21 00:00:00', freq='W-SUN'): -0.0017708694464110596,\n",
              " Timestamp('2013-07-28 00:00:00', freq='W-SUN'): 0.01345745846693271,\n",
              " Timestamp('2013-08-04 00:00:00', freq='W-SUN'): -0.007387049002114402,\n",
              " Timestamp('2013-08-11 00:00:00', freq='W-SUN'): -0.015612043753506333,\n",
              " Timestamp('2013-08-18 00:00:00', freq='W-SUN'): 0.005916421190029106,\n",
              " Timestamp('2013-08-25 00:00:00', freq='W-SUN'): -0.018826063503702032,\n",
              " Timestamp('2013-09-01 00:00:00', freq='W-SUN'): 0.004902239421466849,\n",
              " Timestamp('2013-09-08 00:00:00', freq='W-SUN'): 0.017302523592115242,\n",
              " Timestamp('2013-09-15 00:00:00', freq='W-SUN'): -0.0025707115547858378,\n",
              " Timestamp('2013-09-22 00:00:00', freq='W-SUN'): -0.009267411306604221,\n",
              " Timestamp('2013-09-29 00:00:00', freq='W-SUN'): 0.008418933805085528,\n",
              " Timestamp('2013-10-06 00:00:00', freq='W-SUN'): 0.016963308051168483,\n",
              " Timestamp('2013-10-13 00:00:00', freq='W-SUN'): 0.03061279939548728,\n",
              " Timestamp('2013-10-20 00:00:00', freq='W-SUN'): 0.00859845242645662,\n",
              " Timestamp('2013-10-27 00:00:00', freq='W-SUN'): 0.001819364385805707,\n",
              " Timestamp('2013-11-03 00:00:00', freq='W-SUN'): 0.003395726941018525,\n",
              " Timestamp('2013-11-10 00:00:00', freq='W-SUN'): 0.01654250272534174,\n",
              " Timestamp('2013-11-17 00:00:00', freq='W-SUN'): 0.0025505516201646244,\n",
              " Timestamp('2013-11-24 00:00:00', freq='W-SUN'): -0.0007177441418389584,\n",
              " Timestamp('2013-12-01 00:00:00', freq='W-SUN'): -0.0008282842968311779,\n",
              " Timestamp('2013-12-08 00:00:00', freq='W-SUN'): -0.018515456998316682,\n",
              " Timestamp('2013-12-15 00:00:00', freq='W-SUN'): 0.014585085463846145,\n",
              " Timestamp('2013-12-22 00:00:00', freq='W-SUN'): 0.007673384615073529,\n",
              " Timestamp('2013-12-29 00:00:00', freq='W-SUN'): -0.005329831003693669,\n",
              " Timestamp('2014-01-05 00:00:00', freq='W-SUN'): 0.0035423945843807265,\n",
              " Timestamp('2014-01-12 00:00:00', freq='W-SUN'): -0.00016333097580805583,\n",
              " Timestamp('2014-01-19 00:00:00', freq='W-SUN'): -0.0314564054919828,\n",
              " Timestamp('2014-01-26 00:00:00', freq='W-SUN'): -0.004914581759349798,\n",
              " Timestamp('2014-02-02 00:00:00', freq='W-SUN'): 0.009608315954327604,\n",
              " Timestamp('2014-02-09 00:00:00', freq='W-SUN'): 0.024040106133112533,\n",
              " Timestamp('2014-02-16 00:00:00', freq='W-SUN'): -0.0015745141221718212,\n",
              " Timestamp('2014-02-23 00:00:00', freq='W-SUN'): 0.010907282455542048,\n",
              " Timestamp('2014-03-02 00:00:00', freq='W-SUN'): 0.019550506998662624,\n",
              " Timestamp('2014-03-09 00:00:00', freq='W-SUN'): -0.01760917690264847,\n",
              " Timestamp('2014-03-16 00:00:00', freq='W-SUN'): 0.0032868204814228384,\n",
              " Timestamp('2014-03-23 00:00:00', freq='W-SUN'): -0.007225385511140864,\n",
              " Timestamp('2014-03-30 00:00:00', freq='W-SUN'): -0.0014464241864940725,\n",
              " Timestamp('2014-04-06 00:00:00', freq='W-SUN'): -0.023877397534994276,\n",
              " Timestamp('2014-04-13 00:00:00', freq='W-SUN'): 0.018914372341336028,\n",
              " Timestamp('2014-04-20 00:00:00', freq='W-SUN'): -0.0008045966444474881,\n",
              " Timestamp('2014-04-27 00:00:00', freq='W-SUN'): 0.005399598951089049,\n",
              " Timestamp('2014-05-04 00:00:00', freq='W-SUN'): 0.004381789058361603,\n",
              " Timestamp('2014-05-11 00:00:00', freq='W-SUN'): -0.003972457563996967,\n",
              " Timestamp('2014-05-18 00:00:00', freq='W-SUN'): 0.014172326557916575,\n",
              " Timestamp('2014-05-25 00:00:00', freq='W-SUN'): 0.008478985747712551,\n",
              " Timestamp('2014-06-01 00:00:00', freq='W-SUN'): 0.012593977910245913,\n",
              " Timestamp('2014-06-08 00:00:00', freq='W-SUN'): -0.006245205848624321,\n",
              " Timestamp('2014-06-15 00:00:00', freq='W-SUN'): 0.010573020839512223,\n",
              " Timestamp('2014-06-22 00:00:00', freq='W-SUN'): -0.000867380966697728,\n",
              " Timestamp('2014-06-29 00:00:00', freq='W-SUN'): 0.012774655280142901,\n",
              " Timestamp('2014-07-06 00:00:00', freq='W-SUN'): -0.006116701835927004,\n",
              " Timestamp('2014-07-13 00:00:00', freq='W-SUN'): 0.0005060776250893251,\n",
              " Timestamp('2014-07-20 00:00:00', freq='W-SUN'): 0.0031965346429860537,\n",
              " Timestamp('2014-07-27 00:00:00', freq='W-SUN'): -0.0265978718294365,\n",
              " Timestamp('2014-08-03 00:00:00', freq='W-SUN'): 0.0019184425239395467,\n",
              " Timestamp('2014-08-10 00:00:00', freq='W-SUN'): 0.009022013666948428,\n",
              " Timestamp('2014-08-17 00:00:00', freq='W-SUN'): 0.01214430367666198,\n",
              " Timestamp('2014-08-24 00:00:00', freq='W-SUN'): 0.002848046381772998,\n",
              " Timestamp('2014-08-31 00:00:00', freq='W-SUN'): 0.0006966213828103368,\n",
              " Timestamp('2014-09-07 00:00:00', freq='W-SUN'): -0.008908983763776373,\n",
              " Timestamp('2014-09-14 00:00:00', freq='W-SUN'): 0.007732441097962671,\n",
              " Timestamp('2014-09-21 00:00:00', freq='W-SUN'): -0.01222865947905195,\n",
              " Timestamp('2014-09-28 00:00:00', freq='W-SUN'): 0.0016310244897710367,\n",
              " Timestamp('2014-10-05 00:00:00', freq='W-SUN'): -0.034458311228505366,\n",
              " Timestamp('2014-10-12 00:00:00', freq='W-SUN'): -0.010448419231655253,\n",
              " Timestamp('2014-10-19 00:00:00', freq='W-SUN'): 0.04411836378784971,\n",
              " Timestamp('2014-10-26 00:00:00', freq='W-SUN'): 0.030296878971989488,\n",
              " Timestamp('2014-11-02 00:00:00', freq='W-SUN'): 0.007032478278847947,\n",
              " Timestamp('2014-11-09 00:00:00', freq='W-SUN'): 0.004228537608699465,\n",
              " Timestamp('2014-11-16 00:00:00', freq='W-SUN'): 0.01388269274811789,\n",
              " Timestamp('2014-11-23 00:00:00', freq='W-SUN'): 0.00014480378572964827,\n",
              " Timestamp('2014-11-30 00:00:00', freq='W-SUN'): 0.007751967279611489,\n",
              " Timestamp('2014-12-07 00:00:00', freq='W-SUN'): -0.03194875131170492,\n",
              " Timestamp('2014-12-14 00:00:00', freq='W-SUN'): 0.022477513070155723,\n",
              " Timestamp('2014-12-21 00:00:00', freq='W-SUN'): 0.008174133010882673,\n",
              " Timestamp('2014-12-28 00:00:00', freq='W-SUN'): -0.013399327569881245,\n",
              " Timestamp('2015-01-04 00:00:00', freq='W-SUN'): 0.0003918401370607226,\n",
              " Timestamp('2015-01-11 00:00:00', freq='W-SUN'): -0.013600112252822887,\n",
              " Timestamp('2015-01-18 00:00:00', freq='W-SUN'): 0.012697663419891227,\n",
              " Timestamp('2015-01-25 00:00:00', freq='W-SUN'): -0.025694933418667677,\n",
              " Timestamp('2015-02-01 00:00:00', freq='W-SUN'): 0.0274931263060266,\n",
              " Timestamp('2015-02-08 00:00:00', freq='W-SUN'): 0.024466449685667847,\n",
              " Timestamp('2015-02-15 00:00:00', freq='W-SUN'): 0.00878706328902762,\n",
              " Timestamp('2015-02-22 00:00:00', freq='W-SUN'): -0.0013273821814034409,\n",
              " Timestamp('2015-03-01 00:00:00', freq='W-SUN'): -0.015561244024865964,\n",
              " Timestamp('2015-03-08 00:00:00', freq='W-SUN'): -0.009194199258828308,\n",
              " Timestamp('2015-03-15 00:00:00', freq='W-SUN'): 0.01789945757197907,\n",
              " Timestamp('2015-03-22 00:00:00', freq='W-SUN'): -0.022241198766668538,\n",
              " Timestamp('2015-03-29 00:00:00', freq='W-SUN'): -0.002608918786528565,\n",
              " Timestamp('2015-04-05 00:00:00', freq='W-SUN'): 0.022739436693271678,\n",
              " Timestamp('2015-04-12 00:00:00', freq='W-SUN'): -0.009148511200946055,\n",
              " Timestamp('2015-04-19 00:00:00', freq='W-SUN'): 0.01238876889303321,\n",
              " Timestamp('2015-04-26 00:00:00', freq='W-SUN'): -0.0075825412557572105,\n",
              " Timestamp('2015-05-03 00:00:00', freq='W-SUN'): 0.0018463239472862978,\n",
              " Timestamp('2015-05-10 00:00:00', freq='W-SUN'): 0.004112090424991046,\n",
              " Timestamp('2015-05-17 00:00:00', freq='W-SUN'): 0.003533735310645135,\n",
              " Timestamp('2015-05-24 00:00:00', freq='W-SUN'): -0.00593218001691659,\n",
              " Timestamp('2015-05-31 00:00:00', freq='W-SUN'): -0.01023873728188411,\n",
              " Timestamp('2015-06-07 00:00:00', freq='W-SUN'): 0.001764911284892797,\n",
              " Timestamp('2015-06-14 00:00:00', freq='W-SUN'): 0.010400685440954294,\n",
              " Timestamp('2015-06-21 00:00:00', freq='W-SUN'): -0.009862663208670332,\n",
              " Timestamp('2015-06-28 00:00:00', freq='W-SUN'): -0.0035568612801221465,\n",
              " Timestamp('2015-07-05 00:00:00', freq='W-SUN'): 0.00831021026757622,\n",
              " Timestamp('2015-07-12 00:00:00', freq='W-SUN'): 0.016699320142128344,\n",
              " Timestamp('2015-07-19 00:00:00', freq='W-SUN'): -0.022326674500587545,\n",
              " Timestamp('2015-07-26 00:00:00', freq='W-SUN'): 0.017203044194423114,\n",
              " Timestamp('2015-08-02 00:00:00', freq='W-SUN'): -0.011926303889175458,\n",
              " Timestamp('2015-08-09 00:00:00', freq='W-SUN'): 0.0006689554695572646,\n",
              " Timestamp('2015-08-16 00:00:00', freq='W-SUN'): -0.052129771621348193,\n",
              " Timestamp('2015-08-23 00:00:00', freq='W-SUN'): 0.0628833201001835,\n",
              " Timestamp('2015-08-30 00:00:00', freq='W-SUN'): -0.027863333360944244,\n",
              " Timestamp('2015-09-06 00:00:00', freq='W-SUN'): 0.0040828977841901,\n",
              " Timestamp('2015-09-13 00:00:00', freq='W-SUN'): -0.007616146346018985,\n",
              " Timestamp('2015-09-20 00:00:00', freq='W-SUN'): -0.018275279797645212,\n",
              " Timestamp('2015-09-27 00:00:00', freq='W-SUN'): 0.016790077259307923,\n",
              " Timestamp('2015-10-04 00:00:00', freq='W-SUN'): 0.024788734737243582,\n",
              " Timestamp('2015-10-11 00:00:00', freq='W-SUN'): 0.009184817884865672,\n",
              " Timestamp('2015-10-18 00:00:00', freq='W-SUN'): 0.024740716049382733,\n",
              " Timestamp('2015-10-25 00:00:00', freq='W-SUN'): 0.0030390255228312383,\n",
              " Timestamp('2015-11-01 00:00:00', freq='W-SUN'): 0.00825646093608285,\n",
              " Timestamp('2015-11-08 00:00:00', freq='W-SUN'): -0.03234439379240736,\n",
              " Timestamp('2015-11-15 00:00:00', freq='W-SUN'): 0.0345491832649057,\n",
              " Timestamp('2015-11-22 00:00:00', freq='W-SUN'): 0.0008596475102768101,\n",
              " Timestamp('2015-11-29 00:00:00', freq='W-SUN'): -0.0006198092967819368,\n",
              " Timestamp('2015-12-06 00:00:00', freq='W-SUN'): -0.035128763277326586,\n",
              " Timestamp('2015-12-13 00:00:00', freq='W-SUN'): -0.01014501375258528,\n",
              " Timestamp('2015-12-20 00:00:00', freq='W-SUN'): 0.021200481183645724,\n",
              " Timestamp('2015-12-27 00:00:00', freq='W-SUN'): -0.004832597848127621,\n",
              " Timestamp('2016-01-03 00:00:00', freq='W-SUN'): -0.0427453079269463,\n",
              " Timestamp('2016-01-10 00:00:00', freq='W-SUN'): -0.026941594397740885,\n",
              " Timestamp('2016-01-17 00:00:00', freq='W-SUN'): 0.0029479731488955456,\n",
              " Timestamp('2016-01-24 00:00:00', freq='W-SUN'): 0.020008440606660096,\n",
              " Timestamp('2016-01-31 00:00:00', freq='W-SUN'): -0.02378851100497854,\n",
              " Timestamp('2016-02-07 00:00:00', freq='W-SUN'): 0.00462938569996484,\n",
              " Timestamp('2016-02-14 00:00:00', freq='W-SUN'): 0.017110748167383626,\n",
              " Timestamp('2016-02-21 00:00:00', freq='W-SUN'): 0.006292881990325655,\n",
              " Timestamp('2016-02-28 00:00:00', freq='W-SUN'): 0.027266628941281103,\n",
              " Timestamp('2016-03-06 00:00:00', freq='W-SUN'): 0.017156612163270985,\n",
              " Timestamp('2016-03-13 00:00:00', freq='W-SUN'): 0.010981405599893166,\n",
              " Timestamp('2016-03-20 00:00:00', freq='W-SUN'): -0.004655323993790107,\n",
              " Timestamp('2016-03-27 00:00:00', freq='W-SUN'): 0.016256554116906966,\n",
              " Timestamp('2016-04-03 00:00:00', freq='W-SUN'): -0.011265299895901986,\n",
              " Timestamp('2016-04-10 00:00:00', freq='W-SUN'): 0.012326426309378824,\n",
              " Timestamp('2016-04-17 00:00:00', freq='W-SUN'): 0.005727221126803416,\n",
              " Timestamp('2016-04-24 00:00:00', freq='W-SUN'): -0.009267228686911263,\n",
              " Timestamp('2016-05-01 00:00:00', freq='W-SUN'): -0.005799328298852952,\n",
              " Timestamp('2016-05-08 00:00:00', freq='W-SUN'): -0.003940321897250314,\n",
              " Timestamp('2016-05-15 00:00:00', freq='W-SUN'): 0.002585860567422825,\n",
              " Timestamp('2016-05-22 00:00:00', freq='W-SUN'): 0.023015960853874737,\n",
              " Timestamp('2016-05-29 00:00:00', freq='W-SUN'): -0.0013297824974333617,\n",
              " Timestamp('2016-06-05 00:00:00', freq='W-SUN'): -0.002989985804318698,\n",
              " Timestamp('2016-06-12 00:00:00', freq='W-SUN'): -0.01356513654200838,\n",
              " Timestamp('2016-06-19 00:00:00', freq='W-SUN'): -0.026721587074748098,\n",
              " Timestamp('2016-06-26 00:00:00', freq='W-SUN'): 0.04132150486277096,\n",
              " Timestamp('2016-07-03 00:00:00', freq='W-SUN'): 0.0177075714435162,\n",
              " Timestamp('2016-07-10 00:00:00', freq='W-SUN'): 0.012383319926982387,\n",
              " Timestamp('2016-07-17 00:00:00', freq='W-SUN'): 0.0058804648521532405,\n",
              " Timestamp('2016-07-24 00:00:00', freq='W-SUN'): 0.0005529723502303629,\n",
              " Timestamp('2016-07-31 00:00:00', freq='W-SUN'): 0.004558179432219,\n",
              " Timestamp('2016-08-07 00:00:00', freq='W-SUN'): 0.00027478480608382196,\n",
              " Timestamp('2016-08-14 00:00:00', freq='W-SUN'): -0.0015990040732741708,\n",
              " Timestamp('2016-08-21 00:00:00', freq='W-SUN'): -0.004444250078902429,\n",
              " Timestamp('2016-08-28 00:00:00', freq='W-SUN'): 0.004277009710476346,\n",
              " Timestamp('2016-09-04 00:00:00', freq='W-SUN'): -0.02478279869386552,\n",
              " Timestamp('2016-09-11 00:00:00', freq='W-SUN'): 0.004614134397166224,\n",
              " Timestamp('2016-09-18 00:00:00', freq='W-SUN'): 0.008686311850597421,\n",
              " Timestamp('2016-09-25 00:00:00', freq='W-SUN'): 0.005952929849261856,\n",
              " Timestamp('2016-10-02 00:00:00', freq='W-SUN'): -0.0036141876318259696,\n",
              " Timestamp('2016-10-09 00:00:00', freq='W-SUN'): -0.014063697926282412,\n",
              " Timestamp('2016-10-16 00:00:00', freq='W-SUN'): 0.0041766390572365785,\n",
              " Timestamp('2016-10-23 00:00:00', freq='W-SUN'): -0.011441893023255769,\n",
              " Timestamp('2016-10-30 00:00:00', freq='W-SUN'): -0.02057009413417861,\n",
              " Timestamp('2016-11-06 00:00:00', freq='W-SUN'): 0.03773672925816256,\n",
              " Timestamp('2016-11-13 00:00:00', freq='W-SUN'): 0.006773261792255716,\n",
              " Timestamp('2016-11-20 00:00:00', freq='W-SUN'): 0.010722297857574501,\n",
              " Timestamp('2016-11-27 00:00:00', freq='W-SUN'): -0.0066920373179229576,\n",
              " Timestamp('2016-12-04 00:00:00', freq='W-SUN'): 0.02655790237637628,\n",
              " Timestamp('2016-12-11 00:00:00', freq='W-SUN'): -0.006007071713968255,\n",
              " Timestamp('2016-12-18 00:00:00', freq='W-SUN'): 0.0020422064372918546,\n",
              " Timestamp('2016-12-25 00:00:00', freq='W-SUN'): -0.01101674611066725,\n",
              " Timestamp('2017-01-01 00:00:00', freq='W-SUN'): 0.009642792692408147,\n",
              " Timestamp('2017-01-08 00:00:00', freq='W-SUN'): 0.000616980289683558,\n",
              " Timestamp('2017-01-15 00:00:00', freq='W-SUN'): 0.0019000795537101685,\n",
              " Timestamp('2017-01-22 00:00:00', freq='W-SUN'): 0.009835035506857291,\n",
              " Timestamp('2017-01-29 00:00:00', freq='W-SUN'): 0.0051277469003616375,\n",
              " Timestamp('2017-02-05 00:00:00', freq='W-SUN'): 0.0115349327464267,\n",
              " Timestamp('2017-02-12 00:00:00', freq='W-SUN'): 0.012969639667617747,\n",
              " Timestamp('2017-02-19 00:00:00', freq='W-SUN'): 0.005180031331860865,\n",
              " Timestamp('2017-02-26 00:00:00', freq='W-SUN'): 0.007521970112922472,\n",
              " Timestamp('2017-03-05 00:00:00', freq='W-SUN'): 0.0008000084210526007,\n",
              " Timestamp('2017-03-12 00:00:00', freq='W-SUN'): -0.0024829391987824306,\n",
              " Timestamp('2017-03-19 00:00:00', freq='W-SUN'): -0.013373826154384755,\n",
              " Timestamp('2017-03-26 00:00:00', freq='W-SUN'): 0.016427422562807565,\n",
              " Timestamp('2017-04-02 00:00:00', freq='W-SUN'): -0.0025445546750056977,\n",
              " Timestamp('2017-04-09 00:00:00', freq='W-SUN'): -0.012109134890766794,\n",
              " Timestamp('2017-04-16 00:00:00', freq='W-SUN'): 0.006348912503329286,\n",
              " Timestamp('2017-04-23 00:00:00', freq='W-SUN'): 0.0037946244479398874,\n",
              " Timestamp('2017-04-30 00:00:00', freq='W-SUN'): 0.004273521157678265,\n",
              " Timestamp('2017-05-07 00:00:00', freq='W-SUN'): -0.00321169551616267,\n",
              " Timestamp('2017-05-14 00:00:00', freq='W-SUN'): -0.004844043074940268,\n",
              " Timestamp('2017-05-21 00:00:00', freq='W-SUN'): 0.011762298328061064,\n",
              " Timestamp('2017-05-28 00:00:00', freq='W-SUN'): 0.01172620389038201,\n",
              " Timestamp('2017-06-04 00:00:00', freq='W-SUN'): -0.0022953518781188586,\n",
              " Timestamp('2017-06-11 00:00:00', freq='W-SUN'): -0.002015407353773642,\n",
              " Timestamp('2017-06-18 00:00:00', freq='W-SUN'): -0.001888382148501707,\n",
              " Timestamp('2017-06-25 00:00:00', freq='W-SUN'): -0.008610049412301292,\n",
              " Timestamp('2017-07-02 00:00:00', freq='W-SUN'): -0.0031703062588458036,\n",
              " Timestamp('2017-07-09 00:00:00', freq='W-SUN'): 0.014249708751188663,\n",
              " Timestamp('2017-07-16 00:00:00', freq='W-SUN'): 0.00574409905184306,\n",
              " Timestamp('2017-07-23 00:00:00', freq='W-SUN'): 0.0004862879509055976,\n",
              " Timestamp('2017-07-30 00:00:00', freq='W-SUN'): 0.00016173748154054717,\n",
              " Timestamp('2017-08-06 00:00:00', freq='W-SUN'): -0.013616751916910776,\n",
              " Timestamp('2017-08-13 00:00:00', freq='W-SUN'): -0.011726817243809976,\n",
              " Timestamp('2017-08-20 00:00:00', freq='W-SUN'): 0.00791295337913358,\n",
              " Timestamp('2017-08-27 00:00:00', freq='W-SUN'): 0.010890394509037851,\n",
              " Timestamp('2017-09-03 00:00:00', freq='W-SUN'): -0.0027501132967344597,\n",
              " Timestamp('2017-09-10 00:00:00', freq='W-SUN'): 0.0046363853912864085,\n",
              " Timestamp('2017-09-17 00:00:00', freq='W-SUN'): -0.0006810584484554305,\n",
              " Timestamp('2017-09-24 00:00:00', freq='W-SUN'): 0.00834839273566271,\n",
              " Timestamp('2017-10-01 00:00:00', freq='W-SUN'): 0.011451707593707321,\n",
              " Timestamp('2017-10-08 00:00:00', freq='W-SUN'): 0.0012566940019499468,\n",
              " Timestamp('2017-10-15 00:00:00', freq='W-SUN'): 0.007444762932042882,\n",
              " Timestamp('2017-10-22 00:00:00', freq='W-SUN'): 0.0008931955498479913,\n",
              " Timestamp('2017-10-29 00:00:00', freq='W-SUN'): 0.0077202440530266545,\n",
              " Timestamp('2017-11-05 00:00:00', freq='W-SUN'): -0.0008129771961119865,\n",
              " Timestamp('2017-11-12 00:00:00', freq='W-SUN'): 0.0021374490081026206,\n",
              " Timestamp('2017-11-19 00:00:00', freq='W-SUN'): 0.008599867788804418,\n",
              " Timestamp('2017-11-26 00:00:00', freq='W-SUN'): 0.015552347981224205,\n",
              " Timestamp('2017-12-03 00:00:00', freq='W-SUN'): -0.0030039728361981543,\n",
              " Timestamp('2017-12-10 00:00:00', freq='W-SUN'): 0.0007510495343851685,\n",
              " Timestamp('2017-12-17 00:00:00', freq='W-SUN'): -0.0022006564222157646,\n",
              " Timestamp('2017-12-24 00:00:00', freq='W-SUN'): -0.0007114885172733659,\n",
              " Timestamp('2017-12-31 00:00:00', freq='W-SUN'): 0.020833397115194097,\n",
              " Timestamp('2018-01-07 00:00:00', freq='W-SUN'): 0.016867348555613306,\n",
              " Timestamp('2018-01-14 00:00:00', freq='W-SUN'): 0.003794515758843432,\n",
              " Timestamp('2018-01-21 00:00:00', freq='W-SUN'): 0.022878872479475648,\n",
              " Timestamp('2018-01-28 00:00:00', freq='W-SUN'): -0.036652261940215584,\n",
              " Timestamp('2018-02-04 00:00:00', freq='W-SUN'): -0.04370090135523569,\n",
              " Timestamp('2018-02-11 00:00:00', freq='W-SUN'): 0.035174159334662655,\n",
              " Timestamp('2018-02-18 00:00:00', freq='W-SUN'): 0.009851825202558,\n",
              " Timestamp('2018-02-25 00:00:00', freq='W-SUN'): -0.02482515918448926,\n",
              " Timestamp('2018-03-04 00:00:00', freq='W-SUN'): 0.041609022307178056,\n",
              " Timestamp('2018-03-11 00:00:00', freq='W-SUN'): -0.017908308685889312,\n",
              " Timestamp('2018-03-18 00:00:00', freq='W-SUN'): -0.055972261438326155,\n",
              " Timestamp('2018-03-25 00:00:00', freq='W-SUN'): 0.00389115698525245,\n",
              " Timestamp('2018-04-01 00:00:00', freq='W-SUN'): -0.010778850235559563,\n",
              " Timestamp('2018-04-08 00:00:00', freq='W-SUN'): 0.014462253021812909,\n",
              " Timestamp('2018-04-15 00:00:00', freq='W-SUN'): -0.0014607303370786715,\n",
              " Timestamp('2018-04-22 00:00:00', freq='W-SUN'): -0.0026192171436348263,\n",
              " Timestamp('2018-04-29 00:00:00', freq='W-SUN'): -0.004639755120865305,\n",
              " Timestamp('2018-05-06 00:00:00', freq='W-SUN'): 0.022331262561471256,\n",
              " Timestamp('2018-05-13 00:00:00', freq='W-SUN'): -0.007353512217070378,\n",
              " Timestamp('2018-05-20 00:00:00', freq='W-SUN'): -0.003150126253612569,\n",
              " Timestamp('2018-05-27 00:00:00', freq='W-SUN'): 0.012171240517711077,\n",
              " Timestamp('2018-06-03 00:00:00', freq='W-SUN'): 0.013331887274002495,\n",
              " Timestamp('2018-06-10 00:00:00', freq='W-SUN'): -0.00470477298732389,\n",
              " Timestamp('2018-06-17 00:00:00', freq='W-SUN'): -0.002722421965313513,\n",
              " Timestamp('2018-06-24 00:00:00', freq='W-SUN'): -0.00789936726229258,\n",
              " Timestamp('2018-07-01 00:00:00', freq='W-SUN'): 0.02192869570966941,\n",
              " Timestamp('2018-07-08 00:00:00', freq='W-SUN'): 0.01099261664043175,\n",
              " Timestamp('2018-07-15 00:00:00', freq='W-SUN'): 0.00014296237253462872,\n",
              " Timestamp('2018-07-22 00:00:00', freq='W-SUN'): 0.007049564914672352,\n",
              " Timestamp('2018-07-29 00:00:00', freq='W-SUN'): 0.007424233333656536,\n",
              " Timestamp('2018-08-05 00:00:00', freq='W-SUN'): -0.0016923246883906362,\n",
              " Timestamp('2018-08-12 00:00:00', freq='W-SUN'): 0.005609048556781789,\n",
              " Timestamp('2018-08-19 00:00:00', freq='W-SUN'): 0.0067934410212766045,\n",
              " Timestamp('2018-08-26 00:00:00', freq='W-SUN'): 0.0050197780076739005,\n",
              " Timestamp('2018-09-02 00:00:00', freq='W-SUN'): -0.007728367481760446,\n",
              " Timestamp('2018-09-09 00:00:00', freq='W-SUN'): 0.007411564293536221,\n",
              " Timestamp('2018-09-16 00:00:00', freq='W-SUN'): 0.004023048524305971,\n",
              " Timestamp('2018-09-23 00:00:00', freq='W-SUN'): -0.0021280806223391326,\n",
              " Timestamp('2018-09-30 00:00:00', freq='W-SUN'): -0.014686173771156844,\n",
              " Timestamp('2018-10-07 00:00:00', freq='W-SUN'): -0.03866913939742081,\n",
              " Timestamp('2018-10-14 00:00:00', freq='W-SUN'): 0.0025404174577573027,\n",
              " Timestamp('2018-10-21 00:00:00', freq='W-SUN'): -0.042130010830324846,\n",
              " Timestamp('2018-10-28 00:00:00', freq='W-SUN'): 0.011495636673912428,\n",
              " Timestamp('2018-11-04 00:00:00', freq='W-SUN'): 9.978034745292197e-05,\n",
              " Timestamp('2018-11-11 00:00:00', freq='W-SUN'): -0.012482380226686539,\n",
              " Timestamp('2018-11-18 00:00:00', freq='W-SUN'): -0.03589082010873403,\n",
              " Timestamp('2018-11-25 00:00:00', freq='W-SUN'): 0.005830585911046792,\n",
              " Timestamp('2018-12-02 00:00:00', freq='W-SUN'): -0.05961892414592167,\n",
              " Timestamp('2018-12-09 00:00:00', freq='W-SUN'): -0.01101110246062765,\n",
              " Timestamp('2018-12-16 00:00:00', freq='W-SUN'): -0.07208942726498288,\n",
              " Timestamp('2018-12-23 00:00:00', freq='W-SUN'): 0.03643744668282345,\n",
              " Timestamp('2018-12-30 00:00:00', freq='W-SUN'): 0.011339962424586899,\n",
              " Timestamp('2019-01-06 00:00:00', freq='W-SUN'): 0.024892195774330626,\n",
              " Timestamp('2019-01-13 00:00:00', freq='W-SUN'): 0.037374470764685315,\n",
              " Timestamp('2019-01-20 00:00:00', freq='W-SUN'): 0.003625073539100087,\n",
              " Timestamp('2019-01-27 00:00:00', freq='W-SUN'): 0.025323598542640283,\n",
              " Timestamp('2019-02-03 00:00:00', freq='W-SUN'): 0.0013328496538179812,\n",
              " Timestamp('2019-02-10 00:00:00', freq='W-SUN'): 0.022750673772094086,\n",
              " Timestamp('2019-02-17 00:00:00', freq='W-SUN'): 0.009620963158888239,\n",
              " Timestamp('2019-02-24 00:00:00', freq='W-SUN'): -0.0011042567158949291,\n",
              " Timestamp('2019-03-03 00:00:00', freq='W-SUN'): -0.02535516636317119,\n",
              " Timestamp('2019-03-10 00:00:00', freq='W-SUN'): 0.021979175253245047,\n",
              " Timestamp('2019-03-17 00:00:00', freq='W-SUN'): -0.008169021836363867,\n",
              " Timestamp('2019-03-24 00:00:00', freq='W-SUN'): 0.012945157473825655,\n",
              " Timestamp('2019-03-31 00:00:00', freq='W-SUN'): 0.013593237923713048,\n",
              " Timestamp('2019-04-07 00:00:00', freq='W-SUN'): 0.007150287945499062,\n",
              " Timestamp('2019-04-14 00:00:00', freq='W-SUN'): -0.0007579968563255806,\n",
              " Timestamp('2019-04-21 00:00:00', freq='W-SUN'): 0.014662623402793954,\n",
              " Timestamp('2019-04-28 00:00:00', freq='W-SUN'): 0.0017716227122882545,\n",
              " Timestamp('2019-05-05 00:00:00', freq='W-SUN'): -0.003975778738115791,\n",
              " Timestamp('2019-05-12 00:00:00', freq='W-SUN'): 0.012109563212859147,\n",
              " Timestamp('2019-05-19 00:00:00', freq='W-SUN'): -0.004506086773963971,\n",
              " Timestamp('2019-05-26 00:00:00', freq='W-SUN'): -0.027623749021494833,\n",
              " Timestamp('2019-06-02 00:00:00', freq='W-SUN'): 0.04482218622514386,\n",
              " Timestamp('2019-06-09 00:00:00', freq='W-SUN'): -0.0003800843276788067,\n",
              " Timestamp('2019-06-16 00:00:00', freq='W-SUN'): 0.015473926396149421,\n",
              " Timestamp('2019-06-23 00:00:00', freq='W-SUN'): -0.0041804403154509975,\n",
              " Timestamp('2019-06-30 00:00:00', freq='W-SUN'): 0.005999723749487811,\n",
              " Timestamp('2019-07-07 00:00:00', freq='W-SUN'): 0.012255425330614175,\n",
              " Timestamp('2019-07-14 00:00:00', freq='W-SUN'): -0.01315043979094677,\n",
              " Timestamp('2019-07-21 00:00:00', freq='W-SUN'): 0.014784534194980145,\n",
              " Timestamp('2019-07-28 00:00:00', freq='W-SUN'): -0.030674472792591764,\n",
              " Timestamp('2019-08-04 00:00:00', freq='W-SUN'): 0.012253112044890418,\n",
              " Timestamp('2019-08-11 00:00:00', freq='W-SUN'): -0.0038280626101964343,\n",
              " Timestamp('2019-08-18 00:00:00', freq='W-SUN'): -0.02512062681734054,\n",
              " Timestamp('2019-08-25 00:00:00', freq='W-SUN'): 0.018031897512273742,\n",
              " Timestamp('2019-09-01 00:00:00', freq='W-SUN'): 0.025742440099813916,\n",
              " Timestamp('2019-09-08 00:00:00', freq='W-SUN'): 0.006518623060174613,\n",
              " Timestamp('2019-09-15 00:00:00', freq='W-SUN'): -0.005202764877304794,\n",
              " Timestamp('2019-09-22 00:00:00', freq='W-SUN'): -0.00722565648364265,\n",
              " Timestamp('2019-09-29 00:00:00', freq='W-SUN'): -0.005473510810306809,\n",
              " Timestamp('2019-10-06 00:00:00', freq='W-SUN'): 0.009575077488073305,\n",
              " Timestamp('2019-10-13 00:00:00', freq='W-SUN'): 0.006893549313198545,\n",
              " Timestamp('2019-10-20 00:00:00', freq='W-SUN'): 0.007280719074713368,\n",
              " Timestamp('2019-10-27 00:00:00', freq='W-SUN'): 0.01056319066109999,\n",
              " Timestamp('2019-11-03 00:00:00', freq='W-SUN'): 0.0035406723363844437,\n",
              " Timestamp('2019-11-10 00:00:00', freq='W-SUN'): 0.014215066733472602,\n",
              " Timestamp('2019-11-17 00:00:00', freq='W-SUN'): -0.0018297050102066511,\n",
              " Timestamp('2019-11-24 00:00:00', freq='W-SUN'): 0.007468385530635862,\n",
              " Timestamp('2019-12-01 00:00:00', freq='W-SUN'): 0.0008900441958110839,\n",
              " Timestamp('2019-12-08 00:00:00', freq='W-SUN'): 0.009159155901544558,\n",
              " Timestamp('2019-12-15 00:00:00', freq='W-SUN'): 0.004730311369180046,\n",
              " Timestamp('2019-12-22 00:00:00', freq='W-SUN'): 0.003949093615461874,\n",
              " Timestamp('2019-12-29 00:00:00', freq='W-SUN'): -0.001672110171650962,\n",
              " Timestamp('2020-01-05 00:00:00', freq='W-SUN'): 0.016287563302679203,\n",
              " Timestamp('2020-01-12 00:00:00', freq='W-SUN'): 0.017034825651759015,\n",
              " Timestamp('2020-01-19 00:00:00', freq='W-SUN'): -0.006437005254221863,\n",
              " Timestamp('2020-01-26 00:00:00', freq='W-SUN'): -0.004024356883336971,\n",
              " Timestamp('2020-02-02 00:00:00', freq='W-SUN'): 0.027369741258022454,\n",
              " Timestamp('2020-02-09 00:00:00', freq='W-SUN'): 0.019231334083432486,\n",
              " Timestamp('2020-02-16 00:00:00', freq='W-SUN'): -0.009004186829390401,\n",
              " Timestamp('2020-02-23 00:00:00', freq='W-SUN'): -0.08318377097308727,\n",
              " Timestamp('2020-03-01 00:00:00', freq='W-SUN'): -0.002515006279585046,\n",
              " Timestamp('2020-03-08 00:00:00', freq='W-SUN'): -0.02172169001329564,\n",
              " Timestamp('2020-03-15 00:00:00', freq='W-SUN'): -0.00741481302520048,\n",
              " Timestamp('2020-03-22 00:00:00', freq='W-SUN'): 0.11056573810801755,\n",
              " Timestamp('2020-03-29 00:00:00', freq='W-SUN'): -0.0293703366762261,\n",
              " Timestamp('2020-04-05 00:00:00', freq='W-SUN'): -0.004690199989222475,\n",
              " Timestamp('2020-04-12 00:00:00', freq='W-SUN'): 0.034278702048854255,\n",
              " Timestamp('2020-04-19 00:00:00', freq='W-SUN'): 0.0012738969573209882,\n",
              " Timestamp('2020-04-26 00:00:00', freq='W-SUN'): -0.008171948796505903,\n",
              " Timestamp('2020-05-03 00:00:00', freq='W-SUN'): 0.04167561593202314,\n",
              " Timestamp('2020-05-10 00:00:00', freq='W-SUN'): -0.013983595288056731,\n",
              " Timestamp('2020-05-17 00:00:00', freq='W-SUN'): 0.008155652952969949,\n",
              " Timestamp('2020-05-24 00:00:00', freq='W-SUN'): 0.007915788611302193,\n",
              " Timestamp('2020-05-31 00:00:00', freq='W-SUN'): 0.05177524951872806,\n",
              " Timestamp('2020-06-07 00:00:00', freq='W-SUN'): -0.04999690821935892,\n",
              " Timestamp('2020-06-14 00:00:00', freq='W-SUN'): 0.03563528082675017,\n",
              " Timestamp('2020-06-21 00:00:00', freq='W-SUN'): -0.025780065124843807,\n",
              " Timestamp('2020-06-28 00:00:00', freq='W-SUN'): 0.03589796906674662,\n",
              " Timestamp('2020-07-05 00:00:00', freq='W-SUN'): 0.0038562474927496455,\n",
              " Timestamp('2020-07-12 00:00:00', freq='W-SUN'): 0.00496671969252005,\n",
              " Timestamp('2020-07-19 00:00:00', freq='W-SUN'): -0.0017110662103024146,\n",
              " Timestamp('2020-07-26 00:00:00', freq='W-SUN'): 0.015203755632189935,\n",
              " Timestamp('2020-08-02 00:00:00', freq='W-SUN'): 0.019036305637018337,\n",
              " Timestamp('2020-08-09 00:00:00', freq='W-SUN'): 0.005312475409254846,\n",
              " Timestamp('2020-08-16 00:00:00', freq='W-SUN'): 0.004557048561537257,\n",
              " Timestamp('2020-08-23 00:00:00', freq='W-SUN'): 0.024728142533732934,\n",
              " Timestamp('2020-08-30 00:00:00', freq='W-SUN'): -0.022206361828919254,\n",
              " Timestamp('2020-09-06 00:00:00', freq='W-SUN'): -0.007870253544095146,\n",
              " Timestamp('2020-09-13 00:00:00', freq='W-SUN'): -0.020267255926612774,\n",
              " Timestamp('2020-09-20 00:00:00', freq='W-SUN'): 0.009303036193931658,\n",
              " Timestamp('2020-09-27 00:00:00', freq='W-SUN'): -0.002867903942413085,\n",
              " Timestamp('2020-10-04 00:00:00', freq='W-SUN'): 0.032107385776988545,\n",
              " Timestamp('2020-10-11 00:00:00', freq='W-SUN'): -0.006579098447656916,\n",
              " Timestamp('2020-10-18 00:00:00', freq='W-SUN'): -0.008231736840356914,\n",
              " Timestamp('2020-10-25 00:00:00', freq='W-SUN'): -0.04556746199445438,\n",
              " Timestamp('2020-11-01 00:00:00', freq='W-SUN'): 0.06044818677959345,\n",
              " Timestamp('2020-11-08 00:00:00', freq='W-SUN'): -0.01612768905094466,\n",
              " Timestamp('2020-11-15 00:00:00', freq='W-SUN'): -0.015651902675574945,\n",
              " Timestamp('2020-11-22 00:00:00', freq='W-SUN'): 0.0178851713442823,\n",
              " Timestamp('2020-11-29 00:00:00', freq='W-SUN'): 0.019347957036417694,\n",
              " Timestamp('2020-12-06 00:00:00', freq='W-SUN'): -0.007370877136956461,\n",
              " Timestamp('2020-12-13 00:00:00', freq='W-SUN'): 0.0014647840115783934,\n",
              " Timestamp('2020-12-20 00:00:00', freq='W-SUN'): 0.011042000682132708,\n",
              " Timestamp('2020-12-27 00:00:00', freq='W-SUN'): 0.0057567521858490536,\n",
              " Timestamp('2021-01-03 00:00:00', freq='W-SUN'): 0.015853593114244762,\n",
              " Timestamp('2021-01-10 00:00:00', freq='W-SUN'): -0.005690072689849295,\n",
              " Timestamp('2021-01-17 00:00:00', freq='W-SUN'): 0.011999812464976603,\n",
              " Timestamp('2021-01-24 00:00:00', freq='W-SUN'): -0.03544714348056179,\n",
              " Timestamp('2021-01-31 00:00:00', freq='W-SUN'): 0.03743441604025891,\n",
              " Timestamp('2021-02-07 00:00:00', freq='W-SUN'): 0.008657297236443253,\n",
              " Timestamp('2021-02-14 00:00:00', freq='W-SUN'): -0.00997561196512472,\n",
              " Timestamp('2021-02-21 00:00:00', freq='W-SUN'): -0.017310011457190192,\n",
              " Timestamp('2021-02-28 00:00:00', freq='W-SUN'): -0.005083096087378788,\n",
              " Timestamp('2021-03-07 00:00:00', freq='W-SUN'): 0.02443714943651899,\n",
              " Timestamp('2021-03-14 00:00:00', freq='W-SUN'): -0.012299282732459366,\n",
              " Timestamp('2021-03-21 00:00:00', freq='W-SUN'): 0.015255267582635394,\n",
              " Timestamp('2021-03-28 00:00:00', freq='W-SUN'): 0.01574541352553875,\n",
              " Timestamp('2021-04-04 00:00:00', freq='W-SUN'): 0.019902838395691073,\n",
              " Timestamp('2021-04-11 00:00:00', freq='W-SUN'): 0.01560181065203639,\n",
              " Timestamp('2021-04-18 00:00:00', freq='W-SUN'): 0.0011530773758448595,\n",
              " Timestamp('2021-04-25 00:00:00', freq='W-SUN'): -0.0003354110754340401,\n",
              " Timestamp('2021-05-02 00:00:00', freq='W-SUN'): 0.006413470769602288,\n",
              " Timestamp('2021-05-09 00:00:00', freq='W-SUN'): -0.014011865088757356,\n",
              " Timestamp('2021-05-16 00:00:00', freq='W-SUN'): -0.0010833505470756505,\n",
              " Timestamp('2021-05-23 00:00:00', freq='W-SUN'): 0.006469576426602575,\n",
              " Timestamp('2021-05-30 00:00:00', freq='W-SUN'): 7.099178716683525e-05,\n",
              " Timestamp('2021-06-06 00:00:00', freq='W-SUN'): 0.004070143676567352,\n",
              " Timestamp('2021-06-13 00:00:00', freq='W-SUN'): -0.022406474935431908,\n",
              " Timestamp('2021-06-20 00:00:00', freq='W-SUN'): 0.0235364618100709,\n",
              " Timestamp('2021-06-27 00:00:00', freq='W-SUN'): 0.015333445234134546,\n",
              " Timestamp('2021-07-04 00:00:00', freq='W-SUN'): 0.004011226898453736,\n",
              " Timestamp('2021-07-11 00:00:00', freq='W-SUN'): -0.00939300706370964,\n",
              " Timestamp('2021-07-18 00:00:00', freq='W-SUN'): 0.03226260572860647,\n",
              " Timestamp('2021-07-25 00:00:00', freq='W-SUN'): -0.001821010228863457,\n",
              " Timestamp('2021-08-01 00:00:00', freq='W-SUN'): 0.004882577143866787,\n",
              " Timestamp('2021-08-08 00:00:00', freq='W-SUN'): 0.00781996580567661,\n",
              " Timestamp('2021-08-15 00:00:00', freq='W-SUN'): -0.0026320248411400926,\n",
              " Timestamp('2021-08-22 00:00:00', freq='W-SUN'): 0.011434082025032925,\n",
              " Timestamp('2021-08-29 00:00:00', freq='W-SUN'): 0.0046787724135113635,\n",
              " Timestamp('2021-09-05 00:00:00', freq='W-SUN'): -0.016058821639745983,\n",
              " Timestamp('2021-09-12 00:00:00', freq='W-SUN'): -0.016137706753598456,\n",
              " Timestamp('2021-09-19 00:00:00', freq='W-SUN'): 0.020764346247650618,\n",
              " Timestamp('2021-09-26 00:00:00', freq='W-SUN'): -0.01935369128679888,\n",
              " Timestamp('2021-10-03 00:00:00', freq='W-SUN'): 0.011223983833718233,\n",
              " Timestamp('2021-10-10 00:00:00', freq='W-SUN'): 0.019924034496074352,\n",
              " Timestamp('2021-10-17 00:00:00', freq='W-SUN'): 0.0206094870810877,\n",
              " Timestamp('2021-10-24 00:00:00', freq='W-SUN'): 0.010940391412653907,\n",
              " Timestamp('2021-10-31 00:00:00', freq='W-SUN'): 0.017879668074203797,\n",
              " Timestamp('2021-11-07 00:00:00', freq='W-SUN'): -0.005173563844831253,\n",
              " Timestamp('2021-11-14 00:00:00', freq='W-SUN'): 0.0005334585011909407,\n",
              " Timestamp('2021-11-21 00:00:00', freq='W-SUN'): -0.02531379647113558,\n",
              " Timestamp('2021-11-28 00:00:00', freq='W-SUN'): -0.022949110779313935,\n",
              " Timestamp('2021-12-05 00:00:00', freq='W-SUN'): 0.03203030899052562,\n",
              " Timestamp('2021-12-12 00:00:00', freq='W-SUN'): -0.021948588774969264,\n",
              " Timestamp('2021-12-19 00:00:00', freq='W-SUN'): 0.03546909569142749,\n",
              " Timestamp('2021-12-26 00:00:00', freq='W-SUN'): 0.0061432720677171105,\n",
              " Timestamp('2022-01-02 00:00:00', freq='W-SUN'): -0.02143605344789553,\n",
              " Timestamp('2022-01-09 00:00:00', freq='W-SUN'): 0.004365655819347611,\n",
              " Timestamp('2022-01-16 00:00:00', freq='W-SUN'): -0.04733105553858821,\n",
              " Timestamp('2022-01-23 00:00:00', freq='W-SUN'): 0.02296139856713987,\n",
              " Timestamp('2022-01-30 00:00:00', freq='W-SUN'): 0.016906948982570773,\n",
              " Timestamp('2022-02-06 00:00:00', freq='W-SUN'): -0.020133075568217088,\n",
              " Timestamp('2022-02-13 00:00:00', freq='W-SUN'): -0.012934174013129048,\n",
              " Timestamp('2022-02-20 00:00:00', freq='W-SUN'): 0.01356823449599777,\n",
              " Timestamp('2022-02-27 00:00:00', freq='W-SUN'): 0.0003240839763999996,\n",
              " Timestamp('2022-03-06 00:00:00', freq='W-SUN'): -0.026601740978382346,\n",
              " Timestamp('2022-03-13 00:00:00', freq='W-SUN'): -0.0054709401927773675,\n",
              " Timestamp('2022-03-20 00:00:00', freq='W-SUN'): 0.018791929772623953,\n",
              " Timestamp('2022-03-27 00:00:00', freq='W-SUN'): 0.0019024355258258788,\n",
              " Timestamp('2022-04-03 00:00:00', freq='W-SUN'): -0.01227020488303353,\n",
              " Timestamp('2022-04-10 00:00:00', freq='W-SUN'): -0.014230655048208378,\n",
              " Timestamp('2022-04-17 00:00:00', freq='W-SUN'): -0.007630648195022234,\n",
              " Timestamp('2022-04-24 00:00:00', freq='W-SUN'): -0.007146354211114901,\n",
              " Timestamp('2022-05-01 00:00:00', freq='W-SUN'): -0.010376955254489386,\n",
              " Timestamp('2022-05-08 00:00:00', freq='W-SUN'): -0.008343631078593424,\n",
              " Timestamp('2022-05-15 00:00:00', freq='W-SUN'): -0.025876308103806738,\n",
              " Timestamp('2022-05-22 00:00:00', freq='W-SUN'): 0.05709855088023106,\n",
              " Timestamp('2022-05-29 00:00:00', freq='W-SUN'): -0.007278392183147608,\n",
              " Timestamp('2022-06-05 00:00:00', freq='W-SUN'): -0.06022472409524258,\n",
              " Timestamp('2022-06-12 00:00:00', freq='W-SUN'): -0.03683038246417722,\n",
              " Timestamp('2022-06-19 00:00:00', freq='W-SUN'): 0.04891223551672935,\n",
              " Timestamp('2022-06-26 00:00:00', freq='W-SUN'): -0.025086301754342486,\n",
              " Timestamp('2022-07-03 00:00:00', freq='W-SUN'): 0.034026837900036744,\n",
              " Timestamp('2022-07-10 00:00:00', freq='W-SUN'): -0.0018660126702188641,\n",
              " Timestamp('2022-07-17 00:00:00', freq='W-SUN'): 0.017276870368236392,\n",
              " Timestamp('2022-07-24 00:00:00', freq='W-SUN'): 0.04103598231206564,\n",
              " Timestamp('2022-07-31 00:00:00', freq='W-SUN'): 0.010558492150436234,\n",
              " Timestamp('2022-08-07 00:00:00', freq='W-SUN'): 0.028537040337146314,\n",
              " Timestamp('2022-08-14 00:00:00', freq='W-SUN'): -0.006191524985537536,\n",
              " Timestamp('2022-08-21 00:00:00', freq='W-SUN'): -0.028150078738282996,\n",
              " Timestamp('2022-08-28 00:00:00', freq='W-SUN'): -0.010435174041441639,\n",
              " Timestamp('2022-09-04 00:00:00', freq='W-SUN'): -0.0022020017134619855,\n",
              " Timestamp('2022-09-11 00:00:00', freq='W-SUN'): -0.0568031729947726,\n",
              " Timestamp('2022-09-18 00:00:00', freq='W-SUN'): -0.03743524728103263,\n",
              " Timestamp('2022-09-25 00:00:00', freq='W-SUN'): -0.025190390271112768,\n",
              " Timestamp('2022-10-02 00:00:00', freq='W-SUN'): 0.004735853720965103,\n",
              " Timestamp('2022-10-09 00:00:00', freq='W-SUN'): -0.008413998560917044,\n",
              " Timestamp('2022-10-16 00:00:00', freq='W-SUN'): 0.028240978867586565,\n",
              " Timestamp('2022-10-23 00:00:00', freq='W-SUN'): 0.018580120088281412,\n",
              " Timestamp('2022-10-30 00:00:00', freq='W-SUN'): -0.02611012304052308,\n",
              " Timestamp('2022-11-06 00:00:00', freq='W-SUN'): 0.05506875511799745,\n",
              " Timestamp('2022-11-13 00:00:00', freq='W-SUN'): -0.0015882745768339165,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross validation"
      ],
      "metadata": {
        "id": "59JkxM_-c9uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "def train_epoch(dataloader):\n",
        "    train_loss,train_correct=0.0,0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "        loss = loss_fn(y_output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return train_loss\n",
        "  \n",
        "def valid_epoch(dataloader):\n",
        "\n",
        "    valid_loss, val_correct = 0.0, 0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "        loss = loss_fn(y_output, y)\n",
        "\n",
        "        valid_loss+=loss.item() * x.size(0)\n",
        "\n",
        "    return valid_loss"
      ],
      "metadata": {
        "id": "kBobZ4qo53Lo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = {'train_loss': [], 'test_loss': []}\n",
        " \n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss=train_epoch(train_loader)\n",
        "        test_loss=valid_epoch(test_loader)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1,n_epochs,train_loss,test_loss))\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DeuyMHGu_Lmy",
        "outputId": "11c663c7-9cc6-41d6-d789-6e05591addaf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c07c40cb1bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3768fb6a26b4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a, b)"
      ],
      "metadata": {
        "id": "Nsd-ud7DWRC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build efficient frontier"
      ],
      "metadata": {
        "id": "9Y7k33C-85KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "  print(y_test)"
      ],
      "metadata": {
        "id": "vazYH62WF8H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build ML Portfolio"
      ],
      "metadata": {
        "id": "nwtZLY8wFvv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prob = pd.DataFrame(y_test).astype(\"float\")\n",
        "display(prob)\n",
        "rolling_prob = prob.rolling(25).mean().iloc[-1]\n",
        "display(rolling_prob.to_numpy()[0])"
      ],
      "metadata": {
        "id": "X1Fa8qX06tzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1\n",
        "\n",
        "for k in np.arange(0, 1, 0.1):\n",
        "  print(calculate_ml_portfolio_weights(rolling_prob.to_numpy()[0], k))"
      ],
      "metadata": {
        "id": "FjPZY76E93xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0.5\n",
        "calculate_ml_portfolio_weights_lambda = lambda x: 0 if x < k else 1\n",
        "calculate_ml_portfolio_weights = np.vectorize(calculate_ml_portfolio_weights_lambda)\n",
        "# vfunc(x)\n",
        "# calculate_ml_portfolio_weights = functorch.vmap(ml_portfolio_weights, out_dims=1)\n",
        "# forecast = \n",
        "# portfolio_weights = calculate_ml_portfolio_weights(y_test.numpy())\n",
        "# print(portfolio_weights)\n",
        "\n",
        "portfolio_weights = y_test.apply_(calculate_ml_portfolio_weights_lambda)\n",
        "print(portfolio_weights)"
      ],
      "metadata": {
        "id": "fvjJR_gI9A8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = torch.from_numpy(to_X_train_features(low_risk, high_risk).T[-1])\n",
        "Xt"
      ],
      "metadata": {
        "id": "w0Gjrcdn1YoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(Xt, a)) / (torch.exp (torch.matmul(Xt, a)) + torch.exp(torch.matmul(Xt, b)))\n",
        "  print(y_test)"
      ],
      "metadata": {
        "id": "dQDb3MWz4rzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0.5\n",
        "calculate_ml_portfolio_weights_lambda = lambda x: 0 if x < k else 1\n",
        "calculate_ml_portfolio_weights = np.vectorize(calculate_ml_portfolio_weights_lambda)\n",
        "\n",
        "portfolio_weights = y_test.apply_(calculate_ml_portfolio_weights_lambda)\n",
        "print(portfolio_weights)"
      ],
      "metadata": {
        "id": "wo9vQZJS5BCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MV Portfolio"
      ],
      "metadata": {
        "id": "Yx3K4DmgFpd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Pct Return\"]  = market_data['Close'].pct_change()\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ],
      "metadata": {
        "id": "-vUNbKE2TUN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk"
      ],
      "metadata": {
        "id": "s8neZvz8jlwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk_return_annual = high_risk[\"Pct Return\"].mean() * trading_days_in_year\n",
        "low_risk_return_annual = low_risk[\"Pct Return\"].mean() * trading_days_in_year\n",
        "print(high_risk_return_annual)\n",
        "print(low_risk_return_annual)"
      ],
      "metadata": {
        "id": "7Pw_6fyZUZLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk_var_daily = high_risk[\"Pct Return\"].var()\n",
        "low_risk_var_daily = low_risk[\"Pct Return\"].var()\n",
        "print(high_risk_var_daily)\n",
        "print(low_risk_var_daily)"
      ],
      "metadata": {
        "id": "bHNvPvKeU552"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build data for high and low risk"
      ],
      "metadata": {
        "id": "z1A4Jk4uWHDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mv_data = pd.DataFrame(data={'high': high_risk['Close'], 'low':low_risk['Close']})\n",
        "mv_data"
      ],
      "metadata": {
        "id": "e5kg5IleWKbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_annual_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change()\n",
        "    annual_return = daily_return.mean() * trading_days_in_year\n",
        "    # daily_covariance = data.cov()\n",
        "    daily_covariance = daily_return.cov()\n",
        "    annual_covariance = daily_covariance * trading_days_in_year\n",
        "    return annual_return, annual_covariance"
      ],
      "metadata": {
        "id": "4kyrIwXLVWiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, cov = get_annual_sample_return_and_covariance(mv_data)\n",
        "display(r)\n",
        "display(cov)"
      ],
      "metadata": {
        "id": "zI1us-ILNW0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change().mean()\n",
        "    daily_covariance = data.pct_change().cov()\n",
        "    return daily_return, daily_covariance"
      ],
      "metadata": {
        "id": "SA4aHkEINXGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, cov = get_sample_return_and_covariance(mv_data)\n",
        "display(r)\n",
        "display(cov)"
      ],
      "metadata": {
        "id": "-7yPFP8lXtiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization using linear programming\n",
        "\n",
        "(Reference: https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios)\n"
      ],
      "metadata": {
        "id": "8BOYoifDBaqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TERMINATION = 10**-9"
      ],
      "metadata": {
        "id": "G_t1dGnAtHYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains maximal return portfolio using linear programming\n",
        "\n",
        "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
        "    \n",
        "    #dependencies\n",
        "    from scipy.optimize import linprog\n",
        "    import numpy as np\n",
        "    \n",
        "    c = (np.multiply(-1, MeanReturns))\n",
        "    A = np.ones([PortfolioSize,1]).T\n",
        "    b=[1] \n",
        "    res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n",
        "    \n",
        "    return res"
      ],
      "metadata": {
        "id": "65SYaxYzFVOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains minimal risk portfolio \n",
        "\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
        "    \n",
        "    def  f(x, CovarReturns):\n",
        "        func = np.matmul(np.matmul(x, CovarReturns), x.T) \n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b \n",
        "        return constraintVal\n",
        "    \n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
        "                             constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return opt"
      ],
      "metadata": {
        "id": "ESkZdqjLb_MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_min_variance_portfolio(mean_returns, cov_returns):\n",
        "    number_of_assets = len(mean_returns)\n",
        "    result = MinimizeRisk(cov_returns, number_of_assets)\n",
        "\n",
        "    print()\n",
        "    minRiskWeights = result.x\n",
        "    minRiskExpPortfolioReturn = np.matmul(mean_returns.T, minRiskWeights)\n",
        "    print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)\n",
        "    minRisk = np.matmul(np.matmul(minRiskWeights, cov_returns), minRiskWeights.T) \n",
        "    print(\"Variance of Minimum Risk Portfolio : %7.6f\" % minRisk)\n",
        "    print(\"S.D. of Minimum Risk Portfolio : %7.6f\" % np.sqrt(minRisk))\n",
        "    threshold = 1e-3\n",
        "    print(\"Weights (showing only those > %.6f): \" % threshold)\n",
        "    for i in range(0, number_of_assets):\n",
        "        if result.x[i] > threshold:\n",
        "            print(f\"{mean_returns.index[i]}\\t{result.x[i]:.6f}\")\n",
        "    print('Assets Considered:')\n",
        "    print(mean_returns.index.to_numpy())"
      ],
      "metadata": {
        "id": "i6r-NvbtYDDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function obtains Minimal risk and Maximum return portfolios\n",
        "\n",
        "#dependencies\n",
        "import numpy as np\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ],
      "metadata": {
        "id": "DNuu3KurcJDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_min_variance_portfolio(r, cov)"
      ],
      "metadata": {
        "id": "bRkZ69QycGDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ],
      "metadata": {
        "id": "MvkOfW5-GXpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ],
      "metadata": {
        "id": "FnMjflTbGaO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.000001\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "#initialize optimal weight set and risk-return point set\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "#repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "while (low < high):\n",
        "    \n",
        "    result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "    \n",
        "#gather optimal weight set    \n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "#obtain annualized risk for the efficient set portfolios \n",
        "#for trading days = 251\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint*trading_days_in_year) \n",
        "\n",
        "#obtain expected portfolio annualized return for the \n",
        "#efficient set portfolios, for trading days = 251\n",
        "retPoint = trading_days_in_year*np.array(expPortfolioReturnPoint) \n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "id": "6Kw9InlwDh3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph Efficient Frontier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2_0opIvqHAG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Portfolio"
      ],
      "metadata": {
        "id": "ZMoyxpN5dY_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "naive_risks = []\n",
        "naive_returns = []\n",
        "\n",
        "for x in np.arange(0, 1, 0.01):\n",
        "  weights = [x, 1-x]\n",
        "  risk = np.matmul((np.matmul(weights,cov)),np.transpose(weights)) * trading_days_in_year\n",
        "  naive_risks.append(np.sqrt(risk))\n",
        "\n",
        "  #obtain expected portfolio annualized return for the \n",
        "  #efficient set portfolios, for trading days = 251\n",
        "  ret = trading_days_in_year*(np.matmul(weights,r))\n",
        "  naive_returns.append(ret)\n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[naive_risks, naive_returns])"
      ],
      "metadata": {
        "id": "yGhdT3AWHGa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(naive_risks)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(naive_risks, naive_returns, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2wJgflp2eJ2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combined Graph"
      ],
      "metadata": {
        "id": "A-x_ZCjwg57n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(riskPoint, retPoint, s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(naive_risks, naive_returns, s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DpqNZRCtgYQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov"
      ],
      "metadata": {
        "id": "3sTlOQOIhTCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(high_risk[\"Close\"].var())\n",
        "print(high_risk[\"Close\"].var() * trading_days_in_year)\n",
        "print(high_risk[\"Close\"].pct_change().var())\n",
        "print(high_risk[\"Close\"].pct_change().var() * trading_days_in_year)\n",
        "print(np.sqrt(high_risk[\"Close\"].pct_change().var() * trading_days_in_year))"
      ],
      "metadata": {
        "id": "-5N-KuYQxAmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CU2640mM0RnU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}