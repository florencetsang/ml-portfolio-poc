{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "e4PiESSn5Wx4"
      },
      "outputs": [],
      "source": [
        "# ÔºÅpip install functorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from os import path\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import date\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "26v-Cnl1lg6t"
      },
      "outputs": [],
      "source": [
        "MA_DAYS = 25\n",
        "trading_days_in_year = 252"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRi8JtX9gAb0"
      },
      "source": [
        "# Import raw data from yahoo finance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puHUCbHEMIoP",
        "outputId": "d857ac06-6060-43ea-85ce-db066953b605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_files_path_prefix = \"/content/drive/MyDrive\"\n",
        "data_files_path = \"ML-Portfolio-Data\"\n",
        "data_files_path = path.join(data_files_path_prefix, data_files_path)\n",
        "\n",
        "high_risk_file = 'SPY.csv'\n",
        "low_risk_file = 'IEF.csv'\n",
        "high_risk = pd.read_csv(path.join(data_files_path, high_risk_file))\n",
        "low_risk = pd.read_csv(path.join(data_files_path, low_risk_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "tmNxB-dXPdjh"
      },
      "outputs": [],
      "source": [
        "# Read files from the same directory\n",
        "#high_risk = pd.read_csv('SPY.csv')\n",
        "#low_risk = pd.read_csv('IEF.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEp0KCBSE3uX",
        "outputId": "98627eab-bd62-46f8-d40e-ddf025ef9370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5147, 7)\n",
            "(5147, 7)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)\n",
        "print(low_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffmGB06pT8_q",
        "outputId": "94d86b1b-4600-4ab6-b9b2-b1e1f18a4144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939  47532200\n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453  44669900\n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054  66571900\n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895  51772900\n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496  47191300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d39f4b8e-c576-43e5-8ae7-770d3cd7d837\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d39f4b8e-c576-43e5-8ae7-770d3cd7d837')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d39f4b8e-c576-43e5-8ae7-770d3cd7d837 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d39f4b8e-c576-43e5-8ae7-770d3cd7d837');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DY4FPgNCEssV",
        "outputId": "f7dc0bcb-c57a-4c81-8c7f-c090210ec2f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300\n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600\n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400\n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300\n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e59a7fce-5df0-469a-809c-eb3fb1aa74df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e59a7fce-5df0-469a-809c-eb3fb1aa74df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e59a7fce-5df0-469a-809c-eb3fb1aa74df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e59a7fce-5df0-469a-809c-eb3fb1aa74df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnPRd0TkrMsN"
      },
      "source": [
        "# Build Dataset for ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "IvSntSIA4qiC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZ0sQ3rTgn4"
      },
      "source": [
        "## Enrich data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NraBWrzef4BA"
      },
      "source": [
        "### Calculate daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "2e03XXEgf1r4"
      },
      "outputs": [],
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Daily Return\"]  = market_data['Close'] - market_data['Open']\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dqBMvFWo4oQ"
      },
      "source": [
        "### Calculate moving average (MA) of daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "p9EW2Fzjo9ly"
      },
      "outputs": [],
      "source": [
        "def add_moving_average(market_data, ma_days):\n",
        "    temp_vars = []\n",
        "\n",
        "    # df = market_data\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data[temp_var] = market_data[\"Daily Return\"].shift(i)\n",
        "        temp_vars.append(temp_var)\n",
        "\n",
        "    market_data[\"MA\"] = market_data[temp_vars].mean(axis=1)\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data.drop(temp_var, axis = 1, inplace = True)\n",
        "\n",
        "add_moving_average(high_risk, MA_DAYS)\n",
        "add_moving_average(low_risk, MA_DAYS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xp5iRKB4FeRZ",
        "outputId": "52a62dd4-fd16-44bc-9b5e-5280c9d8d19c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "5142  2022-12-30  380.640015  382.579987  378.429993  382.429993  382.429993   \n",
              "5143  2023-01-03  384.369995  386.429993  377.829987  380.820007  380.820007   \n",
              "5144  2023-01-04  383.179993  385.880005  380.000000  383.760010  383.760010   \n",
              "5145  2023-01-05  381.720001  381.839996  378.760010  379.380005  379.380005   \n",
              "5146  2023-01-06  382.609985  389.250000  379.410004  388.079987  388.079987   \n",
              "\n",
              "         Volume  Daily Return        MA  \n",
              "5142   83975100      1.789978 -0.368799  \n",
              "5143   74850700     -3.549988 -0.530798  \n",
              "5144   85934100      0.580017 -0.380398  \n",
              "5145   76970500     -2.339996 -0.441199  \n",
              "5146  104041300      5.470002 -0.709999  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91f646c2-a669-47c6-8456-db78bf0c75a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>380.640015</td>\n",
              "      <td>382.579987</td>\n",
              "      <td>378.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>83975100</td>\n",
              "      <td>1.789978</td>\n",
              "      <td>-0.368799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>384.369995</td>\n",
              "      <td>386.429993</td>\n",
              "      <td>377.829987</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>74850700</td>\n",
              "      <td>-3.549988</td>\n",
              "      <td>-0.530798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>383.179993</td>\n",
              "      <td>385.880005</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>85934100</td>\n",
              "      <td>0.580017</td>\n",
              "      <td>-0.380398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>381.720001</td>\n",
              "      <td>381.839996</td>\n",
              "      <td>378.760010</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>76970500</td>\n",
              "      <td>-2.339996</td>\n",
              "      <td>-0.441199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>382.609985</td>\n",
              "      <td>389.250000</td>\n",
              "      <td>379.410004</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>104041300</td>\n",
              "      <td>5.470002</td>\n",
              "      <td>-0.709999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91f646c2-a669-47c6-8456-db78bf0c75a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91f646c2-a669-47c6-8456-db78bf0c75a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91f646c2-a669-47c6-8456-db78bf0c75a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ],
      "source": [
        "high_risk.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtkml8ylGG47",
        "outputId": "6f0515d5-7d2b-4b4a-ed1c-dc476b00708b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date       Open       High        Low      Close  Adj Close  \\\n",
              "5142  2022-12-30  95.860001  96.269997  95.620003  95.779999  95.779999   \n",
              "5143  2023-01-03  96.910004  97.000000  96.339996  96.529999  96.529999   \n",
              "5144  2023-01-04  97.339996  97.419998  96.989998  97.269997  97.269997   \n",
              "5145  2023-01-05  96.699997  97.220001  96.570000  97.129997  97.129997   \n",
              "5146  2023-01-06  97.169998  98.430000  97.080002  98.379997  98.379997   \n",
              "\n",
              "       Volume  Daily Return        MA  \n",
              "5142  5039800     -0.080002  0.050399  \n",
              "5143  6808300     -0.380005  0.025599  \n",
              "5144  7800100     -0.069999  0.025599  \n",
              "5145  3177900      0.430000  0.043600  \n",
              "5146  6807700      1.209999  0.050399  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ab6fecd-43f6-472f-860b-4e91b602b6b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.860001</td>\n",
              "      <td>96.269997</td>\n",
              "      <td>95.620003</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>5039800</td>\n",
              "      <td>-0.080002</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.910004</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>96.339996</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>6808300</td>\n",
              "      <td>-0.380005</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.339996</td>\n",
              "      <td>97.419998</td>\n",
              "      <td>96.989998</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>7800100</td>\n",
              "      <td>-0.069999</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>96.699997</td>\n",
              "      <td>97.220001</td>\n",
              "      <td>96.570000</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>3177900</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.043600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>97.169998</td>\n",
              "      <td>98.430000</td>\n",
              "      <td>97.080002</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>6807700</td>\n",
              "      <td>1.209999</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ab6fecd-43f6-472f-860b-4e91b602b6b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ab6fecd-43f6-472f-860b-4e91b602b6b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ab6fecd-43f6-472f-860b-4e91b602b6b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "source": [
        "low_risk.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6a-Fc3EZNxB"
      },
      "source": [
        "### Calculate ROE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "42UscmnQZMpE"
      },
      "outputs": [],
      "source": [
        "def add_roe(market_data):    \n",
        "    market_data[\"Next Close\"] = market_data[\"Close\"].shift(-1)\n",
        "    market_data[\"ROE\"] = (market_data[\"Next Close\"] - market_data[\"Close\"]) / market_data['Close']\n",
        "\n",
        "add_roe(high_risk)\n",
        "add_roe(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "V5kEAXakgkCs"
      },
      "outputs": [],
      "source": [
        "def add_roe_binary(market_data, tau=-0.005):    \n",
        "    market_data[\"ROE Binary\"] = np.where(market_data[\"ROE\"].values < tau, 0, 1)\n",
        "\n",
        "add_roe_binary(high_risk)\n",
        "add_roe_binary(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKK4t3UVfl_6",
        "outputId": "90838bf4-e179-41b1-c027-a7b2183eae06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  \\\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939   \n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453   \n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054   \n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895   \n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496   \n",
              "\n",
              "     Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0  47532200      1.620002  1.620002   91.160004  0.002419           1  \n",
              "1  44669900      0.670006  1.145004   88.779999 -0.026108           0  \n",
              "2  66571900     -2.099998  0.063337   86.790001 -0.022415           0  \n",
              "3  51772900     -1.709999 -0.379997   83.769997 -0.034797           0  \n",
              "4  47191300     -2.720001 -0.847998   86.589996  0.033664           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25511c87-1e25-48de-8b45-511292697a8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>0.002419</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "      <td>0.670006</td>\n",
              "      <td>1.145004</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "      <td>-2.099998</td>\n",
              "      <td>0.063337</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>-0.022415</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "      <td>-1.709999</td>\n",
              "      <td>-0.379997</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>-0.034797</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "      <td>-2.720001</td>\n",
              "      <td>-0.847998</td>\n",
              "      <td>86.589996</td>\n",
              "      <td>0.033664</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25511c87-1e25-48de-8b45-511292697a8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25511c87-1e25-48de-8b45-511292697a8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25511c87-1e25-48de-8b45-511292697a8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uurD8aCKfmH3",
        "outputId": "a9b498a1-4161-4dff-a8b2-1f7d4f80ba6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume  \\\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300   \n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600   \n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400   \n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300   \n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300   \n",
              "\n",
              "   Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0     -0.170005 -0.170005   82.519997  0.009172           1  \n",
              "1      0.469994  0.149994   82.860001  0.004120           1  \n",
              "2      0.320000  0.206663   83.500000  0.007724           1  \n",
              "3      0.480003  0.274998   83.919998  0.005030           1  \n",
              "4      0.239998  0.267998   83.239998 -0.008103           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b771637e-878a-4375-a1a7-d36326a02f07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "      <td>0.469994</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>0.004120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.206663</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>0.007724</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "      <td>0.480003</td>\n",
              "      <td>0.274998</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "      <td>0.239998</td>\n",
              "      <td>0.267998</td>\n",
              "      <td>83.239998</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b771637e-878a-4375-a1a7-d36326a02f07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b771637e-878a-4375-a1a7-d36326a02f07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b771637e-878a-4375-a1a7-d36326a02f07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L1SeZ_ggNPL"
      },
      "source": [
        "## Build feature space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "TKS0pN_Ola5g"
      },
      "outputs": [],
      "source": [
        "def remove_for_ma(market_data, ma_days):\n",
        "  return market_data[ma_days:]\n",
        "\n",
        "high_risk = remove_for_ma(high_risk, MA_DAYS)\n",
        "low_risk = remove_for_ma(low_risk, MA_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnHuHNjPmrQO",
        "outputId": "58e01bda-159e-4f35-a980-2bc4e86736c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5122, 12)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L7qIEJvdIvp",
        "outputId": "e24a808c-62ad-4ffa-a4f4-01fd2a9296ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-178-d0986728a5f2>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  market_data[column] = market_data[column]/market_data[column].std()\n"
          ]
        }
      ],
      "source": [
        "def standardize_columns(market_data, columns):\n",
        "  for column in columns:\n",
        "    market_data[column] = market_data[column]/market_data[column].std()\n",
        "\n",
        "standardize_columns(high_risk, ['Volume', 'Daily Return', 'MA'])\n",
        "standardize_columns(low_risk, ['Volume', 'Daily Return', 'MA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tqgwASZBIDOa",
        "outputId": "252819d1-fad1-4a94-a842-e465003ff9c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.550024      0.479605  0.276737   88.779999 -0.008488           0  \n",
              "26  0.723874      0.149555  0.229367   90.000000  0.013742           1  \n",
              "27  0.415721      0.128926  0.522307   90.660004  0.007333           1  \n",
              "28  0.365951      0.804501  0.929931   91.699997  0.011471           1  \n",
              "29  0.445799      0.288793  1.338801   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9533b970-3cef-461f-a5ee-5218f030b7c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9533b970-3cef-461f-a5ee-5218f030b7c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9533b970-3cef-461f-a5ee-5218f030b7c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9533b970-3cef-461f-a5ee-5218f030b7c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-55dkiIJIal",
        "outputId": "2ea8db78-0839-4dbc-d3b4-4cf4c800620e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acaf1370-1b86-4c17-83e0-01426df1f30b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acaf1370-1b86-4c17-83e0-01426df1f30b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "10wATCSHPIYZ"
      },
      "outputs": [],
      "source": [
        "# def to_dataset(low_risk, high_risk):\n",
        "#   return np.vstack((low_risk['Daily Return'], low_risk['MA'], low_risk['Volume'], high_risk['Daily Return'], high_risk['MA'], high_risk['Volume'],high_risk['ROE Binary']))\n",
        "\n",
        "# dataset = to_dataset(low_risk, high_risk).T\n",
        "# print(dataset.shape, dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "49t7Zc8bKsUQ",
        "outputId": "93af6037-374b-48ef-dc35-1f3e3495a80f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date  l_Daily Return      l_MA  l_Volume  h_Daily Return  \\\n",
              "25    2002-09-04        0.135391  0.912126  0.023505        0.479605   \n",
              "26    2002-09-05       -0.203112  0.564337  0.017606        0.149555   \n",
              "27    2002-09-06       -0.710926  0.216542  0.009791        0.128926   \n",
              "28    2002-09-09       -0.609368 -0.216563  0.027002        0.804501   \n",
              "29    2002-09-10        1.184878 -0.144378  0.006507        0.288793   \n",
              "...          ...             ...       ...       ...             ...   \n",
              "5142  2022-12-30       -0.270837  0.826825  1.532486        0.923099   \n",
              "5143  2023-01-03       -1.286460  0.419968  2.070246       -1.830743   \n",
              "5144  2023-01-04       -0.236973  0.419968  2.371829        0.299117   \n",
              "5145  2023-01-05        1.455712  0.715269  0.966325       -1.206745   \n",
              "5146  2023-01-06        4.096301  0.826824  2.070063        2.820901   \n",
              "\n",
              "          h_MA  h_Volume  h_ROE Binary  \n",
              "25    0.276737  0.550024             0  \n",
              "26    0.229367  0.723874             1  \n",
              "27    0.522307  0.415721             1  \n",
              "28    0.929931  0.365951             1  \n",
              "29    1.338801  0.445799             0  \n",
              "...        ...       ...           ...  \n",
              "5142 -1.149319  0.903889             1  \n",
              "5143 -1.654172  0.805676             1  \n",
              "5144 -1.185467  0.924976             0  \n",
              "5145 -1.374945  0.828493             1  \n",
              "5146 -2.212630  1.119878             1  \n",
              "\n",
              "[5122 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Daily Return</th>\n",
              "      <th>l_MA</th>\n",
              "      <th>l_Volume</th>\n",
              "      <th>h_Daily Return</th>\n",
              "      <th>h_MA</th>\n",
              "      <th>h_Volume</th>\n",
              "      <th>h_ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>-0.270837</td>\n",
              "      <td>0.826825</td>\n",
              "      <td>1.532486</td>\n",
              "      <td>0.923099</td>\n",
              "      <td>-1.149319</td>\n",
              "      <td>0.903889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>-1.286460</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.070246</td>\n",
              "      <td>-1.830743</td>\n",
              "      <td>-1.654172</td>\n",
              "      <td>0.805676</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>-0.236973</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.371829</td>\n",
              "      <td>0.299117</td>\n",
              "      <td>-1.185467</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>1.455712</td>\n",
              "      <td>0.715269</td>\n",
              "      <td>0.966325</td>\n",
              "      <td>-1.206745</td>\n",
              "      <td>-1.374945</td>\n",
              "      <td>0.828493</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>4.096301</td>\n",
              "      <td>0.826824</td>\n",
              "      <td>2.070063</td>\n",
              "      <td>2.820901</td>\n",
              "      <td>-2.212630</td>\n",
              "      <td>1.119878</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows √ó 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "# pd.concat([low_risk, high_risk], join='outer', axis=1)[['Date'],['Daily Return'],['MA'],['Volume'],['ROE Binary']]\n",
        "# pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['Date','ROE Binary']]\n",
        "ml_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']]\n",
        "ml_master_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "nrXWLxZw6GJk"
      },
      "outputs": [],
      "source": [
        "# X_tensor = torch.from_numpy(ml_master_dataset[:,:-1])\n",
        "# Y_tensor = torch.from_numpy(ml_master_dataset[:,-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zmM8pF0Nxl4"
      },
      "source": [
        "## Build graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "qjzCkZxbRPke"
      },
      "outputs": [],
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 500\n",
        "torch.manual_seed(42)\n",
        "lambda1 = 1e-3 #0.5\n",
        "lambda2 = 1e-3 #0.5\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "yjgtH2co3IPg"
      },
      "outputs": [],
      "source": [
        "folds=10\n",
        "splits=KFold(n_splits=folds,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "LUEtsz9ZRRFN"
      },
      "outputs": [],
      "source": [
        "#no cross-validation\n",
        "\n",
        "def train_and_get_a_b(dataset):\n",
        "\n",
        "  a = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  b = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  # print(a, a.size(), b, b.size())\n",
        "\n",
        "  optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "  X_tensor = torch.from_numpy(dataset[:,:-1])\n",
        "  Y_tensor = torch.from_numpy(dataset[:,-1])\n",
        "  # print(X_tensor, Y_tensor)\n",
        "    \n",
        "    \n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "      yhat = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "\n",
        "      loss = loss_fn(yhat, Y_tensor)\n",
        "      loss.backward()   \n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "  return a,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R2xXpWs2tus"
      },
      "source": [
        "# Build Dataset for MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aqbtJ5LC2E7x",
        "outputId": "162f1b1e-5b87-4c52-a484-5d1c52738e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date    l_Close     h_Close\n",
              "25    2002-09-04  85.199997   89.540001\n",
              "26    2002-09-05  85.540001   88.779999\n",
              "27    2002-09-06  84.879997   90.000000\n",
              "28    2002-09-09  84.760002   90.660004\n",
              "29    2002-09-10  85.059998   91.699997\n",
              "...          ...        ...         ...\n",
              "5142  2022-12-30  95.779999  382.429993\n",
              "5143  2023-01-03  96.529999  380.820007\n",
              "5144  2023-01-04  97.269997  383.760010\n",
              "5145  2023-01-05  97.129997  379.380005\n",
              "5146  2023-01-06  98.379997  388.079987\n",
              "\n",
              "[5122 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2a34618-c657-430e-ac98-7c7dca5fc38d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Close</th>\n",
              "      <th>h_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>89.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>88.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>90.660004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>91.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>382.429993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>380.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>383.760010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>379.380005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>388.079987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a34618-c657-430e-ac98-7c7dca5fc38d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "mv_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Close','h_Close']]\n",
        "mv_master_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "Ekt1011K23kV"
      },
      "outputs": [],
      "source": [
        "def get_mv_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(mv_master_dataset['l_Date']) > startdate) & (pd.to_datetime(mv_master_dataset['l_Date']) <= enddate)\n",
        "  subset = mv_master_dataset.loc[mask]\n",
        "  dataset = subset[['l_Close','h_Close']]\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "-ay84qKK3kSO"
      },
      "outputs": [],
      "source": [
        "def get_annual_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change()\n",
        "    annual_return = daily_return.mean() * trading_days_in_year\n",
        "    daily_covariance = daily_return.cov()\n",
        "    annual_covariance = daily_covariance * trading_days_in_year\n",
        "    return annual_return, annual_covariance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "iBzfeFvH32g4"
      },
      "outputs": [],
      "source": [
        "def get_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change().mean()\n",
        "    daily_covariance = data.pct_change().cov()\n",
        "    return daily_return * len(data), daily_covariance * len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "mw2-EUMt4Otu"
      },
      "outputs": [],
      "source": [
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "-WvoS-8a6YvW"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_data(date):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "    \n",
        "  low_risk_mask = (pd.to_datetime(low_risk['Date']) > startdate) & (pd.to_datetime(low_risk['Date']) <= enddate)\n",
        "  high_risk_mask = (pd.to_datetime(high_risk['Date']) > startdate) & (pd.to_datetime(high_risk['Date']) <= enddate)\n",
        "  low_risk_backtest_data = low_risk.loc[low_risk_mask]\n",
        "  high_risk_backtest_data = high_risk.loc[high_risk_mask]\n",
        "\n",
        "  return low_risk_backtest_data, high_risk_backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "jGK6T6AW7Yg4"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "CwpNskex6YvX"
      },
      "outputs": [],
      "source": [
        "def calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, high_risk_weight):\n",
        "  low_return = calculate_backtest_return(low_risk_backtest_data)\n",
        "  high_return = calculate_backtest_return(high_risk_backtest_data)\n",
        "  # print(low_return)\n",
        "  # print(high_return)\n",
        "  return low_return * (1-high_risk_weight) + high_return * high_risk_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {
        "id": "otburto36YvX"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_return(date, high_risk_weight):\n",
        "  low_risk_backtest_data, high_risk_backtest_data = get_mv_backtest_data(date)\n",
        "  return calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, high_risk_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyH6QC07N4X"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "pt5JBhCLyjYr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "Bbj-yDR504Fv"
      },
      "outputs": [],
      "source": [
        "first_date = date(2003,9,21)\n",
        "last_date = date(2023,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "4v4UTD431hJ4"
      },
      "outputs": [],
      "source": [
        "delta_50weeks = timedelta(weeks=50)\n",
        "delta_1week = timedelta(weeks=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKt0kekQ21Ts",
        "outputId": "6685a6b0-c03b-4b12-ca35-af29e1059a87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2003-09-21', '2003-09-28', '2003-10-05', '2003-10-12',\n",
              "               '2003-10-19', '2003-10-26', '2003-11-02', '2003-11-09',\n",
              "               '2003-11-16', '2003-11-23',\n",
              "               ...\n",
              "               '2022-10-30', '2022-11-06', '2022-11-13', '2022-11-20',\n",
              "               '2022-11-27', '2022-12-04', '2022-12-11', '2022-12-18',\n",
              "               '2022-12-25', '2023-01-01'],\n",
              "              dtype='datetime64[ns]', length=1007, freq='W-SUN')"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "daterange = pd.date_range(first_date, last_date, freq='1W')\n",
        "daterange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {
        "id": "EV3MvASZ7kOM"
      },
      "outputs": [],
      "source": [
        "def get_ml_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(ml_master_dataset['l_Date']) > startdate) & (pd.to_datetime(ml_master_dataset['l_Date']) <= enddate)\n",
        "  subset = ml_master_dataset.loc[mask]\n",
        "  # print(subset)\n",
        "  dataset = subset[['l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']].to_numpy()\n",
        "  # print(dataset)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Po5CtXBzyxS"
      },
      "source": [
        "### First date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fra6gOlGT1-v",
        "outputId": "cc4717b7-0df2-47ab-876b-91feddf8ee9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.10155789,  1.89647755,  0.02441736, ..., -0.97480731,\n",
              "         0.57250387,  1.        ],\n",
              "       [ 0.40625526,  1.88335059,  0.04092873, ..., -0.59959326,\n",
              "         0.8560541 ,  0.        ],\n",
              "       [ 0.16925525,  1.88991473,  0.02873525, ..., -0.83893149,\n",
              "         0.86063301,  1.        ],\n",
              "       ...,\n",
              "       [ 0.20311239,  0.702162  ,  0.02435655, ...,  0.53227856,\n",
              "         0.40786757,  1.        ],\n",
              "       [ 1.11718079,  1.03027115,  0.05385199, ...,  0.41510118,\n",
              "         0.3432117 ,  1.        ],\n",
              "       [-0.06772444,  1.33868853,  0.04019894, ...,  0.66191837,\n",
              "         0.32553542,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "dataset = get_ml_dataset_for_date(first_date)\n",
        "dataset[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWm27_faerS",
        "outputId": "4c142090-c425-46a0-f3e4-e1d54b752aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 1.2250968985965647\n",
            "Epoch: 10. Loss: 1.0422664556524388\n",
            "Epoch: 20. Loss: 0.9103199651473237\n",
            "Epoch: 30. Loss: 0.8211627365206585\n",
            "Epoch: 40. Loss: 0.7621501754153689\n",
            "Epoch: 50. Loss: 0.7225548587061368\n",
            "Epoch: 60. Loss: 0.6954737927837602\n",
            "Epoch: 70. Loss: 0.6767014150071979\n",
            "Epoch: 80. Loss: 0.6635699476207669\n",
            "Epoch: 90. Loss: 0.6543132706623938\n",
            "Epoch: 100. Loss: 0.6477360885029361\n",
            "Epoch: 110. Loss: 0.6430221585728905\n",
            "Epoch: 120. Loss: 0.6396116532648428\n",
            "Epoch: 130. Loss: 0.6371191459597229\n",
            "Epoch: 140. Loss: 0.635278073957452\n",
            "Epoch: 150. Loss: 0.6339030752274836\n",
            "Epoch: 160. Loss: 0.6328644511700781\n",
            "Epoch: 170. Loss: 0.6320708338895114\n",
            "Epoch: 180. Loss: 0.6314573915018703\n",
            "Epoch: 190. Loss: 0.6309777707686528\n",
            "Epoch: 200. Loss: 0.6305985665087154\n",
            "Epoch: 210. Loss: 0.6302955051416969\n",
            "Epoch: 220. Loss: 0.6300507962110538\n",
            "Epoch: 230. Loss: 0.6298512837528443\n",
            "Epoch: 240. Loss: 0.6296871483410416\n",
            "Epoch: 250. Loss: 0.6295509903413822\n",
            "Epoch: 260. Loss: 0.6294371785102312\n",
            "Epoch: 270. Loss: 0.6293413842983838\n",
            "Epoch: 280. Loss: 0.6292602468248716\n",
            "Epoch: 290. Loss: 0.6291911302889445\n",
            "Epoch: 300. Loss: 0.6291319471250912\n",
            "Epoch: 310. Loss: 0.6290810281684981\n",
            "Epoch: 320. Loss: 0.6290370266219606\n",
            "Epoch: 330. Loss: 0.6289988464656815\n",
            "Epoch: 340. Loss: 0.6289655886479608\n",
            "Epoch: 350. Loss: 0.6289365102917657\n",
            "Epoch: 360. Loss: 0.6289109934924184\n",
            "Epoch: 370. Loss: 0.628888521232558\n",
            "Epoch: 380. Loss: 0.6288686586180415\n",
            "Epoch: 390. Loss: 0.6288510381231767\n",
            "Epoch: 400. Loss: 0.628835347881967\n",
            "Epoch: 410. Loss: 0.6288213223134048\n",
            "Epoch: 420. Loss: 0.6288087345510793\n",
            "Epoch: 430. Loss: 0.628797390280147\n",
            "Epoch: 440. Loss: 0.6287871226819385\n",
            "Epoch: 450. Loss: 0.6287777882581012\n",
            "Epoch: 460. Loss: 0.6287692633592182\n",
            "Epoch: 470. Loss: 0.628761441282425\n",
            "Epoch: 480. Loss: 0.628754229832236\n",
            "Epoch: 490. Loss: 0.6287475492612717\n"
          ]
        }
      ],
      "source": [
        "a,b = train_and_get_a_b(dataset[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsYhNrSeoDv",
        "outputId": "61e19e31-8e53-4c5d-f6cb-78d1d19b50d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6920, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "  print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "id": "MsH_YCVPyOer"
      },
      "outputs": [],
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJY6MNe079u",
        "outputId": "ccb5fecb-b23d-42e8-fbe7-48a0511ccc95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "weight = calculate_ml_portfolio_weights(y_test.numpy(), 0.5)\n",
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "id": "CkX6whwN4KX0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_data(date, weight):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "\n",
        "  investment = low_risk if weight == 0 else high_risk\n",
        "    \n",
        "  backtest_mask = (pd.to_datetime(investment['Date']) > startdate) & (pd.to_datetime(investment['Date']) <= enddate)\n",
        "  backtest_data = investment.loc[backtest_mask]\n",
        "\n",
        "  return backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "id": "7grWmruL4LNu"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "id": "zGPtDN524CA0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_return(date, weight):\n",
        "  backtest_data = get_backtest_data(date, weight)\n",
        "  return calculate_backtest_return(backtest_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWzbQZb01qHF",
        "outputId": "ab3858d6-c15f-4a08-9339-785658d211c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102.849998"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "backtest_data = get_backtest_data(first_date, weight)\n",
        "backtest_data.iloc[-1]['Close']\n",
        "backtest_data.iloc[0]['Open']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxw0Vpct44Bq",
        "outputId": "870a2d9c-6aaa-48e1-8ddf-107f586989d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.028196412799152443"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "get_backtest_return(first_date, weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5v5C2j_0IQw"
      },
      "source": [
        "## Back test for all range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgECBqg00_LI"
      },
      "source": [
        "### ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8zIjtzG4xOv",
        "outputId": "d8a6c399-4c4f-4cbd-f4e1-f2cecfaf72e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 70. Loss: 0.7040106044458807\n",
            "Epoch: 80. Loss: 0.679055519118547\n",
            "Epoch: 90. Loss: 0.6577346023569663\n",
            "Epoch: 100. Loss: 0.6396032844454671\n",
            "Epoch: 110. Loss: 0.6242389914259289\n",
            "Epoch: 120. Loss: 0.6112497472582207\n",
            "Epoch: 130. Loss: 0.600280973626676\n",
            "Epoch: 140. Loss: 0.5910191162341137\n",
            "Epoch: 150. Loss: 0.583192126415091\n",
            "Epoch: 160. Loss: 0.5765675121282459\n",
            "Epoch: 170. Loss: 0.5709488517580972\n",
            "Epoch: 180. Loss: 0.5661715617854374\n",
            "Epoch: 190. Loss: 0.5620984999922237\n",
            "Epoch: 200. Loss: 0.5586157733150617\n",
            "Epoch: 210. Loss: 0.5556289491227485\n",
            "Epoch: 220. Loss: 0.5530597502276097\n",
            "Epoch: 230. Loss: 0.5508432404045391\n",
            "Epoch: 240. Loss: 0.5489254667271009\n",
            "Epoch: 250. Loss: 0.5472615064427134\n",
            "Epoch: 260. Loss: 0.5458138607672998\n",
            "Epoch: 270. Loss: 0.5445511399409996\n",
            "Epoch: 280. Loss: 0.5434469893749083\n",
            "Epoch: 290. Loss: 0.5424792134969955\n",
            "Epoch: 300. Loss: 0.5416290607435859\n",
            "Epoch: 310. Loss: 0.5408806394319962\n",
            "Epoch: 320. Loss: 0.5402204397427129\n",
            "Epoch: 330. Loss: 0.5396369416865514\n",
            "Epoch: 340. Loss: 0.5391202927838522\n",
            "Epoch: 350. Loss: 0.5386620423321138\n",
            "Epoch: 360. Loss: 0.5382549216906817\n",
            "Epoch: 370. Loss: 0.5378926620675616\n",
            "Epoch: 380. Loss: 0.5375698429446405\n",
            "Epoch: 390. Loss: 0.5372817656010074\n",
            "Epoch: 400. Loss: 0.5370243472540853\n",
            "Epoch: 410. Loss: 0.5367940321875848\n",
            "Epoch: 420. Loss: 0.5365877169164277\n",
            "Epoch: 430. Loss: 0.5364026869858808\n",
            "Epoch: 440. Loss: 0.5362365634423792\n",
            "Epoch: 450. Loss: 0.5360872573685688\n",
            "Epoch: 460. Loss: 0.5359529311621039\n",
            "Epoch: 470. Loss: 0.535831965470362\n",
            "Epoch: 480. Loss: 0.5357229308822454\n",
            "Epoch: 490. Loss: 0.5356245636322814\n",
            "tensor(0.7339, dtype=torch.float64)\n",
            "2004-06-27 00:00:00\n",
            "Epoch: 0. Loss: 0.817447988948405\n",
            "Epoch: 10. Loss: 0.7694846297250097\n",
            "Epoch: 20. Loss: 0.732542126591557\n",
            "Epoch: 30. Loss: 0.7025119296220536\n",
            "Epoch: 40. Loss: 0.6774659461728292\n",
            "Epoch: 50. Loss: 0.6563410467037467\n",
            "Epoch: 60. Loss: 0.6384342791875597\n",
            "Epoch: 70. Loss: 0.6232167836911917\n",
            "Epoch: 80. Loss: 0.6102627406440136\n",
            "Epoch: 90. Loss: 0.5992190554809628\n",
            "Epoch: 100. Loss: 0.5897896968995014\n",
            "Epoch: 110. Loss: 0.5817256449570839\n",
            "Epoch: 120. Loss: 0.5748173159171713\n",
            "Epoch: 130. Loss: 0.5688883619570748\n",
            "Epoch: 140. Loss: 0.5637904337631156\n",
            "Epoch: 150. Loss: 0.5593987231078874\n",
            "Epoch: 160. Loss: 0.5556081758955316\n",
            "Epoch: 170. Loss: 0.5523302894169372\n",
            "Epoch: 180. Loss: 0.5494904165368937\n",
            "Epoch: 190. Loss: 0.5470255057061505\n",
            "Epoch: 200. Loss: 0.5448822121141342\n",
            "Epoch: 210. Loss: 0.5430153223164365\n",
            "Epoch: 220. Loss: 0.5413864419112299\n",
            "Epoch: 230. Loss: 0.5399629028707806\n",
            "Epoch: 240. Loss: 0.5387168536523371\n",
            "Epoch: 250. Loss: 0.5376245010505403\n",
            "Epoch: 260. Loss: 0.5366654778527428\n",
            "Epoch: 270. Loss: 0.5358223147317981\n",
            "Epoch: 280. Loss: 0.5350799985113244\n",
            "Epoch: 290. Loss: 0.5344256020389598\n",
            "Epoch: 300. Loss: 0.5338479734825257\n",
            "Epoch: 310. Loss: 0.5333374749989341\n",
            "Epoch: 320. Loss: 0.5328857624865285\n",
            "Epoch: 330. Loss: 0.5324855995804961\n",
            "Epoch: 340. Loss: 0.5321307002417055\n",
            "Epoch: 350. Loss: 0.5318155952672065\n",
            "Epoch: 360. Loss: 0.5315355188537534\n",
            "Epoch: 370. Loss: 0.5312863120055812\n",
            "Epoch: 380. Loss: 0.5310643401203121\n",
            "Epoch: 390. Loss: 0.5308664225336108\n",
            "Epoch: 400. Loss: 0.5306897721715017\n",
            "Epoch: 410. Loss: 0.5305319437633547\n",
            "Epoch: 420. Loss: 0.5303907893200532\n",
            "Epoch: 430. Loss: 0.5302644197902546\n",
            "Epoch: 440. Loss: 0.5301511719806472\n",
            "Epoch: 450. Loss: 0.530049579969994\n",
            "Epoch: 460. Loss: 0.5299583503666763\n",
            "Epoch: 470. Loss: 0.5298763408595852\n",
            "Epoch: 480. Loss: 0.5298025415960091\n",
            "Epoch: 490. Loss: 0.5297360589904178\n",
            "tensor(0.7257, dtype=torch.float64)\n",
            "2004-07-04 00:00:00\n",
            "Epoch: 0. Loss: 0.8869002561576517\n",
            "Epoch: 10. Loss: 0.8270646901494103\n",
            "Epoch: 20. Loss: 0.7797840955144776\n",
            "Epoch: 30. Loss: 0.7411618871180445\n",
            "Epoch: 40. Loss: 0.7089963649135701\n",
            "Epoch: 50. Loss: 0.6819586979558723\n",
            "Epoch: 60. Loss: 0.6591414084628581\n",
            "Epoch: 70. Loss: 0.6398529096024795\n",
            "Epoch: 80. Loss: 0.6235308061563125\n",
            "Epoch: 90. Loss: 0.6097045574535167\n",
            "Epoch: 100. Loss: 0.5979770465029953\n",
            "Epoch: 110. Loss: 0.5880130995225183\n",
            "Epoch: 120. Loss: 0.5795306376774936\n",
            "Epoch: 130. Loss: 0.5722930524473249\n",
            "Epoch: 140. Loss: 0.5661024197578212\n",
            "Epoch: 150. Loss: 0.5607934799908488\n",
            "Epoch: 160. Loss: 0.5562283728088101\n",
            "Epoch: 170. Loss: 0.5522921026965787\n",
            "Epoch: 180. Loss: 0.5488886858640676\n",
            "Epoch: 190. Loss: 0.5459379107743099\n",
            "Epoch: 200. Loss: 0.5433726361792689\n",
            "Epoch: 210. Loss: 0.5411365501953848\n",
            "Epoch: 220. Loss: 0.5391823187354319\n",
            "Epoch: 230. Loss: 0.5374700590808086\n",
            "Epoch: 240. Loss: 0.5359660828184811\n",
            "Epoch: 250. Loss: 0.5346418607270732\n",
            "Epoch: 260. Loss: 0.5334731699061046\n",
            "Epoch: 270. Loss: 0.5324393902465256\n",
            "Epoch: 280. Loss: 0.5315229231757194\n",
            "Epoch: 290. Loss: 0.5307087105176027\n",
            "Epoch: 300. Loss: 0.529983835380851\n",
            "Epoch: 310. Loss: 0.5293371903366312\n",
            "Epoch: 320. Loss: 0.5287592008830944\n",
            "Epoch: 330. Loss: 0.5282415944201376\n",
            "Epoch: 340. Loss: 0.527777206765005\n",
            "Epoch: 350. Loss: 0.5273598197042256\n",
            "Epoch: 360. Loss: 0.5269840242645237\n",
            "Epoch: 370. Loss: 0.5266451053476863\n",
            "Epoch: 380. Loss: 0.5263389441551991\n",
            "Epoch: 390. Loss: 0.5260619354628201\n",
            "Epoch: 400. Loss: 0.5258109173214542\n",
            "Epoch: 410. Loss: 0.5255831111815239\n",
            "Epoch: 420. Loss: 0.5253760707818046\n",
            "Epoch: 430. Loss: 0.5251876384251344\n",
            "Epoch: 440. Loss: 0.5250159074943365\n",
            "Epoch: 450. Loss: 0.524859190251617\n",
            "Epoch: 460. Loss: 0.524715990121272\n",
            "Epoch: 470. Loss: 0.5245849777849124\n",
            "Epoch: 480. Loss: 0.5244649705255896\n",
            "Epoch: 490. Loss: 0.5243549143461728\n",
            "tensor(0.7470, dtype=torch.float64)\n",
            "2004-07-11 00:00:00\n",
            "Epoch: 0. Loss: 1.2887059160480263\n",
            "Epoch: 10. Loss: 1.1617167198021692\n",
            "Epoch: 20. Loss: 1.0546289355650953\n",
            "Epoch: 30. Loss: 0.9652848760081559\n",
            "Epoch: 40. Loss: 0.8913390147227893\n",
            "Epoch: 50. Loss: 0.8304246944450544\n",
            "Epoch: 60. Loss: 0.7803310527894863\n",
            "Epoch: 70. Loss: 0.7391198354204481\n",
            "Epoch: 80. Loss: 0.7051610328373772\n",
            "Epoch: 90. Loss: 0.677114256167419\n",
            "Epoch: 100. Loss: 0.6538884441346425\n",
            "Epoch: 110. Loss: 0.6345989966602557\n",
            "Epoch: 120. Loss: 0.6185296011298709\n",
            "Epoch: 130. Loss: 0.6051002555040188\n",
            "Epoch: 140. Loss: 0.5938410430715988\n",
            "Epoch: 150. Loss: 0.5843707969559359\n",
            "Epoch: 160. Loss: 0.5763798222035333\n",
            "Epoch: 170. Loss: 0.5696159568650178\n",
            "Epoch: 180. Loss: 0.5638733639687384\n",
            "Epoch: 190. Loss: 0.5589835426545441\n",
            "Epoch: 200. Loss: 0.5548081311496319\n",
            "Epoch: 210. Loss: 0.5512331485014549\n",
            "Epoch: 220. Loss: 0.5481643865462233\n",
            "Epoch: 230. Loss: 0.5455237187018227\n",
            "Epoch: 240. Loss: 0.5432461382961611\n",
            "Epoch: 250. Loss: 0.5412773770744206\n",
            "Epoch: 260. Loss: 0.5395719852877379\n",
            "Epoch: 270. Loss: 0.53809177943927\n",
            "Epoch: 280. Loss: 0.5368045833993071\n",
            "Epoch: 290. Loss: 0.5356832041420707\n",
            "Epoch: 300. Loss: 0.5347045956137935\n",
            "Epoch: 310. Loss: 0.5338491738897699\n",
            "Epoch: 320. Loss: 0.5331002543672532\n",
            "Epoch: 330. Loss: 0.5324435877123543\n",
            "Epoch: 340. Loss: 0.5318669759822497\n",
            "Epoch: 350. Loss: 0.5313599540543334\n",
            "Epoch: 360. Loss: 0.5309135244271233\n",
            "Epoch: 370. Loss: 0.5305199357821281\n",
            "Epoch: 380. Loss: 0.5301724975427735\n",
            "Epoch: 390. Loss: 0.5298654241381667\n",
            "Epoch: 400. Loss: 0.5295937038556775\n",
            "Epoch: 410. Loss: 0.5293529881092607\n",
            "Epoch: 420. Loss: 0.529139497708738\n",
            "Epoch: 430. Loss: 0.5289499433270167\n",
            "Epoch: 440. Loss: 0.5287814578572796\n",
            "Epoch: 450. Loss: 0.5286315387540973\n",
            "Epoch: 460. Loss: 0.5284979987796901\n",
            "Epoch: 470. Loss: 0.528378923843919\n",
            "Epoch: 480. Loss: 0.528272636845611\n",
            "Epoch: 490. Loss: 0.5281776666028185\n",
            "tensor(0.7165, dtype=torch.float64)\n",
            "2004-07-18 00:00:00\n",
            "Epoch: 0. Loss: 0.9640807732378536\n",
            "Epoch: 10. Loss: 0.7890462128110882\n",
            "Epoch: 20. Loss: 0.6856375109634576\n",
            "Epoch: 30. Loss: 0.632360035994164\n",
            "Epoch: 40. Loss: 0.604868218714314\n",
            "Epoch: 50. Loss: 0.5888572788868854\n",
            "Epoch: 60. Loss: 0.5780917009689851\n",
            "Epoch: 70. Loss: 0.570053959442737\n",
            "Epoch: 80. Loss: 0.5636768709110543\n",
            "Epoch: 90. Loss: 0.5584513331218844\n",
            "Epoch: 100. Loss: 0.5540951517580378\n",
            "Epoch: 110. Loss: 0.5504280261802856\n",
            "Epoch: 120. Loss: 0.5473218415042312\n",
            "Epoch: 130. Loss: 0.5446792329700803\n",
            "Epoch: 140. Loss: 0.542423263912767\n",
            "Epoch: 150. Loss: 0.5404917710349352\n",
            "Epoch: 160. Loss: 0.5388338564804929\n",
            "Epoch: 170. Loss: 0.537407486097353\n",
            "Epoch: 180. Loss: 0.5361777308676349\n",
            "Epoch: 190. Loss: 0.5351154243833471\n",
            "Epoch: 200. Loss: 0.5341961117503528\n",
            "Epoch: 210. Loss: 0.5333992136870078\n",
            "Epoch: 220. Loss: 0.5327073548420663\n",
            "Epoch: 230. Loss: 0.532105820016993\n",
            "Epoch: 240. Loss: 0.5315821113309478\n",
            "Epoch: 250. Loss: 0.5311255857828233\n",
            "Epoch: 260. Loss: 0.5307271572913608\n",
            "Epoch: 270. Loss: 0.53037905074034\n",
            "Epoch: 280. Loss: 0.5300745981761901\n",
            "Epoch: 290. Loss: 0.5298080693253234\n",
            "Epoch: 300. Loss: 0.5295745301706077\n",
            "Epoch: 310. Loss: 0.5293697245588344\n",
            "Epoch: 320. Loss: 0.5291899747829203\n",
            "Epoch: 330. Loss: 0.5290320978529345\n",
            "Epoch: 340. Loss: 0.5288933347834757\n",
            "Epoch: 350. Loss: 0.5287712907155714\n",
            "Epoch: 360. Loss: 0.528663884085285\n",
            "Epoch: 370. Loss: 0.5285693033689116\n",
            "Epoch: 380. Loss: 0.5284859701917838\n",
            "Epoch: 390. Loss: 0.5284125077965762\n",
            "Epoch: 400. Loss: 0.5283477140373019\n",
            "Epoch: 410. Loss: 0.5282905382044918\n",
            "Epoch: 420. Loss: 0.5282400611014094\n",
            "Epoch: 430. Loss: 0.5281954778853012\n",
            "Epoch: 440. Loss: 0.528156083265477\n",
            "Epoch: 450. Loss: 0.5281212587144527\n",
            "Epoch: 460. Loss: 0.5280904614019439\n",
            "Epoch: 470. Loss: 0.5280632146061229\n",
            "Epoch: 480. Loss: 0.5280390993938414\n",
            "Epoch: 490. Loss: 0.5280177473927622\n",
            "tensor(0.7995, dtype=torch.float64)\n",
            "2004-07-25 00:00:00\n",
            "Epoch: 0. Loss: 1.322783268397879\n",
            "Epoch: 10. Loss: 1.2044811683860936\n",
            "Epoch: 20. Loss: 1.1055801629562343\n",
            "Epoch: 30. Loss: 1.022054875266472\n",
            "Epoch: 40. Loss: 0.9509451441756702\n",
            "Epoch: 50. Loss: 0.8901710419811341\n",
            "Epoch: 60. Loss: 0.8382078253669222\n",
            "Epoch: 70. Loss: 0.793843496568863\n",
            "Epoch: 80. Loss: 0.7560467193398012\n",
            "Epoch: 90. Loss: 0.723908362193781\n",
            "Epoch: 100. Loss: 0.6966200287178512\n",
            "Epoch: 110. Loss: 0.6734668461915754\n",
            "Epoch: 120. Loss: 0.6538234204965915\n",
            "Epoch: 130. Loss: 0.6371488164042496\n",
            "Epoch: 140. Loss: 0.6229797902430289\n",
            "Epoch: 150. Loss: 0.6109227754533862\n",
            "Epoch: 160. Loss: 0.6006453848694433\n",
            "Epoch: 170. Loss: 0.5918680672578779\n",
            "Epoch: 180. Loss: 0.5843563361313135\n",
            "Epoch: 190. Loss: 0.5779137922287277\n",
            "Epoch: 200. Loss: 0.5723760185722208\n",
            "Epoch: 210. Loss: 0.567605336360189\n",
            "Epoch: 220. Loss: 0.5634863589559723\n",
            "Epoch: 230. Loss: 0.5599222572540123\n",
            "Epoch: 240. Loss: 0.5568316426670089\n",
            "Epoch: 250. Loss: 0.5541459767131389\n",
            "Epoch: 260. Loss: 0.5518074239651753\n",
            "Epoch: 270. Loss: 0.5497670750145784\n",
            "Epoch: 280. Loss: 0.5479834763836448\n",
            "Epoch: 290. Loss: 0.5464214140568134\n",
            "Epoch: 300. Loss: 0.5450509060554606\n",
            "Epoch: 310. Loss: 0.5438463670943294\n",
            "Epoch: 320. Loss: 0.5427859148378852\n",
            "Epoch: 330. Loss: 0.5418507927087498\n",
            "Epoch: 340. Loss: 0.5410248887102179\n",
            "Epoch: 350. Loss: 0.540294333441273\n",
            "Epoch: 360. Loss: 0.5396471635303272\n",
            "Epoch: 370. Loss: 0.5390730392055662\n",
            "Epoch: 380. Loss: 0.5385630067529199\n",
            "Epoch: 390. Loss: 0.5381092982702101\n",
            "Epoch: 400. Loss: 0.537705162477066\n",
            "Epoch: 410. Loss: 0.5373447214419095\n",
            "Epoch: 420. Loss: 0.5370228489864568\n",
            "Epoch: 430. Loss: 0.5367350672629013\n",
            "Epoch: 440. Loss: 0.5364774586001845\n",
            "Epoch: 450. Loss: 0.5362465902086252\n",
            "Epoch: 460. Loss: 0.5360394497369241\n",
            "Epoch: 470. Loss: 0.5358533900086193\n",
            "Epoch: 480. Loss: 0.5356860815396957\n",
            "Epoch: 490. Loss: 0.5355354716659751\n",
            "tensor(0.8195, dtype=torch.float64)\n",
            "2004-08-01 00:00:00\n",
            "Epoch: 0. Loss: 1.0888922187546433\n",
            "Epoch: 10. Loss: 1.0136963362314968\n",
            "Epoch: 20. Loss: 0.9472154092015627\n",
            "Epoch: 30. Loss: 0.8888135323915054\n",
            "Epoch: 40. Loss: 0.8378347395482195\n",
            "Epoch: 50. Loss: 0.7935969953074562\n",
            "Epoch: 60. Loss: 0.7554054683798695\n",
            "Epoch: 70. Loss: 0.7225732467118583\n",
            "Epoch: 80. Loss: 0.6944415858381326\n",
            "Epoch: 90. Loss: 0.6703957127700374\n",
            "Epoch: 100. Loss: 0.6498749847774791\n",
            "Epoch: 110. Loss: 0.6323777706048765\n",
            "Epoch: 120. Loss: 0.6174621156300685\n",
            "Epoch: 130. Loss: 0.6047434141428395\n",
            "Epoch: 140. Loss: 0.5938901969883075\n",
            "Epoch: 150. Loss: 0.5846189181913047\n",
            "Epoch: 160. Loss: 0.5766883842232433\n",
            "Epoch: 170. Loss: 0.5698942585101998\n",
            "Epoch: 180. Loss: 0.5640639065562151\n",
            "Epoch: 190. Loss: 0.5590517239308229\n",
            "Epoch: 200. Loss: 0.554735004310762\n",
            "Epoch: 210. Loss: 0.5510103497844825\n",
            "Epoch: 220. Loss: 0.5477905929073601\n",
            "Epoch: 230. Loss: 0.5450021828377798\n",
            "Epoch: 240. Loss: 0.5425829810138532\n",
            "Epoch: 250. Loss: 0.540480411348936\n",
            "Epoch: 260. Loss: 0.538649913101331\n",
            "Epoch: 270. Loss: 0.5370536495909786\n",
            "Epoch: 280. Loss: 0.5356594316423013\n",
            "Epoch: 290. Loss: 0.5344398203413823\n",
            "Epoch: 300. Loss: 0.533371379030627\n",
            "Epoch: 310. Loss: 0.53243404924603\n",
            "Epoch: 320. Loss: 0.5316106294723968\n",
            "Epoch: 330. Loss: 0.5308863391607265\n",
            "Epoch: 340. Loss: 0.5302484534658702\n",
            "Epoch: 350. Loss: 0.5296859966839944\n",
            "Epoch: 360. Loss: 0.5291894844647216\n",
            "Epoch: 370. Loss: 0.5287507066060285\n",
            "Epoch: 380. Loss: 0.5283625436691438\n",
            "Epoch: 390. Loss: 0.5280188118268426\n",
            "Epoch: 400. Loss: 0.5277141313254362\n",
            "Epoch: 410. Loss: 0.5274438147353432\n",
            "Epoch: 420. Loss: 0.5272037718182413\n",
            "Epoch: 430. Loss: 0.5269904283759604\n",
            "Epoch: 440. Loss: 0.5268006568885005\n",
            "Epoch: 450. Loss: 0.526631717113077\n",
            "Epoch: 460. Loss: 0.5264812051170071\n",
            "Epoch: 470. Loss: 0.5263470094660406\n",
            "Epoch: 480. Loss: 0.5262272734958169\n",
            "Epoch: 490. Loss: 0.5261203627651272\n",
            "tensor(0.7865, dtype=torch.float64)\n",
            "2004-08-08 00:00:00\n",
            "Epoch: 0. Loss: 1.321131912905304\n",
            "Epoch: 10. Loss: 1.1979361990991868\n",
            "Epoch: 20. Loss: 1.0927034188330993\n",
            "Epoch: 30. Loss: 1.0029927320149226\n",
            "Epoch: 40. Loss: 0.9265114863781961\n",
            "Epoch: 50. Loss: 0.8613903988453367\n",
            "Epoch: 60. Loss: 0.8061608904862838\n",
            "Epoch: 70. Loss: 0.759612777271006\n",
            "Epoch: 80. Loss: 0.7206679996610066\n",
            "Epoch: 90. Loss: 0.6883153300769652\n",
            "Epoch: 100. Loss: 0.6615976514680483\n",
            "Epoch: 110. Loss: 0.6396266074964024\n",
            "Epoch: 120. Loss: 0.6216025387734968\n",
            "Epoch: 130. Loss: 0.6068275389657407\n",
            "Epoch: 140. Loss: 0.594708359771915\n",
            "Epoch: 150. Loss: 0.5847509140055182\n",
            "Epoch: 160. Loss: 0.5765497081941418\n",
            "Epoch: 170. Loss: 0.5697752114914705\n",
            "Epoch: 180. Loss: 0.5641612097519246\n",
            "Epoch: 190. Loss: 0.5594932742899904\n",
            "Epoch: 200. Loss: 0.5555988168880555\n",
            "Epoch: 210. Loss: 0.5523388073269434\n",
            "Epoch: 220. Loss: 0.5496010270999684\n",
            "Epoch: 230. Loss: 0.5472946505254531\n",
            "Epoch: 240. Loss: 0.5453459283841396\n",
            "Epoch: 250. Loss: 0.54369476530224\n",
            "Epoch: 260. Loss: 0.5422920108205364\n",
            "Epoch: 270. Loss: 0.5410973152382089\n",
            "Epoch: 280. Loss: 0.5400774301597323\n",
            "Epoch: 290. Loss: 0.5392048584218477\n",
            "Epoch: 300. Loss: 0.5384567784318708\n",
            "Epoch: 310. Loss: 0.5378141842679126\n",
            "Epoch: 320. Loss: 0.5372611957730191\n",
            "Epoch: 330. Loss: 0.536784502947167\n",
            "Epoch: 340. Loss: 0.5363729167735517\n",
            "Epoch: 350. Loss: 0.536017004690352\n",
            "Epoch: 360. Loss: 0.5357087936270228\n",
            "Epoch: 370. Loss: 0.5354415271749807\n",
            "Epoch: 380. Loss: 0.5352094662980753\n",
            "Epoch: 390. Loss: 0.5350077251956121\n",
            "Epoch: 400. Loss: 0.5348321356537956\n",
            "Epoch: 410. Loss: 0.5346791345707762\n",
            "Epoch: 420. Loss: 0.5345456704006301\n",
            "Epoch: 430. Loss: 0.5344291250974881\n",
            "Epoch: 440. Loss: 0.5343272488024922\n",
            "Epoch: 450. Loss: 0.5342381050415932\n",
            "Epoch: 460. Loss: 0.5341600246209787\n",
            "Epoch: 470. Loss: 0.5340915667419563\n",
            "Epoch: 480. Loss: 0.5340314861261456\n",
            "Epoch: 490. Loss: 0.5339787051586142\n",
            "tensor(0.8775, dtype=torch.float64)\n",
            "2004-08-15 00:00:00\n",
            "Epoch: 0. Loss: 0.7698929531857244\n",
            "Epoch: 10. Loss: 0.7138327227715209\n",
            "Epoch: 20. Loss: 0.6701401397975532\n",
            "Epoch: 30. Loss: 0.6371501432677823\n",
            "Epoch: 40. Loss: 0.6127868934734508\n",
            "Epoch: 50. Loss: 0.5949879015242585\n",
            "Epoch: 60. Loss: 0.5819850275442751\n",
            "Epoch: 70. Loss: 0.5724041924918087\n",
            "Epoch: 80. Loss: 0.5652426206510607\n",
            "Epoch: 90. Loss: 0.5597951514597074\n",
            "Epoch: 100. Loss: 0.555574917717909\n",
            "Epoch: 110. Loss: 0.552247358597249\n",
            "Epoch: 120. Loss: 0.5495814101676388\n",
            "Epoch: 130. Loss: 0.5474155720638878\n",
            "Epoch: 140. Loss: 0.5456350860887045\n",
            "Epoch: 150. Loss: 0.5441568313875709\n",
            "Epoch: 160. Loss: 0.5429193747305282\n",
            "Epoch: 170. Loss: 0.5418763968159614\n",
            "Epoch: 180. Loss: 0.5409923112627164\n",
            "Epoch: 190. Loss: 0.5402393070587517\n",
            "Epoch: 200. Loss: 0.539595319854073\n",
            "Epoch: 210. Loss: 0.5390426150571482\n",
            "Epoch: 220. Loss: 0.5385667790404893\n",
            "Epoch: 230. Loss: 0.538155986742587\n",
            "Epoch: 240. Loss: 0.5378004596748172\n",
            "Epoch: 250. Loss: 0.537492057502451\n",
            "Epoch: 260. Loss: 0.5372239650999079\n",
            "Epoch: 270. Loss: 0.5369904491280465\n",
            "Epoch: 280. Loss: 0.5367866661518862\n",
            "Epoch: 290. Loss: 0.536608509617577\n",
            "Epoch: 300. Loss: 0.5364524865848999\n",
            "Epoch: 310. Loss: 0.5363156175647993\n",
            "Epoch: 320. Loss: 0.5361953545219051\n",
            "Epoch: 330. Loss: 0.5360895133148378\n",
            "Epoch: 340. Loss: 0.5359962177216115\n",
            "Epoch: 350. Loss: 0.5359138528383695\n",
            "Epoch: 360. Loss: 0.5358410261166812\n",
            "Epoch: 370. Loss: 0.535776534664814\n",
            "Epoch: 380. Loss: 0.5357193377139539\n",
            "Epoch: 390. Loss: 0.5356685333637271\n",
            "Epoch: 400. Loss: 0.5356233388883782\n",
            "Epoch: 410. Loss: 0.5355830740169126\n",
            "Epoch: 420. Loss: 0.5355471467056645\n",
            "Epoch: 430. Loss: 0.5355150410061753\n",
            "Epoch: 440. Loss: 0.5354863066994884\n",
            "Epoch: 450. Loss: 0.5354605504234308\n",
            "Epoch: 460. Loss: 0.5354374280647772\n",
            "Epoch: 470. Loss: 0.5354166382253983\n",
            "Epoch: 480. Loss: 0.535397916602178\n",
            "Epoch: 490. Loss: 0.5353810311458734\n",
            "tensor(0.7296, dtype=torch.float64)\n",
            "2004-08-22 00:00:00\n",
            "Epoch: 0. Loss: 0.9327091799321935\n",
            "Epoch: 10. Loss: 0.8144849879173486\n",
            "Epoch: 20. Loss: 0.7424260777105972\n",
            "Epoch: 30. Loss: 0.6983782351761064\n",
            "Epoch: 40. Loss: 0.6693098389886782\n",
            "Epoch: 50. Loss: 0.6483350507250683\n",
            "Epoch: 60. Loss: 0.6321279053757889\n",
            "Epoch: 70. Loss: 0.6190339577216811\n",
            "Epoch: 80. Loss: 0.60816025455056\n",
            "Epoch: 90. Loss: 0.5989746311014538\n",
            "Epoch: 100. Loss: 0.5911282806839019\n",
            "Epoch: 110. Loss: 0.584373951469119\n",
            "Epoch: 120. Loss: 0.5785259634418775\n",
            "Epoch: 130. Loss: 0.5734392206274508\n",
            "Epoch: 140. Loss: 0.5689972821097626\n",
            "Epoch: 150. Loss: 0.5651050144364758\n",
            "Epoch: 160. Loss: 0.5616837226297625\n",
            "Epoch: 170. Loss: 0.5586677226615431\n",
            "Epoch: 180. Loss: 0.5560018139842003\n",
            "Epoch: 190. Loss: 0.5536393511758797\n",
            "Epoch: 200. Loss: 0.5515407361754299\n",
            "Epoch: 210. Loss: 0.5496722183617109\n",
            "Epoch: 220. Loss: 0.548004927176724\n",
            "Epoch: 230. Loss: 0.5465140845807804\n",
            "Epoch: 240. Loss: 0.5451783590239018\n",
            "Epoch: 250. Loss: 0.5439793322534243\n",
            "Epoch: 260. Loss: 0.5429010570021514\n",
            "Epoch: 270. Loss: 0.541929688457301\n",
            "Epoch: 280. Loss: 0.5410531760144296\n",
            "Epoch: 290. Loss: 0.5402610045536541\n",
            "Epoch: 300. Loss: 0.5395439765837534\n",
            "Epoch: 310. Loss: 0.5388940282478867\n",
            "Epoch: 320. Loss: 0.5383040734869516\n",
            "Epoch: 330. Loss: 0.537767871694472\n",
            "Epoch: 340. Loss: 0.537279915029898\n",
            "Epoch: 350. Loss: 0.5368353322297216\n",
            "Epoch: 360. Loss: 0.5364298063015042\n",
            "Epoch: 370. Loss: 0.5360595039306262\n",
            "Epoch: 380. Loss: 0.535721014793427\n",
            "Epoch: 390. Loss: 0.5354112992691135\n",
            "Epoch: 400. Loss: 0.5351276432888549\n",
            "Epoch: 410. Loss: 0.5348676192637349\n",
            "Epoch: 420. Loss: 0.5346290522016012\n",
            "Epoch: 430. Loss: 0.5344099902627067\n",
            "Epoch: 440. Loss: 0.5342086791204923\n",
            "Epoch: 450. Loss: 0.5340235395910594\n",
            "Epoch: 460. Loss: 0.5338531480762163\n",
            "Epoch: 470. Loss: 0.5336962194331745\n",
            "Epoch: 480. Loss: 0.5335515919412841\n",
            "Epoch: 490. Loss: 0.5334182140844634\n",
            "tensor(0.7526, dtype=torch.float64)\n",
            "2004-08-29 00:00:00\n",
            "Epoch: 0. Loss: 0.6429431082169577\n",
            "Epoch: 10. Loss: 0.6180475720945334\n",
            "Epoch: 20. Loss: 0.6003199543546264\n",
            "Epoch: 30. Loss: 0.587471289480288\n",
            "Epoch: 40. Loss: 0.5779195453831906\n",
            "Epoch: 50. Loss: 0.5706069242403252\n",
            "Epoch: 60. Loss: 0.5648368520957406\n",
            "Epoch: 70. Loss: 0.5601517554204197\n",
            "Epoch: 80. Loss: 0.5562492797010221\n",
            "Epoch: 90. Loss: 0.5529273520381566\n",
            "Epoch: 100. Loss: 0.5500488458891394\n",
            "Epoch: 110. Loss: 0.5475189820925709\n",
            "Epoch: 120. Loss: 0.5452708527429131\n",
            "Epoch: 130. Loss: 0.5432560989219043\n",
            "Epoch: 140. Loss: 0.5414388641533621\n",
            "Epoch: 150. Loss: 0.5397918406453337\n",
            "Epoch: 160. Loss: 0.5382936616005461\n",
            "Epoch: 170. Loss: 0.536927165650357\n",
            "Epoch: 180. Loss: 0.5356782305092379\n",
            "Epoch: 190. Loss: 0.5345349808304865\n",
            "Epoch: 200. Loss: 0.5334872437889605\n",
            "Epoch: 210. Loss: 0.5325261698049589\n",
            "Epoch: 220. Loss: 0.5316439641379788\n",
            "Epoch: 230. Loss: 0.530833693476601\n",
            "Epoch: 240. Loss: 0.530089143682445\n",
            "Epoch: 250. Loss: 0.5294047127605858\n",
            "Epoch: 260. Loss: 0.5287753283619625\n",
            "Epoch: 270. Loss: 0.5281963825994364\n",
            "Epoch: 280. Loss: 0.5276636792777382\n",
            "Epoch: 290. Loss: 0.5271733901898715\n",
            "Epoch: 300. Loss: 0.5267220181755942\n",
            "Epoch: 310. Loss: 0.526306365340966\n",
            "Epoch: 320. Loss: 0.5259235053140403\n",
            "Epoch: 330. Loss: 0.5255707587353958\n",
            "Epoch: 340. Loss: 0.5252456714032544\n",
            "Epoch: 350. Loss: 0.5249459946448433\n",
            "Epoch: 360. Loss: 0.5246696675908137\n",
            "Epoch: 370. Loss: 0.5244148011030176\n",
            "Epoch: 380. Loss: 0.5241796631578779\n",
            "Epoch: 390. Loss: 0.5239626655248372\n",
            "Epoch: 400. Loss: 0.5237623516065396\n",
            "Epoch: 410. Loss: 0.5235773853276211\n",
            "Epoch: 420. Loss: 0.5234065409743838\n",
            "Epoch: 430. Loss: 0.5232486938996521\n",
            "Epoch: 440. Loss: 0.5231028120167271\n",
            "Epoch: 450. Loss: 0.5229679480142496\n",
            "Epoch: 460. Loss: 0.522843232230419\n",
            "Epoch: 470. Loss: 0.522727866130698\n",
            "Epoch: 480. Loss: 0.5226211163380969\n",
            "Epoch: 490. Loss: 0.5225223091695247\n",
            "tensor(0.7027, dtype=torch.float64)\n",
            "2004-09-05 00:00:00\n",
            "Epoch: 0. Loss: 0.9820732975839987\n",
            "Epoch: 10. Loss: 0.8329275287637558\n",
            "Epoch: 20. Loss: 0.7261950416228385\n",
            "Epoch: 30. Loss: 0.6556360866402485\n",
            "Epoch: 40. Loss: 0.6112169819354187\n",
            "Epoch: 50. Loss: 0.5834470332880346\n",
            "Epoch: 60. Loss: 0.5656645102673062\n",
            "Epoch: 70. Loss: 0.5538223952815546\n",
            "Epoch: 80. Loss: 0.5455885599938874\n",
            "Epoch: 90. Loss: 0.5396245772939403\n",
            "Epoch: 100. Loss: 0.5351468821182318\n",
            "Epoch: 110. Loss: 0.5316823389457274\n",
            "Epoch: 120. Loss: 0.5289349641828617\n",
            "Epoch: 130. Loss: 0.5267127196672498\n",
            "Epoch: 140. Loss: 0.5248864850033051\n",
            "Epoch: 150. Loss: 0.5233664668283866\n",
            "Epoch: 160. Loss: 0.522088251820738\n",
            "Epoch: 170. Loss: 0.5210043236703858\n",
            "Epoch: 180. Loss: 0.5200787554830036\n",
            "Epoch: 190. Loss: 0.5192837953701973\n",
            "Epoch: 200. Loss: 0.5185976095913934\n",
            "Epoch: 210. Loss: 0.518002751193872\n",
            "Epoch: 220. Loss: 0.5174850945135271\n",
            "Epoch: 230. Loss: 0.5170330759884834\n",
            "Epoch: 240. Loss: 0.51663714108605\n",
            "Epoch: 250. Loss: 0.5162893330625092\n",
            "Epoch: 260. Loss: 0.515982981449561\n",
            "Epoch: 270. Loss: 0.5157124621168372\n",
            "Epoch: 280. Loss: 0.5154730097099528\n",
            "Epoch: 290. Loss: 0.5152605691105161\n",
            "Epoch: 300. Loss: 0.5150716764543439\n",
            "Epoch: 310. Loss: 0.5149033628786589\n",
            "Epoch: 320. Loss: 0.5147530759850151\n",
            "Epoch: 330. Loss: 0.5146186152781445\n",
            "Epoch: 340. Loss: 0.5144980787489458\n",
            "Epoch: 350. Loss: 0.5143898184278081\n",
            "Epoch: 360. Loss: 0.5142924032186121\n",
            "Epoch: 370. Loss: 0.5142045876852017\n",
            "Epoch: 380. Loss: 0.5141252857356571\n",
            "Epoch: 390. Loss: 0.514053548359323\n",
            "Epoch: 400. Loss: 0.5139885447340611\n",
            "Epoch: 410. Loss: 0.5139295461485128\n",
            "Epoch: 420. Loss: 0.5138759122848774\n",
            "Epoch: 430. Loss: 0.5138270794880493\n",
            "Epoch: 440. Loss: 0.513782550711568\n",
            "Epoch: 450. Loss: 0.5137418868831346\n",
            "Epoch: 460. Loss: 0.513704699475054\n",
            "Epoch: 470. Loss: 0.5136706440998766\n",
            "Epoch: 480. Loss: 0.513639414980246\n",
            "Epoch: 490. Loss: 0.5136107401657329\n",
            "tensor(0.8121, dtype=torch.float64)\n",
            "2004-09-12 00:00:00\n",
            "Epoch: 0. Loss: 1.0373108231455501\n",
            "Epoch: 10. Loss: 0.8688706278782188\n",
            "Epoch: 20. Loss: 0.7552609180175828\n",
            "Epoch: 30. Loss: 0.6857643251876196\n",
            "Epoch: 40. Loss: 0.6441413066230328\n",
            "Epoch: 50. Loss: 0.6176907111270101\n",
            "Epoch: 60. Loss: 0.5993262699296994\n",
            "Epoch: 70. Loss: 0.5855390856475323\n",
            "Epoch: 80. Loss: 0.5745892872825035\n",
            "Epoch: 90. Loss: 0.5655661814377174\n",
            "Epoch: 100. Loss: 0.5579546057041234\n",
            "Epoch: 110. Loss: 0.5514368839715503\n",
            "Epoch: 120. Loss: 0.5458001668646368\n",
            "Epoch: 130. Loss: 0.5408913945089819\n",
            "Epoch: 140. Loss: 0.53659434181538\n",
            "Epoch: 150. Loss: 0.5328172394746065\n",
            "Epoch: 160. Loss: 0.5294856533174002\n",
            "Epoch: 170. Loss: 0.5265380952898534\n",
            "Epoch: 180. Loss: 0.5239231281309158\n",
            "Epoch: 190. Loss: 0.5215973359340758\n",
            "Epoch: 200. Loss: 0.519523829096629\n",
            "Epoch: 210. Loss: 0.5176711001849414\n",
            "Epoch: 220. Loss: 0.516012123600364\n",
            "Epoch: 230. Loss: 0.5145236328226939\n",
            "Epoch: 240. Loss: 0.5131855318849879\n",
            "Epoch: 250. Loss: 0.5119804111782751\n",
            "Epoch: 260. Loss: 0.5108931460139798\n",
            "Epoch: 270. Loss: 0.5099105618113007\n",
            "Epoch: 280. Loss: 0.5090211535073282\n",
            "Epoch: 290. Loss: 0.5082148494571603\n",
            "Epoch: 300. Loss: 0.5074828120689463\n",
            "Epoch: 310. Loss: 0.5068172689242857\n",
            "Epoch: 320. Loss: 0.5062113693043939\n",
            "Epoch: 330. Loss: 0.5056590619659572\n",
            "Epoch: 340. Loss: 0.5051549907481169\n",
            "Epoch: 350. Loss: 0.5046944051862904\n",
            "Epoch: 360. Loss: 0.5042730837907178\n",
            "Epoch: 370. Loss: 0.5038872680410079\n",
            "Epoch: 380. Loss: 0.5035336054704093\n",
            "Epoch: 390. Loss: 0.5032091004788336\n",
            "Epoch: 400. Loss: 0.5029110717327127\n",
            "Epoch: 410. Loss: 0.5026371151911788\n",
            "Epoch: 420. Loss: 0.502385071948721\n",
            "Epoch: 430. Loss: 0.5021530002099203\n",
            "Epoch: 440. Loss: 0.5019391508166002\n",
            "Epoch: 450. Loss: 0.5017419458353475\n",
            "Epoch: 460. Loss: 0.5015599597868602\n",
            "Epoch: 470. Loss: 0.5013919031603499\n",
            "Epoch: 480. Loss: 0.5012366079082617\n",
            "Epoch: 490. Loss: 0.5010930146604989\n",
            "tensor(0.7653, dtype=torch.float64)\n",
            "2004-09-19 00:00:00\n",
            "Epoch: 0. Loss: 1.1275021889802865\n",
            "Epoch: 10. Loss: 1.0017124068738672\n",
            "Epoch: 20. Loss: 0.8952838756048762\n",
            "Epoch: 30. Loss: 0.8076369575583751\n",
            "Epoch: 40. Loss: 0.7373358253794536\n",
            "Epoch: 50. Loss: 0.6822909076562784\n",
            "Epoch: 60. Loss: 0.6400746358559763\n",
            "Epoch: 70. Loss: 0.6082131948618661\n",
            "Epoch: 80. Loss: 0.5844083806232843\n",
            "Epoch: 90. Loss: 0.5666829540943904\n",
            "Epoch: 100. Loss: 0.5534435172373068\n",
            "Epoch: 110. Loss: 0.543471103009056\n",
            "Epoch: 120. Loss: 0.5358674894887868\n",
            "Epoch: 130. Loss: 0.5299863984164096\n",
            "Epoch: 140. Loss: 0.5253685343321683\n",
            "Epoch: 150. Loss: 0.5216885508163666\n",
            "Epoch: 160. Loss: 0.5187151523751972\n",
            "Epoch: 170. Loss: 0.516282482150908\n",
            "Epoch: 180. Loss: 0.5142701593170538\n",
            "Epoch: 190. Loss: 0.512589549275616\n",
            "Epoch: 200. Loss: 0.5111743717661398\n",
            "Epoch: 210. Loss: 0.5099742712912703\n",
            "Epoch: 220. Loss: 0.5089503923099882\n",
            "Epoch: 230. Loss: 0.5080723079932478\n",
            "Epoch: 240. Loss: 0.5073158650050396\n",
            "Epoch: 250. Loss: 0.5066616517785529\n",
            "Epoch: 260. Loss: 0.5060938947150451\n",
            "Epoch: 270. Loss: 0.5055996511044171\n",
            "Epoch: 280. Loss: 0.505168210218597\n",
            "Epoch: 290. Loss: 0.5047906423345138\n",
            "Epoch: 300. Loss: 0.5044594543068257\n",
            "Epoch: 310. Loss: 0.5041683229589499\n",
            "Epoch: 320. Loss: 0.5039118861074846\n",
            "Epoch: 330. Loss: 0.5036855768619205\n",
            "Epoch: 340. Loss: 0.5034854908538279\n",
            "Epoch: 350. Loss: 0.5033082788424842\n",
            "Epoch: 360. Loss: 0.5031510591101425\n",
            "Epoch: 370. Loss: 0.5030113454610166\n",
            "Epoch: 380. Loss: 0.5028869876483482\n",
            "Epoch: 390. Loss: 0.5027761217915447\n",
            "Epoch: 400. Loss: 0.5026771288905374\n",
            "Epoch: 410. Loss: 0.5025885999523061\n",
            "Epoch: 420. Loss: 0.502509306553123\n",
            "Epoch: 430. Loss: 0.5024381758962371\n",
            "Epoch: 440. Loss: 0.502374269607371\n",
            "Epoch: 450. Loss: 0.5023167656530727\n",
            "Epoch: 460. Loss: 0.5022649428794422\n",
            "Epoch: 470. Loss: 0.5022181677581807\n",
            "Epoch: 480. Loss: 0.5021758829985813\n",
            "Epoch: 490. Loss: 0.5021375977419246\n",
            "tensor(0.8284, dtype=torch.float64)\n",
            "2004-09-26 00:00:00\n",
            "Epoch: 0. Loss: 0.78362047185571\n",
            "Epoch: 10. Loss: 0.7080633367455632\n",
            "Epoch: 20. Loss: 0.6550129251067165\n",
            "Epoch: 30. Loss: 0.6194133866902922\n",
            "Epoch: 40. Loss: 0.5958260662038873\n",
            "Epoch: 50. Loss: 0.5799229194338029\n",
            "Epoch: 60. Loss: 0.5688065230580873\n",
            "Epoch: 70. Loss: 0.5607009683199102\n",
            "Epoch: 80. Loss: 0.5545519185423846\n",
            "Epoch: 90. Loss: 0.549730770740707\n",
            "Epoch: 100. Loss: 0.5458526498863958\n",
            "Epoch: 110. Loss: 0.5426724752778262\n",
            "Epoch: 120. Loss: 0.5400270709198715\n",
            "Epoch: 130. Loss: 0.5378028690456944\n",
            "Epoch: 140. Loss: 0.5359175727836147\n",
            "Epoch: 150. Loss: 0.5343094509039871\n",
            "Epoch: 160. Loss: 0.532930869485424\n",
            "Epoch: 170. Loss: 0.5317442321640616\n",
            "Epoch: 180. Loss: 0.5307193306391035\n",
            "Epoch: 190. Loss: 0.5298315488557069\n",
            "Epoch: 200. Loss: 0.5290606024751445\n",
            "Epoch: 210. Loss: 0.5283896261021858\n",
            "Epoch: 220. Loss: 0.5278044942981341\n",
            "Epoch: 230. Loss: 0.5272933048420783\n",
            "Epoch: 240. Loss: 0.526845977876939\n",
            "Epoch: 250. Loss: 0.5264539399530509\n",
            "Epoch: 260. Loss: 0.5261098716540714\n",
            "Epoch: 270. Loss: 0.5258075037523567\n",
            "Epoch: 280. Loss: 0.5255414510094134\n",
            "Epoch: 290. Loss: 0.5253070755847584\n",
            "Epoch: 300. Loss: 0.5251003740091418\n",
            "Epoch: 310. Loss: 0.5249178831030841\n",
            "Epoch: 320. Loss: 0.524756601260954\n",
            "Epoch: 330. Loss: 0.5246139222921828\n",
            "Epoch: 340. Loss: 0.5244875795927683\n",
            "Epoch: 350. Loss: 0.5243755988647777\n",
            "Epoch: 360. Loss: 0.5242762579456258\n",
            "Epoch: 370. Loss: 0.5241880525780941\n",
            "Epoch: 380. Loss: 0.524109667164748\n",
            "Epoch: 390. Loss: 0.5240399497199022\n",
            "Epoch: 400. Loss: 0.5239778903684091\n",
            "Epoch: 410. Loss: 0.5239226028506324\n",
            "Epoch: 420. Loss: 0.5238733085825402\n",
            "Epoch: 430. Loss: 0.523829322893166\n",
            "Epoch: 440. Loss: 0.5237900431219698\n",
            "Epoch: 450. Loss: 0.5237549383084545\n",
            "Epoch: 460. Loss: 0.5237235402477318\n",
            "Epoch: 470. Loss: 0.5236954357201554\n",
            "Epoch: 480. Loss: 0.5236702597319395\n",
            "Epoch: 490. Loss: 0.5236476896278017\n",
            "tensor(0.7759, dtype=torch.float64)\n",
            "2004-10-03 00:00:00\n",
            "Epoch: 0. Loss: 0.9947587731072424\n",
            "Epoch: 10. Loss: 0.884461276494047\n",
            "Epoch: 20. Loss: 0.8024883548167866\n",
            "Epoch: 30. Loss: 0.7430973328748571\n",
            "Epoch: 40. Loss: 0.6999489445578043\n",
            "Epoch: 50. Loss: 0.6678905554220651\n",
            "Epoch: 60. Loss: 0.6433754745599128\n",
            "Epoch: 70. Loss: 0.6241265138297754\n",
            "Epoch: 80. Loss: 0.6086908356975732\n",
            "Epoch: 90. Loss: 0.5961148299011\n",
            "Epoch: 100. Loss: 0.5857457503090693\n",
            "Epoch: 110. Loss: 0.5771175408750012\n",
            "Epoch: 120. Loss: 0.569885224756468\n",
            "Epoch: 130. Loss: 0.5637861069747999\n",
            "Epoch: 140. Loss: 0.558615807032975\n",
            "Epoch: 150. Loss: 0.5542127192446166\n",
            "Epoch: 160. Loss: 0.5504474653759669\n",
            "Epoch: 170. Loss: 0.5472154489325447\n",
            "Epoch: 180. Loss: 0.5444314298089125\n",
            "Epoch: 190. Loss: 0.5420254721775823\n",
            "Epoch: 200. Loss: 0.5399398597029448\n",
            "Epoch: 210. Loss: 0.5381267119795476\n",
            "Epoch: 220. Loss: 0.5365461208905716\n",
            "Epoch: 230. Loss: 0.5351646793373487\n",
            "Epoch: 240. Loss: 0.5339543102646751\n",
            "Epoch: 250. Loss: 0.5328913281388222\n",
            "Epoch: 260. Loss: 0.5319556820674785\n",
            "Epoch: 270. Loss: 0.5311303420025499\n",
            "Epoch: 280. Loss: 0.5304007984450133\n",
            "Epoch: 290. Loss: 0.5297546527502223\n",
            "Epoch: 300. Loss: 0.529181280162661\n",
            "Epoch: 310. Loss: 0.5286715515373944\n",
            "Epoch: 320. Loss: 0.5282176026445871\n",
            "Epoch: 330. Loss: 0.5278126422274095\n",
            "Epoch: 340. Loss: 0.5274507917550558\n",
            "Epoch: 350. Loss: 0.5271269512010972\n",
            "Epoch: 360. Loss: 0.5268366862719289\n",
            "Epoch: 370. Loss: 0.5265761333774318\n",
            "Epoch: 380. Loss: 0.5263419193266635\n",
            "Epoch: 390. Loss: 0.5261310932839608\n",
            "Epoch: 400. Loss: 0.5259410689648022\n",
            "Epoch: 410. Loss: 0.5257695754089848\n",
            "Epoch: 420. Loss: 0.5256146149587958\n",
            "Epoch: 430. Loss: 0.5254744273057397\n",
            "Epoch: 440. Loss: 0.5253474586618422\n",
            "Epoch: 450. Loss: 0.5252323352691157\n",
            "Epoch: 460. Loss: 0.5251278405902002\n",
            "Epoch: 470. Loss: 0.5250328956298435\n",
            "Epoch: 480. Loss: 0.5249465419250191\n",
            "Epoch: 490. Loss: 0.5248679268145515\n",
            "tensor(0.8806, dtype=torch.float64)\n",
            "2004-10-10 00:00:00\n",
            "Epoch: 0. Loss: 1.248410117052166\n",
            "Epoch: 10. Loss: 1.1234117452065853\n",
            "Epoch: 20. Loss: 1.0174406166284562\n",
            "Epoch: 30. Loss: 0.9292120163675499\n",
            "Epoch: 40. Loss: 0.8566478565777432\n",
            "Epoch: 50. Loss: 0.7974081716638527\n",
            "Epoch: 60. Loss: 0.749252361429708\n",
            "Epoch: 70. Loss: 0.7101940870609956\n",
            "Epoch: 80. Loss: 0.678536572152401\n",
            "Epoch: 90. Loss: 0.6528610485131462\n",
            "Epoch: 100. Loss: 0.6319999542014453\n",
            "Epoch: 110. Loss: 0.6150048818817728\n",
            "Epoch: 120. Loss: 0.6011131382779712\n",
            "Epoch: 130. Loss: 0.5897155519654715\n",
            "Epoch: 140. Loss: 0.5803274133429416\n",
            "Epoch: 150. Loss: 0.5725635219964093\n",
            "Epoch: 160. Loss: 0.5661175297267559\n",
            "Epoch: 170. Loss: 0.5607452666041425\n",
            "Epoch: 180. Loss: 0.5562515031781889\n",
            "Epoch: 190. Loss: 0.5524795464423802\n",
            "Epoch: 200. Loss: 0.5493031073474499\n",
            "Epoch: 210. Loss: 0.5466199574365829\n",
            "Epoch: 220. Loss: 0.5443469800440371\n",
            "Epoch: 230. Loss: 0.542416302514293\n",
            "Epoch: 240. Loss: 0.5407722645559573\n",
            "Epoch: 250. Loss: 0.5393690333835924\n",
            "Epoch: 260. Loss: 0.5381687200181595\n",
            "Epoch: 270. Loss: 0.5371398849753911\n",
            "Epoch: 280. Loss: 0.5362563475502804\n",
            "Epoch: 290. Loss: 0.5354962327415149\n",
            "Epoch: 300. Loss: 0.5348412049759729\n",
            "Epoch: 310. Loss: 0.534275849314754\n",
            "Epoch: 320. Loss: 0.5337871696171346\n",
            "Epoch: 330. Loss: 0.5333641798694388\n",
            "Epoch: 340. Loss: 0.5329975700530774\n",
            "Epoch: 350. Loss: 0.5326794319075028\n",
            "Epoch: 360. Loss: 0.5324030330237929\n",
            "Epoch: 370. Loss: 0.532162630096957\n",
            "Epoch: 380. Loss: 0.5319533140312437\n",
            "Epoch: 390. Loss: 0.53177088105466\n",
            "Epoch: 400. Loss: 0.5316117251490504\n",
            "Epoch: 410. Loss: 0.5314727480107528\n",
            "Epoch: 420. Loss: 0.5313512834777444\n",
            "Epoch: 430. Loss: 0.5312450339334427\n",
            "Epoch: 440. Loss: 0.5311520166566086\n",
            "Epoch: 450. Loss: 0.5310705184555438\n",
            "Epoch: 460. Loss: 0.5309990572219696\n",
            "Epoch: 470. Loss: 0.5309363492803706\n",
            "Epoch: 480. Loss: 0.5308812816037385\n",
            "Epoch: 490. Loss: 0.5308328881256248\n",
            "tensor(0.8262, dtype=torch.float64)\n",
            "2004-10-17 00:00:00\n",
            "Epoch: 0. Loss: 1.751202572610323\n",
            "Epoch: 10. Loss: 1.5423058937233265\n",
            "Epoch: 20. Loss: 1.3519407613953005\n",
            "Epoch: 30. Loss: 1.1843546994962633\n",
            "Epoch: 40. Loss: 1.043445196027612\n",
            "Epoch: 50. Loss: 0.9310159652483402\n",
            "Epoch: 60. Loss: 0.8453437091413568\n",
            "Epoch: 70. Loss: 0.781707962085467\n",
            "Epoch: 80. Loss: 0.7344749949991544\n",
            "Epoch: 90. Loss: 0.6988116925464578\n",
            "Epoch: 100. Loss: 0.6712313639603826\n",
            "Epoch: 110. Loss: 0.6494127235436666\n",
            "Epoch: 120. Loss: 0.6318385841638577\n",
            "Epoch: 130. Loss: 0.6174966116160038\n",
            "Epoch: 140. Loss: 0.6056835413675552\n",
            "Epoch: 150. Loss: 0.5958886925864079\n",
            "Epoch: 160. Loss: 0.5877266845772192\n",
            "Epoch: 170. Loss: 0.580898120587903\n",
            "Epoch: 180. Loss: 0.5751656684916365\n",
            "Epoch: 190. Loss: 0.5703386524718562\n",
            "Epoch: 200. Loss: 0.56626250558869\n",
            "Epoch: 210. Loss: 0.5628111544756028\n",
            "Epoch: 220. Loss: 0.5598812937456326\n",
            "Epoch: 230. Loss: 0.5573879598962878\n",
            "Epoch: 240. Loss: 0.5552610480756328\n",
            "Epoch: 250. Loss: 0.5534425400160928\n",
            "Epoch: 260. Loss: 0.5518842822339497\n",
            "Epoch: 270. Loss: 0.5505461967687723\n",
            "Epoch: 280. Loss: 0.5493948351772319\n",
            "Epoch: 290. Loss: 0.5484022065220103\n",
            "Epoch: 300. Loss: 0.5475448249108124\n",
            "Epoch: 310. Loss: 0.5468029334571899\n",
            "Epoch: 320. Loss: 0.5461598703462374\n",
            "Epoch: 330. Loss: 0.5456015496220551\n",
            "Epoch: 340. Loss: 0.5451160348012497\n",
            "Epoch: 350. Loss: 0.544693187772584\n",
            "Epoch: 360. Loss: 0.5443243789067101\n",
            "Epoch: 370. Loss: 0.54400224705796\n",
            "Epoch: 380. Loss: 0.5437205003389401\n",
            "Epoch: 390. Loss: 0.5434737503039385\n",
            "Epoch: 400. Loss: 0.5432573735805128\n",
            "Epoch: 410. Loss: 0.5430673961126549\n",
            "Epoch: 420. Loss: 0.5429003960809499\n",
            "Epoch: 430. Loss: 0.5427534222906097\n",
            "Epoch: 440. Loss: 0.5426239254030386\n",
            "Epoch: 450. Loss: 0.5425096998591107\n",
            "Epoch: 460. Loss: 0.5424088347251116\n",
            "Epoch: 470. Loss: 0.5423196720031532\n",
            "Epoch: 480. Loss: 0.5422407712009804\n",
            "Epoch: 490. Loss: 0.5421708791627201\n",
            "tensor(0.8074, dtype=torch.float64)\n",
            "2004-10-24 00:00:00\n",
            "Epoch: 0. Loss: 0.8736334156264058\n",
            "Epoch: 10. Loss: 0.786583349342022\n",
            "Epoch: 20. Loss: 0.7219152154937194\n",
            "Epoch: 30. Loss: 0.6748764823175828\n",
            "Epoch: 40. Loss: 0.6410239433865748\n",
            "Epoch: 50. Loss: 0.6167278650296518\n",
            "Epoch: 60. Loss: 0.5992456944248008\n",
            "Epoch: 70. Loss: 0.5865911394650806\n",
            "Epoch: 80. Loss: 0.5773558615892448\n",
            "Epoch: 90. Loss: 0.5705506220614105\n",
            "Epoch: 100. Loss: 0.5654824322326867\n",
            "Epoch: 110. Loss: 0.5616652150705072\n",
            "Epoch: 120. Loss: 0.5587567183358708\n",
            "Epoch: 130. Loss: 0.5565146080888556\n",
            "Epoch: 140. Loss: 0.5547661176863343\n",
            "Epoch: 150. Loss: 0.55338711374817\n",
            "Epoch: 160. Loss: 0.552287646456764\n",
            "Epoch: 170. Loss: 0.5514019476137582\n",
            "Epoch: 180. Loss: 0.5506814777399175\n",
            "Epoch: 190. Loss: 0.5500900669141996\n",
            "Epoch: 200. Loss: 0.5496004981252827\n",
            "Epoch: 210. Loss: 0.5491920889056467\n",
            "Epoch: 220. Loss: 0.5488489674747107\n",
            "Epoch: 230. Loss: 0.5485588348888405\n",
            "Epoch: 240. Loss: 0.5483120694251796\n",
            "Epoch: 250. Loss: 0.5481010735396071\n",
            "Epoch: 260. Loss: 0.5479197939249257\n",
            "Epoch: 270. Loss: 0.5477633659490563\n",
            "Epoch: 280. Loss: 0.5476278480962598\n",
            "Epoch: 290. Loss: 0.5475100220021198\n",
            "Epoch: 300. Loss: 0.5474072406396538\n",
            "Epoch: 310. Loss: 0.5473173121115618\n",
            "Epoch: 320. Loss: 0.5472384099671335\n",
            "Epoch: 330. Loss: 0.5471690034263121\n",
            "Epoch: 340. Loss: 0.5471078026568059\n",
            "Epoch: 350. Loss: 0.5470537155197824\n",
            "Epoch: 360. Loss: 0.5470058131193232\n",
            "Epoch: 370. Loss: 0.5469633021609915\n",
            "Epoch: 380. Loss: 0.5469255026162492\n",
            "Epoch: 390. Loss: 0.5468918295519171\n",
            "Epoch: 400. Loss: 0.5468617782529379\n",
            "Epoch: 410. Loss: 0.5468349119676398\n",
            "Epoch: 420. Loss: 0.5468108517557372\n",
            "Epoch: 430. Loss: 0.546789268033533\n",
            "Epoch: 440. Loss: 0.546769873497748\n",
            "Epoch: 450. Loss: 0.5467524171760126\n",
            "Epoch: 460. Loss: 0.546736679403424\n",
            "Epoch: 470. Loss: 0.5467224675644318\n",
            "Epoch: 480. Loss: 0.546709612470447\n",
            "Epoch: 490. Loss: 0.5466979652680423\n",
            "tensor(0.7552, dtype=torch.float64)\n",
            "2004-10-31 00:00:00\n",
            "Epoch: 0. Loss: 0.9723544428995702\n",
            "Epoch: 10. Loss: 0.8584587511834408\n",
            "Epoch: 20. Loss: 0.7652270925006044\n",
            "Epoch: 30. Loss: 0.6935197159981639\n",
            "Epoch: 40. Loss: 0.6419877262243637\n",
            "Epoch: 50. Loss: 0.6071500420025994\n",
            "Epoch: 60. Loss: 0.5845475168507069\n",
            "Epoch: 70. Loss: 0.5700853491006969\n",
            "Epoch: 80. Loss: 0.5607197505900926\n",
            "Epoch: 90. Loss: 0.5544660942015186\n",
            "Epoch: 100. Loss: 0.550119251396764\n",
            "Epoch: 110. Loss: 0.5469684092911572\n",
            "Epoch: 120. Loss: 0.5445948517324777\n",
            "Epoch: 130. Loss: 0.5427477583139003\n",
            "Epoch: 140. Loss: 0.5412725392607493\n",
            "Epoch: 150. Loss: 0.5400704436806707\n",
            "Epoch: 160. Loss: 0.5390758526154398\n",
            "Epoch: 170. Loss: 0.5382433887176036\n",
            "Epoch: 180. Loss: 0.5375404668718038\n",
            "Epoch: 190. Loss: 0.5369428859889515\n",
            "Epoch: 200. Loss: 0.5364321461134219\n",
            "Epoch: 210. Loss: 0.5359937637053451\n",
            "Epoch: 220. Loss: 0.5356161780605285\n",
            "Epoch: 230. Loss: 0.5352900171778485\n",
            "Epoch: 240. Loss: 0.535007588558556\n",
            "Epoch: 250. Loss: 0.5347625150694562\n",
            "Epoch: 260. Loss: 0.5345494672651933\n",
            "Epoch: 270. Loss: 0.5343639617995631\n",
            "Epoch: 280. Loss: 0.5342022064204757\n",
            "Epoch: 290. Loss: 0.5340609786674063\n",
            "Epoch: 300. Loss: 0.5339375295285695\n",
            "Epoch: 310. Loss: 0.5338295059664668\n",
            "Epoch: 320. Loss: 0.5337348879630194\n",
            "Epoch: 330. Loss: 0.5336519369098481\n",
            "Epoch: 340. Loss: 0.5335791529800182\n",
            "Epoch: 350. Loss: 0.5335152396901374\n",
            "Epoch: 360. Loss: 0.5334590742745992\n",
            "Epoch: 370. Loss: 0.5334096827972147\n",
            "Epoch: 380. Loss: 0.5333662191522975\n",
            "Epoch: 390. Loss: 0.5333279472793945\n",
            "Epoch: 400. Loss: 0.5332942260482129\n",
            "Epoch: 410. Loss: 0.5332644963732913\n",
            "Epoch: 420. Loss: 0.5332382701989413\n",
            "Epoch: 430. Loss: 0.5332151210592436\n",
            "Epoch: 440. Loss: 0.5331946759693061\n",
            "Epoch: 450. Loss: 0.5331766084454354\n",
            "Epoch: 460. Loss: 0.5331606324855049\n",
            "Epoch: 470. Loss: 0.5331464973682642\n",
            "Epoch: 480. Loss: 0.5331339831528659\n",
            "Epoch: 490. Loss: 0.5331228967784909\n",
            "tensor(0.8389, dtype=torch.float64)\n",
            "2004-11-07 00:00:00\n",
            "Epoch: 0. Loss: 1.4371074437122324\n",
            "Epoch: 10. Loss: 1.2948358612561992\n",
            "Epoch: 20. Loss: 1.1695629012118356\n",
            "Epoch: 30. Loss: 1.060893439201387\n",
            "Epoch: 40. Loss: 0.9680370489498642\n",
            "Epoch: 50. Loss: 0.889843139194118\n",
            "Epoch: 60. Loss: 0.8248553299249662\n",
            "Epoch: 70. Loss: 0.7714132101200414\n",
            "Epoch: 80. Loss: 0.7277909570902966\n",
            "Epoch: 90. Loss: 0.6923327474207034\n",
            "Epoch: 100. Loss: 0.6635491450357179\n",
            "Epoch: 110. Loss: 0.6401634021273325\n",
            "Epoch: 120. Loss: 0.6211171770029281\n",
            "Epoch: 130. Loss: 0.6055520486961677\n",
            "Epoch: 140. Loss: 0.5927807247460204\n",
            "Epoch: 150. Loss: 0.5822566319679715\n",
            "Epoch: 160. Loss: 0.5735461964953961\n",
            "Epoch: 170. Loss: 0.5663053770320571\n",
            "Epoch: 180. Loss: 0.560260593164702\n",
            "Epoch: 190. Loss: 0.5551935786598865\n",
            "Epoch: 200. Loss: 0.5509295032990437\n",
            "Epoch: 210. Loss: 0.5473277162577519\n",
            "Epoch: 220. Loss: 0.5442745486275565\n",
            "Epoch: 230. Loss: 0.5416777150458574\n",
            "Epoch: 240. Loss: 0.5394619502694187\n",
            "Epoch: 250. Loss: 0.5375655976344986\n",
            "Epoch: 260. Loss: 0.5359379315614413\n",
            "Epoch: 270. Loss: 0.5345370472562087\n",
            "Epoch: 280. Loss: 0.5333281900170684\n",
            "Epoch: 290. Loss: 0.5322824265177063\n",
            "Epoch: 300. Loss: 0.5313755832152686\n",
            "Epoch: 310. Loss: 0.5305873943258518\n",
            "Epoch: 320. Loss: 0.5299008149499959\n",
            "Epoch: 330. Loss: 0.5293014649344923\n",
            "Epoch: 340. Loss: 0.5287771766946531\n",
            "Epoch: 350. Loss: 0.5283176260728112\n",
            "Epoch: 360. Loss: 0.5279140298091594\n",
            "Epoch: 370. Loss: 0.5275588966763114\n",
            "Epoch: 380. Loss: 0.5272458220240237\n",
            "Epoch: 390. Loss: 0.5269693175795181\n",
            "Epoch: 400. Loss: 0.5267246699907042\n",
            "Epoch: 410. Loss: 0.5265078228894013\n",
            "Epoch: 420. Loss: 0.5263152782692075\n",
            "Epoch: 430. Loss: 0.5261440137787873\n",
            "Epoch: 440. Loss: 0.5259914131725977\n",
            "Epoch: 450. Loss: 0.5258552076732045\n",
            "Epoch: 460. Loss: 0.5257334264099535\n",
            "Epoch: 470. Loss: 0.5256243544292276\n",
            "Epoch: 480. Loss: 0.5255264970384503\n",
            "Epoch: 490. Loss: 0.5254385494623952\n",
            "tensor(0.8170, dtype=torch.float64)\n",
            "2004-11-14 00:00:00\n",
            "Epoch: 0. Loss: 1.0398821593458016\n",
            "Epoch: 10. Loss: 0.9133124485113447\n",
            "Epoch: 20. Loss: 0.8168956488512905\n",
            "Epoch: 30. Loss: 0.7455246914448002\n",
            "Epoch: 40. Loss: 0.6932370825027634\n",
            "Epoch: 50. Loss: 0.6548160404150286\n",
            "Epoch: 60. Loss: 0.6262926168102099\n",
            "Epoch: 70. Loss: 0.6048313977991912\n",
            "Epoch: 80. Loss: 0.5884524172290265\n",
            "Epoch: 90. Loss: 0.5757772950466898\n",
            "Epoch: 100. Loss: 0.5658402724972407\n",
            "Epoch: 110. Loss: 0.5579571660255903\n",
            "Epoch: 120. Loss: 0.5516367683318092\n",
            "Epoch: 130. Loss: 0.5465213453102806\n",
            "Epoch: 140. Loss: 0.5423465807202025\n",
            "Epoch: 150. Loss: 0.5389144159570155\n",
            "Epoch: 160. Loss: 0.5360744447612531\n",
            "Epoch: 170. Loss: 0.5337110147431116\n",
            "Epoch: 180. Loss: 0.531734168688169\n",
            "Epoch: 190. Loss: 0.5300731969423638\n",
            "Epoch: 200. Loss: 0.5286719864642391\n",
            "Epoch: 210. Loss: 0.5274856216953944\n",
            "Epoch: 220. Loss: 0.526477868825035\n",
            "Epoch: 230. Loss: 0.5256192914321868\n",
            "Epoch: 240. Loss: 0.5248858230388276\n",
            "Epoch: 250. Loss: 0.5242576743200733\n",
            "Epoch: 260. Loss: 0.5237184882664231\n",
            "Epoch: 270. Loss: 0.5232546810750343\n",
            "Epoch: 280. Loss: 0.5228549236025376\n",
            "Epoch: 290. Loss: 0.5225097302300399\n",
            "Epoch: 300. Loss: 0.5222111305546397\n",
            "Epoch: 310. Loss: 0.5219524054905185\n",
            "Epoch: 320. Loss: 0.5217278738529791\n",
            "Epoch: 330. Loss: 0.5215327188003475\n",
            "Epoch: 340. Loss: 0.521362845959491\n",
            "Epoch: 350. Loss: 0.5212147668967317\n",
            "Epoch: 360. Loss: 0.5210855029832893\n",
            "Epoch: 370. Loss: 0.5209725057613477\n",
            "Epoch: 380. Loss: 0.5208735907283314\n",
            "Epoch: 390. Loss: 0.5207868820845655\n",
            "Epoch: 400. Loss: 0.5207107664782155\n",
            "Epoch: 410. Loss: 0.5206438541644526\n",
            "Epoch: 420. Loss: 0.5205849462978615\n",
            "Epoch: 430. Loss: 0.520533007316694\n",
            "Epoch: 440. Loss: 0.5204871415686355\n",
            "Epoch: 450. Loss: 0.520446573480895\n",
            "Epoch: 460. Loss: 0.5204106307007846\n",
            "Epoch: 470. Loss: 0.5203787297327568\n",
            "Epoch: 480. Loss: 0.5203503636789732\n",
            "Epoch: 490. Loss: 0.5203250917566546\n",
            "tensor(0.8656, dtype=torch.float64)\n",
            "2004-11-21 00:00:00\n",
            "Epoch: 0. Loss: 1.1984181383172452\n",
            "Epoch: 10. Loss: 1.059082156079701\n",
            "Epoch: 20. Loss: 0.9364393779271454\n",
            "Epoch: 30. Loss: 0.8326515959593764\n",
            "Epoch: 40. Loss: 0.7491668147096963\n",
            "Epoch: 50. Loss: 0.685917830119403\n",
            "Epoch: 60. Loss: 0.6407612607145955\n",
            "Epoch: 70. Loss: 0.6099238329223583\n",
            "Epoch: 80. Loss: 0.5892562470380438\n",
            "Epoch: 90. Loss: 0.5752848602220164\n",
            "Epoch: 100. Loss: 0.565557079525751\n",
            "Epoch: 110. Loss: 0.5585048239439075\n",
            "Epoch: 120. Loss: 0.5531736257017298\n",
            "Epoch: 130. Loss: 0.548990729365613\n",
            "Epoch: 140. Loss: 0.5456088715896044\n",
            "Epoch: 150. Loss: 0.5428116133298594\n",
            "Epoch: 160. Loss: 0.5404586967767957\n",
            "Epoch: 170. Loss: 0.5384550766039807\n",
            "Epoch: 180. Loss: 0.5367333660655246\n",
            "Epoch: 190. Loss: 0.5352437587286158\n",
            "Epoch: 200. Loss: 0.5339481105241042\n",
            "Epoch: 210. Loss: 0.5328163578128382\n",
            "Epoch: 220. Loss: 0.531824269283931\n",
            "Epoch: 230. Loss: 0.5309519774690827\n",
            "Epoch: 240. Loss: 0.5301829794156382\n",
            "Epoch: 250. Loss: 0.5295034294144987\n",
            "Epoch: 260. Loss: 0.5289016203919171\n",
            "Epoch: 270. Loss: 0.5283675919174808\n",
            "Epoch: 280. Loss: 0.5278928264013751\n",
            "Epoch: 290. Loss: 0.5274700088540318\n",
            "Epoch: 300. Loss: 0.5270928338560331\n",
            "Epoch: 310. Loss: 0.5267558484951679\n",
            "Epoch: 320. Loss: 0.5264543232834695\n",
            "Epoch: 330. Loss: 0.526184145211424\n",
            "Epoch: 340. Loss: 0.5259417285556914\n",
            "Epoch: 350. Loss: 0.5257239400808557\n",
            "Epoch: 360. Loss: 0.5255280360151786\n",
            "Epoch: 370. Loss: 0.5253516087276777\n",
            "Epoch: 380. Loss: 0.5251925414476667\n",
            "Epoch: 390. Loss: 0.5250489696864028\n",
            "Epoch: 400. Loss: 0.5249192482692631\n",
            "Epoch: 410. Loss: 0.5248019230835567\n",
            "Epoch: 420. Loss: 0.5246957068041731\n",
            "Epoch: 430. Loss: 0.5245994579857639\n",
            "Epoch: 440. Loss: 0.5245121630127739\n",
            "Epoch: 450. Loss: 0.5244329204823569\n",
            "Epoch: 460. Loss: 0.524360927663899\n",
            "Epoch: 470. Loss: 0.5242954687354789\n",
            "Epoch: 480. Loss: 0.5242359045444359\n",
            "Epoch: 490. Loss: 0.5241816636781363\n",
            "tensor(0.8628, dtype=torch.float64)\n",
            "2004-11-28 00:00:00\n",
            "Epoch: 0. Loss: 1.016993622585333\n",
            "Epoch: 10. Loss: 0.8921717414343222\n",
            "Epoch: 20. Loss: 0.7875091302249841\n",
            "Epoch: 30. Loss: 0.7049354943219871\n",
            "Epoch: 40. Loss: 0.644316539395049\n",
            "Epoch: 50. Loss: 0.6028830540766504\n",
            "Epoch: 60. Loss: 0.5760502500699229\n",
            "Epoch: 70. Loss: 0.5590999026339173\n",
            "Epoch: 80. Loss: 0.548345166630107\n",
            "Epoch: 90. Loss: 0.541341211745351\n",
            "Epoch: 100. Loss: 0.5366015905296709\n",
            "Epoch: 110. Loss: 0.5332548263393764\n",
            "Epoch: 120. Loss: 0.5307928586266351\n",
            "Epoch: 130. Loss: 0.5289156160658522\n",
            "Epoch: 140. Loss: 0.5274414118740177\n",
            "Epoch: 150. Loss: 0.526256588230859\n",
            "Epoch: 160. Loss: 0.5252873294253944\n",
            "Epoch: 170. Loss: 0.5244837604146775\n",
            "Epoch: 180. Loss: 0.5238108399048012\n",
            "Epoch: 190. Loss: 0.523243037951914\n",
            "Epoch: 200. Loss: 0.5227611483235168\n",
            "Epoch: 210. Loss: 0.5223503251196369\n",
            "Epoch: 220. Loss: 0.5219988355116003\n",
            "Epoch: 230. Loss: 0.5216972409842923\n",
            "Epoch: 240. Loss: 0.5214378415835841\n",
            "Epoch: 250. Loss: 0.5212142861400334\n",
            "Epoch: 260. Loss: 0.521021290380601\n",
            "Epoch: 270. Loss: 0.5208544273409993\n",
            "Epoch: 280. Loss: 0.5207099677226666\n",
            "Epoch: 290. Loss: 0.5205847557702237\n",
            "Epoch: 300. Loss: 0.5204761111012969\n",
            "Epoch: 310. Loss: 0.5203817499619102\n",
            "Epoch: 320. Loss: 0.520299721332093\n",
            "Epoch: 330. Loss: 0.520228354590492\n",
            "Epoch: 340. Loss: 0.5201662163137752\n",
            "Epoch: 350. Loss: 0.5201120743870309\n",
            "Epoch: 360. Loss: 0.5200648680274624\n",
            "Epoch: 370. Loss: 0.5200236826330313\n",
            "Epoch: 380. Loss: 0.5199877285970488\n",
            "Epoch: 390. Loss: 0.5199563234029108\n",
            "Epoch: 400. Loss: 0.519928876446143\n",
            "Epoch: 410. Loss: 0.5199048761344246\n",
            "Epoch: 420. Loss: 0.5198838788978506\n",
            "Epoch: 430. Loss: 0.5198654998066436\n",
            "Epoch: 440. Loss: 0.5198494045457192\n",
            "Epoch: 450. Loss: 0.5198353025377594\n",
            "Epoch: 460. Loss: 0.5198229410408826\n",
            "Epoch: 470. Loss: 0.5198121000752206\n",
            "Epoch: 480. Loss: 0.5198025880559713\n",
            "Epoch: 490. Loss: 0.5197942380297267\n",
            "tensor(0.6762, dtype=torch.float64)\n",
            "2004-12-05 00:00:00\n",
            "Epoch: 0. Loss: 0.9544204458253134\n",
            "Epoch: 10. Loss: 0.8636282352294041\n",
            "Epoch: 20. Loss: 0.7903472179080882\n",
            "Epoch: 30. Loss: 0.7325502182823566\n",
            "Epoch: 40. Loss: 0.6876080473938625\n",
            "Epoch: 50. Loss: 0.6528407867357975\n",
            "Epoch: 60. Loss: 0.6258915328614431\n",
            "Epoch: 70. Loss: 0.6048675574588652\n",
            "Epoch: 80. Loss: 0.5883247796429313\n",
            "Epoch: 90. Loss: 0.5751877336324852\n",
            "Epoch: 100. Loss: 0.5646611398165174\n",
            "Epoch: 110. Loss: 0.5561552947549276\n",
            "Epoch: 120. Loss: 0.5492294983868686\n",
            "Epoch: 130. Loss: 0.5435510830530407\n",
            "Epoch: 140. Loss: 0.5388662388667288\n",
            "Epoch: 150. Loss: 0.5349792817881468\n",
            "Epoch: 160. Loss: 0.531737839721405\n",
            "Epoch: 170. Loss: 0.5290221697045447\n",
            "Epoch: 180. Loss: 0.5267373711839084\n",
            "Epoch: 190. Loss: 0.5248076468321783\n",
            "Epoch: 200. Loss: 0.5231720260681851\n",
            "Epoch: 210. Loss: 0.521781145067255\n",
            "Epoch: 220. Loss: 0.5205947983159065\n",
            "Epoch: 230. Loss: 0.5195800596626711\n",
            "Epoch: 240. Loss: 0.5187098280205608\n",
            "Epoch: 250. Loss: 0.5179616927646373\n",
            "Epoch: 260. Loss: 0.5173170419828165\n",
            "Epoch: 270. Loss: 0.5167603567670342\n",
            "Epoch: 280. Loss: 0.5162786491490203\n",
            "Epoch: 290. Loss: 0.5158610117659815\n",
            "Epoch: 300. Loss: 0.5154982550332615\n",
            "Epoch: 310. Loss: 0.5151826132964751\n",
            "Epoch: 320. Loss: 0.514907505688609\n",
            "Epoch: 330. Loss: 0.5146673406188768\n",
            "Epoch: 340. Loss: 0.5144573552479919\n",
            "Epoch: 350. Loss: 0.5142734831589764\n",
            "Epoch: 360. Loss: 0.5141122448586518\n",
            "Epoch: 370. Loss: 0.5139706568485224\n",
            "Epoch: 380. Loss: 0.5138461558629499\n",
            "Epoch: 390. Loss: 0.513736535545277\n",
            "Epoch: 400. Loss: 0.5136398933621863\n",
            "Epoch: 410. Loss: 0.513554585975711\n",
            "Epoch: 420. Loss: 0.5134791916255936\n",
            "Epoch: 430. Loss: 0.513412478340967\n",
            "Epoch: 440. Loss: 0.5133533770140094\n",
            "Epoch: 450. Loss: 0.5133009585404279\n",
            "Epoch: 460. Loss: 0.5132544143709517\n",
            "Epoch: 470. Loss: 0.5132130399312003\n",
            "Epoch: 480. Loss: 0.5131762204595522\n",
            "Epoch: 490. Loss: 0.5131434188881298\n",
            "tensor(0.8345, dtype=torch.float64)\n",
            "2004-12-12 00:00:00\n",
            "Epoch: 0. Loss: 0.6938168785651345\n",
            "Epoch: 10. Loss: 0.6481837981641728\n",
            "Epoch: 20. Loss: 0.6157992289017657\n",
            "Epoch: 30. Loss: 0.593036562835631\n",
            "Epoch: 40. Loss: 0.5769429808522976\n",
            "Epoch: 50. Loss: 0.5653654768581475\n",
            "Epoch: 60. Loss: 0.5568324488794675\n",
            "Epoch: 70. Loss: 0.5503716386789536\n",
            "Epoch: 80. Loss: 0.5453486447992458\n",
            "Epoch: 90. Loss: 0.5413484090992827\n",
            "Epoch: 100. Loss: 0.53809578898693\n",
            "Epoch: 110. Loss: 0.5354046885409249\n",
            "Epoch: 120. Loss: 0.5331461390662798\n",
            "Epoch: 130. Loss: 0.5312283781235878\n",
            "Epoch: 140. Loss: 0.5295843635869846\n",
            "Epoch: 150. Loss: 0.528163861968595\n",
            "Epoch: 160. Loss: 0.5269283559898934\n",
            "Epoch: 170. Loss: 0.5258477033490974\n",
            "Epoch: 180. Loss: 0.5248978965702384\n",
            "Epoch: 190. Loss: 0.5240595259793355\n",
            "Epoch: 200. Loss: 0.523316699879391\n",
            "Epoch: 210. Loss: 0.5226562680339345\n",
            "Epoch: 220. Loss: 0.5220672507144389\n",
            "Epoch: 230. Loss: 0.5215404101689031\n",
            "Epoch: 240. Loss: 0.5210679229587534\n",
            "Epoch: 250. Loss: 0.5206431252745125\n",
            "Epoch: 260. Loss: 0.5202603121249774\n",
            "Epoch: 270. Loss: 0.5199145770396281\n",
            "Epoch: 280. Loss: 0.5196016827501417\n",
            "Epoch: 290. Loss: 0.5193179559137213\n",
            "Epoch: 300. Loss: 0.5190602007376496\n",
            "Epoch: 310. Loss: 0.5188256276315825\n",
            "Epoch: 320. Loss: 0.5186117939245104\n",
            "Epoch: 330. Loss: 0.5184165543491248\n",
            "Epoch: 340. Loss: 0.518238019491399\n",
            "Epoch: 350. Loss: 0.5180745207769105\n",
            "Epoch: 360. Loss: 0.5179245808514604\n",
            "Epoch: 370. Loss: 0.5177868884351383\n",
            "Epoch: 380. Loss: 0.5176602769025254\n",
            "Epoch: 390. Loss: 0.5175437059789472\n",
            "Epoch: 400. Loss: 0.5174362460520808\n",
            "Epoch: 410. Loss: 0.5173370646860841\n",
            "Epoch: 420. Loss: 0.5172454149964295\n",
            "Epoch: 430. Loss: 0.5171606256013505\n",
            "Epoch: 440. Loss: 0.5170820919129716\n",
            "Epoch: 450. Loss: 0.5170092685698894\n",
            "Epoch: 460. Loss: 0.5169416628448601\n",
            "Epoch: 470. Loss: 0.5168788288876152\n",
            "Epoch: 480. Loss: 0.5168203626847048\n",
            "Epoch: 490. Loss: 0.5167658976364676\n",
            "tensor(0.8301, dtype=torch.float64)\n",
            "2004-12-19 00:00:00\n",
            "Epoch: 0. Loss: 0.7876395242506616\n",
            "Epoch: 10. Loss: 0.7375887248002604\n",
            "Epoch: 20. Loss: 0.6966571467243095\n",
            "Epoch: 30. Loss: 0.6634357034886704\n",
            "Epoch: 40. Loss: 0.6365969017372943\n",
            "Epoch: 50. Loss: 0.6149568079515463\n",
            "Epoch: 60. Loss: 0.5975038093022488\n",
            "Epoch: 70. Loss: 0.5834004583895015\n",
            "Epoch: 80. Loss: 0.5719685702594928\n",
            "Epoch: 90. Loss: 0.562666661877788\n",
            "Epoch: 100. Loss: 0.5550659007787458\n",
            "Epoch: 110. Loss: 0.5488279195407473\n",
            "Epoch: 120. Loss: 0.5436858749875386\n",
            "Epoch: 130. Loss: 0.5394289901011575\n",
            "Epoch: 140. Loss: 0.5358902711346413\n",
            "Epoch: 150. Loss: 0.5329368974040571\n",
            "Epoch: 160. Loss: 0.5304627637331741\n",
            "Epoch: 170. Loss: 0.5283827134732816\n",
            "Epoch: 180. Loss: 0.5266280804632752\n",
            "Epoch: 190. Loss: 0.525143237006253\n",
            "Epoch: 200. Loss: 0.5238829127495347\n",
            "Epoch: 210. Loss: 0.5228101042441823\n",
            "Epoch: 220. Loss: 0.5218944379036896\n",
            "Epoch: 230. Loss: 0.5211108820408815\n",
            "Epoch: 240. Loss: 0.5204387286928722\n",
            "Epoch: 250. Loss: 0.519860784854511\n",
            "Epoch: 260. Loss: 0.5193627270021376\n",
            "Epoch: 270. Loss: 0.5189325835499163\n",
            "Epoch: 280. Loss: 0.5185603180161947\n",
            "Epoch: 290. Loss: 0.5182374918462823\n",
            "Epoch: 300. Loss: 0.5179569905332498\n",
            "Epoch: 310. Loss: 0.5177128002666224\n",
            "Epoch: 320. Loss: 0.5174998250931871\n",
            "Epoch: 330. Loss: 0.5173137366979813\n",
            "Epoch: 340. Loss: 0.5171508505587195\n",
            "Epoch: 350. Loss: 0.5170080235072418\n",
            "Epoch: 360. Loss: 0.5168825687324631\n",
            "Epoch: 370. Loss: 0.5167721850452905\n",
            "Epoch: 380. Loss: 0.5166748978459368\n",
            "Epoch: 390. Loss: 0.5165890097251213\n",
            "Epoch: 400. Loss: 0.5165130590212909\n",
            "Epoch: 410. Loss: 0.5164457849679672\n",
            "Epoch: 420. Loss: 0.516386098315478\n",
            "Epoch: 430. Loss: 0.5163330565126611\n",
            "Epoch: 440. Loss: 0.5162858426967624\n",
            "Epoch: 450. Loss: 0.5162437478715886\n",
            "Epoch: 460. Loss: 0.516206155761214\n",
            "Epoch: 470. Loss: 0.5161725299140499\n",
            "Epoch: 480. Loss: 0.5161424027037333\n",
            "Epoch: 490. Loss: 0.5161153659321119\n",
            "tensor(0.8983, dtype=torch.float64)\n",
            "2004-12-26 00:00:00\n",
            "Epoch: 0. Loss: 1.512643464859564\n",
            "Epoch: 10. Loss: 1.3269616162097608\n",
            "Epoch: 20. Loss: 1.1708613016736065\n",
            "Epoch: 30. Loss: 1.0432042884328785\n",
            "Epoch: 40. Loss: 0.9406207816162717\n",
            "Epoch: 50. Loss: 0.8587907411758275\n",
            "Epoch: 60. Loss: 0.7935361012530912\n",
            "Epoch: 70. Loss: 0.7413463673744769\n",
            "Epoch: 80. Loss: 0.6994559196133648\n",
            "Epoch: 90. Loss: 0.6657250586442303\n",
            "Epoch: 100. Loss: 0.6384903409554545\n",
            "Epoch: 110. Loss: 0.6164442913542343\n",
            "Epoch: 120. Loss: 0.5985502823903751\n",
            "Epoch: 130. Loss: 0.583982874623637\n",
            "Epoch: 140. Loss: 0.5720841205600091\n",
            "Epoch: 150. Loss: 0.5623298611968305\n",
            "Epoch: 160. Loss: 0.5543028336568242\n",
            "Epoch: 170. Loss: 0.5476709338531393\n",
            "Epoch: 180. Loss: 0.5421696568478132\n",
            "Epoch: 190. Loss: 0.5375880046388012\n",
            "Epoch: 200. Loss: 0.5337572638977844\n",
            "Epoch: 210. Loss: 0.530542128519573\n",
            "Epoch: 220. Loss: 0.5278337105125677\n",
            "Epoch: 230. Loss: 0.5255440529744516\n",
            "Epoch: 240. Loss: 0.5236018268686279\n",
            "Epoch: 250. Loss: 0.5219489549103631\n",
            "Epoch: 260. Loss: 0.5205379588307057\n",
            "Epoch: 270. Loss: 0.519329870119242\n",
            "Epoch: 280. Loss: 0.5182925796674328\n",
            "Epoch: 290. Loss: 0.5173995296754014\n",
            "Epoch: 300. Loss: 0.5166286730162305\n",
            "Epoch: 310. Loss: 0.5159616421735913\n",
            "Epoch: 320. Loss: 0.5153830829227345\n",
            "Epoch: 330. Loss: 0.5148801179715554\n",
            "Epoch: 340. Loss: 0.514441913505643\n",
            "Epoch: 350. Loss: 0.5140593275283912\n",
            "Epoch: 360. Loss: 0.5137246234718583\n",
            "Epoch: 370. Loss: 0.5134312360964497\n",
            "Epoch: 380. Loss: 0.513173579442379\n",
            "Epoch: 390. Loss: 0.5129468887295102\n",
            "Epoch: 400. Loss: 0.5127470897664542\n",
            "Epoch: 410. Loss: 0.5125706907325945\n",
            "Epoch: 420. Loss: 0.5124146922203558\n",
            "Epoch: 430. Loss: 0.5122765122323266\n",
            "Epoch: 440. Loss: 0.5121539234669421\n",
            "Epoch: 450. Loss: 0.5120450007342474\n",
            "Epoch: 460. Loss: 0.5119480767482769\n",
            "Epoch: 470. Loss: 0.511861704866775\n",
            "Epoch: 480. Loss: 0.5117846276094163\n",
            "Epoch: 490. Loss: 0.5117157499956264\n",
            "tensor(0.6919, dtype=torch.float64)\n",
            "2005-01-02 00:00:00\n",
            "Epoch: 0. Loss: 1.428089751243728\n",
            "Epoch: 10. Loss: 1.28545400730066\n",
            "Epoch: 20. Loss: 1.1539325404595933\n",
            "Epoch: 30. Loss: 1.0352531236013276\n",
            "Epoch: 40. Loss: 0.9311644402077742\n",
            "Epoch: 50. Loss: 0.8430263540747457\n",
            "Epoch: 60. Loss: 0.7712339609386876\n",
            "Epoch: 70. Loss: 0.7148644545334348\n",
            "Epoch: 80. Loss: 0.6718590809046981\n",
            "Epoch: 90. Loss: 0.639596092842171\n",
            "Epoch: 100. Loss: 0.615480112835941\n",
            "Epoch: 110. Loss: 0.5973085569943303\n",
            "Epoch: 120. Loss: 0.5833905940103801\n",
            "Epoch: 130. Loss: 0.572507437451407\n",
            "Epoch: 140. Loss: 0.5638107132009348\n",
            "Epoch: 150. Loss: 0.5567181020226729\n",
            "Epoch: 160. Loss: 0.550829456875748\n",
            "Epoch: 170. Loss: 0.5458665933903349\n",
            "Epoch: 180. Loss: 0.5416324994512058\n",
            "Epoch: 190. Loss: 0.5379844700503145\n",
            "Epoch: 200. Loss: 0.5348166011423646\n",
            "Epoch: 210. Loss: 0.5320483763550645\n",
            "Epoch: 220. Loss: 0.5296171663769678\n",
            "Epoch: 230. Loss: 0.5274732342698841\n",
            "Epoch: 240. Loss: 0.5255763529657842\n",
            "Epoch: 250. Loss: 0.5238934698363291\n",
            "Epoch: 260. Loss: 0.5223970602849164\n",
            "Epoch: 270. Loss: 0.5210639419779673\n",
            "Epoch: 280. Loss: 0.5198744025575041\n",
            "Epoch: 290. Loss: 0.5188115447945953\n",
            "Epoch: 300. Loss: 0.5178607855649068\n",
            "Epoch: 310. Loss: 0.5170094658034758\n",
            "Epoch: 320. Loss: 0.5162465420738701\n",
            "Epoch: 330. Loss: 0.515562339253857\n",
            "Epoch: 340. Loss: 0.5149483497636856\n",
            "Epoch: 350. Loss: 0.5143970687865321\n",
            "Epoch: 360. Loss: 0.5139018577105153\n",
            "Epoch: 370. Loss: 0.5134568299760127\n",
            "Epoch: 380. Loss: 0.5130567549097536\n",
            "Epoch: 390. Loss: 0.5126969761435772\n",
            "Epoch: 400. Loss: 0.5123733419664965\n",
            "Epoch: 410. Loss: 0.5120821455213171\n",
            "Epoch: 420. Loss: 0.5118200731842516\n",
            "Epoch: 430. Loss: 0.5115841597941693\n",
            "Epoch: 440. Loss: 0.5113717496529291\n",
            "Epoch: 450. Loss: 0.511180462417919\n",
            "Epoch: 460. Loss: 0.5110081631656818\n",
            "Epoch: 470. Loss: 0.5108529360310882\n",
            "Epoch: 480. Loss: 0.510713060927142\n",
            "Epoch: 490. Loss: 0.5105869929316466\n",
            "tensor(0.7209, dtype=torch.float64)\n",
            "2005-01-09 00:00:00\n",
            "Epoch: 0. Loss: 1.1477280789933453\n",
            "Epoch: 10. Loss: 1.0256765260868195\n",
            "Epoch: 20. Loss: 0.920535915086901\n",
            "Epoch: 30. Loss: 0.8333909156380208\n",
            "Epoch: 40. Loss: 0.7639466431916554\n",
            "Epoch: 50. Loss: 0.7103984128544293\n",
            "Epoch: 60. Loss: 0.6699220033432557\n",
            "Epoch: 70. Loss: 0.6394793561521418\n",
            "Epoch: 80. Loss: 0.616427685547916\n",
            "Epoch: 90. Loss: 0.5987398473851903\n",
            "Epoch: 100. Loss: 0.5849601082008231\n",
            "Epoch: 110. Loss: 0.5740686764894857\n",
            "Epoch: 120. Loss: 0.5653505507510822\n",
            "Epoch: 130. Loss: 0.558297082530343\n",
            "Epoch: 140. Loss: 0.5525390893753632\n",
            "Epoch: 150. Loss: 0.5478030023698239\n",
            "Epoch: 160. Loss: 0.543882212381081\n",
            "Epoch: 170. Loss: 0.5406180905998997\n",
            "Epoch: 180. Loss: 0.5378871418866714\n",
            "Epoch: 190. Loss: 0.53559209600387\n",
            "Epoch: 200. Loss: 0.5336555819028844\n",
            "Epoch: 210. Loss: 0.5320155387092727\n",
            "Epoch: 220. Loss: 0.530621823712626\n",
            "Epoch: 230. Loss: 0.5294336646975979\n",
            "Epoch: 240. Loss: 0.528417720267777\n",
            "Epoch: 250. Loss: 0.5275465858872502\n",
            "Epoch: 260. Loss: 0.5267976317372187\n",
            "Epoch: 270. Loss: 0.5261520908622598\n",
            "Epoch: 280. Loss: 0.5255943382560234\n",
            "Epoch: 290. Loss: 0.5251113170423369\n",
            "Epoch: 300. Loss: 0.5246920789510182\n",
            "Epoch: 310. Loss: 0.5243274142793447\n",
            "Epoch: 320. Loss: 0.524009552394246\n",
            "Epoch: 330. Loss: 0.5237319181855126\n",
            "Epoch: 340. Loss: 0.5234889331492436\n",
            "Epoch: 350. Loss: 0.5232758522572297\n",
            "Epoch: 360. Loss: 0.5230886296597241\n",
            "Epoch: 370. Loss: 0.5229238077249119\n",
            "Epoch: 380. Loss: 0.5227784250463885\n",
            "Epoch: 390. Loss: 0.5226499399293535\n",
            "Epoch: 400. Loss: 0.5225361665557257\n",
            "Epoch: 410. Loss: 0.5224352215718797\n",
            "Epoch: 420. Loss: 0.522345479273235\n",
            "Epoch: 430. Loss: 0.5222655339025701\n",
            "Epoch: 440. Loss: 0.5221941678528318\n",
            "Epoch: 450. Loss: 0.5221303247850735\n",
            "Epoch: 460. Loss: 0.5220730868493357\n",
            "Epoch: 470. Loss: 0.5220216553396124\n",
            "Epoch: 480. Loss: 0.521975334230403\n",
            "Epoch: 490. Loss: 0.5219335161371452\n",
            "tensor(0.7757, dtype=torch.float64)\n",
            "2005-01-16 00:00:00\n",
            "Epoch: 0. Loss: 0.9005445779929873\n",
            "Epoch: 10. Loss: 0.7925782202319781\n",
            "Epoch: 20. Loss: 0.7139869349800894\n",
            "Epoch: 30. Loss: 0.6590884703650771\n",
            "Epoch: 40. Loss: 0.6214908033338258\n",
            "Epoch: 50. Loss: 0.5957937426610256\n",
            "Epoch: 60. Loss: 0.5780576390952415\n",
            "Epoch: 70. Loss: 0.5656074616259839\n",
            "Epoch: 80. Loss: 0.5566837401116069\n",
            "Epoch: 90. Loss: 0.5501416236411456\n",
            "Epoch: 100. Loss: 0.5452354585131658\n",
            "Epoch: 110. Loss: 0.5414755858381186\n",
            "Epoch: 120. Loss: 0.5385362415232645\n",
            "Epoch: 130. Loss: 0.5361971424802064\n",
            "Epoch: 140. Loss: 0.5343065626259039\n",
            "Epoch: 150. Loss: 0.5327579186978264\n",
            "Epoch: 160. Loss: 0.5314748112296044\n",
            "Epoch: 170. Loss: 0.5304013666608479\n",
            "Epoch: 180. Loss: 0.529495922599117\n",
            "Epoch: 190. Loss: 0.5287268396685549\n",
            "Epoch: 200. Loss: 0.5280696804738387\n",
            "Epoch: 210. Loss: 0.5275052781055011\n",
            "Epoch: 220. Loss: 0.5270183911519828\n",
            "Epoch: 230. Loss: 0.5265967509345294\n",
            "Epoch: 240. Loss: 0.5262303749777566\n",
            "Epoch: 250. Loss: 0.5259110640093944\n",
            "Epoch: 260. Loss: 0.525632027484325\n",
            "Epoch: 270. Loss: 0.5253876005488833\n",
            "Epoch: 280. Loss: 0.5251730270873487\n",
            "Epoch: 290. Loss: 0.5249842912575051\n",
            "Epoch: 300. Loss: 0.5248179851289512\n",
            "Epoch: 310. Loss: 0.5246712035749702\n",
            "Epoch: 320. Loss: 0.5245414600040248\n",
            "Epoch: 330. Loss: 0.5244266182165364\n",
            "Epoch: 340. Loss: 0.5243248368751828\n",
            "Epoch: 350. Loss: 0.5242345239394778\n",
            "Epoch: 360. Loss: 0.5241542990423714\n",
            "Epoch: 370. Loss: 0.5240829622482701\n",
            "Epoch: 380. Loss: 0.5240194679760386\n",
            "Epoch: 390. Loss: 0.5239629031301117\n",
            "Epoch: 400. Loss: 0.5239124686807575\n",
            "Epoch: 410. Loss: 0.5238674640869515\n",
            "Epoch: 420. Loss: 0.5238272740738139\n",
            "Epoch: 430. Loss: 0.5237913573694349\n",
            "Epoch: 440. Loss: 0.523759237079298\n",
            "Epoch: 450. Loss: 0.5237304924348863\n",
            "Epoch: 460. Loss: 0.5237047516997978\n",
            "Epoch: 470. Loss: 0.5236816860543398\n",
            "Epoch: 480. Loss: 0.5236610043100586\n",
            "Epoch: 490. Loss: 0.5236424483304596\n",
            "tensor(0.7778, dtype=torch.float64)\n",
            "2005-01-23 00:00:00\n",
            "Epoch: 0. Loss: 1.1966859304685151\n",
            "Epoch: 10. Loss: 1.0831983783773227\n",
            "Epoch: 20. Loss: 0.9817162305241282\n",
            "Epoch: 30. Loss: 0.8933793553981714\n",
            "Epoch: 40. Loss: 0.8187104986435622\n",
            "Epoch: 50. Loss: 0.7574152228682801\n",
            "Epoch: 60. Loss: 0.7084252967017262\n",
            "Epoch: 70. Loss: 0.6701472814983113\n",
            "Epoch: 80. Loss: 0.6407661432455254\n",
            "Epoch: 90. Loss: 0.6184919581326066\n",
            "Epoch: 100. Loss: 0.6017186900747611\n",
            "Epoch: 110. Loss: 0.5891029383798378\n",
            "Epoch: 120. Loss: 0.5795802617054461\n",
            "Epoch: 130. Loss: 0.5723405421291796\n",
            "Epoch: 140. Loss: 0.5667837980345222\n",
            "Epoch: 150. Loss: 0.5624726327989236\n",
            "Epoch: 160. Loss: 0.5590902480529694\n",
            "Epoch: 170. Loss: 0.5564071128046386\n",
            "Epoch: 180. Loss: 0.5542560820829905\n",
            "Epoch: 190. Loss: 0.5525144597715996\n",
            "Epoch: 200. Loss: 0.5510912981927695\n",
            "Epoch: 210. Loss: 0.5499184689465546\n",
            "Epoch: 220. Loss: 0.5489443852730564\n",
            "Epoch: 230. Loss: 0.5481295688026564\n",
            "Epoch: 240. Loss: 0.5474434960949779\n",
            "Epoch: 250. Loss: 0.5468623356148855\n",
            "Epoch: 260. Loss: 0.5463673079368314\n",
            "Epoch: 270. Loss: 0.5459434856071314\n",
            "Epoch: 280. Loss: 0.5455789059622702\n",
            "Epoch: 290. Loss: 0.545263908844981\n",
            "Epoch: 300. Loss: 0.5449906375096905\n",
            "Epoch: 310. Loss: 0.544752659083588\n",
            "Epoch: 320. Loss: 0.5445446734414899\n",
            "Epoch: 330. Loss: 0.544362288059235\n",
            "Epoch: 340. Loss: 0.5442018425328189\n",
            "Epoch: 350. Loss: 0.5440602707950143\n",
            "Epoch: 360. Loss: 0.5439349921721264\n",
            "Epoch: 370. Loss: 0.5438238246709567\n",
            "Epoch: 380. Loss: 0.5437249155237472\n",
            "Epoch: 390. Loss: 0.5436366852222595\n",
            "Epoch: 400. Loss: 0.5435577821635114\n",
            "Epoch: 410. Loss: 0.543487045695023\n",
            "Epoch: 420. Loss: 0.5434234758477016\n",
            "Epoch: 430. Loss: 0.5433662084233079\n",
            "Epoch: 440. Loss: 0.5433144943921975\n",
            "Epoch: 450. Loss: 0.5432676827785644\n",
            "Epoch: 460. Loss: 0.543225206381384\n",
            "Epoch: 470. Loss: 0.5431865698119966\n",
            "Epoch: 480. Loss: 0.543151339432895\n",
            "Epoch: 490. Loss: 0.5431191348636072\n",
            "tensor(0.8232, dtype=torch.float64)\n",
            "2005-01-30 00:00:00\n",
            "Epoch: 0. Loss: 0.8139761157552973\n",
            "Epoch: 10. Loss: 0.7556214739099986\n",
            "Epoch: 20. Loss: 0.7078530777318213\n",
            "Epoch: 30. Loss: 0.6695737347584347\n",
            "Epoch: 40. Loss: 0.639499470828769\n",
            "Epoch: 50. Loss: 0.6162529106935293\n",
            "Epoch: 60. Loss: 0.5984902713367636\n",
            "Epoch: 70. Loss: 0.585007406164308\n",
            "Epoch: 80. Loss: 0.5747959866287258\n",
            "Epoch: 90. Loss: 0.5670525279565785\n",
            "Epoch: 100. Loss: 0.561158056800383\n",
            "Epoch: 110. Loss: 0.556645832174812\n",
            "Epoch: 120. Loss: 0.5531681958101077\n",
            "Epoch: 130. Loss: 0.5504676983003637\n",
            "Epoch: 140. Loss: 0.5483539670693751\n",
            "Epoch: 150. Loss: 0.5466860160272764\n",
            "Epoch: 160. Loss: 0.5453590682755732\n",
            "Epoch: 170. Loss: 0.5442948814048874\n",
            "Epoch: 180. Loss: 0.5434346950640064\n",
            "Epoch: 190. Loss: 0.5427341031944742\n",
            "Epoch: 200. Loss: 0.5421593242232038\n",
            "Epoch: 210. Loss: 0.5416844818432305\n",
            "Epoch: 220. Loss: 0.5412896155083194\n",
            "Epoch: 230. Loss: 0.540959218432405\n",
            "Epoch: 240. Loss: 0.5406811579228847\n",
            "Epoch: 250. Loss: 0.5404458738293878\n",
            "Epoch: 260. Loss: 0.5402457801593772\n",
            "Epoch: 270. Loss: 0.5400748158050814\n",
            "Epoch: 280. Loss: 0.5399281052524417\n",
            "Epoch: 290. Loss: 0.5398017008296058\n",
            "Epoch: 300. Loss: 0.5396923857277843\n",
            "Epoch: 310. Loss: 0.5395975225600227\n",
            "Epoch: 320. Loss: 0.5395149362279845\n",
            "Epoch: 330. Loss: 0.5394428227778785\n",
            "Epoch: 340. Loss: 0.5393796780522748\n",
            "Epoch: 350. Loss: 0.5393242415038209\n",
            "Epoch: 360. Loss: 0.5392754516859923\n",
            "Epoch: 370. Loss: 0.5392324107868759\n",
            "Epoch: 380. Loss: 0.5391943562049438\n",
            "Epoch: 390. Loss: 0.5391606376388959\n",
            "Epoch: 400. Loss: 0.5391306985189239\n",
            "Epoch: 410. Loss: 0.5391040608748429\n",
            "Epoch: 420. Loss: 0.5390803129397473\n",
            "Epoch: 430. Loss: 0.5390590989426531\n",
            "Epoch: 440. Loss: 0.5390401106620395\n",
            "Epoch: 450. Loss: 0.5390230804032908\n",
            "Epoch: 460. Loss: 0.5390077751334041\n",
            "Epoch: 470. Loss: 0.5389939915609382\n",
            "Epoch: 480. Loss: 0.5389815519917752\n",
            "Epoch: 490. Loss: 0.538970300824634\n",
            "tensor(0.8192, dtype=torch.float64)\n",
            "2005-02-06 00:00:00\n",
            "Epoch: 0. Loss: 0.6848083942640986\n",
            "Epoch: 10. Loss: 0.6576602507890059\n",
            "Epoch: 20. Loss: 0.6357884494038046\n",
            "Epoch: 30. Loss: 0.6184170908945907\n",
            "Epoch: 40. Loss: 0.604750728216706\n",
            "Epoch: 50. Loss: 0.5940380700148932\n",
            "Epoch: 60. Loss: 0.5856194565084907\n",
            "Epoch: 70. Loss: 0.5789494628069417\n",
            "Epoch: 80. Loss: 0.5735976385774965\n",
            "Epoch: 90. Loss: 0.5692356972748756\n",
            "Epoch: 100. Loss: 0.5656191370954616\n",
            "Epoch: 110. Loss: 0.5625685894076496\n",
            "Epoch: 120. Loss: 0.5599535270819714\n",
            "Epoch: 130. Loss: 0.5576791748007893\n",
            "Epoch: 140. Loss: 0.5556765192379384\n",
            "Epoch: 150. Loss: 0.5538949340288691\n",
            "Epoch: 160. Loss: 0.5522968531493102\n",
            "Epoch: 170. Loss: 0.550853979065661\n",
            "Epoch: 180. Loss: 0.5495446084796656\n",
            "Epoch: 190. Loss: 0.5483517566820328\n",
            "Epoch: 200. Loss: 0.5472618454131729\n",
            "Epoch: 210. Loss: 0.5462637850210849\n",
            "Epoch: 220. Loss: 0.5453483310493957\n",
            "Epoch: 230. Loss: 0.5445076312537322\n",
            "Epoch: 240. Loss: 0.5437349046072789\n",
            "Epoch: 250. Loss: 0.5430242118351056\n",
            "Epoch: 260. Loss: 0.5423702895460072\n",
            "Epoch: 270. Loss: 0.541768428706947\n",
            "Epoch: 280. Loss: 0.5412143841879768\n",
            "Epoch: 290. Loss: 0.5407043062199286\n",
            "Epoch: 300. Loss: 0.5402346874327865\n",
            "Epoch: 310. Loss: 0.5398023210825741\n",
            "Epoch: 320. Loss: 0.5394042674073443\n",
            "Epoch: 330. Loss: 0.5390378259699364\n",
            "Epoch: 340. Loss: 0.5387005124777652\n",
            "Epoch: 350. Loss: 0.5383900390077\n",
            "Epoch: 360. Loss: 0.5381042968683439\n",
            "Epoch: 370. Loss: 0.5378413415444883\n",
            "Epoch: 380. Loss: 0.5375993793177383\n",
            "Epoch: 390. Loss: 0.5373767552627763\n",
            "Epoch: 400. Loss: 0.5371719423937839\n",
            "Epoch: 410. Loss: 0.5369835317893872\n",
            "Epoch: 420. Loss: 0.5368102235633894\n",
            "Epoch: 430. Loss: 0.5366508185769342\n",
            "Epoch: 440. Loss: 0.5365042108086059\n",
            "Epoch: 450. Loss: 0.5363693803144739\n",
            "Epoch: 460. Loss: 0.5362453867217103\n",
            "Epoch: 470. Loss: 0.5361313632082287\n",
            "Epoch: 480. Loss: 0.536026510927552\n",
            "Epoch: 490. Loss: 0.5359300938433784\n",
            "tensor(0.8728, dtype=torch.float64)\n",
            "2005-02-13 00:00:00\n",
            "Epoch: 0. Loss: 0.9253763860579238\n",
            "Epoch: 10. Loss: 0.8787190847799022\n",
            "Epoch: 20. Loss: 0.83694590001389\n",
            "Epoch: 30. Loss: 0.7998010436678608\n",
            "Epoch: 40. Loss: 0.7669686865814853\n",
            "Epoch: 50. Loss: 0.7380890224835884\n",
            "Epoch: 60. Loss: 0.7127796053635306\n",
            "Epoch: 70. Loss: 0.690656291717222\n",
            "Epoch: 80. Loss: 0.6713499108168963\n",
            "Epoch: 90. Loss: 0.6545172352073735\n",
            "Epoch: 100. Loss: 0.6398466963585882\n",
            "Epoch: 110. Loss: 0.6270601625652522\n",
            "Epoch: 120. Loss: 0.6159121850121632\n",
            "Epoch: 130. Loss: 0.6061878306933958\n",
            "Epoch: 140. Loss: 0.5976998599046359\n",
            "Epoch: 150. Loss: 0.5902857094959061\n",
            "Epoch: 160. Loss: 0.5838045401503733\n",
            "Epoch: 170. Loss: 0.5781344803568501\n",
            "Epoch: 180. Loss: 0.5731701263804588\n",
            "Epoch: 190. Loss: 0.5688203161379293\n",
            "Epoch: 200. Loss: 0.565006172148366\n",
            "Epoch: 210. Loss: 0.5616593967341611\n",
            "Epoch: 220. Loss: 0.5587207968641126\n",
            "Epoch: 230. Loss: 0.5561390138882555\n",
            "Epoch: 240. Loss: 0.5538694334161177\n",
            "Epoch: 250. Loss: 0.5518732518355425\n",
            "Epoch: 260. Loss: 0.5501166778930437\n",
            "Epoch: 270. Loss: 0.548570249995297\n",
            "Epoch: 280. Loss: 0.5472082522094209\n",
            "Epoch: 290. Loss: 0.5460082141879006\n",
            "Epoch: 300. Loss: 0.5449504823331642\n",
            "Epoch: 310. Loss: 0.5440178513997515\n",
            "Epoch: 320. Loss: 0.5431952473906695\n",
            "Epoch: 330. Loss: 0.5424694540401345\n",
            "Epoch: 340. Loss: 0.5418288764006609\n",
            "Epoch: 350. Loss: 0.5412633360883129\n",
            "Epoch: 360. Loss: 0.5407638936086056\n",
            "Epoch: 370. Loss: 0.5403226939102438\n",
            "Epoch: 380. Loss: 0.5399328319165057\n",
            "Epoch: 390. Loss: 0.5395882352845587\n",
            "Epoch: 400. Loss: 0.5392835620587142\n",
            "Epoch: 410. Loss: 0.5390141112295149\n",
            "Epoch: 420. Loss: 0.5387757444991211\n",
            "Epoch: 430. Loss: 0.5385648177950555\n",
            "Epoch: 440. Loss: 0.5383781212774983\n",
            "Epoch: 450. Loss: 0.5382128267568659\n",
            "Epoch: 460. Loss: 0.5380664415839514\n",
            "Epoch: 470. Loss: 0.5379367681989617\n",
            "Epoch: 480. Loss: 0.5378218686319689\n",
            "Epoch: 490. Loss: 0.5377200333385594\n",
            "tensor(0.8267, dtype=torch.float64)\n",
            "2005-02-20 00:00:00\n",
            "Epoch: 0. Loss: 1.3548782164796953\n",
            "Epoch: 10. Loss: 1.1672452643790623\n",
            "Epoch: 20. Loss: 1.0088471223811453\n",
            "Epoch: 30. Loss: 0.8816726509895524\n",
            "Epoch: 40. Loss: 0.7849863514842564\n",
            "Epoch: 50. Loss: 0.7148414888044556\n",
            "Epoch: 60. Loss: 0.6653787640601772\n",
            "Epoch: 70. Loss: 0.6307817634880788\n",
            "Epoch: 80. Loss: 0.606411382702676\n",
            "Epoch: 90. Loss: 0.5889793383507742\n",
            "Epoch: 100. Loss: 0.5762801843682724\n",
            "Epoch: 110. Loss: 0.5668592125949703\n",
            "Epoch: 120. Loss: 0.5597518846284131\n",
            "Epoch: 130. Loss: 0.5543085407523071\n",
            "Epoch: 140. Loss: 0.5500830852606532\n",
            "Epoch: 150. Loss: 0.546763224683329\n",
            "Epoch: 160. Loss: 0.5441263796287902\n",
            "Epoch: 170. Loss: 0.5420113236020784\n",
            "Epoch: 180. Loss: 0.540299560137072\n",
            "Epoch: 190. Loss: 0.5389028451885586\n",
            "Epoch: 200. Loss: 0.5377546704655886\n",
            "Epoch: 210. Loss: 0.5368043529182326\n",
            "Epoch: 220. Loss: 0.5360128715978169\n",
            "Epoch: 230. Loss: 0.535349895985419\n",
            "Epoch: 240. Loss: 0.5347916389877584\n",
            "Epoch: 250. Loss: 0.5343192884105964\n",
            "Epoch: 260. Loss: 0.5339178491525738\n",
            "Epoch: 270. Loss: 0.5335752802565051\n",
            "Epoch: 280. Loss: 0.5332818458201231\n",
            "Epoch: 290. Loss: 0.5330296225131304\n",
            "Epoch: 300. Loss: 0.5328121228173727\n",
            "Epoch: 310. Loss: 0.5326240045180277\n",
            "Epoch: 320. Loss: 0.5324608450091778\n",
            "Epoch: 330. Loss: 0.5323189646891091\n",
            "Epoch: 340. Loss: 0.5321952878169711\n",
            "Epoch: 350. Loss: 0.53208723216472\n",
            "Epoch: 360. Loss: 0.531992620957554\n",
            "Epoch: 370. Loss: 0.5319096121820787\n",
            "Epoch: 380. Loss: 0.5318366415149496\n",
            "Epoch: 390. Loss: 0.5317723759992147\n",
            "Epoch: 400. Loss: 0.5317156762516748\n",
            "Epoch: 410. Loss: 0.5316655654801389\n",
            "Epoch: 420. Loss: 0.5316212039661325\n",
            "Epoch: 430. Loss: 0.5315818679567669\n",
            "Epoch: 440. Loss: 0.5315469321312088\n",
            "Epoch: 450. Loss: 0.5315158549788401\n",
            "Epoch: 460. Loss: 0.5314881665598098\n",
            "Epoch: 470. Loss: 0.5314634582232806\n",
            "Epoch: 480. Loss: 0.5314413739409702\n",
            "Epoch: 490. Loss: 0.5314216029786891\n",
            "tensor(0.7973, dtype=torch.float64)\n",
            "2005-02-27 00:00:00\n",
            "Epoch: 0. Loss: 0.9409029465092762\n",
            "Epoch: 10. Loss: 0.8617778288456014\n",
            "Epoch: 20. Loss: 0.7952988402712042\n",
            "Epoch: 30. Loss: 0.7408520595997726\n",
            "Epoch: 40. Loss: 0.6972360209292696\n",
            "Epoch: 50. Loss: 0.6628501292550304\n",
            "Epoch: 60. Loss: 0.6359656306459726\n",
            "Epoch: 70. Loss: 0.6149644822337726\n",
            "Epoch: 80. Loss: 0.5984770074940228\n",
            "Epoch: 90. Loss: 0.5854191953044647\n",
            "Epoch: 100. Loss: 0.574967626142507\n",
            "Epoch: 110. Loss: 0.5665099072090466\n",
            "Epoch: 120. Loss: 0.5595936553839675\n",
            "Epoch: 130. Loss: 0.5538836882482943\n",
            "Epoch: 140. Loss: 0.5491294132781868\n",
            "Epoch: 150. Loss: 0.5451411814553568\n",
            "Epoch: 160. Loss: 0.5417735326993208\n",
            "Epoch: 170. Loss: 0.5389134077170414\n",
            "Epoch: 180. Loss: 0.536471828293222\n",
            "Epoch: 190. Loss: 0.534377970336994\n",
            "Epoch: 200. Loss: 0.5325748868717988\n",
            "Epoch: 210. Loss: 0.531016376749159\n",
            "Epoch: 220. Loss: 0.529664658175499\n",
            "Epoch: 230. Loss: 0.5284886155359667\n",
            "Epoch: 240. Loss: 0.527462460752107\n",
            "Epoch: 250. Loss: 0.5265646988834305\n",
            "Epoch: 260. Loss: 0.5257773202296433\n",
            "Epoch: 270. Loss: 0.525085163296094\n",
            "Epoch: 280. Loss: 0.5244754082069947\n",
            "Epoch: 290. Loss: 0.5239371707895695\n",
            "Epoch: 300. Loss: 0.5234611751006566\n",
            "Epoch: 310. Loss: 0.5230394876025692\n",
            "Epoch: 320. Loss: 0.5226653001638266\n",
            "Epoch: 330. Loss: 0.5223327519961588\n",
            "Epoch: 340. Loss: 0.5220367828367631\n",
            "Epoch: 350. Loss: 0.5217730113474838\n",
            "Epoch: 360. Loss: 0.5215376339728061\n",
            "Epoch: 370. Loss: 0.5213273404773779\n",
            "Epoch: 380. Loss: 0.521139243143923\n",
            "Epoch: 390. Loss: 0.5209708172069238\n",
            "Epoch: 400. Loss: 0.5208198505653424\n",
            "Epoch: 410. Loss: 0.5206844011880472\n",
            "Epoch: 420. Loss: 0.5205627609203737\n",
            "Epoch: 430. Loss: 0.5204534246359769\n",
            "Epoch: 440. Loss: 0.5203550638674984\n",
            "Epoch: 450. Loss: 0.5202665042023614\n",
            "Epoch: 460. Loss: 0.5201867058537618\n",
            "Epoch: 470. Loss: 0.5201147469175608\n",
            "Epoch: 480. Loss: 0.5200498089079089\n",
            "Epoch: 490. Loss: 0.5199911642316956\n",
            "tensor(0.8686, dtype=torch.float64)\n",
            "2005-03-06 00:00:00\n",
            "Epoch: 0. Loss: 0.70910478921628\n",
            "Epoch: 10. Loss: 0.6400092861394785\n",
            "Epoch: 20. Loss: 0.5962969194719007\n",
            "Epoch: 30. Loss: 0.5693490227852273\n",
            "Epoch: 40. Loss: 0.5527052727560119\n",
            "Epoch: 50. Loss: 0.542211584006614\n",
            "Epoch: 60. Loss: 0.5353881150858888\n",
            "Epoch: 70. Loss: 0.5307916351301359\n",
            "Epoch: 80. Loss: 0.527581163205868\n",
            "Epoch: 90. Loss: 0.5252594038891691\n",
            "Epoch: 100. Loss: 0.5235259509675231\n",
            "Epoch: 110. Loss: 0.5221947821923913\n",
            "Epoch: 120. Loss: 0.5211475833430783\n",
            "Epoch: 130. Loss: 0.5203069716637133\n",
            "Epoch: 140. Loss: 0.5196208695691312\n",
            "Epoch: 150. Loss: 0.5190532149281029\n",
            "Epoch: 160. Loss: 0.5185783310606592\n",
            "Epoch: 170. Loss: 0.5181774463805205\n",
            "Epoch: 180. Loss: 0.5178364984448466\n",
            "Epoch: 190. Loss: 0.5175447187581056\n",
            "Epoch: 200. Loss: 0.5172937005393816\n",
            "Epoch: 210. Loss: 0.5170767706462215\n",
            "Epoch: 220. Loss: 0.5168885566319845\n",
            "Epoch: 230. Loss: 0.5167246814266585\n",
            "Epoch: 240. Loss: 0.5165815431709431\n",
            "Epoch: 250. Loss: 0.5164561530455187\n",
            "Epoch: 260. Loss: 0.51634601343087\n",
            "Epoch: 270. Loss: 0.5162490247022603\n",
            "Epoch: 280. Loss: 0.516163412772648\n",
            "Epoch: 290. Loss: 0.5160876719628926\n",
            "Epoch: 300. Loss: 0.516020519401646\n",
            "Epoch: 310. Loss: 0.5159608582431268\n",
            "Epoch: 320. Loss: 0.5159077477299122\n",
            "Epoch: 330. Loss: 0.5158603786396757\n",
            "Epoch: 340. Loss: 0.5158180530156412\n",
            "Epoch: 350. Loss: 0.5157801673394511\n",
            "Epoch: 360. Loss: 0.5157461984941852\n",
            "Epoch: 370. Loss: 0.5157156920055563\n",
            "Epoch: 380. Loss: 0.5156882521550531\n",
            "Epoch: 390. Loss: 0.5156635336396413\n",
            "Epoch: 400. Loss: 0.5156412345152377\n",
            "Epoch: 410. Loss: 0.515621090210226\n",
            "Epoch: 420. Loss: 0.5156028684341014\n",
            "Epoch: 430. Loss: 0.5155863648373422\n",
            "Epoch: 440. Loss: 0.515571399303565\n",
            "Epoch: 450. Loss: 0.5155578127752516\n",
            "Epoch: 460. Loss: 0.51554546453083\n",
            "Epoch: 470. Loss: 0.515534229844416\n",
            "Epoch: 480. Loss: 0.5155239979706501\n",
            "Epoch: 490. Loss: 0.5155146704062754\n",
            "tensor(0.8457, dtype=torch.float64)\n",
            "2005-03-13 00:00:00\n",
            "Epoch: 0. Loss: 0.7092858484001475\n",
            "Epoch: 10. Loss: 0.6736218603652978\n",
            "Epoch: 20. Loss: 0.6445621572207741\n",
            "Epoch: 30. Loss: 0.6211381543765853\n",
            "Epoch: 40. Loss: 0.6024139792953203\n",
            "Epoch: 50. Loss: 0.587528684392614\n",
            "Epoch: 60. Loss: 0.5757270595132019\n",
            "Epoch: 70. Loss: 0.5663728761615733\n",
            "Epoch: 80. Loss: 0.5589466528650661\n",
            "Epoch: 90. Loss: 0.5530336274839905\n",
            "Epoch: 100. Loss: 0.5483074936875424\n",
            "Epoch: 110. Loss: 0.5445137435999182\n",
            "Epoch: 120. Loss: 0.54145466740648\n",
            "Epoch: 130. Loss: 0.538976784739733\n",
            "Epoch: 140. Loss: 0.5369607575155658\n",
            "Epoch: 150. Loss: 0.5353135017781832\n",
            "Epoch: 160. Loss: 0.5339621119437484\n",
            "Epoch: 170. Loss: 0.53284921863342\n",
            "Epoch: 180. Loss: 0.5319294536637688\n",
            "Epoch: 190. Loss: 0.531166758577721\n",
            "Epoch: 200. Loss: 0.5305323314014105\n",
            "Epoch: 210. Loss: 0.5300030550050878\n",
            "Epoch: 220. Loss: 0.5295602889625184\n",
            "Epoch: 230. Loss: 0.5291889363568366\n",
            "Epoch: 240. Loss: 0.5288767192672158\n",
            "Epoch: 250. Loss: 0.5286136133180467\n",
            "Epoch: 260. Loss: 0.528391404051333\n",
            "Epoch: 270. Loss: 0.5282033370767011\n",
            "Epoch: 280. Loss: 0.5280438407879771\n",
            "Epoch: 290. Loss: 0.5279083055285995\n",
            "Epoch: 300. Loss: 0.5277929068970327\n",
            "Epoch: 310. Loss: 0.5276944637435963\n",
            "Epoch: 320. Loss: 0.5276103235679231\n",
            "Epoch: 330. Loss: 0.5275382696620733\n",
            "Epoch: 340. Loss: 0.5274764455907017\n",
            "Epoch: 350. Loss: 0.5274232935541742\n",
            "Epoch: 360. Loss: 0.5273775039152251\n",
            "Epoch: 370. Loss: 0.5273379737381424\n",
            "Epoch: 380. Loss: 0.5273037726313635\n",
            "Epoch: 390. Loss: 0.527274114529598\n",
            "Epoch: 400. Loss: 0.5272483343225792\n",
            "Epoch: 410. Loss: 0.5272258684512242\n",
            "Epoch: 420. Loss: 0.5272062387612135\n",
            "Epoch: 430. Loss: 0.5271890390386071\n",
            "Epoch: 440. Loss: 0.5271739237596139\n",
            "Epoch: 450. Loss: 0.5271605986728144\n",
            "Epoch: 460. Loss: 0.5271488129015027\n",
            "Epoch: 470. Loss: 0.527138352309829\n",
            "Epoch: 480. Loss: 0.5271290339218246\n",
            "Epoch: 490. Loss: 0.5271207012192966\n",
            "tensor(0.7714, dtype=torch.float64)\n",
            "2005-03-20 00:00:00\n",
            "Epoch: 0. Loss: 0.7093761725998518\n",
            "Epoch: 10. Loss: 0.6826128001234902\n",
            "Epoch: 20. Loss: 0.6605688854308202\n",
            "Epoch: 30. Loss: 0.6423528135351806\n",
            "Epoch: 40. Loss: 0.6272419178077746\n",
            "Epoch: 50. Loss: 0.6146535962642631\n",
            "Epoch: 60. Loss: 0.6041196097981548\n",
            "Epoch: 70. Loss: 0.5952641142391674\n",
            "Epoch: 80. Loss: 0.5877853730055899\n",
            "Epoch: 90. Loss: 0.58144080965274\n",
            "Epoch: 100. Loss: 0.5760349477998246\n",
            "Epoch: 110. Loss: 0.5714097692942519\n",
            "Epoch: 120. Loss: 0.5674370536889766\n",
            "Epoch: 130. Loss: 0.5640123160121415\n",
            "Epoch: 140. Loss: 0.5610500197804663\n",
            "Epoch: 150. Loss: 0.5584797998176392\n",
            "Epoch: 160. Loss: 0.5562434806939839\n",
            "Epoch: 170. Loss: 0.554292720130464\n",
            "Epoch: 180. Loss: 0.5525871425674661\n",
            "Epoch: 190. Loss: 0.5510928570377861\n",
            "Epoch: 200. Loss: 0.5497812765132135\n",
            "Epoch: 210. Loss: 0.5486281740474622\n",
            "Epoch: 220. Loss: 0.5476129252569453\n",
            "Epoch: 230. Loss: 0.5467178977727201\n",
            "Epoch: 240. Loss: 0.545927956928914\n",
            "Epoch: 250. Loss: 0.5452300636627285\n",
            "Epoch: 260. Loss: 0.54461294581527\n",
            "Epoch: 270. Loss: 0.544066828075774\n",
            "Epoch: 280. Loss: 0.5435832089653155\n",
            "Epoch: 290. Loss: 0.543154675712433\n",
            "Epoch: 300. Loss: 0.542774749789146\n",
            "Epoch: 310. Loss: 0.5424377573729209\n",
            "Epoch: 320. Loss: 0.5421387201720365\n",
            "Epoch: 330. Loss: 0.541873262971026\n",
            "Epoch: 340. Loss: 0.5416375349755386\n",
            "Epoch: 350. Loss: 0.5414281426054802\n",
            "Epoch: 360. Loss: 0.5412420918353565\n",
            "Epoch: 370. Loss: 0.541076738537432\n",
            "Epoch: 380. Loss: 0.5409297455669358\n",
            "Epoch: 390. Loss: 0.5407990455548654\n",
            "Epoch: 400. Loss: 0.5406828085551925\n",
            "Epoch: 410. Loss: 0.5405794138390905\n",
            "Epoch: 420. Loss: 0.5404874252465747\n",
            "Epoch: 430. Loss: 0.5404055696015484\n",
            "Epoch: 440. Loss: 0.5403327177742331\n",
            "Epoch: 450. Loss: 0.5402678680388815\n",
            "Epoch: 460. Loss: 0.5402101314273712\n",
            "Epoch: 470. Loss: 0.5401587188229328\n",
            "Epoch: 480. Loss: 0.5401129295746404\n",
            "Epoch: 490. Loss: 0.5400721414437548\n",
            "tensor(0.7379, dtype=torch.float64)\n",
            "2005-03-27 00:00:00\n",
            "Epoch: 0. Loss: 0.921275326391451\n",
            "Epoch: 10. Loss: 0.844302294667106\n",
            "Epoch: 20. Loss: 0.7829661663622024\n",
            "Epoch: 30. Loss: 0.7341044020605262\n",
            "Epoch: 40. Loss: 0.6952400980589242\n",
            "Epoch: 50. Loss: 0.6644242390837575\n",
            "Epoch: 60. Loss: 0.6400796575175005\n",
            "Epoch: 70. Loss: 0.6209036205188914\n",
            "Epoch: 80. Loss: 0.605817835107066\n",
            "Epoch: 90. Loss: 0.5939406493365961\n",
            "Epoch: 100. Loss: 0.5845642031042193\n",
            "Epoch: 110. Loss: 0.577130136581399\n",
            "Epoch: 120. Loss: 0.5712040620866918\n",
            "Epoch: 130. Loss: 0.566451059621021\n",
            "Epoch: 140. Loss: 0.5626140533910442\n",
            "Epoch: 150. Loss: 0.5594958850240153\n",
            "Epoch: 160. Loss: 0.5569450715070215\n",
            "Epoch: 170. Loss: 0.5548447969721994\n",
            "Epoch: 180. Loss: 0.5531045433339606\n",
            "Epoch: 190. Loss: 0.5516537829456242\n",
            "Epoch: 200. Loss: 0.5504372417512448\n",
            "Epoch: 210. Loss: 0.5494113414432037\n",
            "Epoch: 220. Loss: 0.5485415204501078\n",
            "Epoch: 230. Loss: 0.5478002085058944\n",
            "Epoch: 240. Loss: 0.5471652877202369\n",
            "Epoch: 250. Loss: 0.5466189168633789\n",
            "Epoch: 260. Loss: 0.5461466279919759\n",
            "Epoch: 270. Loss: 0.5457366283249677\n",
            "Epoch: 280. Loss: 0.54537925766801\n",
            "Epoch: 290. Loss: 0.5450665643997923\n",
            "Epoch: 300. Loss: 0.5447919723512978\n",
            "Epoch: 310. Loss: 0.5445500177629263\n",
            "Epoch: 320. Loss: 0.5443361405697139\n",
            "Epoch: 330. Loss: 0.5441465180282712\n",
            "Epoch: 340. Loss: 0.5439779315109669\n",
            "Epoch: 350. Loss: 0.5438276594060524\n",
            "Epoch: 360. Loss: 0.543693390659747\n",
            "Epoch: 370. Loss: 0.5435731547106305\n",
            "Epoch: 380. Loss: 0.5434652644950321\n",
            "Epoch: 390. Loss: 0.543368269915661\n",
            "Epoch: 400. Loss: 0.5432809197170344\n",
            "Epoch: 410. Loss: 0.5432021301393294\n",
            "Epoch: 420. Loss: 0.5431309590562331\n",
            "Epoch: 430. Loss: 0.5430665845640477\n",
            "Epoch: 440. Loss: 0.5430082871952223\n",
            "Epoch: 450. Loss: 0.542955435092174\n",
            "Epoch: 460. Loss: 0.5429074716062573\n",
            "Epoch: 470. Loss: 0.5428639048894122\n",
            "Epoch: 480. Loss: 0.5428242991279798\n",
            "Epoch: 490. Loss: 0.542788267133829\n",
            "tensor(0.6763, dtype=torch.float64)\n",
            "2005-04-03 00:00:00\n",
            "Epoch: 0. Loss: 1.1355776377199518\n",
            "Epoch: 10. Loss: 1.0114874613204432\n",
            "Epoch: 20. Loss: 0.909415855109881\n",
            "Epoch: 30. Loss: 0.8276884446782664\n",
            "Epoch: 40. Loss: 0.7636731301570997\n",
            "Epoch: 50. Loss: 0.7143237054445127\n",
            "Epoch: 60. Loss: 0.676663373332214\n",
            "Epoch: 70. Loss: 0.6480654144726727\n",
            "Epoch: 80. Loss: 0.6263586796421939\n",
            "Epoch: 90. Loss: 0.6098285183496349\n",
            "Epoch: 100. Loss: 0.5971642777756915\n",
            "Epoch: 110. Loss: 0.5873856977444437\n",
            "Epoch: 120. Loss: 0.5797685908450948\n",
            "Epoch: 130. Loss: 0.5737804687836416\n",
            "Epoch: 140. Loss: 0.5690294976927623\n",
            "Epoch: 150. Loss: 0.5652260743346156\n",
            "Epoch: 160. Loss: 0.5621547366575746\n",
            "Epoch: 170. Loss: 0.5596539284148428\n",
            "Epoch: 180. Loss: 0.5576014999493265\n",
            "Epoch: 190. Loss: 0.5559043140789888\n",
            "Epoch: 200. Loss: 0.5544907641909503\n",
            "Epoch: 210. Loss: 0.5533053547683239\n",
            "Epoch: 220. Loss: 0.5523047463770239\n",
            "Epoch: 230. Loss: 0.5514548460044144\n",
            "Epoch: 240. Loss: 0.5507286486972892\n",
            "Epoch: 250. Loss: 0.5501046233310419\n",
            "Epoch: 260. Loss: 0.5495654956709558\n",
            "Epoch: 270. Loss: 0.5490973239002872\n",
            "Epoch: 280. Loss: 0.5486887911994717\n",
            "Epoch: 290. Loss: 0.5483306606815775\n",
            "Epoch: 300. Loss: 0.5480153526949542\n",
            "Epoch: 310. Loss: 0.5477366150217662\n",
            "Epoch: 320. Loss: 0.547489264083172\n",
            "Epoch: 330. Loss: 0.5472689807710864\n",
            "Epoch: 340. Loss: 0.547072148560847\n",
            "Epoch: 350. Loss: 0.5468957245360725\n",
            "Epoch: 360. Loss: 0.5467371361699825\n",
            "Epoch: 370. Loss: 0.5465941983642085\n",
            "Epoch: 380. Loss: 0.5464650464949382\n",
            "Epoch: 390. Loss: 0.5463480821636634\n",
            "Epoch: 400. Loss: 0.5462419290730052\n",
            "Epoch: 410. Loss: 0.5461453970033717\n",
            "Epoch: 420. Loss: 0.5460574522948963\n",
            "Epoch: 430. Loss: 0.5459771935717768\n",
            "Epoch: 440. Loss: 0.5459038317055641\n",
            "Epoch: 450. Loss: 0.5458366732171761\n",
            "Epoch: 460. Loss: 0.5457751064772904\n",
            "Epoch: 470. Loss: 0.5457185901910521\n",
            "Epoch: 480. Loss: 0.5456666437531552\n",
            "Epoch: 490. Loss: 0.5456188391390024\n",
            "tensor(0.8475, dtype=torch.float64)\n",
            "2005-04-10 00:00:00\n",
            "Epoch: 0. Loss: 1.130661368151377\n",
            "Epoch: 10. Loss: 1.0276203095486782\n",
            "Epoch: 20. Loss: 0.935821892650786\n",
            "Epoch: 30. Loss: 0.8564303836137567\n",
            "Epoch: 40. Loss: 0.7900628927626615\n",
            "Epoch: 50. Loss: 0.736421162074508\n",
            "Epoch: 60. Loss: 0.6942489346447562\n",
            "Epoch: 70. Loss: 0.6616830204299852\n",
            "Epoch: 80. Loss: 0.6367335356369725\n",
            "Epoch: 90. Loss: 0.6176196980960469\n",
            "Epoch: 100. Loss: 0.6029013764303\n",
            "Epoch: 110. Loss: 0.5914774006789998\n",
            "Epoch: 120. Loss: 0.5825289805284425\n",
            "Epoch: 130. Loss: 0.575453708355743\n",
            "Epoch: 140. Loss: 0.5698084856360268\n",
            "Epoch: 150. Loss: 0.5652655804088123\n",
            "Epoch: 160. Loss: 0.561580527504969\n",
            "Epoch: 170. Loss: 0.5585692001392817\n",
            "Epoch: 180. Loss: 0.5560915377546659\n",
            "Epoch: 190. Loss: 0.554039971328157\n",
            "Epoch: 200. Loss: 0.5523311326257719\n",
            "Epoch: 210. Loss: 0.5508998604769597\n",
            "Epoch: 220. Loss: 0.5496948233308286\n",
            "Epoch: 230. Loss: 0.5486752891000211\n",
            "Epoch: 240. Loss: 0.547808717604762\n",
            "Epoch: 250. Loss: 0.5470689490056725\n",
            "Epoch: 260. Loss: 0.5464348285204802\n",
            "Epoch: 270. Loss: 0.5458891536992557\n",
            "Epoch: 280. Loss: 0.5454178624242625\n",
            "Epoch: 290. Loss: 0.5450094021456121\n",
            "Epoch: 300. Loss: 0.5446542366838327\n",
            "Epoch: 310. Loss: 0.544344458246496\n",
            "Epoch: 320. Loss: 0.5440734804815501\n",
            "Epoch: 330. Loss: 0.5438357943530796\n",
            "Epoch: 340. Loss: 0.5436267730140231\n",
            "Epoch: 350. Loss: 0.5434425151080619\n",
            "Epoch: 360. Loss: 0.5432797183703479\n",
            "Epoch: 370. Loss: 0.5431355772341118\n",
            "Epoch: 380. Loss: 0.5430076995449048\n",
            "Epoch: 390. Loss: 0.5428940385498283\n",
            "Epoch: 400. Loss: 0.5427928371481967\n",
            "Epoch: 410. Loss: 0.5427025820232664\n",
            "Epoch: 420. Loss: 0.5426219657667171\n",
            "Epoch: 430. Loss: 0.5425498554918476\n",
            "Epoch: 440. Loss: 0.5424852667329264\n",
            "Epoch: 450. Loss: 0.5424273416656916\n",
            "Epoch: 460. Loss: 0.5423753308719272\n",
            "Epoch: 470. Loss: 0.542328578020293\n",
            "Epoch: 480. Loss: 0.5422865069545288\n",
            "Epoch: 490. Loss: 0.5422486107752942\n",
            "tensor(0.7892, dtype=torch.float64)\n",
            "2005-04-17 00:00:00\n",
            "Epoch: 0. Loss: 0.7888574943472728\n",
            "Epoch: 10. Loss: 0.7282193509719939\n",
            "Epoch: 20. Loss: 0.6819030402062564\n",
            "Epoch: 30. Loss: 0.6474070351469324\n",
            "Epoch: 40. Loss: 0.6221846162914412\n",
            "Epoch: 50. Loss: 0.6039438672644281\n",
            "Epoch: 60. Loss: 0.5908023014717845\n",
            "Epoch: 70. Loss: 0.581313213071627\n",
            "Epoch: 80. Loss: 0.574414546603179\n",
            "Epoch: 90. Loss: 0.5693487801457259\n",
            "Epoch: 100. Loss: 0.5655840353299801\n",
            "Epoch: 110. Loss: 0.5627491794413136\n",
            "Epoch: 120. Loss: 0.56058516037188\n",
            "Epoch: 130. Loss: 0.5589103204300578\n",
            "Epoch: 140. Loss: 0.5575963354464826\n",
            "Epoch: 150. Loss: 0.5565517384750251\n",
            "Epoch: 160. Loss: 0.5557106838103304\n",
            "Epoch: 170. Loss: 0.5550252745469435\n",
            "Epoch: 180. Loss: 0.5544602988585867\n",
            "Epoch: 190. Loss: 0.5539895943382435\n",
            "Epoch: 200. Loss: 0.553593516754399\n",
            "Epoch: 210. Loss: 0.5532571624298376\n",
            "Epoch: 220. Loss: 0.5529691086165726\n",
            "Epoch: 230. Loss: 0.5527205127879495\n",
            "Epoch: 240. Loss: 0.5525044627374379\n",
            "Epoch: 250. Loss: 0.552315503459117\n",
            "Epoch: 260. Loss: 0.5521492897164336\n",
            "Epoch: 270. Loss: 0.5520023287412522\n",
            "Epoch: 280. Loss: 0.551871788109785\n",
            "Epoch: 290. Loss: 0.5517553511379348\n",
            "Epoch: 300. Loss: 0.5516511071985722\n",
            "Epoch: 310. Loss: 0.5515574679008853\n",
            "Epoch: 320. Loss: 0.5514731025650157\n",
            "Epoch: 330. Loss: 0.551396888196021\n",
            "Epoch: 340. Loss: 0.5513278704287354\n",
            "Epoch: 350. Loss: 0.55126523282923\n",
            "Epoch: 360. Loss: 0.5512082726026524\n",
            "Epoch: 370. Loss: 0.5511563812430761\n",
            "Epoch: 380. Loss: 0.5511090290188841\n",
            "Epoch: 390. Loss: 0.5510657524525701\n",
            "Epoch: 400. Loss: 0.551026144151855\n",
            "Epoch: 410. Loss: 0.5509898444976589\n",
            "Epoch: 420. Loss: 0.5509565348067059\n",
            "Epoch: 430. Loss: 0.5509259316717561\n",
            "Epoch: 440. Loss: 0.5508977822475092\n",
            "Epoch: 450. Loss: 0.5508718603001262\n",
            "Epoch: 460. Loss: 0.5508479628767906\n",
            "Epoch: 470. Loss: 0.5508259074815338\n",
            "Epoch: 480. Loss: 0.5508055296667344\n",
            "Epoch: 490. Loss: 0.5507866809678206\n",
            "tensor(0.9298, dtype=torch.float64)\n",
            "2005-04-24 00:00:00\n",
            "Epoch: 0. Loss: 1.1109768351248204\n",
            "Epoch: 10. Loss: 0.9763066031928427\n",
            "Epoch: 20. Loss: 0.8682814448546031\n",
            "Epoch: 30. Loss: 0.7843304588593595\n",
            "Epoch: 40. Loss: 0.7209022881734767\n",
            "Epoch: 50. Loss: 0.6740052463057767\n",
            "Epoch: 60. Loss: 0.6398130257927768\n",
            "Epoch: 70. Loss: 0.6150536756422934\n",
            "Epoch: 80. Loss: 0.5971391234829785\n",
            "Epoch: 90. Loss: 0.5841260391728148\n",
            "Epoch: 100. Loss: 0.5746036966471209\n",
            "Epoch: 110. Loss: 0.5675686397156687\n",
            "Epoch: 120. Loss: 0.5623143711703243\n",
            "Epoch: 130. Loss: 0.5583448494696144\n",
            "Epoch: 140. Loss: 0.5553109397488128\n",
            "Epoch: 150. Loss: 0.5529654474927116\n",
            "Epoch: 160. Loss: 0.5511319375727128\n",
            "Epoch: 170. Loss: 0.5496833059975915\n",
            "Epoch: 180. Loss: 0.5485270791618427\n",
            "Epoch: 190. Loss: 0.5475952987256605\n",
            "Epoch: 200. Loss: 0.5468375208638536\n",
            "Epoch: 210. Loss: 0.5462159340367391\n",
            "Epoch: 220. Loss: 0.545701924878671\n",
            "Epoch: 230. Loss: 0.5452736407489507\n",
            "Epoch: 240. Loss: 0.5449142437481594\n",
            "Epoch: 250. Loss: 0.5446106486148184\n",
            "Epoch: 260. Loss: 0.5443526022552024\n",
            "Epoch: 270. Loss: 0.5441320066292217\n",
            "Epoch: 280. Loss: 0.5439424165091667\n",
            "Epoch: 290. Loss: 0.5437786639732451\n",
            "Epoch: 300. Loss: 0.5436365755036656\n",
            "Epoch: 310. Loss: 0.5435127572853712\n",
            "Epoch: 320. Loss: 0.5434044311125241\n",
            "Epoch: 330. Loss: 0.5433093081194588\n",
            "Epoch: 340. Loss: 0.5432254909770377\n",
            "Epoch: 350. Loss: 0.54315139765267\n",
            "Epoch: 360. Loss: 0.5430857016091941\n",
            "Epoch: 370. Loss: 0.5430272846122393\n",
            "Epoch: 380. Loss: 0.542975199265188\n",
            "Epoch: 390. Loss: 0.5429286390920355\n",
            "Epoch: 400. Loss: 0.5428869145095042\n",
            "Epoch: 410. Loss: 0.5428494334193484\n",
            "Epoch: 420. Loss: 0.5428156854446942\n",
            "Epoch: 430. Loss: 0.5427852290557259\n",
            "Epoch: 440. Loss: 0.5427576809983303\n",
            "Epoch: 450. Loss: 0.5427327075678472\n",
            "Epoch: 460. Loss: 0.5427100173687281\n",
            "Epoch: 470. Loss: 0.5426893552769554\n",
            "Epoch: 480. Loss: 0.5426704973809774\n",
            "Epoch: 490. Loss: 0.5426532467227273\n",
            "tensor(0.8437, dtype=torch.float64)\n",
            "2005-05-01 00:00:00\n",
            "Epoch: 0. Loss: 0.9275318367636189\n",
            "Epoch: 10. Loss: 0.8606481148252157\n",
            "Epoch: 20. Loss: 0.8036020198011758\n",
            "Epoch: 30. Loss: 0.7556423995855344\n",
            "Epoch: 40. Loss: 0.7159666300191847\n",
            "Epoch: 50. Loss: 0.6836606638243807\n",
            "Epoch: 60. Loss: 0.6577087593457775\n",
            "Epoch: 70. Loss: 0.63705871892121\n",
            "Epoch: 80. Loss: 0.6207058879898487\n",
            "Epoch: 90. Loss: 0.6077596098410318\n",
            "Epoch: 100. Loss: 0.5974756209527639\n",
            "Epoch: 110. Loss: 0.5892578590137911\n",
            "Epoch: 120. Loss: 0.5826419184404067\n",
            "Epoch: 130. Loss: 0.5772715669629489\n",
            "Epoch: 140. Loss: 0.5728753969073586\n",
            "Epoch: 150. Loss: 0.5692467716590569\n",
            "Epoch: 160. Loss: 0.5662278508839386\n",
            "Epoch: 170. Loss: 0.5636973728806822\n",
            "Epoch: 180. Loss: 0.5615615079130947\n",
            "Epoch: 190. Loss: 0.5597470771883365\n",
            "Epoch: 200. Loss: 0.5581965389618507\n",
            "Epoch: 210. Loss: 0.5568642748302765\n",
            "Epoch: 220. Loss: 0.5557138269289752\n",
            "Epoch: 230. Loss: 0.5547158302556985\n",
            "Epoch: 240. Loss: 0.5538464546198205\n",
            "Epoch: 250. Loss: 0.553086222066376\n",
            "Epoch: 260. Loss: 0.5524191026315766\n",
            "Epoch: 270. Loss: 0.551831817813443\n",
            "Epoch: 280. Loss: 0.5513133001481861\n",
            "Epoch: 290. Loss: 0.5508542709384089\n",
            "Epoch: 300. Loss: 0.5504469080348138\n",
            "Epoch: 310. Loss: 0.5500845827268726\n",
            "Epoch: 320. Loss: 0.5497616500234537\n",
            "Epoch: 330. Loss: 0.5494732804467771\n",
            "Epoch: 340. Loss: 0.5492153243073665\n",
            "Epoch: 350. Loss: 0.5489842015471776\n",
            "Epoch: 360. Loss: 0.5487768118277635\n",
            "Epoch: 370. Loss: 0.5485904607401793\n",
            "Epoch: 380. Loss: 0.5484227989244506\n",
            "Epoch: 390. Loss: 0.54827177158236\n",
            "Epoch: 400. Loss: 0.5481355764018804\n",
            "Epoch: 410. Loss: 0.5480126283244401\n",
            "Epoch: 420. Loss: 0.5479015299067255\n",
            "Epoch: 430. Loss: 0.5478010462788301\n",
            "Epoch: 440. Loss: 0.5477100838966709\n",
            "Epoch: 450. Loss: 0.5476276724410941\n",
            "Epoch: 460. Loss: 0.5475529493384002\n",
            "Epoch: 470. Loss: 0.5474851464742512\n",
            "Epoch: 480. Loss: 0.5474235787506029\n",
            "Epoch: 490. Loss: 0.5473676341975983\n",
            "tensor(0.8999, dtype=torch.float64)\n",
            "2005-05-08 00:00:00\n",
            "Epoch: 0. Loss: 1.5504244094494581\n",
            "Epoch: 10. Loss: 1.2457963991764118\n",
            "Epoch: 20. Loss: 1.0027166484541594\n",
            "Epoch: 30. Loss: 0.8284514099443812\n",
            "Epoch: 40. Loss: 0.7165061008951075\n",
            "Epoch: 50. Loss: 0.6499004947117994\n",
            "Epoch: 60. Loss: 0.6111669173458597\n",
            "Epoch: 70. Loss: 0.5882051396197738\n",
            "Epoch: 80. Loss: 0.5740692025272788\n",
            "Epoch: 90. Loss: 0.5650017359644807\n",
            "Epoch: 100. Loss: 0.558959206919316\n",
            "Epoch: 110. Loss: 0.5547953944133004\n",
            "Epoch: 120. Loss: 0.5518424493264349\n",
            "Epoch: 130. Loss: 0.5496961640634226\n",
            "Epoch: 140. Loss: 0.5481030731793303\n",
            "Epoch: 150. Loss: 0.5468990545105971\n",
            "Epoch: 160. Loss: 0.5459747448069056\n",
            "Epoch: 170. Loss: 0.5452553894504192\n",
            "Epoch: 180. Loss: 0.5446887253446309\n",
            "Epoch: 190. Loss: 0.544237478978804\n",
            "Epoch: 200. Loss: 0.5438745959335549\n",
            "Epoch: 210. Loss: 0.5435801321148358\n",
            "Epoch: 220. Loss: 0.543339182020979\n",
            "Epoch: 230. Loss: 0.5431404696079435\n",
            "Epoch: 240. Loss: 0.5429753718246526\n",
            "Epoch: 250. Loss: 0.5428372304144372\n",
            "Epoch: 260. Loss: 0.5427208593714883\n",
            "Epoch: 270. Loss: 0.5426221874869183\n",
            "Epoch: 280. Loss: 0.5425379956485561\n",
            "Epoch: 290. Loss: 0.5424657215714\n",
            "Epoch: 300. Loss: 0.5424033131553657\n",
            "Epoch: 310. Loss: 0.542349117338303\n",
            "Epoch: 320. Loss: 0.542301795146875\n",
            "Epoch: 330. Loss: 0.5422602562789282\n",
            "Epoch: 340. Loss: 0.5422236083812365\n",
            "Epoch: 350. Loss: 0.5421911174762399\n",
            "Epoch: 360. Loss: 0.5421621769112845\n",
            "Epoch: 370. Loss: 0.542136282867406\n",
            "Epoch: 380. Loss: 0.5421130149483553\n",
            "Epoch: 390. Loss: 0.5420920207265589\n",
            "Epoch: 400. Loss: 0.5420730033871108\n",
            "Epoch: 410. Loss: 0.5420557118088819\n",
            "Epoch: 420. Loss: 0.5420399325712673\n",
            "Epoch: 430. Loss: 0.5420254834886297\n",
            "Epoch: 440. Loss: 0.5420122083613604\n",
            "Epoch: 450. Loss: 0.5419999726992887\n",
            "Epoch: 460. Loss: 0.5419886602248648\n",
            "Epoch: 470. Loss: 0.5419781700037272\n",
            "Epoch: 480. Loss: 0.5419684140816291\n",
            "Epoch: 490. Loss: 0.5419593155313192\n",
            "tensor(0.8060, dtype=torch.float64)\n",
            "2005-05-15 00:00:00\n",
            "Epoch: 0. Loss: 1.1464256969949782\n",
            "Epoch: 10. Loss: 0.9976642667962013\n",
            "Epoch: 20. Loss: 0.8813374786775394\n",
            "Epoch: 30. Loss: 0.7937231242672179\n",
            "Epoch: 40. Loss: 0.7295509898652976\n",
            "Epoch: 50. Loss: 0.6831601433495407\n",
            "Epoch: 60. Loss: 0.6496426005752061\n",
            "Epoch: 70. Loss: 0.6252621960040388\n",
            "Epoch: 80. Loss: 0.6073503254961362\n",
            "Epoch: 90. Loss: 0.5940470610193185\n",
            "Epoch: 100. Loss: 0.5840609843745821\n",
            "Epoch: 110. Loss: 0.5764895724973945\n",
            "Epoch: 120. Loss: 0.5706950780548503\n",
            "Epoch: 130. Loss: 0.5662211927756388\n",
            "Epoch: 140. Loss: 0.5627374369989062\n",
            "Epoch: 150. Loss: 0.5600018431514034\n",
            "Epoch: 160. Loss: 0.5578356025109342\n",
            "Epoch: 170. Loss: 0.5561055614436604\n",
            "Epoch: 180. Loss: 0.5547119294253341\n",
            "Epoch: 190. Loss: 0.5535795083667722\n",
            "Epoch: 200. Loss: 0.5526513489444184\n",
            "Epoch: 210. Loss: 0.5518841128236851\n",
            "Epoch: 220. Loss: 0.5512446548151674\n",
            "Epoch: 230. Loss: 0.5507074896674765\n",
            "Epoch: 240. Loss: 0.5502529070517198\n",
            "Epoch: 250. Loss: 0.5498655649349644\n",
            "Epoch: 260. Loss: 0.5495334376901496\n",
            "Epoch: 270. Loss: 0.549247028011962\n",
            "Epoch: 280. Loss: 0.5489987753479368\n",
            "Epoch: 290. Loss: 0.5487826108651953\n",
            "Epoch: 300. Loss: 0.5485936217632873\n",
            "Epoch: 310. Loss: 0.5484277972426795\n",
            "Epoch: 320. Loss: 0.5482818355111572\n",
            "Epoch: 330. Loss: 0.5481529964804721\n",
            "Epoch: 340. Loss: 0.5480389887310593\n",
            "Epoch: 350. Loss: 0.5479378822439752\n",
            "Epoch: 360. Loss: 0.54784804057087\n",
            "Epoch: 370. Loss: 0.5477680677255189\n",
            "Epoch: 380. Loss: 0.5476967662771631\n",
            "Epoch: 390. Loss: 0.5476331040135601\n",
            "Epoch: 400. Loss: 0.547576187200097\n",
            "Epoch: 410. Loss: 0.5475252389500187\n",
            "Epoch: 420. Loss: 0.5474795815839377\n",
            "Epoch: 430. Loss: 0.5474386221270563\n",
            "Epoch: 440. Loss: 0.5474018402941425\n",
            "Epoch: 450. Loss: 0.5473687784631662\n",
            "Epoch: 460. Loss: 0.5473390332517604\n",
            "Epoch: 470. Loss: 0.5473122483961075\n",
            "Epoch: 480. Loss: 0.5472881086965636\n",
            "Epoch: 490. Loss: 0.547266334843664\n",
            "tensor(0.8767, dtype=torch.float64)\n",
            "2005-05-22 00:00:00\n",
            "Epoch: 0. Loss: 1.469141633318029\n",
            "Epoch: 10. Loss: 1.1567085278447655\n",
            "Epoch: 20. Loss: 0.9327742240990009\n",
            "Epoch: 30. Loss: 0.7909690583882512\n",
            "Epoch: 40. Loss: 0.707345470553201\n",
            "Epoch: 50. Loss: 0.6578122469342457\n",
            "Epoch: 60. Loss: 0.626893494222057\n",
            "Epoch: 70. Loss: 0.6063210708136882\n",
            "Epoch: 80. Loss: 0.5918462221687659\n",
            "Epoch: 90. Loss: 0.5812165084762674\n",
            "Epoch: 100. Loss: 0.5731646264137082\n",
            "Epoch: 110. Loss: 0.5669283641156495\n",
            "Epoch: 120. Loss: 0.5620195260492424\n",
            "Epoch: 130. Loss: 0.5581081864986982\n",
            "Epoch: 140. Loss: 0.5549616499076842\n",
            "Epoch: 150. Loss: 0.5524103710029503\n",
            "Epoch: 160. Loss: 0.5503277827974883\n",
            "Epoch: 170. Loss: 0.5486176742775466\n",
            "Epoch: 180. Loss: 0.5472058936195398\n",
            "Epoch: 190. Loss: 0.5460346668709476\n",
            "Epoch: 200. Loss: 0.5450585794914381\n",
            "Epoch: 210. Loss: 0.544241662313027\n",
            "Epoch: 220. Loss: 0.5435552378332836\n",
            "Epoch: 230. Loss: 0.5429763050006974\n",
            "Epoch: 240. Loss: 0.5424863138169437\n",
            "Epoch: 250. Loss: 0.5420702269269532\n",
            "Epoch: 260. Loss: 0.5417157952904448\n",
            "Epoch: 270. Loss: 0.5414129952389386\n",
            "Epoch: 280. Loss: 0.5411535882548872\n",
            "Epoch: 290. Loss: 0.5409307747669301\n",
            "Epoch: 300. Loss: 0.5407389204419252\n",
            "Epoch: 310. Loss: 0.5405733387111704\n",
            "Epoch: 320. Loss: 0.540430117154808\n",
            "Epoch: 330. Loss: 0.5403059782674999\n",
            "Epoch: 340. Loss: 0.5401981673072627\n",
            "Epoch: 350. Loss: 0.5401043615776248\n",
            "Epoch: 360. Loss: 0.5400225967475897\n",
            "Epoch: 370. Loss: 0.5399512067735945\n",
            "Epoch: 380. Loss: 0.5398887747256826\n",
            "Epoch: 390. Loss: 0.5398340923903884\n",
            "Epoch: 400. Loss: 0.5397861269655003\n",
            "Epoch: 410. Loss: 0.5397439935070112\n",
            "Epoch: 420. Loss: 0.539706932058785\n",
            "Epoch: 430. Loss: 0.539674288607926\n",
            "Epoch: 440. Loss: 0.5396454991765159\n",
            "Epoch: 450. Loss: 0.5396200764932612\n",
            "Epoch: 460. Loss: 0.5395975987942557\n",
            "Epoch: 470. Loss: 0.5395777003864284\n",
            "Epoch: 480. Loss: 0.5395600636748038\n",
            "Epoch: 490. Loss: 0.5395444124090323\n",
            "tensor(0.8080, dtype=torch.float64)\n",
            "2005-05-29 00:00:00\n",
            "Epoch: 0. Loss: 1.68832924359321\n",
            "Epoch: 10. Loss: 1.45012105494808\n",
            "Epoch: 20. Loss: 1.2696974855848613\n",
            "Epoch: 30. Loss: 1.131817682552467\n",
            "Epoch: 40. Loss: 1.024357740441781\n",
            "Epoch: 50. Loss: 0.9389365632622119\n",
            "Epoch: 60. Loss: 0.8700343172234278\n",
            "Epoch: 70. Loss: 0.8139440595574756\n",
            "Epoch: 80. Loss: 0.7680353983481285\n",
            "Epoch: 90. Loss: 0.7303259729851822\n",
            "Epoch: 100. Loss: 0.6992542602576337\n",
            "Epoch: 110. Loss: 0.6735630679495032\n",
            "Epoch: 120. Loss: 0.652235305184398\n",
            "Epoch: 130. Loss: 0.6344509543904355\n",
            "Epoch: 140. Loss: 0.6195522537542267\n",
            "Epoch: 150. Loss: 0.6070133470344968\n",
            "Epoch: 160. Loss: 0.5964140194620589\n",
            "Epoch: 170. Loss: 0.5874177041005219\n",
            "Epoch: 180. Loss: 0.5797536475718358\n",
            "Epoch: 190. Loss: 0.5732027915296019\n",
            "Epoch: 200. Loss: 0.5675867647069341\n",
            "Epoch: 210. Loss: 0.5627593674499253\n",
            "Epoch: 220. Loss: 0.5585999988776874\n",
            "Epoch: 230. Loss: 0.5550085737563896\n",
            "Epoch: 240. Loss: 0.5519015726009189\n",
            "Epoch: 250. Loss: 0.5492089518752717\n",
            "Epoch: 260. Loss: 0.5468717081983515\n",
            "Epoch: 270. Loss: 0.5448399422059321\n",
            "Epoch: 280. Loss: 0.5430713067195924\n",
            "Epoch: 290. Loss: 0.5415297528761724\n",
            "Epoch: 300. Loss: 0.54018450929604\n",
            "Epoch: 310. Loss: 0.5390092451627415\n",
            "Epoch: 320. Loss: 0.5379813797449988\n",
            "Epoch: 330. Loss: 0.5370815095301656\n",
            "Epoch: 340. Loss: 0.5362929305755723\n",
            "Epoch: 350. Loss: 0.5356012385166719\n",
            "Epoch: 360. Loss: 0.5349939923297592\n",
            "Epoch: 370. Loss: 0.5344604307435286\n",
            "Epoch: 380. Loss: 0.5339912323524871\n",
            "Epoch: 390. Loss: 0.5335783121686405\n",
            "Epoch: 400. Loss: 0.5332146486737498\n",
            "Epoch: 410. Loss: 0.5328941364887357\n",
            "Epoch: 420. Loss: 0.5326114606225796\n",
            "Epoch: 430. Loss: 0.5323619889470512\n",
            "Epoch: 440. Loss: 0.5321416801007035\n",
            "Epoch: 450. Loss: 0.5319470044821848\n",
            "Epoch: 460. Loss: 0.5317748763692027\n",
            "Epoch: 470. Loss: 0.5316225955109793\n",
            "Epoch: 480. Loss: 0.5314877968009512\n",
            "Epoch: 490. Loss: 0.5313684068523925\n",
            "tensor(0.6929, dtype=torch.float64)\n",
            "2005-06-05 00:00:00\n",
            "Epoch: 0. Loss: 0.6053239636791531\n",
            "Epoch: 10. Loss: 0.5920853599679549\n",
            "Epoch: 20. Loss: 0.5821999743785984\n",
            "Epoch: 30. Loss: 0.5745999925607245\n",
            "Epoch: 40. Loss: 0.5686256901996647\n",
            "Epoch: 50. Loss: 0.5638479966531486\n",
            "Epoch: 60. Loss: 0.5599752281486001\n",
            "Epoch: 70. Loss: 0.5568015888833362\n",
            "Epoch: 80. Loss: 0.5541773622942693\n",
            "Epoch: 90. Loss: 0.5519908728567333\n",
            "Epoch: 100. Loss: 0.5501571106624755\n",
            "Epoch: 110. Loss: 0.548610282788404\n",
            "Epoch: 120. Loss: 0.5472987694048084\n",
            "Epoch: 130. Loss: 0.546181606458475\n",
            "Epoch: 140. Loss: 0.5452259701320263\n",
            "Epoch: 150. Loss: 0.5444053387042154\n",
            "Epoch: 160. Loss: 0.5436981248169337\n",
            "Epoch: 170. Loss: 0.5430866420790763\n",
            "Epoch: 180. Loss: 0.542556314102081\n",
            "Epoch: 190. Loss: 0.5420950623641485\n",
            "Epoch: 200. Loss: 0.5416928279315071\n",
            "Epoch: 210. Loss: 0.5413411946374789\n",
            "Epoch: 220. Loss: 0.5410330899959969\n",
            "Epoch: 230. Loss: 0.5407625462339073\n",
            "Epoch: 240. Loss: 0.5405245082023742\n",
            "Epoch: 250. Loss: 0.5403146781115672\n",
            "Epoch: 260. Loss: 0.5401293893805789\n",
            "Epoch: 270. Loss: 0.5399655036460977\n",
            "Epoch: 280. Loss: 0.5398203262935752\n",
            "Epoch: 290. Loss: 0.5396915368786922\n",
            "Epoch: 300. Loss: 0.539577131576663\n",
            "Epoch: 310. Loss: 0.5394753753912314\n",
            "Epoch: 320. Loss: 0.5393847623170364\n",
            "Epoch: 330. Loss: 0.5393039820100187\n",
            "Epoch: 340. Loss: 0.5392318918042186\n",
            "Epoch: 350. Loss: 0.5391674931373732\n",
            "Epoch: 360. Loss: 0.5391099116254982\n",
            "Epoch: 370. Loss: 0.539058380168332\n",
            "Epoch: 380. Loss: 0.5390122245808997\n",
            "Epoch: 390. Loss: 0.5389708513375622\n",
            "Epoch: 400. Loss: 0.5389337370883858\n",
            "Epoch: 410. Loss: 0.5389004196671331\n",
            "Epoch: 420. Loss: 0.5388704903584907\n",
            "Epoch: 430. Loss: 0.5388435872315098\n",
            "Epoch: 440. Loss: 0.5388193893784363\n",
            "Epoch: 450. Loss: 0.5387976119245185\n",
            "Epoch: 460. Loss: 0.5387780016961096\n",
            "Epoch: 470. Loss: 0.5387603334523329\n",
            "Epoch: 480. Loss: 0.5387444066004263\n",
            "Epoch: 490. Loss: 0.538730042327222\n",
            "tensor(0.8146, dtype=torch.float64)\n",
            "2005-06-12 00:00:00\n",
            "Epoch: 0. Loss: 0.6435587100504607\n",
            "Epoch: 10. Loss: 0.6236296695406377\n",
            "Epoch: 20. Loss: 0.6076192187644763\n",
            "Epoch: 30. Loss: 0.5947741378566131\n",
            "Epoch: 40. Loss: 0.5844689413205872\n",
            "Epoch: 50. Loss: 0.5761904179569747\n",
            "Epoch: 60. Loss: 0.5695230987469326\n",
            "Epoch: 70. Loss: 0.5641348643370249\n",
            "Epoch: 80. Loss: 0.5597627025904055\n",
            "Epoch: 90. Loss: 0.5561994380943089\n",
            "Epoch: 100. Loss: 0.5532821791148853\n",
            "Epoch: 110. Loss: 0.5508827713210108\n",
            "Epoch: 120. Loss: 0.5489001708060388\n",
            "Epoch: 130. Loss: 0.5472544657980015\n",
            "Epoch: 140. Loss: 0.5458822343570497\n",
            "Epoch: 150. Loss: 0.5447329520073646\n",
            "Epoch: 160. Loss: 0.543766212281793\n",
            "Epoch: 170. Loss: 0.5429495727711113\n",
            "Epoch: 180. Loss: 0.5422568817281108\n",
            "Epoch: 190. Loss: 0.5416669741745249\n",
            "Epoch: 200. Loss: 0.5411626526949144\n",
            "Epoch: 210. Loss: 0.5407298881379994\n",
            "Epoch: 220. Loss: 0.5403571906732347\n",
            "Epoch: 230. Loss: 0.5400351132135073\n",
            "Epoch: 240. Loss: 0.5397558580047731\n",
            "Epoch: 250. Loss: 0.5395129638780776\n",
            "Epoch: 260. Loss: 0.5393010567698348\n",
            "Epoch: 270. Loss: 0.5391156500269796\n",
            "Epoch: 280. Loss: 0.5389529840140002\n",
            "Epoch: 290. Loss: 0.5388098968469524\n",
            "Epoch: 300. Loss: 0.5386837198599557\n",
            "Epoch: 310. Loss: 0.538572192786883\n",
            "Epoch: 320. Loss: 0.5384733947093614\n",
            "Epoch: 330. Loss: 0.5383856876534497\n",
            "Epoch: 340. Loss: 0.5383076703660226\n",
            "Epoch: 350. Loss: 0.5382381403095776\n",
            "Epoch: 360. Loss: 0.538176062312725\n",
            "Epoch: 370. Loss: 0.5381205426274124\n",
            "Epoch: 380. Loss: 0.5380708073917398\n",
            "Epoch: 390. Loss: 0.5380261846934923\n",
            "Epoch: 400. Loss: 0.5379860895854115\n",
            "Epoch: 410. Loss: 0.5379500115274346\n",
            "Epoch: 420. Loss: 0.5379175038303399\n",
            "Epoch: 430. Loss: 0.5378881747547305\n",
            "Epoch: 440. Loss: 0.5378616799831423\n",
            "Epoch: 450. Loss: 0.5378377162344973\n",
            "Epoch: 460. Loss: 0.5378160158316663\n",
            "Epoch: 470. Loss: 0.53779634206655\n",
            "Epoch: 480. Loss: 0.5377784852344005\n",
            "Epoch: 490. Loss: 0.5377622592313324\n",
            "tensor(0.6926, dtype=torch.float64)\n",
            "2005-06-19 00:00:00\n",
            "Epoch: 0. Loss: 2.1923512390350295\n",
            "Epoch: 10. Loss: 1.7527064815047388\n",
            "Epoch: 20. Loss: 1.3716935024748058\n",
            "Epoch: 30. Loss: 1.0707623502751835\n",
            "Epoch: 40. Loss: 0.8609720696752303\n",
            "Epoch: 50. Loss: 0.7316822324090024\n",
            "Epoch: 60. Loss: 0.658118491276934\n",
            "Epoch: 70. Loss: 0.6169723940658434\n",
            "Epoch: 80. Loss: 0.5931303619963088\n",
            "Epoch: 90. Loss: 0.5784350265116839\n",
            "Epoch: 100. Loss: 0.5687479246202207\n",
            "Epoch: 110. Loss: 0.5619530492570637\n",
            "Epoch: 120. Loss: 0.5569264534184613\n",
            "Epoch: 130. Loss: 0.5530419783991206\n",
            "Epoch: 140. Loss: 0.5499333990716955\n",
            "Epoch: 150. Loss: 0.5473763269603573\n",
            "Epoch: 160. Loss: 0.5452271849930882\n",
            "Epoch: 170. Loss: 0.543390351052906\n",
            "Epoch: 180. Loss: 0.5417997558047\n",
            "Epoch: 190. Loss: 0.5404081883085461\n",
            "Epoch: 200. Loss: 0.539180864909958\n",
            "Epoch: 210. Loss: 0.5380914382536535\n",
            "Epoch: 220. Loss: 0.5371194479680799\n",
            "Epoch: 230. Loss: 0.5362486484461703\n",
            "Epoch: 240. Loss: 0.5354658848087055\n",
            "Epoch: 250. Loss: 0.5347603200366372\n",
            "Epoch: 260. Loss: 0.5341228921961336\n",
            "Epoch: 270. Loss: 0.5335459255706944\n",
            "Epoch: 280. Loss: 0.533022846715207\n",
            "Epoch: 290. Loss: 0.5325479733102637\n",
            "Epoch: 300. Loss: 0.5321163543726479\n",
            "Epoch: 310. Loss: 0.5317236472703775\n",
            "Epoch: 320. Loss: 0.5313660215184673\n",
            "Epoch: 330. Loss: 0.5310400823535328\n",
            "Epoch: 340. Loss: 0.5307428091314734\n",
            "Epoch: 350. Loss: 0.5304715049960954\n",
            "Epoch: 360. Loss: 0.5302237552410383\n",
            "Epoch: 370. Loss: 0.5299973924715278\n",
            "Epoch: 380. Loss: 0.5297904671579299\n",
            "Epoch: 390. Loss: 0.5296012225210551\n",
            "Epoch: 400. Loss: 0.5294280729411452\n",
            "Epoch: 410. Loss: 0.5292695852667707\n",
            "Epoch: 420. Loss: 0.5291244625360865\n",
            "Epoch: 430. Loss: 0.5289915297246126\n",
            "Epoch: 440. Loss: 0.5288697212105132\n",
            "Epoch: 450. Loss: 0.5287580697069857\n",
            "Epoch: 460. Loss: 0.5286556964566393\n",
            "Epoch: 470. Loss: 0.5285618025181159\n",
            "Epoch: 480. Loss: 0.5284756610031277\n",
            "Epoch: 490. Loss: 0.5283966101444151\n",
            "tensor(0.7969, dtype=torch.float64)\n",
            "2005-06-26 00:00:00\n",
            "Epoch: 0. Loss: 0.674764899831016\n",
            "Epoch: 10. Loss: 0.6532474983434734\n",
            "Epoch: 20. Loss: 0.6362169194457316\n",
            "Epoch: 30. Loss: 0.622401440045245\n",
            "Epoch: 40. Loss: 0.6109442320726053\n",
            "Epoch: 50. Loss: 0.6012631917988577\n",
            "Epoch: 60. Loss: 0.5929583532937848\n",
            "Epoch: 70. Loss: 0.5857508192217908\n",
            "Epoch: 80. Loss: 0.5794424423622572\n",
            "Epoch: 90. Loss: 0.57388913839547\n",
            "Epoch: 100. Loss: 0.5689831645547415\n",
            "Epoch: 110. Loss: 0.5646413217088097\n",
            "Epoch: 120. Loss: 0.5607970956890334\n",
            "Epoch: 130. Loss: 0.557395437202576\n",
            "Epoch: 140. Loss: 0.5543893194775376\n",
            "Epoch: 150. Loss: 0.5517374964415973\n",
            "Epoch: 160. Loss: 0.5494030688552205\n",
            "Epoch: 170. Loss: 0.5473525879377836\n",
            "Epoch: 180. Loss: 0.5455555086272683\n",
            "Epoch: 190. Loss: 0.5439838619437491\n",
            "Epoch: 200. Loss: 0.5426120566894902\n",
            "Epoch: 210. Loss: 0.5414167501992747\n",
            "Epoch: 220. Loss: 0.5403767492929038\n",
            "Epoch: 230. Loss: 0.5394729180395381\n",
            "Epoch: 240. Loss: 0.5386880798288329\n",
            "Epoch: 250. Loss: 0.5380069086053189\n",
            "Epoch: 260. Loss: 0.5374158087989517\n",
            "Epoch: 270. Loss: 0.5369027861713236\n",
            "Epoch: 280. Loss: 0.5364573130699742\n",
            "Epoch: 290. Loss: 0.5360701919088909\n",
            "Epoch: 300. Loss: 0.5357334204345816\n",
            "Epoch: 310. Loss: 0.5354400617629954\n",
            "Epoch: 320. Loss: 0.5351841214711869\n",
            "Epoch: 330. Loss: 0.5349604333212504\n",
            "Epoch: 340. Loss: 0.5347645545546694\n",
            "Epoch: 350. Loss: 0.534592671158427\n",
            "Epoch: 360. Loss: 0.5344415130811477\n",
            "Epoch: 370. Loss: 0.5343082790640532\n",
            "Epoch: 380. Loss: 0.5341905705352017\n",
            "Epoch: 390. Loss: 0.5340863338801395\n",
            "Epoch: 400. Loss: 0.5339938103310232\n",
            "Epoch: 410. Loss: 0.5339114926937975\n",
            "Epoch: 420. Loss: 0.5338380881456044\n",
            "Epoch: 430. Loss: 0.5337724863710254\n",
            "Epoch: 440. Loss: 0.5337137323571367\n",
            "Epoch: 450. Loss: 0.5336610032269499\n",
            "Epoch: 460. Loss: 0.5336135885536205\n",
            "Epoch: 470. Loss: 0.5335708736603539\n",
            "Epoch: 480. Loss: 0.5335323254708945\n",
            "Epoch: 490. Loss: 0.5334974805313668\n",
            "tensor(0.7835, dtype=torch.float64)\n",
            "2005-07-03 00:00:00\n",
            "Epoch: 0. Loss: 0.972464156540622\n",
            "Epoch: 10. Loss: 0.829130487778914\n",
            "Epoch: 20. Loss: 0.7376527539455184\n",
            "Epoch: 30. Loss: 0.6800457914529414\n",
            "Epoch: 40. Loss: 0.6431537655839468\n",
            "Epoch: 50. Loss: 0.6187810278865833\n",
            "Epoch: 60. Loss: 0.6020733240029872\n",
            "Epoch: 70. Loss: 0.5901742260850331\n",
            "Epoch: 80. Loss: 0.5813810393624002\n",
            "Epoch: 90. Loss: 0.5746564958221112\n",
            "Epoch: 100. Loss: 0.5693526217192203\n",
            "Epoch: 110. Loss: 0.5650540489770317\n",
            "Epoch: 120. Loss: 0.5614876934842532\n",
            "Epoch: 130. Loss: 0.5584695838931933\n",
            "Epoch: 140. Loss: 0.5558728423556605\n",
            "Epoch: 150. Loss: 0.5536079635421225\n",
            "Epoch: 160. Loss: 0.5516104041149561\n",
            "Epoch: 170. Loss: 0.5498326135764756\n",
            "Epoch: 180. Loss: 0.5482388201496523\n",
            "Epoch: 190. Loss: 0.5468015592888699\n",
            "Epoch: 200. Loss: 0.545499324596695\n",
            "Epoch: 210. Loss: 0.5443149538877062\n",
            "Epoch: 220. Loss: 0.5432345042809859\n",
            "Epoch: 230. Loss: 0.542246457315203\n",
            "Epoch: 240. Loss: 0.5413411497879315\n",
            "Epoch: 250. Loss: 0.5405103609373123\n",
            "Epoch: 260. Loss: 0.5397470092053053\n",
            "Epoch: 270. Loss: 0.5390449266818962\n",
            "Epoch: 280. Loss: 0.5383986892178286\n",
            "Epoch: 290. Loss: 0.5378034868523969\n",
            "Epoch: 300. Loss: 0.5372550237375507\n",
            "Epoch: 310. Loss: 0.5367494398602576\n",
            "Epoch: 320. Loss: 0.5362832490340994\n",
            "Epoch: 330. Loss: 0.5358532891529725\n",
            "Epoch: 340. Loss: 0.535456681777317\n",
            "Epoch: 350. Loss: 0.5350907988929249\n",
            "Epoch: 360. Loss: 0.5347532352367225\n",
            "Epoch: 370. Loss: 0.5344417849864702\n",
            "Epoch: 380. Loss: 0.534154421905944\n",
            "Epoch: 390. Loss: 0.5338892822544332\n",
            "Epoch: 400. Loss: 0.5336446499307876\n",
            "Epoch: 410. Loss: 0.5334189434429498\n",
            "Epoch: 420. Loss: 0.5332107043848081\n",
            "Epoch: 430. Loss: 0.5330185871710378\n",
            "Epoch: 440. Loss: 0.53284134983307\n",
            "Epoch: 450. Loss: 0.5326778457195137\n",
            "Epoch: 460. Loss: 0.5325270159753167\n",
            "Epoch: 470. Loss: 0.5323878826979136\n",
            "Epoch: 480. Loss: 0.5322595426872548\n",
            "Epoch: 490. Loss: 0.5321411617211838\n",
            "tensor(0.7033, dtype=torch.float64)\n",
            "2005-07-10 00:00:00\n",
            "Epoch: 0. Loss: 0.6290026192847954\n",
            "Epoch: 10. Loss: 0.592932273935416\n",
            "Epoch: 20. Loss: 0.5711107343867049\n",
            "Epoch: 30. Loss: 0.557367194222259\n",
            "Epoch: 40. Loss: 0.5483757121842844\n",
            "Epoch: 50. Loss: 0.5422947838399669\n",
            "Epoch: 60. Loss: 0.5380633539991304\n",
            "Epoch: 70. Loss: 0.5350451555909702\n",
            "Epoch: 80. Loss: 0.5328447359005959\n",
            "Epoch: 90. Loss: 0.5312085881313009\n",
            "Epoch: 100. Loss: 0.5299698388636733\n",
            "Epoch: 110. Loss: 0.529016115433643\n",
            "Epoch: 120. Loss: 0.52827023913703\n",
            "Epoch: 130. Loss: 0.5276782760753599\n",
            "Epoch: 140. Loss: 0.5272019481339071\n",
            "Epoch: 150. Loss: 0.5268137033757468\n",
            "Epoch: 160. Loss: 0.526493450357297\n",
            "Epoch: 170. Loss: 0.5262263571486612\n",
            "Epoch: 180. Loss: 0.5260013452558772\n",
            "Epoch: 190. Loss: 0.5258100450849994\n",
            "Epoch: 200. Loss: 0.5256460627354539\n",
            "Epoch: 210. Loss: 0.5255044597035904\n",
            "Epoch: 220. Loss: 0.5253813799845408\n",
            "Epoch: 230. Loss: 0.5252737803443365\n",
            "Epoch: 240. Loss: 0.5251792335234651\n",
            "Epoch: 250. Loss: 0.525095783461956\n",
            "Epoch: 260. Loss: 0.5250218379390413\n",
            "Epoch: 270. Loss: 0.5249560883293657\n",
            "Epoch: 280. Loss: 0.5248974491548825\n",
            "Epoch: 290. Loss: 0.5248450121883672\n",
            "Epoch: 300. Loss: 0.5247980113257569\n",
            "Epoch: 310. Loss: 0.5247557954807969\n",
            "Epoch: 320. Loss: 0.5247178074956013\n",
            "Epoch: 330. Loss: 0.5246835675927782\n",
            "Epoch: 340. Loss: 0.5246526602795638\n",
            "Epoch: 350. Loss: 0.5246247238942245\n",
            "Epoch: 360. Loss: 0.5245994421895752\n",
            "Epoch: 370. Loss: 0.5245765374987663\n",
            "Epoch: 380. Loss: 0.5245557651394792\n",
            "Epoch: 390. Loss: 0.524536908795006\n",
            "Epoch: 400. Loss: 0.5245197766720654\n",
            "Epoch: 410. Loss: 0.5245041982811829\n",
            "Epoch: 420. Loss: 0.5244900217200769\n",
            "Epoch: 430. Loss: 0.524477111366683\n",
            "Epoch: 440. Loss: 0.5244653459083704\n",
            "Epoch: 450. Loss: 0.5244546166491573\n",
            "Epoch: 460. Loss: 0.5244448260484569\n",
            "Epoch: 470. Loss: 0.5244358864539765\n",
            "Epoch: 480. Loss: 0.5244277189984728\n",
            "Epoch: 490. Loss: 0.5244202526356239\n",
            "tensor(0.8048, dtype=torch.float64)\n",
            "2005-07-17 00:00:00\n",
            "Epoch: 0. Loss: 0.9424468943229989\n",
            "Epoch: 10. Loss: 0.8703075626891599\n",
            "Epoch: 20. Loss: 0.8083299756868557\n",
            "Epoch: 30. Loss: 0.7560732512645985\n",
            "Epoch: 40. Loss: 0.7126775664943675\n",
            "Epoch: 50. Loss: 0.6770597867568643\n",
            "Epoch: 60. Loss: 0.648105418397251\n",
            "Epoch: 70. Loss: 0.6247642578007292\n",
            "Epoch: 80. Loss: 0.6060746835177682\n",
            "Epoch: 90. Loss: 0.5911716244795305\n",
            "Epoch: 100. Loss: 0.5793000986985729\n",
            "Epoch: 110. Loss: 0.5698264510357808\n",
            "Epoch: 120. Loss: 0.5622372689398356\n",
            "Epoch: 130. Loss: 0.5561265775608514\n",
            "Epoch: 140. Loss: 0.5511776317324482\n",
            "Epoch: 150. Loss: 0.5471446541138407\n",
            "Epoch: 160. Loss: 0.5438370673115495\n",
            "Epoch: 170. Loss: 0.5411068161799925\n",
            "Epoch: 180. Loss: 0.538838508309241\n",
            "Epoch: 190. Loss: 0.5369418550470982\n",
            "Epoch: 200. Loss: 0.5353459053300741\n",
            "Epoch: 210. Loss: 0.5339946499744482\n",
            "Epoch: 220. Loss: 0.5328436660569279\n",
            "Epoch: 230. Loss: 0.531857549209043\n",
            "Epoch: 240. Loss: 0.5310079431204842\n",
            "Epoch: 250. Loss: 0.5302720224598401\n",
            "Epoch: 260. Loss: 0.5296313208244058\n",
            "Epoch: 270. Loss: 0.5290708219417258\n",
            "Epoch: 280. Loss: 0.5285782523256893\n",
            "Epoch: 290. Loss: 0.5281435285933348\n",
            "Epoch: 300. Loss: 0.5277583239236111\n",
            "Epoch: 310. Loss: 0.5274157266235245\n",
            "Epoch: 320. Loss: 0.5271099701623696\n",
            "Epoch: 330. Loss: 0.5268362188658536\n",
            "Epoch: 340. Loss: 0.5265903971207252\n",
            "Epoch: 350. Loss: 0.5263690527194513\n",
            "Epoch: 360. Loss: 0.5261692470917477\n",
            "Epoch: 370. Loss: 0.5259884667882645\n",
            "Epoch: 380. Loss: 0.5258245518232533\n",
            "Epoch: 390. Loss: 0.5256756374387653\n",
            "Epoch: 400. Loss: 0.5255401065912771\n",
            "Epoch: 410. Loss: 0.5254165510340958\n",
            "Epoch: 420. Loss: 0.5253037393142883\n",
            "Epoch: 430. Loss: 0.5252005903506343\n",
            "Epoch: 440. Loss: 0.5251061515315186\n",
            "Epoch: 450. Loss: 0.525019580485812\n",
            "Epoch: 460. Loss: 0.5249401298486158\n",
            "Epoch: 470. Loss: 0.524867134477297\n",
            "Epoch: 480. Loss: 0.5248000006791732\n",
            "Epoch: 490. Loss: 0.5247381970965017\n",
            "tensor(0.8028, dtype=torch.float64)\n",
            "2005-07-24 00:00:00\n",
            "Epoch: 0. Loss: 0.8923502499026709\n",
            "Epoch: 10. Loss: 0.8169578275045455\n",
            "Epoch: 20. Loss: 0.7584421052868215\n",
            "Epoch: 30. Loss: 0.713244421284055\n",
            "Epoch: 40. Loss: 0.6783791503121432\n",
            "Epoch: 50. Loss: 0.6513927584075819\n",
            "Epoch: 60. Loss: 0.6303356878018901\n",
            "Epoch: 70. Loss: 0.6137091436343339\n",
            "Epoch: 80. Loss: 0.6003914411969565\n",
            "Epoch: 90. Loss: 0.589558698408826\n",
            "Epoch: 100. Loss: 0.5806119740051198\n",
            "Epoch: 110. Loss: 0.5731170283984781\n",
            "Epoch: 120. Loss: 0.5667579067906867\n",
            "Epoch: 130. Loss: 0.5613027673488958\n",
            "Epoch: 140. Loss: 0.5565794175603589\n",
            "Epoch: 150. Loss: 0.5524580721623167\n",
            "Epoch: 160. Loss: 0.5488392879836227\n",
            "Epoch: 170. Loss: 0.5456455342536561\n",
            "Epoch: 180. Loss: 0.5428152896589099\n",
            "Epoch: 190. Loss: 0.5402988887649013\n",
            "Epoch: 200. Loss: 0.5380555797380736\n",
            "Epoch: 210. Loss: 0.5360514229206854\n",
            "Epoch: 220. Loss: 0.5342577754071937\n",
            "Epoch: 230. Loss: 0.5326501859731757\n",
            "Epoch: 240. Loss: 0.5312075789143388\n",
            "Epoch: 250. Loss: 0.5299116425253702\n",
            "Epoch: 260. Loss: 0.5287463635289402\n",
            "Epoch: 270. Loss: 0.527697666439305\n",
            "Epoch: 280. Loss: 0.5267531291025224\n",
            "Epoch: 290. Loss: 0.5259017541828868\n",
            "Epoch: 300. Loss: 0.5251337823112794\n",
            "Epoch: 310. Loss: 0.52444053676305\n",
            "Epoch: 320. Loss: 0.5238142924342606\n",
            "Epoch: 330. Loss: 0.5232481639130273\n",
            "Epoch: 340. Loss: 0.5227360088607215\n",
            "Epoch: 350. Loss: 0.5222723439103177\n",
            "Epoch: 360. Loss: 0.5218522709854571\n",
            "Epoch: 370. Loss: 0.5214714124343758\n",
            "Epoch: 380. Loss: 0.5211258537210282\n",
            "Epoch: 390. Loss: 0.5208120926655592\n",
            "Epoch: 400. Loss: 0.5205269944083343\n",
            "Epoch: 410. Loss: 0.5202677514070423\n",
            "Epoch: 420. Loss: 0.5200318478793696\n",
            "Epoch: 430. Loss: 0.5198170281842452\n",
            "Epoch: 440. Loss: 0.5196212686992961\n",
            "Epoch: 450. Loss: 0.5194427528054331\n",
            "Epoch: 460. Loss: 0.5192798486344155\n",
            "Epoch: 470. Loss: 0.5191310892738602\n",
            "Epoch: 480. Loss: 0.5189951551578246\n",
            "Epoch: 490. Loss: 0.518870858400775\n",
            "tensor(0.7407, dtype=torch.float64)\n",
            "2005-07-31 00:00:00\n",
            "Epoch: 0. Loss: 0.7821816766769248\n",
            "Epoch: 10. Loss: 0.733017077910175\n",
            "Epoch: 20. Loss: 0.6936399139772524\n",
            "Epoch: 30. Loss: 0.6620332270926532\n",
            "Epoch: 40. Loss: 0.6365563425718325\n",
            "Epoch: 50. Loss: 0.6159136578889038\n",
            "Epoch: 60. Loss: 0.599097602276772\n",
            "Epoch: 70. Loss: 0.5853291479480748\n",
            "Epoch: 80. Loss: 0.5740052017273745\n",
            "Epoch: 90. Loss: 0.5646561721020851\n",
            "Epoch: 100. Loss: 0.5569134747454803\n",
            "Epoch: 110. Loss: 0.5504852016500456\n",
            "Epoch: 120. Loss: 0.5451380050932364\n",
            "Epoch: 130. Loss: 0.5406836064881717\n",
            "Epoch: 140. Loss: 0.5369687443562711\n",
            "Epoch: 150. Loss: 0.5338676806311188\n",
            "Epoch: 160. Loss: 0.5312765981735559\n",
            "Epoch: 170. Loss: 0.5291093802639464\n",
            "Epoch: 180. Loss: 0.5272943878347345\n",
            "Epoch: 190. Loss: 0.5257719516220268\n",
            "Epoch: 200. Loss: 0.5244923772440178\n",
            "Epoch: 210. Loss: 0.5234143231435987\n",
            "Epoch: 220. Loss: 0.5225034565954647\n",
            "Epoch: 230. Loss: 0.521731324480682\n",
            "Epoch: 240. Loss: 0.5210743964176522\n",
            "Epoch: 250. Loss: 0.5205132510497514\n",
            "Epoch: 260. Loss: 0.5200318842977398\n",
            "Epoch: 270. Loss: 0.5196171230917359\n",
            "Epoch: 280. Loss: 0.5192581308593045\n",
            "Epoch: 290. Loss: 0.5189459927596776\n",
            "Epoch: 300. Loss: 0.518673369865756\n",
            "Epoch: 310. Loss: 0.5184342125062533\n",
            "Epoch: 320. Loss: 0.5182235239327019\n",
            "Epoch: 330. Loss: 0.5180371664195442\n",
            "Epoch: 340. Loss: 0.5178717028414419\n",
            "Epoch: 350. Loss: 0.5177242676814618\n",
            "Epoch: 360. Loss: 0.5175924622841728\n",
            "Epoch: 370. Loss: 0.5174742699599494\n",
            "Epoch: 380. Loss: 0.5173679872587361\n",
            "Epoch: 390. Loss: 0.5172721683577652\n",
            "Epoch: 400. Loss: 0.5171855800485824\n",
            "Epoch: 410. Loss: 0.517107165268562\n",
            "Epoch: 420. Loss: 0.5170360135079113\n",
            "Epoch: 430. Loss: 0.5169713367432377\n",
            "Epoch: 440. Loss: 0.5169124498118178\n",
            "Epoch: 450. Loss: 0.516858754355182\n",
            "Epoch: 460. Loss: 0.5168097256343603\n",
            "Epoch: 470. Loss: 0.5167649016590922\n",
            "Epoch: 480. Loss: 0.5167238741855575\n",
            "Epoch: 490. Loss: 0.5166862812269116\n",
            "tensor(0.7978, dtype=torch.float64)\n",
            "2005-08-07 00:00:00\n",
            "Epoch: 0. Loss: 1.1159154816950057\n",
            "Epoch: 10. Loss: 0.9915293769404371\n",
            "Epoch: 20. Loss: 0.8899997323133332\n",
            "Epoch: 30. Loss: 0.8091651535340195\n",
            "Epoch: 40. Loss: 0.7460591326915806\n",
            "Epoch: 50. Loss: 0.6973909587754229\n",
            "Epoch: 60. Loss: 0.6600604059528222\n",
            "Epoch: 70. Loss: 0.6314392922733293\n",
            "Epoch: 80. Loss: 0.6094335616205633\n",
            "Epoch: 90. Loss: 0.5924314803820192\n",
            "Epoch: 100. Loss: 0.5792151967000243\n",
            "Epoch: 110. Loss: 0.5688725250340209\n",
            "Epoch: 120. Loss: 0.5607221325762831\n",
            "Epoch: 130. Loss: 0.5542545844208548\n",
            "Epoch: 140. Loss: 0.5490876254863999\n",
            "Epoch: 150. Loss: 0.5449329519472386\n",
            "Epoch: 160. Loss: 0.5415717797546817\n",
            "Epoch: 170. Loss: 0.5388369603698943\n",
            "Epoch: 180. Loss: 0.5365998950062584\n",
            "Epoch: 190. Loss: 0.5347609390456789\n",
            "Epoch: 200. Loss: 0.533242338074746\n",
            "Epoch: 210. Loss: 0.531983001087961\n",
            "Epoch: 220. Loss: 0.5309346103640805\n",
            "Epoch: 230. Loss: 0.5300587078009488\n",
            "Epoch: 240. Loss: 0.5293244981457164\n",
            "Epoch: 250. Loss: 0.52870718153678\n",
            "Epoch: 260. Loss: 0.5281866792352583\n",
            "Epoch: 270. Loss: 0.5277466532817838\n",
            "Epoch: 280. Loss: 0.5273737472970992\n",
            "Epoch: 290. Loss: 0.5270569947518892\n",
            "Epoch: 300. Loss: 0.5267873548830128\n",
            "Epoch: 310. Loss: 0.5265573465280241\n",
            "Epoch: 320. Loss: 0.526360757547531\n",
            "Epoch: 330. Loss: 0.5261924129573\n",
            "Epoch: 340. Loss: 0.5260479889342298\n",
            "Epoch: 350. Loss: 0.5259238628748198\n",
            "Epoch: 360. Loss: 0.5258169919462183\n",
            "Epoch: 370. Loss: 0.5257248142764714\n",
            "Epoch: 380. Loss: 0.5256451682259485\n",
            "Epoch: 390. Loss: 0.5255762261708209\n",
            "Epoch: 400. Loss: 0.5255164399887553\n",
            "Epoch: 410. Loss: 0.5254644960231767\n",
            "Epoch: 420. Loss: 0.525419277757519\n",
            "Epoch: 430. Loss: 0.5253798347860158\n",
            "Epoch: 440. Loss: 0.5253453569461587\n",
            "Epoch: 450. Loss: 0.5253151526975909\n",
            "Epoch: 460. Loss: 0.5252886310061972\n",
            "Epoch: 470. Loss: 0.5252652861306529\n",
            "Epoch: 480. Loss: 0.5252446848194314\n",
            "Epoch: 490. Loss: 0.5252264555151991\n",
            "tensor(0.8012, dtype=torch.float64)\n",
            "2005-08-14 00:00:00\n",
            "Epoch: 0. Loss: 1.3252759117427908\n",
            "Epoch: 10. Loss: 1.1586359470639105\n",
            "Epoch: 20. Loss: 1.0160971724908172\n",
            "Epoch: 30. Loss: 0.8977473957387212\n",
            "Epoch: 40. Loss: 0.8027445796772634\n",
            "Epoch: 50. Loss: 0.7291498022872498\n",
            "Epoch: 60. Loss: 0.6740099949532491\n",
            "Epoch: 70. Loss: 0.6338089810943272\n",
            "Epoch: 80. Loss: 0.6050603611975044\n",
            "Epoch: 90. Loss: 0.5847181053228027\n",
            "Epoch: 100. Loss: 0.570343992428762\n",
            "Epoch: 110. Loss: 0.5601151732991716\n",
            "Epoch: 120. Loss: 0.5527390422978997\n",
            "Epoch: 130. Loss: 0.547329758056137\n",
            "Epoch: 140. Loss: 0.5432896785685266\n",
            "Epoch: 150. Loss: 0.5402161630581167\n",
            "Epoch: 160. Loss: 0.5378358391651885\n",
            "Epoch: 170. Loss: 0.535960737674426\n",
            "Epoch: 180. Loss: 0.534459696550116\n",
            "Epoch: 190. Loss: 0.5332398020211166\n",
            "Epoch: 200. Loss: 0.532234268052255\n",
            "Epoch: 210. Loss: 0.5313944259053897\n",
            "Epoch: 220. Loss: 0.5306843531134482\n",
            "Epoch: 230. Loss: 0.5300772172568438\n",
            "Epoch: 240. Loss: 0.5295527498956025\n",
            "Epoch: 250. Loss: 0.529095476772723\n",
            "Epoch: 260. Loss: 0.5286934618038102\n",
            "Epoch: 270. Loss: 0.5283374051896049\n",
            "Epoch: 280. Loss: 0.5280199889088886\n",
            "Epoch: 290. Loss: 0.5277353971703316\n",
            "Epoch: 300. Loss: 0.5274789619992611\n",
            "Epoch: 310. Loss: 0.5272468992356757\n",
            "Epoch: 320. Loss: 0.5270361104543984\n",
            "Epoch: 330. Loss: 0.5268440333480806\n",
            "Epoch: 340. Loss: 0.5266685280026795\n",
            "Epoch: 350. Loss: 0.5265077899342171\n",
            "Epoch: 360. Loss: 0.526360283200558\n",
            "Epoch: 370. Loss: 0.526224688656771\n",
            "Epoch: 380. Loss: 0.5260998636932027\n",
            "Epoch: 390. Loss: 0.5259848107226157\n",
            "Epoch: 400. Loss: 0.5258786523642506\n",
            "Epoch: 410. Loss: 0.5257806117768365\n",
            "Epoch: 420. Loss: 0.5256899969677108\n",
            "Epoch: 430. Loss: 0.5256061881858066\n",
            "Epoch: 440. Loss: 0.5255286277171696\n",
            "Epoch: 450. Loss: 0.5254568115608338\n",
            "Epoch: 460. Loss: 0.5253902825835183\n",
            "Epoch: 470. Loss: 0.5253286248433217\n",
            "Epoch: 480. Loss: 0.5252714588425842\n",
            "Epoch: 490. Loss: 0.5252184375236295\n",
            "tensor(0.7668, dtype=torch.float64)\n",
            "2005-08-21 00:00:00\n",
            "Epoch: 0. Loss: 1.115503616706935\n",
            "Epoch: 10. Loss: 0.9935970769790348\n",
            "Epoch: 20. Loss: 0.889544416993684\n",
            "Epoch: 30. Loss: 0.804231860898323\n",
            "Epoch: 40. Loss: 0.7370943590441772\n",
            "Epoch: 50. Loss: 0.6862231186935005\n",
            "Epoch: 60. Loss: 0.6488438393895692\n",
            "Epoch: 70. Loss: 0.6218576125576316\n",
            "Epoch: 80. Loss: 0.6023971457209296\n",
            "Epoch: 90. Loss: 0.5881958801235555\n",
            "Epoch: 100. Loss: 0.5776367626140996\n",
            "Epoch: 110. Loss: 0.569619767012425\n",
            "Epoch: 120. Loss: 0.5634053059399885\n",
            "Epoch: 130. Loss: 0.5584929732477331\n",
            "Epoch: 140. Loss: 0.5545394488390607\n",
            "Epoch: 150. Loss: 0.5513052486254768\n",
            "Epoch: 160. Loss: 0.5486204280524896\n",
            "Epoch: 170. Loss: 0.5463623343343327\n",
            "Epoch: 180. Loss: 0.5444409908309861\n",
            "Epoch: 190. Loss: 0.5427893542638925\n",
            "Epoch: 200. Loss: 0.5413567217054001\n",
            "Epoch: 210. Loss: 0.5401042022024459\n",
            "Epoch: 220. Loss: 0.5390015613701145\n",
            "Epoch: 230. Loss: 0.5380249921504187\n",
            "Epoch: 240. Loss: 0.5371555191008369\n",
            "Epoch: 250. Loss: 0.536377841897078\n",
            "Epoch: 260. Loss: 0.5356794872684574\n",
            "Epoch: 270. Loss: 0.5350501801840848\n",
            "Epoch: 280. Loss: 0.5344813727025197\n",
            "Epoch: 290. Loss: 0.5339658874359997\n",
            "Epoch: 300. Loss: 0.5334976451897037\n",
            "Epoch: 310. Loss: 0.5330714550161592\n",
            "Epoch: 320. Loss: 0.5326828509685928\n",
            "Epoch: 330. Loss: 0.5323279640918448\n",
            "Epoch: 340. Loss: 0.5320034212163921\n",
            "Epoch: 350. Loss: 0.5317062642958608\n",
            "Epoch: 360. Loss: 0.5314338856056611\n",
            "Epoch: 370. Loss: 0.5311839752742662\n",
            "Epoch: 380. Loss: 0.5309544784697482\n",
            "Epoch: 390. Loss: 0.5307435601966908\n",
            "Epoch: 400. Loss: 0.5305495761319892\n",
            "Epoch: 410. Loss: 0.5303710482846654\n",
            "Epoch: 420. Loss: 0.5302066445351077\n",
            "Epoch: 430. Loss: 0.5300551613151588\n",
            "Epoch: 440. Loss: 0.5299155088483355\n",
            "Epoch: 450. Loss: 0.5297866984910412\n",
            "Epoch: 460. Loss: 0.5296678318097149\n",
            "Epoch: 470. Loss: 0.5295580911020102\n",
            "Epoch: 480. Loss: 0.5294567311272315\n",
            "Epoch: 490. Loss: 0.5293630718560872\n",
            "tensor(0.7133, dtype=torch.float64)\n",
            "2005-08-28 00:00:00\n",
            "Epoch: 0. Loss: 0.6693126353753571\n",
            "Epoch: 10. Loss: 0.6395374090713251\n",
            "Epoch: 20. Loss: 0.6186105282262635\n",
            "Epoch: 30. Loss: 0.6034920562689828\n",
            "Epoch: 40. Loss: 0.5922241226077453\n",
            "Epoch: 50. Loss: 0.5835657857198586\n",
            "Epoch: 60. Loss: 0.5767280341772946\n",
            "Epoch: 70. Loss: 0.5712009096693599\n",
            "Epoch: 80. Loss: 0.5666465961175292\n",
            "Epoch: 90. Loss: 0.5628347419381309\n",
            "Epoch: 100. Loss: 0.5596034539282544\n",
            "Epoch: 110. Loss: 0.556835569428862\n",
            "Epoch: 120. Loss: 0.5544439834703457\n",
            "Epoch: 130. Loss: 0.5523623754187748\n",
            "Epoch: 140. Loss: 0.5505391980915011\n",
            "Epoch: 150. Loss: 0.5489336751151971\n",
            "Epoch: 160. Loss: 0.547513062834728\n",
            "Epoch: 170. Loss: 0.5462507288216916\n",
            "Epoch: 180. Loss: 0.5451247715962626\n",
            "Epoch: 190. Loss: 0.5441170081680475\n",
            "Epoch: 200. Loss: 0.543212217399463\n",
            "Epoch: 210. Loss: 0.5423975650167366\n",
            "Epoch: 220. Loss: 0.5416621600006919\n",
            "Epoch: 230. Loss: 0.5409967075994331\n",
            "Epoch: 240. Loss: 0.5403932345103595\n",
            "Epoch: 250. Loss: 0.5398448687663555\n",
            "Epoch: 260. Loss: 0.5393456616769086\n",
            "Epoch: 270. Loss: 0.5388904425379554\n",
            "Epoch: 280. Loss: 0.5384746991988462\n",
            "Epoch: 290. Loss: 0.5380944792688273\n",
            "Epoch: 300. Loss: 0.5377463079669879\n",
            "Epoch: 310. Loss: 0.5374271195110771\n",
            "Epoch: 320. Loss: 0.5371341996000512\n",
            "Epoch: 330. Loss: 0.5368651370404656\n",
            "Epoch: 340. Loss: 0.536617782944762\n",
            "Epoch: 350. Loss: 0.53639021622262\n",
            "Epoch: 360. Loss: 0.5361807143174133\n",
            "Epoch: 370. Loss: 0.535987728324186\n",
            "Epoch: 380. Loss: 0.5358098617745711\n",
            "Epoch: 390. Loss: 0.535645852495646\n",
            "Epoch: 400. Loss: 0.5354945570496245\n",
            "Epoch: 410. Loss: 0.5353549373438324\n",
            "Epoch: 420. Loss: 0.5352260490688455\n",
            "Epoch: 430. Loss: 0.5351070316795231\n",
            "Epoch: 440. Loss: 0.5349970996809715\n",
            "Epoch: 450. Loss: 0.5348955350208238\n",
            "Epoch: 460. Loss: 0.5348016804219636\n",
            "Epoch: 470. Loss: 0.5347149335170667\n",
            "Epoch: 480. Loss: 0.5346347416689682\n",
            "Epoch: 490. Loss: 0.5345605973796839\n",
            "tensor(0.7760, dtype=torch.float64)\n",
            "2005-09-04 00:00:00\n",
            "Epoch: 0. Loss: 1.456101882785517\n",
            "Epoch: 10. Loss: 1.1690819358518887\n",
            "Epoch: 20. Loss: 0.9502119032802349\n",
            "Epoch: 30. Loss: 0.7994463532950643\n",
            "Epoch: 40. Loss: 0.7034732826623361\n",
            "Epoch: 50. Loss: 0.6442432555560054\n",
            "Epoch: 60. Loss: 0.6073443102187139\n",
            "Epoch: 70. Loss: 0.5837163391389882\n",
            "Epoch: 80. Loss: 0.5681144959602186\n",
            "Epoch: 90. Loss: 0.5575177543536578\n",
            "Epoch: 100. Loss: 0.5501426143845501\n",
            "Epoch: 110. Loss: 0.5449015137205246\n",
            "Epoch: 120. Loss: 0.5411097691366715\n",
            "Epoch: 130. Loss: 0.5383237124968754\n",
            "Epoch: 140. Loss: 0.536248474571278\n",
            "Epoch: 150. Loss: 0.5346837156322838\n",
            "Epoch: 160. Loss: 0.5334906920926119\n",
            "Epoch: 170. Loss: 0.5325717040048535\n",
            "Epoch: 180. Loss: 0.5318569430515119\n",
            "Epoch: 190. Loss: 0.531295885783139\n",
            "Epoch: 200. Loss: 0.5308515479360155\n",
            "Epoch: 210. Loss: 0.5304965800594532\n",
            "Epoch: 220. Loss: 0.5302105720382051\n",
            "Epoch: 230. Loss: 0.529978165690691\n",
            "Epoch: 240. Loss: 0.5297877163342174\n",
            "Epoch: 250. Loss: 0.5296303327791515\n",
            "Epoch: 260. Loss: 0.5294991816586936\n",
            "Epoch: 270. Loss: 0.5293889786188002\n",
            "Epoch: 280. Loss: 0.5292956130396397\n",
            "Epoch: 290. Loss: 0.5292158691235636\n",
            "Epoch: 300. Loss: 0.5291472171543832\n",
            "Epoch: 310. Loss: 0.5290876562725475\n",
            "Epoch: 320. Loss: 0.5290355953538839\n",
            "Epoch: 330. Loss: 0.5289897622648808\n",
            "Epoch: 340. Loss: 0.5289491343836642\n",
            "Epoch: 350. Loss: 0.52891288515008\n",
            "Epoch: 360. Loss: 0.5288803427624175\n",
            "Epoch: 370. Loss: 0.5288509581243163\n",
            "Epoch: 380. Loss: 0.528824279868547\n",
            "Epoch: 390. Loss: 0.5287999348183012\n",
            "Epoch: 400. Loss: 0.5287776126432853\n",
            "Epoch: 410. Loss: 0.5287570537643033\n",
            "Epoch: 420. Loss: 0.5287380397826443\n",
            "Epoch: 430. Loss: 0.5287203858786543\n",
            "Epoch: 440. Loss: 0.5287039347513124\n",
            "Epoch: 450. Loss: 0.5286885517676965\n",
            "Epoch: 460. Loss: 0.528674121065429\n",
            "Epoch: 470. Loss: 0.5286605424081459\n",
            "Epoch: 480. Loss: 0.5286477286378863\n",
            "Epoch: 490. Loss: 0.5286356036021873\n",
            "tensor(0.7680, dtype=torch.float64)\n",
            "2005-09-11 00:00:00\n",
            "Epoch: 0. Loss: 1.0426037803248955\n",
            "Epoch: 10. Loss: 0.9264697991998732\n",
            "Epoch: 20. Loss: 0.8355821712551755\n",
            "Epoch: 30. Loss: 0.7648006193468824\n",
            "Epoch: 40. Loss: 0.7098802155413896\n",
            "Epoch: 50. Loss: 0.6674031846997945\n",
            "Epoch: 60. Loss: 0.6346385558528879\n",
            "Epoch: 70. Loss: 0.6094102392188767\n",
            "Epoch: 80. Loss: 0.5899918950463912\n",
            "Epoch: 90. Loss: 0.5750247041846618\n",
            "Epoch: 100. Loss: 0.5634500314225146\n",
            "Epoch: 110. Loss: 0.5544518948110663\n",
            "Epoch: 120. Loss: 0.5474074442440531\n",
            "Epoch: 130. Loss: 0.5418450528191563\n",
            "Epoch: 140. Loss: 0.5374097209212468\n",
            "Epoch: 150. Loss: 0.5338352221143505\n",
            "Epoch: 160. Loss: 0.5309221879431762\n",
            "Epoch: 170. Loss: 0.5285212112165745\n",
            "Epoch: 180. Loss: 0.5265200349172268\n",
            "Epoch: 190. Loss: 0.5248339622949798\n",
            "Epoch: 200. Loss: 0.5233987415376491\n",
            "Epoch: 210. Loss: 0.5221653145409785\n",
            "Epoch: 220. Loss: 0.5210959506900282\n",
            "Epoch: 230. Loss: 0.5201614006294694\n",
            "Epoch: 240. Loss: 0.519338797513826\n",
            "Epoch: 250. Loss: 0.5186101049759734\n",
            "Epoch: 260. Loss: 0.5179609650789145\n",
            "Epoch: 270. Loss: 0.5173798394338832\n",
            "Epoch: 280. Loss: 0.5168573658193873\n",
            "Epoch: 290. Loss: 0.5163858737861552\n",
            "Epoch: 300. Loss: 0.5159590180335427\n",
            "Epoch: 310. Loss: 0.5155714994075296\n",
            "Epoch: 320. Loss: 0.515218851382845\n",
            "Epoch: 330. Loss: 0.5148972757089445\n",
            "Epoch: 340. Loss: 0.5146035151372235\n",
            "Epoch: 350. Loss: 0.5143347542458164\n",
            "Epoch: 360. Loss: 0.5140885416539632\n",
            "Epoch: 370. Loss: 0.5138627285960665\n",
            "Epoch: 380. Loss: 0.5136554200683805\n",
            "Epoch: 390. Loss: 0.5134649356855211\n",
            "Epoch: 400. Loss: 0.51328977807414\n",
            "Epoch: 410. Loss: 0.5131286071484451\n",
            "Epoch: 420. Loss: 0.5129802190015229\n",
            "Epoch: 430. Loss: 0.5128435284403603\n",
            "Epoch: 440. Loss: 0.5127175544151928\n",
            "Epoch: 450. Loss: 0.5126014077631299\n",
            "Epoch: 460. Loss: 0.5124942808151479\n",
            "Epoch: 470. Loss: 0.5123954385143437\n",
            "Epoch: 480. Loss: 0.5123042107691687\n",
            "Epoch: 490. Loss: 0.5122199858237511\n",
            "tensor(0.7587, dtype=torch.float64)\n",
            "2005-09-18 00:00:00\n",
            "Epoch: 0. Loss: 0.7285740953136115\n",
            "Epoch: 10. Loss: 0.6764999012336126\n",
            "Epoch: 20. Loss: 0.6370527726368528\n",
            "Epoch: 30. Loss: 0.6078440588124486\n",
            "Epoch: 40. Loss: 0.5866106536178262\n",
            "Epoch: 50. Loss: 0.5713094435911735\n",
            "Epoch: 60. Loss: 0.5602513303984931\n",
            "Epoch: 70. Loss: 0.5521634696431701\n",
            "Epoch: 80. Loss: 0.5461454679091475\n",
            "Epoch: 90. Loss: 0.5415792755763255\n",
            "Epoch: 100. Loss: 0.5380438398277022\n",
            "Epoch: 110. Loss: 0.535251026401624\n",
            "Epoch: 120. Loss: 0.5330016827699706\n",
            "Epoch: 130. Loss: 0.5311564783478081\n",
            "Epoch: 140. Loss: 0.5296166835917819\n",
            "Epoch: 150. Loss: 0.5283114418786002\n",
            "Epoch: 160. Loss: 0.5271892604735788\n",
            "Epoch: 170. Loss: 0.5262122570405499\n",
            "Epoch: 180. Loss: 0.5253522231162446\n",
            "Epoch: 190. Loss: 0.5245878993409091\n",
            "Epoch: 200. Loss: 0.5239030684586389\n",
            "Epoch: 210. Loss: 0.5232852067050288\n",
            "Epoch: 220. Loss: 0.5227245207910941\n",
            "Epoch: 230. Loss: 0.5222132540152891\n",
            "Epoch: 240. Loss: 0.521745182098372\n",
            "Epoch: 250. Loss: 0.521315244010832\n",
            "Epoch: 260. Loss: 0.5209192696786288\n",
            "Epoch: 270. Loss: 0.5205537777659928\n",
            "Epoch: 280. Loss: 0.5202158245178508\n",
            "Epoch: 290. Loss: 0.5199028900537975\n",
            "Epoch: 300. Loss: 0.519612792300327\n",
            "Epoch: 310. Loss: 0.519343621433907\n",
            "Epoch: 320. Loss: 0.5190936896242813\n",
            "Epoch: 330. Loss: 0.5188614922459548\n",
            "Epoch: 340. Loss: 0.518645677724407\n",
            "Epoch: 350. Loss: 0.5184450239117061\n",
            "Epoch: 360. Loss: 0.5182584194203421\n",
            "Epoch: 370. Loss: 0.5180848487380842\n",
            "Epoch: 380. Loss: 0.5179233802387385\n",
            "Epoch: 390. Loss: 0.5177731564211461\n",
            "Epoch: 400. Loss: 0.5176333858713342\n",
            "Epoch: 410. Loss: 0.5175033365646828\n",
            "Epoch: 420. Loss: 0.5173823302167319\n",
            "Epoch: 430. Loss: 0.5172697374604791\n",
            "Epoch: 440. Loss: 0.517164973680365\n",
            "Epoch: 450. Loss: 0.5170674953727945\n",
            "Epoch: 460. Loss: 0.5169767969331347\n",
            "Epoch: 470. Loss: 0.5168924077919919\n",
            "Epoch: 480. Loss: 0.5168138898409669\n",
            "Epoch: 490. Loss: 0.5167408351013347\n",
            "tensor(0.8344, dtype=torch.float64)\n",
            "2005-09-25 00:00:00\n",
            "Epoch: 0. Loss: 1.1707657045936994\n",
            "Epoch: 10. Loss: 0.997754728640613\n",
            "Epoch: 20. Loss: 0.8649034729083412\n",
            "Epoch: 30. Loss: 0.7681745880506574\n",
            "Epoch: 40. Loss: 0.7002407445254301\n",
            "Epoch: 50. Loss: 0.6532493982074711\n",
            "Epoch: 60. Loss: 0.620710445426177\n",
            "Epoch: 70. Loss: 0.5979239920104111\n",
            "Epoch: 80. Loss: 0.5816886435139043\n",
            "Epoch: 90. Loss: 0.569877711780945\n",
            "Epoch: 100. Loss: 0.5610887127253478\n",
            "Epoch: 110. Loss: 0.5543947633140963\n",
            "Epoch: 120. Loss: 0.549178472167777\n",
            "Epoch: 130. Loss: 0.5450238524191566\n",
            "Epoch: 140. Loss: 0.5416467575037635\n",
            "Epoch: 150. Loss: 0.5388501839934078\n",
            "Epoch: 160. Loss: 0.5364954215126698\n",
            "Epoch: 170. Loss: 0.5344832707757102\n",
            "Epoch: 180. Loss: 0.5327416806049565\n",
            "Epoch: 190. Loss: 0.5312175092006848\n",
            "Epoch: 200. Loss: 0.529870962770522\n",
            "Epoch: 210. Loss: 0.5286717927744442\n",
            "Epoch: 220. Loss: 0.5275966627205466\n",
            "Epoch: 230. Loss: 0.5266273025704815\n",
            "Epoch: 240. Loss: 0.5257492001320854\n",
            "Epoch: 250. Loss: 0.5249506629663891\n",
            "Epoch: 260. Loss: 0.5242221388815258\n",
            "Epoch: 270. Loss: 0.5235557188615313\n",
            "Epoch: 280. Loss: 0.5229447700216577\n",
            "Epoch: 290. Loss: 0.5223836621249026\n",
            "Epoch: 300. Loss: 0.5218675620221431\n",
            "Epoch: 310. Loss: 0.5213922778132407\n",
            "Epoch: 320. Loss: 0.5209541396861306\n",
            "Epoch: 330. Loss: 0.5205499080079542\n",
            "Epoch: 340. Loss: 0.5201767018024104\n",
            "Epoch: 350. Loss: 0.5198319425759925\n",
            "Epoch: 360. Loss: 0.519513309772867\n",
            "Epoch: 370. Loss: 0.5192187050942951\n",
            "Epoch: 380. Loss: 0.5189462236176688\n",
            "Epoch: 390. Loss: 0.5186941301648198\n",
            "Epoch: 400. Loss: 0.5184608397502419\n",
            "Epoch: 410. Loss: 0.5182449012234009\n",
            "Epoch: 420. Loss: 0.5180449834313035\n",
            "Epoch: 430. Loss: 0.5178598633866303\n",
            "Epoch: 440. Loss: 0.5176884160466354\n",
            "Epoch: 450. Loss: 0.5175296053986042\n",
            "Epoch: 460. Loss: 0.5173824766163115\n",
            "Epoch: 470. Loss: 0.5172461491040744\n",
            "Epoch: 480. Loss: 0.5171198102846937\n",
            "Epoch: 490. Loss: 0.5170027100178906\n",
            "tensor(0.7699, dtype=torch.float64)\n",
            "2005-10-02 00:00:00\n",
            "Epoch: 0. Loss: 1.2467171170099967\n",
            "Epoch: 10. Loss: 1.0247488502329556\n",
            "Epoch: 20. Loss: 0.8596809312767737\n",
            "Epoch: 30. Loss: 0.744431697394297\n",
            "Epoch: 40. Loss: 0.6673215834592842\n",
            "Epoch: 50. Loss: 0.6165989133253807\n",
            "Epoch: 60. Loss: 0.5831398693578493\n",
            "Epoch: 70. Loss: 0.5607622743371786\n",
            "Epoch: 80. Loss: 0.5455217443797383\n",
            "Epoch: 90. Loss: 0.5349435450881361\n",
            "Epoch: 100. Loss: 0.5274666776047868\n",
            "Epoch: 110. Loss: 0.5220915102291435\n",
            "Epoch: 120. Loss: 0.5181659878006752\n",
            "Epoch: 130. Loss: 0.5152567304696603\n",
            "Epoch: 140. Loss: 0.5130705319776706\n",
            "Epoch: 150. Loss: 0.5114057506021426\n",
            "Epoch: 160. Loss: 0.5101216409185286\n",
            "Epoch: 170. Loss: 0.5091186372400618\n",
            "Epoch: 180. Loss: 0.5083254475540897\n",
            "Epoch: 190. Loss: 0.507690462071032\n",
            "Epoch: 200. Loss: 0.5071759444410185\n",
            "Epoch: 210. Loss: 0.5067540480934102\n",
            "Epoch: 220. Loss: 0.5064040485836719\n",
            "Epoch: 230. Loss: 0.5061103979643952\n",
            "Epoch: 240. Loss: 0.5058613423246178\n",
            "Epoch: 250. Loss: 0.5056479299172247\n",
            "Epoch: 260. Loss: 0.5054632932389762\n",
            "Epoch: 270. Loss: 0.5053021252373276\n",
            "Epoch: 280. Loss: 0.5051602943708687\n",
            "Epoch: 290. Loss: 0.5050345598378125\n",
            "Epoch: 300. Loss: 0.5049223596277393\n",
            "Epoch: 310. Loss: 0.5048216518917799\n",
            "Epoch: 320. Loss: 0.5047307956023527\n",
            "Epoch: 330. Loss: 0.5046484603349716\n",
            "Epoch: 340. Loss: 0.5045735577516656\n",
            "Epoch: 350. Loss: 0.5045051893358234\n",
            "Epoch: 360. Loss: 0.5044426063520597\n",
            "Epoch: 370. Loss: 0.5043851790407261\n",
            "Epoch: 380. Loss: 0.5043323728153664\n",
            "Epoch: 390. Loss: 0.5042837297902141\n",
            "Epoch: 400. Loss: 0.5042388543786396\n",
            "Epoch: 410. Loss: 0.5041974020113614\n",
            "Epoch: 420. Loss: 0.5041590702533876\n",
            "Epoch: 430. Loss: 0.5041235917713786\n",
            "Epoch: 440. Loss: 0.5040907287332286\n",
            "Epoch: 450. Loss: 0.5040602683200063\n",
            "Epoch: 460. Loss: 0.5040320191049529\n",
            "Epoch: 470. Loss: 0.5040058081109349\n",
            "Epoch: 480. Loss: 0.5039814784009639\n",
            "Epoch: 490. Loss: 0.5039588870894266\n",
            "tensor(0.7404, dtype=torch.float64)\n",
            "2005-10-09 00:00:00\n",
            "Epoch: 0. Loss: 0.5764854524573408\n",
            "Epoch: 10. Loss: 0.5550480566483661\n",
            "Epoch: 20. Loss: 0.5412072882784325\n",
            "Epoch: 30. Loss: 0.5320032271784649\n",
            "Epoch: 40. Loss: 0.5256905428600275\n",
            "Epoch: 50. Loss: 0.5212305000958958\n",
            "Epoch: 60. Loss: 0.5179912553559016\n",
            "Epoch: 70. Loss: 0.5155783713171743\n",
            "Epoch: 80. Loss: 0.5137390705253739\n",
            "Epoch: 90. Loss: 0.5123072612353436\n",
            "Epoch: 100. Loss: 0.5111712450798195\n",
            "Epoch: 110. Loss: 0.5102542762675603\n",
            "Epoch: 120. Loss: 0.5095025708669355\n",
            "Epoch: 130. Loss: 0.5088777394720152\n",
            "Epoch: 140. Loss: 0.5083519083745697\n",
            "Epoch: 150. Loss: 0.5079045114919704\n",
            "Epoch: 160. Loss: 0.507520142356429\n",
            "Epoch: 170. Loss: 0.507187091765785\n",
            "Epoch: 180. Loss: 0.5068963368835101\n",
            "Epoch: 190. Loss: 0.5066408324878257\n",
            "Epoch: 200. Loss: 0.5064150075176996\n",
            "Epoch: 210. Loss: 0.5062144030594047\n",
            "Epoch: 220. Loss: 0.5060354090353605\n",
            "Epoch: 230. Loss: 0.5058750705914699\n",
            "Epoch: 240. Loss: 0.5057309442460981\n",
            "Epoch: 250. Loss: 0.5056009899332543\n",
            "Epoch: 260. Loss: 0.5054834891881552\n",
            "Epoch: 270. Loss: 0.5053769825477259\n",
            "Epoch: 280. Loss: 0.505280221198432\n",
            "Epoch: 290. Loss: 0.505192129277789\n",
            "Epoch: 300. Loss: 0.5051117742083028\n",
            "Epoch: 310. Loss: 0.505038343136884\n",
            "Epoch: 320. Loss: 0.5049711240525788\n",
            "Epoch: 330. Loss: 0.5049094905179872\n",
            "Epoch: 340. Loss: 0.504852889214603\n",
            "Epoch: 350. Loss: 0.5048008296971176\n",
            "Epoch: 360. Loss: 0.5047528758959413\n",
            "Epoch: 370. Loss: 0.5047086390146157\n",
            "Epoch: 380. Loss: 0.5046677715492771\n",
            "Epoch: 390. Loss: 0.5046299622180077\n",
            "Epoch: 400. Loss: 0.5045949316339072\n",
            "Epoch: 410. Loss: 0.5045624285908016\n",
            "Epoch: 420. Loss: 0.5045322268574141\n",
            "Epoch: 430. Loss: 0.5045041223965998\n",
            "Epoch: 440. Loss: 0.5044779309423704\n",
            "Epoch: 450. Loss: 0.5044534858800398\n",
            "Epoch: 460. Loss: 0.5044306363847427\n",
            "Epoch: 470. Loss: 0.5044092457814179\n",
            "Epoch: 480. Loss: 0.5043891900956161\n",
            "Epoch: 490. Loss: 0.5043703567695089\n",
            "tensor(0.6983, dtype=torch.float64)\n",
            "2005-10-16 00:00:00\n",
            "Epoch: 0. Loss: 1.3657733684360451\n",
            "Epoch: 10. Loss: 1.1856392866201728\n",
            "Epoch: 20. Loss: 1.0327118130417952\n",
            "Epoch: 30. Loss: 0.9064519653075286\n",
            "Epoch: 40. Loss: 0.805499136233505\n",
            "Epoch: 50. Loss: 0.727392609324645\n",
            "Epoch: 60. Loss: 0.6686880385910976\n",
            "Epoch: 70. Loss: 0.6255141304841964\n",
            "Epoch: 80. Loss: 0.5942056809748248\n",
            "Epoch: 90. Loss: 0.5716795981387941\n",
            "Epoch: 100. Loss: 0.5555260511958509\n",
            "Epoch: 110. Loss: 0.5439419625558973\n",
            "Epoch: 120. Loss: 0.5356134919930324\n",
            "Epoch: 130. Loss: 0.5295989205528083\n",
            "Epoch: 140. Loss: 0.525229887372631\n",
            "Epoch: 150. Loss: 0.5220344171305318\n",
            "Epoch: 160. Loss: 0.5196796564559301\n",
            "Epoch: 170. Loss: 0.5179305297023373\n",
            "Epoch: 180. Loss: 0.5166204538612266\n",
            "Epoch: 190. Loss: 0.5156308277678178\n",
            "Epoch: 200. Loss: 0.5148767455134391\n",
            "Epoch: 210. Loss: 0.5142970587555276\n",
            "Epoch: 220. Loss: 0.5138474536030896\n",
            "Epoch: 230. Loss: 0.5134956110869912\n",
            "Epoch: 240. Loss: 0.513217808519707\n",
            "Epoch: 250. Loss: 0.5129965201106519\n",
            "Epoch: 260. Loss: 0.512818713528202\n",
            "Epoch: 270. Loss: 0.5126746336488497\n",
            "Epoch: 280. Loss: 0.512556929248975\n",
            "Epoch: 290. Loss: 0.5124600224778123\n",
            "Epoch: 300. Loss: 0.5123796511761198\n",
            "Epoch: 310. Loss: 0.5123125349278749\n",
            "Epoch: 320. Loss: 0.5122561301559276\n",
            "Epoch: 330. Loss: 0.5122084496218969\n",
            "Epoch: 340. Loss: 0.512167928733892\n",
            "Epoch: 350. Loss: 0.5121333260309648\n",
            "Epoch: 360. Loss: 0.5121036487333691\n",
            "Epoch: 370. Loss: 0.5120780967567605\n",
            "Epoch: 380. Loss: 0.5120560203858383\n",
            "Epoch: 390. Loss: 0.5120368880966052\n",
            "Epoch: 400. Loss: 0.5120202619516477\n",
            "Epoch: 410. Loss: 0.5120057786717211\n",
            "Epoch: 420. Loss: 0.5119931349816401\n",
            "Epoch: 430. Loss: 0.5119820761902925\n",
            "Epoch: 440. Loss: 0.5119723872301293\n",
            "Epoch: 450. Loss: 0.5119638855770171\n",
            "Epoch: 460. Loss: 0.5119564156157925\n",
            "Epoch: 470. Loss: 0.5119498441239144\n",
            "Epoch: 480. Loss: 0.5119440566252195\n",
            "Epoch: 490. Loss: 0.5119389544251756\n",
            "tensor(0.6748, dtype=torch.float64)\n",
            "2005-10-23 00:00:00\n",
            "Epoch: 0. Loss: 0.6990941591511801\n",
            "Epoch: 10. Loss: 0.6696592949206408\n",
            "Epoch: 20. Loss: 0.6470928947257637\n",
            "Epoch: 30. Loss: 0.6296857300282583\n",
            "Epoch: 40. Loss: 0.616087212738827\n",
            "Epoch: 50. Loss: 0.6052711915602162\n",
            "Epoch: 60. Loss: 0.5964839292048952\n",
            "Epoch: 70. Loss: 0.5891852496307154\n",
            "Epoch: 80. Loss: 0.5829936628830733\n",
            "Epoch: 90. Loss: 0.57764130541127\n",
            "Epoch: 100. Loss: 0.5729398355007567\n",
            "Epoch: 110. Loss: 0.5687558866815359\n",
            "Epoch: 120. Loss: 0.5649939134969619\n",
            "Epoch: 130. Loss: 0.5615843925755964\n",
            "Epoch: 140. Loss: 0.5584757663284861\n",
            "Epoch: 150. Loss: 0.5556289533652976\n",
            "Epoch: 160. Loss: 0.55301360394954\n",
            "Epoch: 170. Loss: 0.5506055387087357\n",
            "Epoch: 180. Loss: 0.5483849903286993\n",
            "Epoch: 190. Loss: 0.5463353916294609\n",
            "Epoch: 200. Loss: 0.5444425367194287\n",
            "Epoch: 210. Loss: 0.5426939978206985\n",
            "Epoch: 220. Loss: 0.5410787178932313\n",
            "Epoch: 230. Loss: 0.5395867244734988\n",
            "Epoch: 240. Loss: 0.5382089272597943\n",
            "Epoch: 250. Loss: 0.536936973623654\n",
            "Epoch: 260. Loss: 0.5357631441955133\n",
            "Epoch: 270. Loss: 0.5346802761532911\n",
            "Epoch: 280. Loss: 0.533681705630168\n",
            "Epoch: 290. Loss: 0.5327612232864806\n",
            "Epoch: 300. Loss: 0.5319130389213802\n",
            "Epoch: 310. Loss: 0.5311317522782035\n",
            "Epoch: 320. Loss: 0.5304123280913494\n",
            "Epoch: 330. Loss: 0.5297500740475554\n",
            "Epoch: 340. Loss: 0.529140620770874\n",
            "Epoch: 350. Loss: 0.5285799032441822\n",
            "Epoch: 360. Loss: 0.528064143289785\n",
            "Epoch: 370. Loss: 0.5275898328750759\n",
            "Epoch: 380. Loss: 0.527153718105795\n",
            "Epoch: 390. Loss: 0.5267527838329783\n",
            "Epoch: 400. Loss: 0.5263842388400967\n",
            "Epoch: 410. Loss: 0.5260455016012033\n",
            "Epoch: 420. Loss: 0.5257341866141902\n",
            "Epoch: 430. Loss: 0.5254480913191142\n",
            "Epoch: 440. Loss: 0.5251851836125866\n",
            "Epoch: 450. Loss: 0.5249435899672446\n",
            "Epoch: 460. Loss: 0.5247215841616362\n",
            "Epoch: 470. Loss: 0.5245175766213406\n",
            "Epoch: 480. Loss: 0.5243301043674096\n",
            "Epoch: 490. Loss: 0.5241578215636601\n",
            "tensor(0.7397, dtype=torch.float64)\n",
            "2005-10-30 00:00:00\n",
            "Epoch: 0. Loss: 0.8945905040201153\n",
            "Epoch: 10. Loss: 0.7732557729297757\n",
            "Epoch: 20. Loss: 0.6882360548498998\n",
            "Epoch: 30. Loss: 0.6319692647638345\n",
            "Epoch: 40. Loss: 0.5961256059101165\n",
            "Epoch: 50. Loss: 0.573653901059979\n",
            "Epoch: 60. Loss: 0.5595250741509472\n",
            "Epoch: 70. Loss: 0.5505030231451291\n",
            "Epoch: 80. Loss: 0.5446121069391436\n",
            "Epoch: 90. Loss: 0.5406677381680215\n",
            "Epoch: 100. Loss: 0.537957513348389\n",
            "Epoch: 110. Loss: 0.5360469853496773\n",
            "Epoch: 120. Loss: 0.5346662259242565\n",
            "Epoch: 130. Loss: 0.5336441268636951\n",
            "Epoch: 140. Loss: 0.5328700389016652\n",
            "Epoch: 150. Loss: 0.5322710206854131\n",
            "Epoch: 160. Loss: 0.5317980953295002\n",
            "Epoch: 170. Loss: 0.5314177904583293\n",
            "Epoch: 180. Loss: 0.5311068349665461\n",
            "Epoch: 190. Loss: 0.530848777184014\n",
            "Epoch: 200. Loss: 0.5306317935793637\n",
            "Epoch: 210. Loss: 0.5304472475709134\n",
            "Epoch: 220. Loss: 0.5302887283318422\n",
            "Epoch: 230. Loss: 0.5301514011871287\n",
            "Epoch: 240. Loss: 0.5300315630018104\n",
            "Epoch: 250. Loss: 0.5299263341267821\n",
            "Epoch: 260. Loss: 0.5298334423953353\n",
            "Epoch: 270. Loss: 0.529751069872831\n",
            "Epoch: 280. Loss: 0.5296777428539675\n",
            "Epoch: 290. Loss: 0.5296122519815052\n",
            "Epoch: 300. Loss: 0.5295535935625352\n",
            "Epoch: 310. Loss: 0.5295009259552761\n",
            "Epoch: 320. Loss: 0.5294535367793017\n",
            "Epoch: 330. Loss: 0.5294108179776243\n",
            "Epoch: 340. Loss: 0.5293722466323335\n",
            "Epoch: 350. Loss: 0.5293373700386845\n",
            "Epoch: 360. Loss: 0.5293057939627381\n",
            "Epoch: 370. Loss: 0.5292771733028658\n",
            "Epoch: 380. Loss: 0.5292512045845679\n",
            "Epoch: 390. Loss: 0.5292276198674025\n",
            "Epoch: 400. Loss: 0.5292061817503559\n",
            "Epoch: 410. Loss: 0.5291866792400197\n",
            "Epoch: 420. Loss: 0.5291689243030215\n",
            "Epoch: 430. Loss: 0.5291527489662327\n",
            "Epoch: 440. Loss: 0.5291380028595307\n",
            "Epoch: 450. Loss: 0.5291245511192977\n",
            "Epoch: 460. Loss: 0.5291122725884759\n",
            "Epoch: 470. Loss: 0.5291010582624245\n",
            "Epoch: 480. Loss: 0.5290908099400811\n",
            "Epoch: 490. Loss: 0.5290814390478622\n",
            "tensor(0.6897, dtype=torch.float64)\n",
            "2005-11-06 00:00:00\n",
            "Epoch: 0. Loss: 0.7447242738803362\n",
            "Epoch: 10. Loss: 0.6711216925805743\n",
            "Epoch: 20. Loss: 0.623417374830523\n",
            "Epoch: 30. Loss: 0.592809716984461\n",
            "Epoch: 40. Loss: 0.5728664317153168\n",
            "Epoch: 50. Loss: 0.5595190366813673\n",
            "Epoch: 60. Loss: 0.5503197236923159\n",
            "Epoch: 70. Loss: 0.5437989634479472\n",
            "Epoch: 80. Loss: 0.5390578524143409\n",
            "Epoch: 90. Loss: 0.5355319341812973\n",
            "Epoch: 100. Loss: 0.5328568561163515\n",
            "Epoch: 110. Loss: 0.5307911451162138\n",
            "Epoch: 120. Loss: 0.5291708324035941\n",
            "Epoch: 130. Loss: 0.5278820974810672\n",
            "Epoch: 140. Loss: 0.526844340634049\n",
            "Epoch: 150. Loss: 0.5259994454943188\n",
            "Epoch: 160. Loss: 0.5253048099954833\n",
            "Epoch: 170. Loss: 0.5247287274718744\n",
            "Epoch: 180. Loss: 0.5242472666609329\n",
            "Epoch: 190. Loss: 0.5238421275678471\n",
            "Epoch: 200. Loss: 0.5234991446880521\n",
            "Epoch: 210. Loss: 0.52320722704624\n",
            "Epoch: 220. Loss: 0.5229575975870868\n",
            "Epoch: 230. Loss: 0.522743240631979\n",
            "Epoch: 240. Loss: 0.5225584958383244\n",
            "Epoch: 250. Loss: 0.522398756553556\n",
            "Epoch: 260. Loss: 0.5222602433894175\n",
            "Epoch: 270. Loss: 0.522139832562421\n",
            "Epoch: 280. Loss: 0.5220349245026642\n",
            "Epoch: 290. Loss: 0.5219433423501898\n",
            "Epoch: 300. Loss: 0.5218632528350418\n",
            "Epoch: 310. Loss: 0.5217931040680016\n",
            "Epoch: 320. Loss: 0.521731576216037\n",
            "Epoch: 330. Loss: 0.5216775420766506\n",
            "Epoch: 340. Loss: 0.5216300353191643\n",
            "Epoch: 350. Loss: 0.5215882247116157\n",
            "Epoch: 360. Loss: 0.521551393057159\n",
            "Epoch: 370. Loss: 0.5215189198642108\n",
            "Epoch: 380. Loss: 0.5214902669987606\n",
            "Epoch: 390. Loss: 0.5214649667357389\n",
            "Epoch: 400. Loss: 0.5214426117537923\n",
            "Epoch: 410. Loss: 0.5214228467148883\n",
            "Epoch: 420. Loss: 0.5214053611445889\n",
            "Epoch: 430. Loss: 0.5213898833862598\n",
            "Epoch: 440. Loss: 0.5213761754470864\n",
            "Epoch: 450. Loss: 0.5213640285886347\n",
            "Epoch: 460. Loss: 0.5213532595421454\n",
            "Epoch: 470. Loss: 0.5213437072504659\n",
            "Epoch: 480. Loss: 0.5213352300558581\n",
            "Epoch: 490. Loss: 0.5213277032668021\n",
            "tensor(0.6452, dtype=torch.float64)\n",
            "2005-11-13 00:00:00\n",
            "Epoch: 0. Loss: 0.6021137249103442\n",
            "Epoch: 10. Loss: 0.5906254954435853\n",
            "Epoch: 20. Loss: 0.5814576539159858\n",
            "Epoch: 30. Loss: 0.5740018956209305\n",
            "Epoch: 40. Loss: 0.5678277741281552\n",
            "Epoch: 50. Loss: 0.5626319127116146\n",
            "Epoch: 60. Loss: 0.5581990755952738\n",
            "Epoch: 70. Loss: 0.554374399287407\n",
            "Epoch: 80. Loss: 0.5510443320036534\n",
            "Epoch: 90. Loss: 0.5481237938154664\n",
            "Epoch: 100. Loss: 0.545547583119882\n",
            "Epoch: 110. Loss: 0.543264615481097\n",
            "Epoch: 120. Loss: 0.541234032589919\n",
            "Epoch: 130. Loss: 0.5394225434145699\n",
            "Epoch: 140. Loss: 0.5378025799588049\n",
            "Epoch: 150. Loss: 0.5363509955413833\n",
            "Epoch: 160. Loss: 0.5350481282102687\n",
            "Epoch: 170. Loss: 0.5338771131497795\n",
            "Epoch: 180. Loss: 0.5328233674952263\n",
            "Epoch: 190. Loss: 0.5318741965718188\n",
            "Epoch: 200. Loss: 0.5310184872229385\n",
            "Epoch: 210. Loss: 0.5302464647920713\n",
            "Epoch: 220. Loss: 0.5295494975194159\n",
            "Epoch: 230. Loss: 0.5289199369149877\n",
            "Epoch: 240. Loss: 0.5283509859104909\n",
            "Epoch: 250. Loss: 0.527836588808751\n",
            "Epoch: 260. Loss: 0.5273713385880153\n",
            "Epoch: 270. Loss: 0.5269503982034965\n",
            "Epoch: 280. Loss: 0.5265694333067558\n",
            "Epoch: 290. Loss: 0.5262245543714958\n",
            "Epoch: 300. Loss: 0.5259122666360766\n",
            "Epoch: 310. Loss: 0.5256294265915541\n",
            "Epoch: 320. Loss: 0.5253732039883376\n",
            "Epoch: 330. Loss: 0.525141048524616\n",
            "Epoch: 340. Loss: 0.524930660529389\n",
            "Epoch: 350. Loss: 0.5247399650720934\n",
            "Epoch: 360. Loss: 0.5245670890264716\n",
            "Epoch: 370. Loss: 0.5244103406937125\n",
            "Epoch: 380. Loss: 0.5242681916528449\n",
            "Epoch: 390. Loss: 0.5241392605578556\n",
            "Epoch: 400. Loss: 0.5240222986433011\n",
            "Epoch: 410. Loss: 0.5239161767350695\n",
            "Epoch: 420. Loss: 0.5238198735918599\n",
            "Epoch: 430. Loss: 0.5237324654269739\n",
            "Epoch: 440. Loss: 0.5236531164801002\n",
            "Epoch: 450. Loss: 0.5235810705256172\n",
            "Epoch: 460. Loss: 0.5235156432181567\n",
            "Epoch: 470. Loss: 0.5234562151882106\n",
            "Epoch: 480. Loss: 0.5234022258108395\n",
            "Epoch: 490. Loss: 0.5233531675793383\n",
            "tensor(0.6786, dtype=torch.float64)\n",
            "2005-11-20 00:00:00\n",
            "Epoch: 0. Loss: 0.5784519487974904\n",
            "Epoch: 10. Loss: 0.5598508527830667\n",
            "Epoch: 20. Loss: 0.5486754068009871\n",
            "Epoch: 30. Loss: 0.5417365609035202\n",
            "Epoch: 40. Loss: 0.5372877908081105\n",
            "Epoch: 50. Loss: 0.5343481834033108\n",
            "Epoch: 60. Loss: 0.5323497359955056\n",
            "Epoch: 70. Loss: 0.5309535610963481\n",
            "Epoch: 80. Loss: 0.5299518941763685\n",
            "Epoch: 90. Loss: 0.5292142552053652\n",
            "Epoch: 100. Loss: 0.5286569439341365\n",
            "Epoch: 110. Loss: 0.5282252482324463\n",
            "Epoch: 120. Loss: 0.527882791932595\n",
            "Epoch: 130. Loss: 0.5276050073629877\n",
            "Epoch: 140. Loss: 0.5273750529618618\n",
            "Epoch: 150. Loss: 0.5271812140541227\n",
            "Epoch: 160. Loss: 0.5270152218329102\n",
            "Epoch: 170. Loss: 0.5268711511002323\n",
            "Epoch: 180. Loss: 0.5267446886260242\n",
            "Epoch: 190. Loss: 0.5266326421676242\n",
            "Epoch: 200. Loss: 0.5265326076939327\n",
            "Epoch: 210. Loss: 0.5264427417486307\n",
            "Epoch: 220. Loss: 0.5263616043686031\n",
            "Epoch: 230. Loss: 0.526288049765645\n",
            "Epoch: 240. Loss: 0.5262211496010628\n",
            "Epoch: 250. Loss: 0.5261601386659364\n",
            "Epoch: 260. Loss: 0.5261043760715524\n",
            "Epoch: 270. Loss: 0.526053317248993\n",
            "Epoch: 280. Loss: 0.5260064935318707\n",
            "Epoch: 290. Loss: 0.525963497094945\n",
            "Epoch: 300. Loss: 0.5259239697021273\n",
            "Epoch: 310. Loss: 0.525887594184197\n",
            "Epoch: 320. Loss: 0.5258540878884443\n",
            "Epoch: 330. Loss: 0.5258231975655274\n",
            "Epoch: 340. Loss: 0.5257946953141677\n",
            "Epoch: 350. Loss: 0.5257683753129662\n",
            "Epoch: 360. Loss: 0.525744051144957\n",
            "Epoch: 370. Loss: 0.5257215535743811\n",
            "Epoch: 380. Loss: 0.5257007286733323\n",
            "Epoch: 390. Loss: 0.5256814362231048\n",
            "Epoch: 400. Loss: 0.5256635483345138\n",
            "Epoch: 410. Loss: 0.5256469482454321\n",
            "Epoch: 420. Loss: 0.5256315292639041\n",
            "Epoch: 430. Loss: 0.5256171938325501\n",
            "Epoch: 440. Loss: 0.5256038526953709\n",
            "Epoch: 450. Loss: 0.5255914241520482\n",
            "Epoch: 460. Loss: 0.5255798333878136\n",
            "Epoch: 470. Loss: 0.525569011869192\n",
            "Epoch: 480. Loss: 0.5255588967976401\n",
            "Epoch: 490. Loss: 0.5255494306144146\n",
            "tensor(0.8957, dtype=torch.float64)\n",
            "2005-11-27 00:00:00\n",
            "Epoch: 0. Loss: 0.9549289613980014\n",
            "Epoch: 10. Loss: 0.8312522847429646\n",
            "Epoch: 20. Loss: 0.7452417979616535\n",
            "Epoch: 30. Loss: 0.6861276104913829\n",
            "Epoch: 40. Loss: 0.6453412479821975\n",
            "Epoch: 50. Loss: 0.6167775444609694\n",
            "Epoch: 60. Loss: 0.5963494992229975\n",
            "Epoch: 70. Loss: 0.5813917694603578\n",
            "Epoch: 80. Loss: 0.5701759000021579\n",
            "Epoch: 90. Loss: 0.5615741842416988\n",
            "Epoch: 100. Loss: 0.5548409254057232\n",
            "Epoch: 110. Loss: 0.5494741056689284\n",
            "Epoch: 120. Loss: 0.5451288169880862\n",
            "Epoch: 130. Loss: 0.541563011779384\n",
            "Epoch: 140. Loss: 0.5386031981817774\n",
            "Epoch: 150. Loss: 0.5361224502311227\n",
            "Epoch: 160. Loss: 0.5340260849361566\n",
            "Epoch: 170. Loss: 0.5322421730517032\n",
            "Epoch: 180. Loss: 0.5307151426667143\n",
            "Epoch: 190. Loss: 0.52940139290353\n",
            "Epoch: 200. Loss: 0.5282662348421532\n",
            "Epoch: 210. Loss: 0.5272817225585654\n",
            "Epoch: 220. Loss: 0.5264250903229373\n",
            "Epoch: 230. Loss: 0.5256776088097435\n",
            "Epoch: 240. Loss: 0.525023735229788\n",
            "Epoch: 250. Loss: 0.5244504726253085\n",
            "Epoch: 260. Loss: 0.5239468801278294\n",
            "Epoch: 270. Loss: 0.5235036936903322\n",
            "Epoch: 280. Loss: 0.523113028762724\n",
            "Epoch: 290. Loss: 0.5227681445487452\n",
            "Epoch: 300. Loss: 0.5224632551290453\n",
            "Epoch: 310. Loss: 0.5221933766833793\n",
            "Epoch: 320. Loss: 0.5219542028372889\n",
            "Epoch: 330. Loss: 0.5217420021562108\n",
            "Epoch: 340. Loss: 0.5215535332551439\n",
            "Epoch: 350. Loss: 0.5213859740493805\n",
            "Epoch: 360. Loss: 0.5212368624540217\n",
            "Epoch: 370. Loss: 0.5211040464249921\n",
            "Epoch: 380. Loss: 0.5209856416764331\n",
            "Epoch: 390. Loss: 0.5208799957470022\n",
            "Epoch: 400. Loss: 0.5207856573480228\n",
            "Epoch: 410. Loss: 0.5207013501291688\n",
            "Epoch: 420. Loss: 0.5206259501566363\n",
            "Epoch: 430. Loss: 0.5205584665249428\n",
            "Epoch: 440. Loss: 0.5204980246242557\n",
            "Epoch: 450. Loss: 0.5204438516662254\n",
            "Epoch: 460. Loss: 0.5203952641369787\n",
            "Epoch: 470. Loss: 0.5203516568994718\n",
            "Epoch: 480. Loss: 0.5203124937113384\n",
            "Epoch: 490. Loss: 0.5202772989605796\n",
            "tensor(0.7067, dtype=torch.float64)\n",
            "2005-12-04 00:00:00\n",
            "Epoch: 0. Loss: 1.1757360348822317\n",
            "Epoch: 10. Loss: 1.027353230694156\n",
            "Epoch: 20. Loss: 0.9108852105896189\n",
            "Epoch: 30. Loss: 0.8207427294466184\n",
            "Epoch: 40. Loss: 0.751532434475972\n",
            "Epoch: 50. Loss: 0.698755613379548\n",
            "Epoch: 60. Loss: 0.6587760197261501\n",
            "Epoch: 70. Loss: 0.6286413376637823\n",
            "Epoch: 80. Loss: 0.6059645983459132\n",
            "Epoch: 90. Loss: 0.5888573188086076\n",
            "Epoch: 100. Loss: 0.5758691816018704\n",
            "Epoch: 110. Loss: 0.5659163480374482\n",
            "Epoch: 120. Loss: 0.5582044678129892\n",
            "Epoch: 130. Loss: 0.552157557839164\n",
            "Epoch: 140. Loss: 0.5473592943033365\n",
            "Epoch: 150. Loss: 0.5435079892813224\n",
            "Epoch: 160. Loss: 0.5403835879796799\n",
            "Epoch: 170. Loss: 0.5378240962999631\n",
            "Epoch: 180. Loss: 0.535708963327513\n",
            "Epoch: 190. Loss: 0.5339474211401964\n",
            "Epoch: 200. Loss: 0.5324702957403997\n",
            "Epoch: 210. Loss: 0.5312242297041418\n",
            "Epoch: 220. Loss: 0.5301675781244127\n",
            "Epoch: 230. Loss: 0.5292674685913181\n",
            "Epoch: 240. Loss: 0.5284976751885927\n",
            "Epoch: 250. Loss: 0.5278370656643354\n",
            "Epoch: 260. Loss: 0.5272684554020463\n",
            "Epoch: 270. Loss: 0.5267777526025972\n",
            "Epoch: 280. Loss: 0.5263533138234554\n",
            "Epoch: 290. Loss: 0.5259854528961138\n",
            "Epoch: 300. Loss: 0.5256660627512255\n",
            "Epoch: 310. Loss: 0.5253883211722348\n",
            "Epoch: 320. Loss: 0.5251464595532995\n",
            "Epoch: 330. Loss: 0.5249355794242139\n",
            "Epoch: 340. Loss: 0.5247515055493791\n",
            "Epoch: 350. Loss: 0.5245906673054154\n",
            "Epoch: 360. Loss: 0.5244500021335903\n",
            "Epoch: 370. Loss: 0.5243268763847044\n",
            "Epoch: 380. Loss: 0.5242190199896078\n",
            "Epoch: 390. Loss: 0.5241244722130847\n",
            "Epoch: 400. Loss: 0.5240415363634551\n",
            "Epoch: 410. Loss: 0.5239687417922777\n",
            "Epoch: 420. Loss: 0.5239048118689044\n",
            "Epoch: 430. Loss: 0.5238486368826542\n",
            "Epoch: 440. Loss: 0.5237992510321983\n",
            "Epoch: 450. Loss: 0.5237558128227177\n",
            "Epoch: 460. Loss: 0.5237175883177405\n",
            "Epoch: 470. Loss: 0.5236839367925438\n",
            "Epoch: 480. Loss: 0.5236542984157202\n",
            "Epoch: 490. Loss: 0.52362818364955\n",
            "tensor(0.7940, dtype=torch.float64)\n",
            "2005-12-11 00:00:00\n",
            "Epoch: 0. Loss: 1.9375173130038639\n",
            "Epoch: 10. Loss: 1.5885283741906615\n",
            "Epoch: 20. Loss: 1.2880881785271219\n",
            "Epoch: 30. Loss: 1.0450861153729953\n",
            "Epoch: 40. Loss: 0.8636685715720122\n",
            "Epoch: 50. Loss: 0.7395455376173179\n",
            "Epoch: 60. Loss: 0.6608215877304615\n",
            "Epoch: 70. Loss: 0.6130962495918442\n",
            "Epoch: 80. Loss: 0.5844341005990974\n",
            "Epoch: 90. Loss: 0.5669199204511692\n",
            "Epoch: 100. Loss: 0.5558734313360331\n",
            "Epoch: 110. Loss: 0.5486440257378015\n",
            "Epoch: 120. Loss: 0.5437322306146795\n",
            "Epoch: 130. Loss: 0.5402729096818175\n",
            "Epoch: 140. Loss: 0.5377529339124868\n",
            "Epoch: 150. Loss: 0.5358589587020393\n",
            "Epoch: 160. Loss: 0.5343942010175194\n",
            "Epoch: 170. Loss: 0.5332318073233013\n",
            "Epoch: 180. Loss: 0.5322879948101571\n",
            "Epoch: 190. Loss: 0.5315061571826318\n",
            "Epoch: 200. Loss: 0.5308472185203073\n",
            "Epoch: 210. Loss: 0.5302836425225343\n",
            "Epoch: 220. Loss: 0.5297956331874406\n",
            "Epoch: 230. Loss: 0.5293686788855401\n",
            "Epoch: 240. Loss: 0.528991936793122\n",
            "Epoch: 250. Loss: 0.5286571527719441\n",
            "Epoch: 260. Loss: 0.5283579282027541\n",
            "Epoch: 270. Loss: 0.528089215146745\n",
            "Epoch: 280. Loss: 0.5278469639481103\n",
            "Epoch: 290. Loss: 0.5276278739952596\n",
            "Epoch: 300. Loss: 0.5274292151852672\n",
            "Epoch: 310. Loss: 0.5272486984363922\n",
            "Epoch: 320. Loss: 0.5270843806206484\n",
            "Epoch: 330. Loss: 0.526934593919256\n",
            "Epoch: 340. Loss: 0.5267978926924459\n",
            "Epoch: 350. Loss: 0.5266730130387965\n",
            "Epoch: 360. Loss: 0.5265588416404242\n",
            "Epoch: 370. Loss: 0.5264543914697423\n",
            "Epoch: 380. Loss: 0.5263587826152376\n",
            "Epoch: 390. Loss: 0.5262712269627473\n",
            "Epoch: 400. Loss: 0.5261910158084152\n",
            "Epoch: 410. Loss: 0.5261175097224362\n",
            "Epoch: 420. Loss: 0.526050130157861\n",
            "Epoch: 430. Loss: 0.5259883524259769\n",
            "Epoch: 440. Loss: 0.5259316997529083\n",
            "Epoch: 450. Loss: 0.5258797382006695\n",
            "Epoch: 460. Loss: 0.5258320722867673\n",
            "Epoch: 470. Loss: 0.5257883411743898\n",
            "Epoch: 480. Loss: 0.5257482153336815\n",
            "Epoch: 490. Loss: 0.5257113935960888\n",
            "tensor(0.7995, dtype=torch.float64)\n",
            "2005-12-18 00:00:00\n",
            "Epoch: 0. Loss: 0.8667008942452943\n",
            "Epoch: 10. Loss: 0.7611085478816971\n",
            "Epoch: 20. Loss: 0.6843626151633347\n",
            "Epoch: 30. Loss: 0.6314004089083272\n",
            "Epoch: 40. Loss: 0.5962630254949686\n",
            "Epoch: 50. Loss: 0.5734496761902623\n",
            "Epoch: 60. Loss: 0.558708402031134\n",
            "Epoch: 70. Loss: 0.5491179121692918\n",
            "Epoch: 80. Loss: 0.5427972563178314\n",
            "Epoch: 90. Loss: 0.5385669558879226\n",
            "Epoch: 100. Loss: 0.535689923932427\n",
            "Epoch: 110. Loss: 0.5337016965496543\n",
            "Epoch: 120. Loss: 0.5323056994801556\n",
            "Epoch: 130. Loss: 0.5313097779436212\n",
            "Epoch: 140. Loss: 0.5305876464762945\n",
            "Epoch: 150. Loss: 0.5300552064792174\n",
            "Epoch: 160. Loss: 0.5296557773940956\n",
            "Epoch: 170. Loss: 0.5293507396581075\n",
            "Epoch: 180. Loss: 0.5291135153188973\n",
            "Epoch: 190. Loss: 0.5289256411038814\n",
            "Epoch: 200. Loss: 0.5287741741978075\n",
            "Epoch: 210. Loss: 0.528649959343502\n",
            "Epoch: 220. Loss: 0.5285464600011044\n",
            "Epoch: 230. Loss: 0.5284589632394555\n",
            "Epoch: 240. Loss: 0.5283840348072286\n",
            "Epoch: 250. Loss: 0.5283191431812283\n",
            "Epoch: 260. Loss: 0.5282623986367878\n",
            "Epoch: 270. Loss: 0.5282123711450262\n",
            "Epoch: 280. Loss: 0.5281679626124771\n",
            "Epoch: 290. Loss: 0.5281283167801925\n",
            "Epoch: 300. Loss: 0.528092755343722\n",
            "Epoch: 310. Loss: 0.5280607324083904\n",
            "Epoch: 320. Loss: 0.5280318018178912\n",
            "Epoch: 330. Loss: 0.5280055935571877\n",
            "Epoch: 340. Loss: 0.5279817965775557\n",
            "Epoch: 350. Loss: 0.5279601461860186\n",
            "Epoch: 360. Loss: 0.5279404146937764\n",
            "Epoch: 370. Loss: 0.5279224044035893\n",
            "Epoch: 380. Loss: 0.5279059422856802\n",
            "Epoch: 390. Loss: 0.527890875880878\n",
            "Epoch: 400. Loss: 0.5278770701027222\n",
            "Epoch: 410. Loss: 0.5278644047040114\n",
            "Epoch: 420. Loss: 0.5278527722395145\n",
            "Epoch: 430. Loss: 0.5278420764034635\n",
            "Epoch: 440. Loss: 0.5278322306537593\n",
            "Epoch: 450. Loss: 0.5278231570585273\n",
            "Epoch: 460. Loss: 0.5278147853176022\n",
            "Epoch: 470. Loss: 0.5278070519236701\n",
            "Epoch: 480. Loss: 0.5277998994365467\n",
            "Epoch: 490. Loss: 0.5277932758504119\n",
            "tensor(0.7557, dtype=torch.float64)\n",
            "2005-12-25 00:00:00\n",
            "Epoch: 0. Loss: 0.6092537558588754\n",
            "Epoch: 10. Loss: 0.5876418133190026\n",
            "Epoch: 20. Loss: 0.57280631017964\n",
            "Epoch: 30. Loss: 0.5624152552956354\n",
            "Epoch: 40. Loss: 0.5549570673675626\n",
            "Epoch: 50. Loss: 0.5494642625585943\n",
            "Epoch: 60. Loss: 0.5453142506256086\n",
            "Epoch: 70. Loss: 0.5421008904916839\n",
            "Epoch: 80. Loss: 0.5395547839779421\n",
            "Epoch: 90. Loss: 0.5374941082671156\n",
            "Epoch: 100. Loss: 0.5357940303165233\n",
            "Epoch: 110. Loss: 0.5343674067264464\n",
            "Epoch: 120. Loss: 0.5331524070931689\n",
            "Epoch: 130. Loss: 0.5321044487509766\n",
            "Epoch: 140. Loss: 0.5311908607640813\n",
            "Epoch: 150. Loss: 0.5303873040261903\n",
            "Epoch: 160. Loss: 0.5296753388806503\n",
            "Epoch: 170. Loss: 0.5290407533233156\n",
            "Epoch: 180. Loss: 0.5284724018672062\n",
            "Epoch: 190. Loss: 0.5279613912600398\n",
            "Epoch: 200. Loss: 0.5275005042339989\n",
            "Epoch: 210. Loss: 0.5270837881123258\n",
            "Epoch: 220. Loss: 0.52670625852875\n",
            "Epoch: 230. Loss: 0.5263636841171065\n",
            "Epoch: 240. Loss: 0.5260524285379086\n",
            "Epoch: 250. Loss: 0.5257693333621668\n",
            "Epoch: 260. Loss: 0.5255116302472147\n",
            "Epoch: 270. Loss: 0.5252768742428853\n",
            "Epoch: 280. Loss: 0.5250628924401439\n",
            "Epoch: 290. Loss: 0.5248677438396595\n",
            "Epoch: 300. Loss: 0.524689687492114\n",
            "Epoch: 310. Loss: 0.524527156793564\n",
            "Epoch: 320. Loss: 0.524378738410027\n",
            "Epoch: 330. Loss: 0.5242431547265304\n",
            "Epoch: 340. Loss: 0.524119249016686\n",
            "Epoch: 350. Loss: 0.5240059727442432\n",
            "Epoch: 360. Loss: 0.523902374562609\n",
            "Epoch: 370. Loss: 0.5238075906894641\n",
            "Epoch: 380. Loss: 0.5237208364137104\n",
            "Epoch: 390. Loss: 0.5236413985499319\n",
            "Epoch: 400. Loss: 0.5235686286976168\n",
            "Epoch: 410. Loss: 0.5235019371930946\n",
            "Epoch: 420. Loss: 0.5234407876647149\n",
            "Epoch: 430. Loss: 0.5233846921185239\n",
            "Epoch: 440. Loss: 0.5233332064942391\n",
            "Epoch: 450. Loss: 0.5232859266408549\n",
            "Epoch: 460. Loss: 0.5232424846685652\n",
            "Epoch: 470. Loss: 0.523202545639466\n",
            "Epoch: 480. Loss: 0.5231658045641332\n",
            "Epoch: 490. Loss: 0.5231319836749461\n",
            "tensor(0.5890, dtype=torch.float64)\n",
            "2006-01-01 00:00:00\n",
            "Epoch: 0. Loss: 1.4051982725951613\n",
            "Epoch: 10. Loss: 1.144627870753676\n",
            "Epoch: 20. Loss: 0.9449482711032209\n",
            "Epoch: 30. Loss: 0.8022733030309901\n",
            "Epoch: 40. Loss: 0.7059454167752612\n",
            "Epoch: 50. Loss: 0.6432067348360965\n",
            "Epoch: 60. Loss: 0.6029291753368137\n",
            "Epoch: 70. Loss: 0.5769727109988251\n",
            "Epoch: 80. Loss: 0.5599789955906888\n",
            "Epoch: 90. Loss: 0.5486117816264052\n",
            "Epoch: 100. Loss: 0.5408324553791645\n",
            "Epoch: 110. Loss: 0.5353898534791209\n",
            "Epoch: 120. Loss: 0.5315034881800905\n",
            "Epoch: 130. Loss: 0.528676091812108\n",
            "Epoch: 140. Loss: 0.5265837431533852\n",
            "Epoch: 150. Loss: 0.525010878180302\n",
            "Epoch: 160. Loss: 0.5238111683572795\n",
            "Epoch: 170. Loss: 0.5228834742795492\n",
            "Epoch: 180. Loss: 0.5221567435669988\n",
            "Epoch: 190. Loss: 0.521580325129925\n",
            "Epoch: 200. Loss: 0.5211176330119677\n",
            "Epoch: 210. Loss: 0.5207419245592694\n",
            "Epoch: 220. Loss: 0.5204334394783542\n",
            "Epoch: 230. Loss: 0.5201774309942815\n",
            "Epoch: 240. Loss: 0.5199627918245684\n",
            "Epoch: 250. Loss: 0.5197810830221129\n",
            "Epoch: 260. Loss: 0.5196258396440977\n",
            "Epoch: 270. Loss: 0.5194920691660894\n",
            "Epoch: 280. Loss: 0.5193758857256268\n",
            "Epoch: 290. Loss: 0.5192742411421649\n",
            "Epoch: 300. Loss: 0.5191847255792622\n",
            "Epoch: 310. Loss: 0.5191054187778238\n",
            "Epoch: 320. Loss: 0.5190347783138219\n",
            "Epoch: 330. Loss: 0.5189715551646678\n",
            "Epoch: 340. Loss: 0.518914729554149\n",
            "Epoch: 350. Loss: 0.5188634619481604\n",
            "Epoch: 360. Loss: 0.5188170554336151\n",
            "Epoch: 370. Loss: 0.5187749266938892\n",
            "Epoch: 380. Loss: 0.5187365835072861\n",
            "Epoch: 390. Loss: 0.5187016072171682\n",
            "Epoch: 400. Loss: 0.5186696390073074\n",
            "Epoch: 410. Loss: 0.5186403691014012\n",
            "Epoch: 420. Loss: 0.518613528218495\n",
            "Epoch: 430. Loss: 0.518588880775495\n",
            "Epoch: 440. Loss: 0.5185662194479584\n",
            "Epoch: 450. Loss: 0.5185453607910425\n",
            "Epoch: 460. Loss: 0.5185261416912937\n",
            "Epoch: 470. Loss: 0.5185084164723244\n",
            "Epoch: 480. Loss: 0.5184920545174176\n",
            "Epoch: 490. Loss: 0.5184769383027205\n",
            "tensor(0.6756, dtype=torch.float64)\n",
            "2006-01-08 00:00:00\n",
            "Epoch: 0. Loss: 1.2040273662543723\n",
            "Epoch: 10. Loss: 1.0417684052784313\n",
            "Epoch: 20. Loss: 0.9175357336697737\n",
            "Epoch: 30. Loss: 0.8231005679272598\n",
            "Epoch: 40. Loss: 0.7515572030691626\n",
            "Epoch: 50. Loss: 0.69749511726082\n",
            "Epoch: 60. Loss: 0.6566814568373502\n",
            "Epoch: 70. Loss: 0.6258105652463682\n",
            "Epoch: 80. Loss: 0.602338797647208\n",
            "Epoch: 90. Loss: 0.5843464620694497\n",
            "Epoch: 100. Loss: 0.5704093550633295\n",
            "Epoch: 110. Loss: 0.5594837065271075\n",
            "Epoch: 120. Loss: 0.5508098270373868\n",
            "Epoch: 130. Loss: 0.5438359162669385\n",
            "Epoch: 140. Loss: 0.5381603217926324\n",
            "Epoch: 150. Loss: 0.5334890581662329\n",
            "Epoch: 160. Loss: 0.529605158159466\n",
            "Epoch: 170. Loss: 0.5263468228761743\n",
            "Epoch: 180. Loss: 0.5235919424263572\n",
            "Epoch: 190. Loss: 0.5212471532394262\n",
            "Epoch: 200. Loss: 0.5192400951064461\n",
            "Epoch: 210. Loss: 0.5175139140817492\n",
            "Epoch: 220. Loss: 0.5160233392616961\n",
            "Epoch: 230. Loss: 0.5147318633596879\n",
            "Epoch: 240. Loss: 0.5136096993345347\n",
            "Epoch: 250. Loss: 0.5126322847832603\n",
            "Epoch: 260. Loss: 0.5117791749775785\n",
            "Epoch: 270. Loss: 0.5110332134320938\n",
            "Epoch: 280. Loss: 0.5103799022016151\n",
            "Epoch: 290. Loss: 0.5098069172294247\n",
            "Epoch: 300. Loss: 0.5093037301423138\n",
            "Epoch: 310. Loss: 0.5088613090813363\n",
            "Epoch: 320. Loss: 0.5084718789698278\n",
            "Epoch: 330. Loss: 0.5081287270896135\n",
            "Epoch: 340. Loss: 0.5078260436799721\n",
            "Epoch: 350. Loss: 0.5075587899882091\n",
            "Epoch: 360. Loss: 0.507322588129212\n",
            "Epoch: 370. Loss: 0.5071136284918947\n",
            "Epoch: 380. Loss: 0.5069285914276991\n",
            "Epoch: 390. Loss: 0.5067645806843992\n",
            "Epoch: 400. Loss: 0.5066190665864245\n",
            "Epoch: 410. Loss: 0.5064898373657747\n",
            "Epoch: 420. Loss: 0.5063749573535249\n",
            "Epoch: 430. Loss: 0.5062727309776796\n",
            "Epoch: 440. Loss: 0.5061816716974233\n",
            "Epoch: 450. Loss: 0.5061004751499248\n",
            "Epoch: 460. Loss: 0.5060279959031585\n",
            "Epoch: 470. Loss: 0.5059632273035266\n",
            "Epoch: 480. Loss: 0.5059052839852973\n",
            "Epoch: 490. Loss: 0.5058533866736733\n",
            "tensor(0.8265, dtype=torch.float64)\n",
            "2006-01-15 00:00:00\n",
            "Epoch: 0. Loss: 0.9733035567813783\n",
            "Epoch: 10. Loss: 0.8411799289550356\n",
            "Epoch: 20. Loss: 0.748012755304111\n",
            "Epoch: 30. Loss: 0.6833053456075103\n",
            "Epoch: 40. Loss: 0.6383618619913164\n",
            "Epoch: 50. Loss: 0.6067981759838956\n",
            "Epoch: 60. Loss: 0.5842336329965417\n",
            "Epoch: 70. Loss: 0.5677588725149026\n",
            "Epoch: 80. Loss: 0.5554641142803844\n",
            "Epoch: 90. Loss: 0.5460933163177958\n",
            "Epoch: 100. Loss: 0.5388113553042986\n",
            "Epoch: 110. Loss: 0.5330538701675919\n",
            "Epoch: 120. Loss: 0.5284321679230685\n",
            "Epoch: 130. Loss: 0.5246731453576058\n",
            "Epoch: 140. Loss: 0.5215810558094868\n",
            "Epoch: 150. Loss: 0.519012867131441\n",
            "Epoch: 160. Loss: 0.5168621331803235\n",
            "Epoch: 170. Loss: 0.5150482621424405\n",
            "Epoch: 180. Loss: 0.5135092555726974\n",
            "Epoch: 190. Loss: 0.5121967139398425\n",
            "Epoch: 200. Loss: 0.5110723453382248\n",
            "Epoch: 210. Loss: 0.5101054863720912\n",
            "Epoch: 220. Loss: 0.5092713147477131\n",
            "Epoch: 230. Loss: 0.5085495414101513\n",
            "Epoch: 240. Loss: 0.5079234398189031\n",
            "Epoch: 250. Loss: 0.507379115504371\n",
            "Epoch: 260. Loss: 0.5069049491771233\n",
            "Epoch: 270. Loss: 0.5064911668421572\n",
            "Epoch: 280. Loss: 0.5061295040482144\n",
            "Epoch: 290. Loss: 0.5058129407797614\n",
            "Epoch: 300. Loss: 0.5055354900007855\n",
            "Epoch: 310. Loss: 0.5052920274168461\n",
            "Epoch: 320. Loss: 0.505078153251158\n",
            "Epoch: 330. Loss: 0.5048900791436217\n",
            "Epoch: 340. Loss: 0.5047245349564587\n",
            "Epoch: 350. Loss: 0.5045786914956296\n",
            "Epoch: 360. Loss: 0.5044500960635125\n",
            "Epoch: 370. Loss: 0.5043366184355423\n",
            "Epoch: 380. Loss: 0.5042364053647224\n",
            "Epoch: 390. Loss: 0.5041478421076419\n",
            "Epoch: 400. Loss: 0.5040695197655803\n",
            "Epoch: 410. Loss: 0.5040002074672426\n",
            "Epoch: 420. Loss: 0.503938828602185\n",
            "Epoch: 430. Loss: 0.5038844404581674\n",
            "Epoch: 440. Loss: 0.5038362167304343\n",
            "Epoch: 450. Loss: 0.5037934324629495\n",
            "Epoch: 460. Loss: 0.503755451055903\n",
            "Epoch: 470. Loss: 0.5037217130341569\n",
            "Epoch: 480. Loss: 0.5036917263206149\n",
            "Epoch: 490. Loss: 0.5036650577990206\n",
            "tensor(0.7348, dtype=torch.float64)\n",
            "2006-01-22 00:00:00\n",
            "Epoch: 0. Loss: 1.9579484190757563\n",
            "Epoch: 10. Loss: 1.7025727397580999\n",
            "Epoch: 20. Loss: 1.4758990277244164\n",
            "Epoch: 30. Loss: 1.2776979778318958\n",
            "Epoch: 40. Loss: 1.1075642840234659\n",
            "Epoch: 50. Loss: 0.9649454861711608\n",
            "Epoch: 60. Loss: 0.8489513281330829\n",
            "Epoch: 70. Loss: 0.7579633505214024\n",
            "Epoch: 80. Loss: 0.6892942649338191\n",
            "Epoch: 90. Loss: 0.6392566122592239\n",
            "Epoch: 100. Loss: 0.6037261367944955\n",
            "Epoch: 110. Loss: 0.5788455414265409\n",
            "Epoch: 120. Loss: 0.5614717793571444\n",
            "Epoch: 130. Loss: 0.5492745011813305\n",
            "Epoch: 140. Loss: 0.5406213018781029\n",
            "Epoch: 150. Loss: 0.5344011336418291\n",
            "Epoch: 160. Loss: 0.5298654552279586\n",
            "Epoch: 170. Loss: 0.5265093820979934\n",
            "Epoch: 180. Loss: 0.5239898164514468\n",
            "Epoch: 190. Loss: 0.5220710982035833\n",
            "Epoch: 200. Loss: 0.520589405140581\n",
            "Epoch: 210. Loss: 0.5194294478904838\n",
            "Epoch: 220. Loss: 0.5185091161380595\n",
            "Epoch: 230. Loss: 0.5177692615981428\n",
            "Epoch: 240. Loss: 0.5171668191324663\n",
            "Epoch: 250. Loss: 0.5166701181334042\n",
            "Epoch: 260. Loss: 0.5162556475837302\n",
            "Epoch: 270. Loss: 0.5159057977645841\n",
            "Epoch: 280. Loss: 0.5156072662294927\n",
            "Epoch: 290. Loss: 0.5153499210148651\n",
            "Epoch: 300. Loss: 0.5151259821938917\n",
            "Epoch: 310. Loss: 0.5149294274639892\n",
            "Epoch: 320. Loss: 0.5147555569815264\n",
            "Epoch: 330. Loss: 0.5146006724434843\n",
            "Epoch: 340. Loss: 0.5144618388312705\n",
            "Epoch: 350. Loss: 0.5143367064309022\n",
            "Epoch: 360. Loss: 0.5142233771193517\n",
            "Epoch: 370. Loss: 0.5141203033705184\n",
            "Epoch: 380. Loss: 0.5140262115892752\n",
            "Epoch: 390. Loss: 0.5139400436318585\n",
            "Epoch: 400. Loss: 0.5138609119885481\n",
            "Epoch: 410. Loss: 0.5137880652766278\n",
            "Epoch: 420. Loss: 0.5137208615467698\n",
            "Epoch: 430. Loss: 0.5136587475339844\n",
            "Epoch: 440. Loss: 0.5136012424481643\n",
            "Epoch: 450. Loss: 0.5135479252437734\n",
            "Epoch: 460. Loss: 0.5134984245653454\n",
            "Epoch: 470. Loss: 0.5134524107581949\n",
            "Epoch: 480. Loss: 0.513409589478791\n",
            "Epoch: 490. Loss: 0.5133696965488173\n",
            "tensor(0.9401, dtype=torch.float64)\n",
            "2006-01-29 00:00:00\n",
            "Epoch: 0. Loss: 0.9679243665046051\n",
            "Epoch: 10. Loss: 0.8516731284974614\n",
            "Epoch: 20. Loss: 0.7694963670546019\n",
            "Epoch: 30. Loss: 0.7111569836591941\n",
            "Epoch: 40. Loss: 0.6692148802723225\n",
            "Epoch: 50. Loss: 0.6385086857036949\n",
            "Epoch: 60. Loss: 0.6155450415832463\n",
            "Epoch: 70. Loss: 0.5979820804874088\n",
            "Epoch: 80. Loss: 0.5842493507291622\n",
            "Epoch: 90. Loss: 0.573285993837981\n",
            "Epoch: 100. Loss: 0.5643667023744167\n",
            "Epoch: 110. Loss: 0.5569880906373025\n",
            "Epoch: 120. Loss: 0.5507949092066567\n",
            "Epoch: 130. Loss: 0.5455319866116775\n",
            "Epoch: 140. Loss: 0.5410126742476231\n",
            "Epoch: 150. Loss: 0.5370979058856871\n",
            "Epoch: 160. Loss: 0.5336821383676836\n",
            "Epoch: 170. Loss: 0.5306837998429009\n",
            "Epoch: 180. Loss: 0.5280387239507979\n",
            "Epoch: 190. Loss: 0.5256955839344919\n",
            "Epoch: 200. Loss: 0.5236126802784455\n",
            "Epoch: 210. Loss: 0.5217556533024613\n",
            "Epoch: 220. Loss: 0.520095833626534\n",
            "Epoch: 230. Loss: 0.5186090364357456\n",
            "Epoch: 240. Loss: 0.5172746673058731\n",
            "Epoch: 250. Loss: 0.5160750488479666\n",
            "Epoch: 260. Loss: 0.5149949055027467\n",
            "Epoch: 270. Loss: 0.5140209629287498\n",
            "Epoch: 280. Loss: 0.5131416315090322\n",
            "Epoch: 290. Loss: 0.5123467524930787\n",
            "Epoch: 300. Loss: 0.5116273914966109\n",
            "Epoch: 310. Loss: 0.5109756683834111\n",
            "Epoch: 320. Loss: 0.5103846155491104\n",
            "Epoch: 330. Loss: 0.5098480587259387\n",
            "Epoch: 340. Loss: 0.5093605159091984\n",
            "Epoch: 350. Loss: 0.5089171110619922\n",
            "Epoch: 360. Loss: 0.5085135000154769\n",
            "Epoch: 370. Loss: 0.5081458065373097\n",
            "Epoch: 380. Loss: 0.5078105669524691\n",
            "Epoch: 390. Loss: 0.5075046820104334\n",
            "Epoch: 400. Loss: 0.5072253749298323\n",
            "Epoch: 410. Loss: 0.5069701547361992\n",
            "Epoch: 420. Loss: 0.5067367841543068\n",
            "Epoch: 430. Loss: 0.5065232514335616\n",
            "Epoch: 440. Loss: 0.5063277455799947\n",
            "Epoch: 450. Loss: 0.5061486345465295\n",
            "Epoch: 460. Loss: 0.5059844459980453\n",
            "Epoch: 470. Loss: 0.5058338503220092\n",
            "Epoch: 480. Loss: 0.5056956456011442\n",
            "Epoch: 490. Loss: 0.5055687443033026\n",
            "tensor(0.8593, dtype=torch.float64)\n",
            "2006-02-05 00:00:00\n",
            "Epoch: 0. Loss: 0.9253084677885188\n",
            "Epoch: 10. Loss: 0.8266974798017521\n",
            "Epoch: 20. Loss: 0.7505910545222148\n",
            "Epoch: 30. Loss: 0.6929920768940706\n",
            "Epoch: 40. Loss: 0.6497929887999044\n",
            "Epoch: 50. Loss: 0.6174195922394624\n",
            "Epoch: 60. Loss: 0.5930465888426764\n",
            "Epoch: 70. Loss: 0.5745493890463591\n",
            "Epoch: 80. Loss: 0.560366781897148\n",
            "Epoch: 90. Loss: 0.5493643862802252\n",
            "Epoch: 100. Loss: 0.5407237479709295\n",
            "Epoch: 110. Loss: 0.5338562200493303\n",
            "Epoch: 120. Loss: 0.5283373536499071\n",
            "Epoch: 130. Loss: 0.5238584801809264\n",
            "Epoch: 140. Loss: 0.5201922237846527\n",
            "Epoch: 150. Loss: 0.5171685668474849\n",
            "Epoch: 160. Loss: 0.514658441004984\n",
            "Epoch: 170. Loss: 0.5125624733483887\n",
            "Epoch: 180. Loss: 0.510803192721273\n",
            "Epoch: 190. Loss: 0.509319547393469\n",
            "Epoch: 200. Loss: 0.5080629772392007\n",
            "Epoch: 210. Loss: 0.5069945467243048\n",
            "Epoch: 220. Loss: 0.506082815736556\n",
            "Epoch: 230. Loss: 0.5053022343661465\n",
            "Epoch: 240. Loss: 0.5046319173139344\n",
            "Epoch: 250. Loss: 0.5040546983718903\n",
            "Epoch: 260. Loss: 0.503556394712713\n",
            "Epoch: 270. Loss: 0.5031252303224957\n",
            "Epoch: 280. Loss: 0.5027513813508581\n",
            "Epoch: 290. Loss: 0.5024266156033526\n",
            "Epoch: 300. Loss: 0.5021440051985161\n",
            "Epoch: 310. Loss: 0.5018976963965199\n",
            "Epoch: 320. Loss: 0.5016827243182441\n",
            "Epoch: 330. Loss: 0.5014948630704733\n",
            "Epoch: 340. Loss: 0.5013305039188487\n",
            "Epoch: 350. Loss: 0.5011865557766342\n",
            "Epoch: 360. Loss: 0.5010603635276696\n",
            "Epoch: 370. Loss: 0.5009496406667154\n",
            "Epoch: 380. Loss: 0.5008524134873296\n",
            "Epoch: 390. Loss: 0.5007669746273288\n",
            "Epoch: 400. Loss: 0.5006918442334525\n",
            "Epoch: 410. Loss: 0.5006257373594836\n",
            "Epoch: 420. Loss: 0.5005675364883492\n",
            "Epoch: 430. Loss: 0.5005162682858899\n",
            "Epoch: 440. Loss: 0.5004710838653125\n",
            "Epoch: 450. Loss: 0.500431241977029\n",
            "Epoch: 460. Loss: 0.5003960946464923\n",
            "Epoch: 470. Loss: 0.500365074868814\n",
            "Epoch: 480. Loss: 0.5003376860380845\n",
            "Epoch: 490. Loss: 0.5003134928450301\n",
            "tensor(0.8471, dtype=torch.float64)\n",
            "2006-02-12 00:00:00\n",
            "Epoch: 0. Loss: 0.6499613843051637\n",
            "Epoch: 10. Loss: 0.5981827520030653\n",
            "Epoch: 20. Loss: 0.5670217965537682\n",
            "Epoch: 30. Loss: 0.5476552112923367\n",
            "Epoch: 40. Loss: 0.5351124575856014\n",
            "Epoch: 50. Loss: 0.5266570892872955\n",
            "Epoch: 60. Loss: 0.5207510673074673\n",
            "Epoch: 70. Loss: 0.516497810692021\n",
            "Epoch: 80. Loss: 0.5133538059465074\n",
            "Epoch: 90. Loss: 0.5109772019337157\n",
            "Epoch: 100. Loss: 0.5091457419437276\n",
            "Epoch: 110. Loss: 0.5077106200819299\n",
            "Epoch: 120. Loss: 0.506569587660673\n",
            "Epoch: 130. Loss: 0.505650749188716\n",
            "Epoch: 140. Loss: 0.5049025012469281\n",
            "Epoch: 150. Loss: 0.5042871147973564\n",
            "Epoch: 160. Loss: 0.5037765412854004\n",
            "Epoch: 170. Loss: 0.5033496115631892\n",
            "Epoch: 180. Loss: 0.5029901277327263\n",
            "Epoch: 190. Loss: 0.502685539629856\n",
            "Epoch: 200. Loss: 0.5024260115260865\n",
            "Epoch: 210. Loss: 0.50220375390523\n",
            "Epoch: 220. Loss: 0.5020125382498763\n",
            "Epoch: 230. Loss: 0.5018473400919647\n",
            "Epoch: 240. Loss: 0.5017040732228295\n",
            "Epoch: 250. Loss: 0.5015793895408656\n",
            "Epoch: 260. Loss: 0.5014705267383265\n",
            "Epoch: 270. Loss: 0.5013751912534532\n",
            "Epoch: 280. Loss: 0.5012914674966723\n",
            "Epoch: 290. Loss: 0.5012177468476331\n",
            "Epoch: 300. Loss: 0.5011526716687014\n",
            "Epoch: 310. Loss: 0.50109509082388\n",
            "Epoch: 320. Loss: 0.501044024085675\n",
            "Epoch: 330. Loss: 0.5009986334611473\n",
            "Epoch: 340. Loss: 0.500958199943932\n",
            "Epoch: 350. Loss: 0.5009221045507565\n",
            "Epoch: 360. Loss: 0.5008898127634073\n",
            "Epoch: 370. Loss: 0.5008608616944515\n",
            "Epoch: 380. Loss: 0.5008348494445521\n",
            "Epoch: 390. Loss: 0.5008114262333414\n",
            "Epoch: 400. Loss: 0.500790286973482\n",
            "Epoch: 410. Loss: 0.5007711650253321\n",
            "Epoch: 420. Loss: 0.500753826922341\n",
            "Epoch: 430. Loss: 0.5007380678985454\n",
            "Epoch: 440. Loss: 0.5007237080819609\n",
            "Epoch: 450. Loss: 0.5007105892433111\n",
            "Epoch: 460. Loss: 0.500698572009904\n",
            "Epoch: 470. Loss: 0.5006875334707414\n",
            "Epoch: 480. Loss: 0.5006773651119995\n",
            "Epoch: 490. Loss: 0.5006679710325401\n",
            "tensor(0.8059, dtype=torch.float64)\n",
            "2006-02-19 00:00:00\n",
            "Epoch: 0. Loss: 1.5198204655996228\n",
            "Epoch: 10. Loss: 1.231727295136947\n",
            "Epoch: 20. Loss: 1.0101410799586776\n",
            "Epoch: 30. Loss: 0.8462167777998232\n",
            "Epoch: 40. Loss: 0.7301195310321906\n",
            "Epoch: 50. Loss: 0.6514751744210219\n",
            "Epoch: 60. Loss: 0.600038000750089\n",
            "Epoch: 70. Loss: 0.5669672318950011\n",
            "Epoch: 80. Loss: 0.5456810358667569\n",
            "Epoch: 90. Loss: 0.5317925862276065\n",
            "Epoch: 100. Loss: 0.5225518056032654\n",
            "Epoch: 110. Loss: 0.5162719011094438\n",
            "Epoch: 120. Loss: 0.5119156918605153\n",
            "Epoch: 130. Loss: 0.5088358918795455\n",
            "Epoch: 140. Loss: 0.5066204192917988\n",
            "Epoch: 150. Loss: 0.505001344606496\n",
            "Epoch: 160. Loss: 0.5038008797101824\n",
            "Epoch: 170. Loss: 0.5028988006620474\n",
            "Epoch: 180. Loss: 0.502212399177636\n",
            "Epoch: 190. Loss: 0.5016838849084004\n",
            "Epoch: 200. Loss: 0.5012723081760188\n",
            "Epoch: 210. Loss: 0.5009482821047364\n",
            "Epoch: 220. Loss: 0.5006904731771301\n",
            "Epoch: 230. Loss: 0.5004832300882739\n",
            "Epoch: 240. Loss: 0.5003149581803477\n",
            "Epoch: 250. Loss: 0.5001769901334644\n",
            "Epoch: 260. Loss: 0.5000627918664787\n",
            "Epoch: 270. Loss: 0.49996739794350104\n",
            "Epoch: 280. Loss: 0.4998870060722572\n",
            "Epoch: 290. Loss: 0.4998186831447122\n",
            "Epoch: 300. Loss: 0.49976015030400467\n",
            "Epoch: 310. Loss: 0.49970962454267254\n",
            "Epoch: 320. Loss: 0.49966570110193476\n",
            "Epoch: 330. Loss: 0.49962726556245285\n",
            "Epoch: 340. Loss: 0.49959342770772847\n",
            "Epoch: 350. Loss: 0.49956347146709057\n",
            "Epoch: 360. Loss: 0.4995368168126615\n",
            "Epoch: 370. Loss: 0.4995129905982806\n",
            "Epoch: 380. Loss: 0.49949160412607835\n",
            "Epoch: 390. Loss: 0.49947233580226846\n",
            "Epoch: 400. Loss: 0.4994549176624696\n",
            "Epoch: 410. Loss: 0.4994391248534331\n",
            "Epoch: 420. Loss: 0.4994247673839249\n",
            "Epoch: 430. Loss: 0.49941168362492516\n",
            "Epoch: 440. Loss: 0.4993997351640997\n",
            "Epoch: 450. Loss: 0.49938880271299324\n",
            "Epoch: 460. Loss: 0.499378782835816\n",
            "Epoch: 470. Loss: 0.4993695853219485\n",
            "Epoch: 480. Loss: 0.499361131064775\n",
            "Epoch: 490. Loss: 0.49935335034032596\n",
            "tensor(0.6757, dtype=torch.float64)\n",
            "2006-02-26 00:00:00\n",
            "Epoch: 0. Loss: 0.9491965860848788\n",
            "Epoch: 10. Loss: 0.825981975714909\n",
            "Epoch: 20. Loss: 0.7342773137629034\n",
            "Epoch: 30. Loss: 0.6679235336886762\n",
            "Epoch: 40. Loss: 0.6208449572955599\n",
            "Epoch: 50. Loss: 0.5876758640084108\n",
            "Epoch: 60. Loss: 0.5642157163929511\n",
            "Epoch: 70. Loss: 0.5474579205297624\n",
            "Epoch: 80. Loss: 0.5353317517316896\n",
            "Epoch: 90. Loss: 0.5264247937262388\n",
            "Epoch: 100. Loss: 0.5197762521786509\n",
            "Epoch: 110. Loss: 0.5147325774081547\n",
            "Epoch: 120. Loss: 0.5108469881503304\n",
            "Epoch: 130. Loss: 0.507810790648227\n",
            "Epoch: 140. Loss: 0.5054075661172249\n",
            "Epoch: 150. Loss: 0.5034830904954005\n",
            "Epoch: 160. Loss: 0.5019256481646766\n",
            "Epoch: 170. Loss: 0.5006530591394484\n",
            "Epoch: 180. Loss: 0.4996040157320258\n",
            "Epoch: 190. Loss: 0.4987322005565504\n",
            "Epoch: 200. Loss: 0.4980022223505999\n",
            "Epoch: 210. Loss: 0.49738675956292094\n",
            "Epoch: 220. Loss: 0.49686452090642647\n",
            "Epoch: 230. Loss: 0.4964187684915732\n",
            "Epoch: 240. Loss: 0.49603623494168414\n",
            "Epoch: 250. Loss: 0.4957063206669528\n",
            "Epoch: 260. Loss: 0.4954204930730327\n",
            "Epoch: 270. Loss: 0.49517183305254714\n",
            "Epoch: 280. Loss: 0.4949546900081241\n",
            "Epoch: 290. Loss: 0.4947644175703675\n",
            "Epoch: 300. Loss: 0.49459716978784596\n",
            "Epoch: 310. Loss: 0.4944497429536112\n",
            "Epoch: 320. Loss: 0.4943194520928775\n",
            "Epoch: 330. Loss: 0.49420403393234896\n",
            "Epoch: 340. Loss: 0.49410157021560047\n",
            "Epoch: 350. Loss: 0.49401042673513273\n",
            "Epoch: 360. Loss: 0.49392920456942263\n",
            "Epoch: 370. Loss: 0.4938567008477327\n",
            "Epoch: 380. Loss: 0.4937918769918292\n",
            "Epoch: 390. Loss: 0.493733832856266\n",
            "Epoch: 400. Loss: 0.49368178554696013\n",
            "Epoch: 410. Loss: 0.4936350519703164\n",
            "Epoch: 420. Loss: 0.4935930343734229\n",
            "Epoch: 430. Loss: 0.49355520829566324\n",
            "Epoch: 440. Loss: 0.4935211124752176\n",
            "Epoch: 450. Loss: 0.4934903403491642\n",
            "Epoch: 460. Loss: 0.4934625328598628\n",
            "Epoch: 470. Loss: 0.4934373723379834\n",
            "Epoch: 480. Loss: 0.49341457727771415\n",
            "Epoch: 490. Loss: 0.49339389785520577\n",
            "tensor(0.6995, dtype=torch.float64)\n",
            "2006-03-05 00:00:00\n",
            "Epoch: 0. Loss: 2.1974477775754617\n",
            "Epoch: 10. Loss: 1.7345087174546947\n",
            "Epoch: 20. Loss: 1.3741296784729742\n",
            "Epoch: 30. Loss: 1.113055120281321\n",
            "Epoch: 40. Loss: 0.9303771193196346\n",
            "Epoch: 50. Loss: 0.8040790187528702\n",
            "Epoch: 60. Loss: 0.7170599453648563\n",
            "Epoch: 70. Loss: 0.6569136558056192\n",
            "Epoch: 80. Loss: 0.6149147645606116\n",
            "Epoch: 90. Loss: 0.5851166611404892\n",
            "Epoch: 100. Loss: 0.5635613985348235\n",
            "Epoch: 110. Loss: 0.5476419969460724\n",
            "Epoch: 120. Loss: 0.5356389908794525\n",
            "Epoch: 130. Loss: 0.5264076983652101\n",
            "Epoch: 140. Loss: 0.5191755194843496\n",
            "Epoch: 150. Loss: 0.5134126354230353\n",
            "Epoch: 160. Loss: 0.508749614660077\n",
            "Epoch: 170. Loss: 0.504924519869743\n",
            "Epoch: 180. Loss: 0.501748551460368\n",
            "Epoch: 190. Loss: 0.49908342375955644\n",
            "Epoch: 200. Loss: 0.4968262532277272\n",
            "Epoch: 210. Loss: 0.4948993212632511\n",
            "Epoch: 220. Loss: 0.4932430446150852\n",
            "Epoch: 230. Loss: 0.49181108572414267\n",
            "Epoch: 240. Loss: 0.4905669096051701\n",
            "Epoch: 250. Loss: 0.48948133072786065\n",
            "Epoch: 260. Loss: 0.4885307453165118\n",
            "Epoch: 270. Loss: 0.487695843341103\n",
            "Epoch: 280. Loss: 0.4869606596430414\n",
            "Epoch: 290. Loss: 0.48631186714801916\n",
            "Epoch: 300. Loss: 0.4857382445079605\n",
            "Epoch: 310. Loss: 0.4852302705800828\n",
            "Epoch: 320. Loss: 0.4847798119856875\n",
            "Epoch: 330. Loss: 0.48437987961426976\n",
            "Epoch: 340. Loss: 0.4840244366859524\n",
            "Epoch: 350. Loss: 0.4837082457512644\n",
            "Epoch: 360. Loss: 0.48342674539677355\n",
            "Epoch: 370. Loss: 0.48317594985122975\n",
            "Epoch: 380. Loss: 0.4829523664343701\n",
            "Epoch: 390. Loss: 0.4827529270570768\n",
            "Epoch: 400. Loss: 0.4825749309053638\n",
            "Epoch: 410. Loss: 0.482415996118912\n",
            "Epoch: 420. Loss: 0.4822740187763001\n",
            "Epoch: 430. Loss: 0.482147137872544\n",
            "Epoch: 440. Loss: 0.4820337052549061\n",
            "Epoch: 450. Loss: 0.4819322596951659\n",
            "Epoch: 460. Loss: 0.481841504438631\n",
            "Epoch: 470. Loss: 0.48176028769511814\n",
            "Epoch: 480. Loss: 0.4816875856343877\n",
            "Epoch: 490. Loss: 0.4816224875249526\n",
            "tensor(0.8802, dtype=torch.float64)\n",
            "2006-03-12 00:00:00\n",
            "Epoch: 0. Loss: 0.753870436928261\n",
            "Epoch: 10. Loss: 0.681984143346634\n",
            "Epoch: 20. Loss: 0.6303234375894265\n",
            "Epoch: 30. Loss: 0.5931400159294048\n",
            "Epoch: 40. Loss: 0.5661233687502432\n",
            "Epoch: 50. Loss: 0.5462478358554504\n",
            "Epoch: 60. Loss: 0.5314558338716624\n",
            "Epoch: 70. Loss: 0.5203463696731516\n",
            "Epoch: 80. Loss: 0.5119427852328179\n",
            "Epoch: 90. Loss: 0.5055446102887313\n",
            "Epoch: 100. Loss: 0.5006399752108311\n",
            "Epoch: 110. Loss: 0.49685239290059735\n",
            "Epoch: 120. Loss: 0.49390481435869565\n",
            "Epoch: 130. Loss: 0.49159319178148225\n",
            "Epoch: 140. Loss: 0.4897666523806381\n",
            "Epoch: 150. Loss: 0.4883128786546245\n",
            "Epoch: 160. Loss: 0.4871475537366727\n",
            "Epoch: 170. Loss: 0.4862068355196388\n",
            "Epoch: 180. Loss: 0.485442000587546\n",
            "Epoch: 190. Loss: 0.48481560851551714\n",
            "Epoch: 200. Loss: 0.4842987242778149\n",
            "Epoch: 210. Loss: 0.48386888039019604\n",
            "Epoch: 220. Loss: 0.4835085623067454\n",
            "Epoch: 230. Loss: 0.4832040696729519\n",
            "Epoch: 240. Loss: 0.48294465196769765\n",
            "Epoch: 250. Loss: 0.4827218475083688\n",
            "Epoch: 260. Loss: 0.4825289751387859\n",
            "Epoch: 270. Loss: 0.48236074174128535\n",
            "Epoch: 280. Loss: 0.4822129383032631\n",
            "Epoch: 290. Loss: 0.48208220407342117\n",
            "Epoch: 300. Loss: 0.48196584327832753\n",
            "Epoch: 310. Loss: 0.4818616825182896\n",
            "Epoch: 320. Loss: 0.4817679597006871\n",
            "Epoch: 330. Loss: 0.4816832374498369\n",
            "Epoch: 340. Loss: 0.4816063355267678\n",
            "Epoch: 350. Loss: 0.4815362780207492\n",
            "Epoch: 360. Loss: 0.48147225202443716\n",
            "Epoch: 370. Loss: 0.4814135752406933\n",
            "Epoch: 380. Loss: 0.4813596705402529\n",
            "Epoch: 390. Loss: 0.4813100459326257\n",
            "Epoch: 400. Loss: 0.4812642787565661\n",
            "Epoch: 410. Loss: 0.48122200316331376\n",
            "Epoch: 420. Loss: 0.48118290017280285\n",
            "Epoch: 430. Loss: 0.4811466897435563\n",
            "Epoch: 440. Loss: 0.48111312442144827\n",
            "Epoch: 450. Loss: 0.48108198422901555\n",
            "Epoch: 460. Loss: 0.48105307253182744\n",
            "Epoch: 470. Loss: 0.48102621267646734\n",
            "Epoch: 480. Loss: 0.4810012452397185\n",
            "Epoch: 490. Loss: 0.480978025763517\n",
            "tensor(0.8246, dtype=torch.float64)\n",
            "2006-03-19 00:00:00\n",
            "Epoch: 0. Loss: 0.8782360589042923\n",
            "Epoch: 10. Loss: 0.7599766417483599\n",
            "Epoch: 20. Loss: 0.6787617608096368\n",
            "Epoch: 30. Loss: 0.6233909117994426\n",
            "Epoch: 40. Loss: 0.5855081883036489\n",
            "Epoch: 50. Loss: 0.5592865382498552\n",
            "Epoch: 60. Loss: 0.5408240564712896\n",
            "Epoch: 70. Loss: 0.5275610660306367\n",
            "Epoch: 80. Loss: 0.5178275199213347\n",
            "Epoch: 90. Loss: 0.5105287644998462\n",
            "Epoch: 100. Loss: 0.5049396643478601\n",
            "Epoch: 110. Loss: 0.5005732252514995\n",
            "Epoch: 120. Loss: 0.4970973950471403\n",
            "Epoch: 130. Loss: 0.4942822099470705\n",
            "Epoch: 140. Loss: 0.4919659122591533\n",
            "Epoch: 150. Loss: 0.4900329649795357\n",
            "Epoch: 160. Loss: 0.48839959316001913\n",
            "Epoch: 170. Loss: 0.4870041440699094\n",
            "Epoch: 180. Loss: 0.4858005735221036\n",
            "Epoch: 190. Loss: 0.4847539880120874\n",
            "Epoch: 200. Loss: 0.48383755693523917\n",
            "Epoch: 210. Loss: 0.48303034957603214\n",
            "Epoch: 220. Loss: 0.4823158037893275\n",
            "Epoch: 230. Loss: 0.4816806309732945\n",
            "Epoch: 240. Loss: 0.48111402545797827\n",
            "Epoch: 250. Loss: 0.4806070882904674\n",
            "Epoch: 260. Loss: 0.4801524033253526\n",
            "Epoch: 270. Loss: 0.4797437223841482\n",
            "Epoch: 280. Loss: 0.4793757291171329\n",
            "Epoch: 290. Loss: 0.47904386007406136\n",
            "Epoch: 300. Loss: 0.47874416766346356\n",
            "Epoch: 310. Loss: 0.4784732140102963\n",
            "Epoch: 320. Loss: 0.4782279877809814\n",
            "Epoch: 330. Loss: 0.47800583822017023\n",
            "Epoch: 340. Loss: 0.4778044221991555\n",
            "Epoch: 350. Loss: 0.47762166119386046\n",
            "Epoch: 360. Loss: 0.47745570591756836\n",
            "Epoch: 370. Loss: 0.47730490691882826\n",
            "Epoch: 380. Loss: 0.4771677898810755\n",
            "Epoch: 390. Loss: 0.47704303467195697\n",
            "Epoch: 400. Loss: 0.4769294574189762\n",
            "Epoch: 410. Loss: 0.4768259950566649\n",
            "Epoch: 420. Loss: 0.4767316919154427\n",
            "Epoch: 430. Loss: 0.47664568801548235\n",
            "Epoch: 440. Loss: 0.4765672087988091\n",
            "Epoch: 450. Loss: 0.4764955560857236\n",
            "Epoch: 460. Loss: 0.4764301000819696\n",
            "Epoch: 470. Loss: 0.4763702722941152\n",
            "Epoch: 480. Loss: 0.47631555923479696\n",
            "Epoch: 490. Loss: 0.47626549681850255\n",
            "tensor(0.8270, dtype=torch.float64)\n",
            "2006-03-26 00:00:00\n",
            "Epoch: 0. Loss: 0.6091269598487385\n",
            "Epoch: 10. Loss: 0.5929042041312482\n",
            "Epoch: 20. Loss: 0.5795009277715913\n",
            "Epoch: 30. Loss: 0.5682334194371039\n",
            "Epoch: 40. Loss: 0.5586086212478121\n",
            "Epoch: 50. Loss: 0.550270104439412\n",
            "Epoch: 60. Loss: 0.542958475849407\n",
            "Epoch: 70. Loss: 0.5364831323592624\n",
            "Epoch: 80. Loss: 0.530702336104862\n",
            "Epoch: 90. Loss: 0.5255092003486038\n",
            "Epoch: 100. Loss: 0.5208218178152696\n",
            "Epoch: 110. Loss: 0.5165762814037604\n",
            "Epoch: 120. Loss: 0.5127217280912554\n",
            "Epoch: 130. Loss: 0.5092168051758248\n",
            "Epoch: 140. Loss: 0.5060271431638208\n",
            "Epoch: 150. Loss: 0.5031235462091183\n",
            "Epoch: 160. Loss: 0.5004806973784038\n",
            "Epoch: 170. Loss: 0.4980762350947417\n",
            "Epoch: 180. Loss: 0.4958900977991755\n",
            "Epoch: 190. Loss: 0.4939040621922727\n",
            "Epoch: 200. Loss: 0.4921014204151256\n",
            "Epoch: 210. Loss: 0.4904667558931099\n",
            "Epoch: 220. Loss: 0.4889857880760434\n",
            "Epoch: 230. Loss: 0.48764526413717896\n",
            "Epoch: 240. Loss: 0.4864328816102501\n",
            "Epoch: 250. Loss: 0.4853372304561796\n",
            "Epoch: 260. Loss: 0.48434774649937407\n",
            "Epoch: 270. Loss: 0.48345467079357646\n",
            "Epoch: 280. Loss: 0.4826490114405563\n",
            "Epoch: 290. Loss: 0.48192250582356383\n",
            "Epoch: 300. Loss: 0.48126758223838545\n",
            "Epoch: 310. Loss: 0.4806773205974931\n",
            "Epoch: 320. Loss: 0.4801454123230738\n",
            "Epoch: 330. Loss: 0.4796661197965969\n",
            "Epoch: 340. Loss: 0.4792342358491103\n",
            "Epoch: 350. Loss: 0.47884504380047166\n",
            "Epoch: 360. Loss: 0.4784942785207406\n",
            "Epoch: 370. Loss: 0.47817808891826813\n",
            "Epoch: 380. Loss: 0.47789300217483865\n",
            "Epoch: 390. Loss: 0.4776358899610537\n",
            "Epoch: 400. Loss: 0.4774039367829487\n",
            "Epoch: 410. Loss: 0.4771946105381628\n",
            "Epoch: 420. Loss: 0.47700563529897033\n",
            "Epoch: 430. Loss: 0.476834966290551\n",
            "Epoch: 440. Loss: 0.4766807669954687\n",
            "Epoch: 450. Loss: 0.47654138828818976\n",
            "Epoch: 460. Loss: 0.47641534948517017\n",
            "Epoch: 470. Loss: 0.4763013211849866\n",
            "Epoch: 480. Loss: 0.47619810976773674\n",
            "Epoch: 490. Loss: 0.47610464342213565\n",
            "tensor(0.7057, dtype=torch.float64)\n",
            "2006-04-02 00:00:00\n",
            "Epoch: 0. Loss: 1.3501890570116866\n",
            "Epoch: 10. Loss: 1.1604495936040273\n",
            "Epoch: 20. Loss: 0.9988161380299292\n",
            "Epoch: 30. Loss: 0.8653305754965034\n",
            "Epoch: 40. Loss: 0.758906614581964\n",
            "Epoch: 50. Loss: 0.6771047928243199\n",
            "Epoch: 60. Loss: 0.6163019167493959\n",
            "Epoch: 70. Loss: 0.5722814510386478\n",
            "Epoch: 80. Loss: 0.5409515668700974\n",
            "Epoch: 90. Loss: 0.5188362642981654\n",
            "Epoch: 100. Loss: 0.503238684690175\n",
            "Epoch: 110. Loss: 0.49218586384555413\n",
            "Epoch: 120. Loss: 0.4842865355503256\n",
            "Epoch: 130. Loss: 0.47858003265048243\n",
            "Epoch: 140. Loss: 0.4744090117817492\n",
            "Epoch: 150. Loss: 0.47132380613513913\n",
            "Epoch: 160. Loss: 0.4690150705848386\n",
            "Epoch: 170. Loss: 0.4672680294912301\n",
            "Epoch: 180. Loss: 0.46593192287585056\n",
            "Epoch: 190. Loss: 0.4648996955989549\n",
            "Epoch: 200. Loss: 0.46409445224566265\n",
            "Epoch: 210. Loss: 0.4634603529973496\n",
            "Epoch: 220. Loss: 0.462956430763669\n",
            "Epoch: 230. Loss: 0.46255234356596714\n",
            "Epoch: 240. Loss: 0.46222542167521913\n",
            "Epoch: 250. Loss: 0.4619585908009956\n",
            "Epoch: 260. Loss: 0.4617388950639006\n",
            "Epoch: 270. Loss: 0.4615564354738136\n",
            "Epoch: 280. Loss: 0.46140359956432403\n",
            "Epoch: 290. Loss: 0.4612744972819708\n",
            "Epoch: 300. Loss: 0.4611645444893791\n",
            "Epoch: 310. Loss: 0.4610701531257256\n",
            "Epoch: 320. Loss: 0.4609884991145846\n",
            "Epoch: 330. Loss: 0.4609173474079422\n",
            "Epoch: 340. Loss: 0.46085491933400846\n",
            "Epoch: 350. Loss: 0.46079979148213684\n",
            "Epoch: 360. Loss: 0.4607508182463835\n",
            "Epoch: 370. Loss: 0.4607070722198193\n",
            "Epoch: 380. Loss: 0.46066779812876407\n",
            "Epoch: 390. Loss: 0.4606323770871317\n",
            "Epoch: 400. Loss: 0.4606002987520431\n",
            "Epoch: 410. Loss: 0.46057113955391193\n",
            "Epoch: 420. Loss: 0.46054454561459013\n",
            "Epoch: 430. Loss: 0.4605202192966459\n",
            "Epoch: 440. Loss: 0.46049790857468154\n",
            "Epoch: 450. Loss: 0.46047739860694265\n",
            "Epoch: 460. Loss: 0.46045850502774094\n",
            "Epoch: 470. Loss: 0.4604410685897022\n",
            "Epoch: 480. Loss: 0.46042495086790836\n",
            "Epoch: 490. Loss: 0.46041003080181964\n",
            "tensor(0.8538, dtype=torch.float64)\n",
            "2006-04-09 00:00:00\n",
            "Epoch: 0. Loss: 0.5302609551582932\n",
            "Epoch: 10. Loss: 0.5170790654942199\n",
            "Epoch: 20. Loss: 0.5072526770680019\n",
            "Epoch: 30. Loss: 0.49980612961539717\n",
            "Epoch: 40. Loss: 0.49407038969671024\n",
            "Epoch: 50. Loss: 0.4895825056508261\n",
            "Epoch: 60. Loss: 0.4860184107162961\n",
            "Epoch: 70. Loss: 0.48314831281233334\n",
            "Epoch: 80. Loss: 0.4808070582261442\n",
            "Epoch: 90. Loss: 0.47887433151365427\n",
            "Epoch: 100. Loss: 0.4772613104923012\n",
            "Epoch: 110. Loss: 0.47590157589693\n",
            "Epoch: 120. Loss: 0.47474484693811436\n",
            "Epoch: 130. Loss: 0.4737526120171539\n",
            "Epoch: 140. Loss: 0.4728950441969163\n",
            "Epoch: 150. Loss: 0.4721487975827866\n",
            "Epoch: 160. Loss: 0.4714954147405411\n",
            "Epoch: 170. Loss: 0.47092016287263316\n",
            "Epoch: 180. Loss: 0.47041117427924917\n",
            "Epoch: 190. Loss: 0.469958805158945\n",
            "Epoch: 200. Loss: 0.4695551527506516\n",
            "Epoch: 210. Loss: 0.4691936884769825\n",
            "Epoch: 220. Loss: 0.46886897689285195\n",
            "Epoch: 230. Loss: 0.4685764586828773\n",
            "Epoch: 240. Loss: 0.46831228187671886\n",
            "Epoch: 250. Loss: 0.46807316965445056\n",
            "Epoch: 260. Loss: 0.46785631612468426\n",
            "Epoch: 270. Loss: 0.46765930363547065\n",
            "Epoch: 280. Loss: 0.4674800367672494\n",
            "Epoch: 290. Loss: 0.46731668932741227\n",
            "Epoch: 300. Loss: 0.46716766153507416\n",
            "Epoch: 310. Loss: 0.4670315452350744\n",
            "Epoch: 320. Loss: 0.4669070954706313\n",
            "Epoch: 330. Loss: 0.4667932071163549\n",
            "Epoch: 340. Loss: 0.4666888955577056\n",
            "Epoch: 350. Loss: 0.46659328062148564\n",
            "Epoch: 360. Loss: 0.4665055731306982\n",
            "Epoch: 370. Loss: 0.46642506358807223\n",
            "Epoch: 380. Loss: 0.4663511125946132\n",
            "Epoch: 390. Loss: 0.46628314268941806\n",
            "Epoch: 400. Loss: 0.46622063135971237\n",
            "Epoch: 410. Loss: 0.466163105019507\n",
            "Epoch: 420. Loss: 0.46611013379434146\n",
            "Epoch: 430. Loss: 0.46606132698057273\n",
            "Epoch: 440. Loss: 0.4660163290723082\n",
            "Epoch: 450. Loss: 0.46597481626873666\n",
            "Epoch: 460. Loss: 0.4659364933903323\n",
            "Epoch: 470. Loss: 0.4659010911450209\n",
            "Epoch: 480. Loss: 0.4658683636955494\n",
            "Epoch: 490. Loss: 0.4658380864874937\n",
            "tensor(0.8953, dtype=torch.float64)\n",
            "2006-04-16 00:00:00\n",
            "Epoch: 0. Loss: 0.9935987204147343\n",
            "Epoch: 10. Loss: 0.8373050301510963\n",
            "Epoch: 20. Loss: 0.726725391444241\n",
            "Epoch: 30. Loss: 0.6514122765816995\n",
            "Epoch: 40. Loss: 0.600955132623567\n",
            "Epoch: 50. Loss: 0.5670640009456933\n",
            "Epoch: 60. Loss: 0.5439407470455604\n",
            "Epoch: 70. Loss: 0.5277908557570333\n",
            "Epoch: 80. Loss: 0.5161977432850767\n",
            "Epoch: 90. Loss: 0.5076304745824504\n",
            "Epoch: 100. Loss: 0.5011128203547218\n",
            "Epoch: 110. Loss: 0.49601427458305036\n",
            "Epoch: 120. Loss: 0.49192110159486935\n",
            "Epoch: 130. Loss: 0.48855707255454006\n",
            "Epoch: 140. Loss: 0.4857344430560608\n",
            "Epoch: 150. Loss: 0.48332328731749213\n",
            "Epoch: 160. Loss: 0.4812320481585841\n",
            "Epoch: 170. Loss: 0.47939501812134144\n",
            "Epoch: 180. Loss: 0.4777641630077646\n",
            "Epoch: 190. Loss: 0.47630370586376203\n",
            "Epoch: 200. Loss: 0.47498649141368987\n",
            "Epoch: 210. Loss: 0.4737915149829346\n",
            "Epoch: 220. Loss: 0.4727022230646124\n",
            "Epoch: 230. Loss: 0.4717053314192822\n",
            "Epoch: 240. Loss: 0.4707899941278625\n",
            "Epoch: 250. Loss: 0.46994721304129555\n",
            "Epoch: 260. Loss: 0.4691694134228755\n",
            "Epoch: 270. Loss: 0.4684501354730707\n",
            "Epoch: 280. Loss: 0.4677838073191906\n",
            "Epoch: 290. Loss: 0.4671655757368674\n",
            "Epoch: 300. Loss: 0.4665911781225015\n",
            "Epoch: 310. Loss: 0.4660568441994188\n",
            "Epoch: 320. Loss: 0.4655592193621108\n",
            "Epoch: 330. Loss: 0.4650953039359543\n",
            "Epoch: 340. Loss: 0.4646624042840037\n",
            "Epoch: 350. Loss: 0.4642580928505334\n",
            "Epoch: 360. Loss: 0.46388017504481227\n",
            "Epoch: 370. Loss: 0.46352666144241667\n",
            "Epoch: 380. Loss: 0.46319574418738596\n",
            "Epoch: 390. Loss: 0.4628857767668638\n",
            "Epoch: 400. Loss: 0.4625952565355624\n",
            "Epoch: 410. Loss: 0.46232280951495636\n",
            "Epoch: 420. Loss: 0.46206717709875816\n",
            "Epoch: 430. Loss: 0.46182720437400016\n",
            "Epoch: 440. Loss: 0.46160182982443404\n",
            "Epoch: 450. Loss: 0.4613900762258861\n",
            "Epoch: 460. Loss: 0.4611910425758468\n",
            "Epoch: 470. Loss: 0.46100389692484267\n",
            "Epoch: 480. Loss: 0.46082786999707004\n",
            "Epoch: 490. Loss: 0.4606622495038032\n",
            "tensor(0.8014, dtype=torch.float64)\n",
            "2006-04-23 00:00:00\n",
            "Epoch: 0. Loss: 0.9386596942748433\n",
            "Epoch: 10. Loss: 0.8275451243292105\n",
            "Epoch: 20. Loss: 0.7388577323487513\n",
            "Epoch: 30. Loss: 0.6694860826877221\n",
            "Epoch: 40. Loss: 0.6163639278022656\n",
            "Epoch: 50. Loss: 0.576434001187014\n",
            "Epoch: 60. Loss: 0.5468024960183586\n",
            "Epoch: 70. Loss: 0.5249421014218004\n",
            "Epoch: 80. Loss: 0.5088088705009619\n",
            "Epoch: 90. Loss: 0.4968440703734872\n",
            "Epoch: 100. Loss: 0.4879034623231075\n",
            "Epoch: 110. Loss: 0.48116415329139167\n",
            "Epoch: 120. Loss: 0.4760387967301119\n",
            "Epoch: 130. Loss: 0.472107688036242\n",
            "Epoch: 140. Loss: 0.46906897309375756\n"
          ]
        }
      ],
      "source": [
        "parameters = pd.DataFrame(columns=['a','b','prob'])\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_ml_dataset_for_date(date)\n",
        "  a,b = train_and_get_a_b(dataset[:-1])  \n",
        "  with torch.no_grad():\n",
        "    y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "    print(y_test)\n",
        "    parameters.loc[date] = [a,b,y_test.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWaPoTs-NqAF"
      },
      "outputs": [],
      "source": [
        "ks = np.arange(0, 1, 0.05)\n",
        "backtest_returns = pd.DataFrame(columns = ks)\n",
        "\n",
        "for date in daterange:  \n",
        "  print(date)\n",
        "  prob = parameters.loc[date]['prob']\n",
        "  rets = []\n",
        "  for k in ks:\n",
        "    weight = calculate_ml_portfolio_weights(prob, k)\n",
        "    rets.append(get_backtest_return(date, weight))\n",
        "  backtest_returns.loc[date] = rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QJznmoa50iU"
      },
      "outputs": [],
      "source": [
        "backtest_mean = backtest_returns.mean()\n",
        "backtest_var = backtest_returns.var()\n",
        "print(backtest_mean)\n",
        "print(backtest_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy0n-yp8SPt5"
      },
      "outputs": [],
      "source": [
        "NoPoints = len(backtest_mean)\n",
        "\n",
        "colours = \"red\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for ML Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter( np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aPJVsE3U1u"
      },
      "source": [
        "### MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_mv_dataset_for_date(date(2023,1,1))\n",
        "r, cov = get_sample_return_and_covariance(dataset)"
      ],
      "metadata": {
        "id": "HQdOY59TvGDj"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a4N3uUyzyz",
        "outputId": "582b6172-730f-430c-dae4-cd8722bbba93"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "metadata": {},
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r)\n",
        "print(cov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfgBvPuDzNXt",
        "outputId": "21752377-cfdd-4a31-bca5-4e37c704147f"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l_Close   -0.149595\n",
            "h_Close   -0.148826\n",
            "dtype: float64\n",
            "          l_Close   h_Close\n",
            "l_Close  0.010103  0.004556\n",
            "h_Close  0.004556  0.057944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_markovitz_weights(r, cov, m):\n",
        "  r = r.to_numpy()\n",
        "  cov = cov.to_numpy()\n",
        "  cov_inv = np.linalg.inv(cov)\n",
        "  ones = [1,1]\n",
        "  a = np.matmul(np.matmul(r, cov_inv), ones)\n",
        "  b = np.matmul(np.matmul(r, cov_inv), r)\n",
        "  c = np.matmul(np.matmul(ones, cov_inv), ones)\n",
        "  # print(r, cov, cov_inv,a,b,c)\n",
        "  numerator = b * np.matmul(cov_inv, ones) - a * np.matmul(cov_inv, r)  + m * (c * np.matmul(cov_inv, r) - a * np.matmul(cov_inv, ones))\n",
        "  denominator = b*c-pow(a,2)\n",
        "  x =  numerator / denominator\n",
        "  # print(numerator,denominator,x)\n",
        "  #/ (b*c-a^2) \n",
        "  return x"
      ],
      "metadata": {
        "id": "f5jaNAq8t8NN"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = calculate_markovitz_weights(r , cov , 0.01)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zcZVqWVvdki",
        "outputId": "53161a89-68f5-4b01-c6e0-76f0b228fa3b"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-206.6925489,  207.6925489])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ms = np.arange(0.02, 0.11, 0.005)\n",
        "ms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x9YHqcv5NDA",
        "outputId": "d4f0dd20-ce10-41c2-ea00-5e5a236f8f71"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02 , 0.025, 0.03 , 0.035, 0.04 , 0.045, 0.05 , 0.055, 0.06 ,\n",
              "       0.065, 0.07 , 0.075, 0.08 , 0.085, 0.09 , 0.095, 0.1  , 0.105])"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_weight_for_constraint(weight):\n",
        "  if weight < 0:\n",
        "    return 0\n",
        "  if weight > 1:\n",
        "    return 1\n",
        "  return weight"
      ],
      "metadata": {
        "id": "-mrSWBmGFGFJ"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XevciqKG3aJ0",
        "outputId": "58feac93-75be-43a1-f583-74d7b21e71c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "mv_backtest_weights = pd.DataFrame(columns = ms)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  weights = []\n",
        "  rets = []\n",
        "  for m in ms:\n",
        "    weight = calculate_markovitz_weights(r, cov, m)\n",
        "    high_risk_weight = weight[1]\n",
        "    # ret = get_mv_backtest_return(date, high_risk_weight)\n",
        "    weights.append(high_risk_weight)\n",
        "    # rets.append(ret)\n",
        "  mv_backtest_weights.loc[date] = weights\n",
        "  # mv_backtest_returns.loc[date] = rets\n",
        "  # print(weights)\n",
        "  # print(rets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_weights.tail(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7E6vrK_UBmkZ",
        "outputId": "03c99339-d828-434e-b54c-7d7982772a88"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0.020       0.025       0.030       0.035       0.040  \\\n",
              "2022-01-23    0.374714    0.404953    0.435192    0.465431    0.495671   \n",
              "2022-01-30    0.344008    0.374308    0.404608    0.434908    0.465208   \n",
              "2022-02-06    0.317395    0.342211    0.367028    0.391844    0.416661   \n",
              "2022-02-13    0.339591    0.369028    0.398466    0.427903    0.457340   \n",
              "2022-02-20    0.266657    0.297640    0.328623    0.359607    0.390590   \n",
              "2022-02-27    0.344608    0.381462    0.418316    0.455171    0.492025   \n",
              "2022-03-06    0.202566    0.248964    0.295363    0.341761    0.388159   \n",
              "2022-03-13    0.455537    0.509958    0.564378    0.618799    0.673220   \n",
              "2022-03-20    0.400948    0.438025    0.475101    0.512178    0.549255   \n",
              "2022-03-27    0.499691    0.528662    0.557632    0.586602    0.615573   \n",
              "2022-04-03    0.524433    0.554783    0.585133    0.615483    0.645833   \n",
              "2022-04-10    0.648881    0.677833    0.706785    0.735738    0.764690   \n",
              "2022-04-17    0.757388    0.789918    0.822448    0.854977    0.887507   \n",
              "2022-04-24    0.918149    0.955027    0.991906    1.028784    1.065662   \n",
              "2022-05-01    1.148111    1.195238    1.242364    1.289490    1.336616   \n",
              "2022-05-08    1.216421    1.259524    1.302628    1.345732    1.388836   \n",
              "2022-05-15    1.640166    1.705314    1.770463    1.835611    1.900759   \n",
              "2022-05-22    3.618716    3.773119    3.927522    4.081925    4.236327   \n",
              "2022-05-29    1.306851    1.362877    1.418903    1.474930    1.530956   \n",
              "2022-06-05    1.268296    1.315672    1.363049    1.410425    1.457801   \n",
              "2022-06-12    2.661445    2.748678    2.835911    2.923144    3.010377   \n",
              "2022-06-19  -54.417880  -56.045379  -57.672879  -59.300378  -60.927878   \n",
              "2022-06-26    3.679229    3.796011    3.912792    4.029574    4.146356   \n",
              "2022-07-03    3.643590    3.764457    3.885324    4.006190    4.127057   \n",
              "2022-07-10    4.793202    4.942213    5.091225    5.240236    5.389248   \n",
              "2022-07-17    5.477191    5.651596    5.826001    6.000406    6.174811   \n",
              "2022-07-24    7.158097    7.431453    7.704809    7.978165    8.251521   \n",
              "2022-07-31    2.721358    2.827698    2.934039    3.040380    3.146720   \n",
              "2022-08-07    2.189878    2.266162    2.342445    2.418729    2.495013   \n",
              "2022-08-14    1.660999    1.719785    1.778572    1.837359    1.896145   \n",
              "2022-08-21    1.833811    1.896865    1.959918    2.022971    2.086025   \n",
              "2022-08-28    2.618164    2.703163    2.788162    2.873161    2.958160   \n",
              "2022-09-04    2.427806    2.499480    2.571154    2.642828    2.714502   \n",
              "2022-09-11    2.036211    2.098618    2.161025    2.223432    2.285840   \n",
              "2022-09-18    2.464046    2.534867    2.605688    2.676508    2.747329   \n",
              "2022-09-25   10.475023   10.763755   11.052488   11.341220   11.629952   \n",
              "2022-10-02   -6.430591   -6.597965   -6.765340   -6.932715   -7.100090   \n",
              "2022-10-09   -7.432313   -7.620779   -7.809245   -7.997711   -8.186176   \n",
              "2022-10-16   -5.801838   -5.939338   -6.076837   -6.214337   -6.351837   \n",
              "2022-10-23   25.814793   26.378419   26.942046   27.505673   28.069300   \n",
              "2022-10-30    8.413185    8.621773    8.830360    9.038947    9.247535   \n",
              "2022-11-06   45.344827   46.396861   47.448894   48.500928   49.552962   \n",
              "2022-11-13    3.760330    3.855218    3.950106    4.044994    4.139882   \n",
              "2022-11-20    3.231004    3.310999    3.390993    3.470988    3.550983   \n",
              "2022-11-27    3.704208    3.800312    3.896416    3.992521    4.088625   \n",
              "2022-12-04    2.423418    2.491991    2.560564    2.629137    2.697711   \n",
              "2022-12-11  -31.426200  -32.297871  -33.169543  -34.041214  -34.912885   \n",
              "2022-12-18   -3.059969   -3.155603   -3.251236   -3.346869   -3.442503   \n",
              "2022-12-25   -8.892108   -9.156374   -9.420640   -9.684907   -9.949173   \n",
              "2023-01-01  220.706286  227.213155  233.720023  240.226892  246.733761   \n",
              "\n",
              "                 0.045       0.050       0.055       0.060       0.065  \\\n",
              "2022-01-23    0.525910    0.556149    0.586388    0.616627    0.646866   \n",
              "2022-01-30    0.495508    0.525808    0.556108    0.586408    0.616708   \n",
              "2022-02-06    0.441477    0.466293    0.491110    0.515926    0.540742   \n",
              "2022-02-13    0.486778    0.516215    0.545653    0.575090    0.604528   \n",
              "2022-02-20    0.421573    0.452557    0.483540    0.514523    0.545507   \n",
              "2022-02-27    0.528879    0.565733    0.602588    0.639442    0.676296   \n",
              "2022-03-06    0.434557    0.480955    0.527354    0.573752    0.620150   \n",
              "2022-03-13    0.727641    0.782062    0.836482    0.890903    0.945324   \n",
              "2022-03-20    0.586332    0.623409    0.660485    0.697562    0.734639   \n",
              "2022-03-27    0.644543    0.673513    0.702483    0.731454    0.760424   \n",
              "2022-04-03    0.676183    0.706533    0.736883    0.767233    0.797583   \n",
              "2022-04-10    0.793642    0.822594    0.851546    0.880499    0.909451   \n",
              "2022-04-17    0.920037    0.952567    0.985096    1.017626    1.050156   \n",
              "2022-04-24    1.102540    1.139418    1.176296    1.213175    1.250053   \n",
              "2022-05-01    1.383742    1.430868    1.477994    1.525121    1.572247   \n",
              "2022-05-08    1.431940    1.475044    1.518148    1.561252    1.604356   \n",
              "2022-05-15    1.965907    2.031056    2.096204    2.161352    2.226501   \n",
              "2022-05-22    4.390730    4.545133    4.699536    4.853938    5.008341   \n",
              "2022-05-29    1.586982    1.643008    1.699035    1.755061    1.811087   \n",
              "2022-06-05    1.505177    1.552553    1.599929    1.647305    1.694682   \n",
              "2022-06-12    3.097610    3.184842    3.272075    3.359308    3.446541   \n",
              "2022-06-19  -62.555377  -64.182876  -65.810376  -67.437875  -69.065374   \n",
              "2022-06-26    4.263138    4.379920    4.496702    4.613483    4.730265   \n",
              "2022-07-03    4.247924    4.368791    4.489657    4.610524    4.731391   \n",
              "2022-07-10    5.538260    5.687271    5.836283    5.985294    6.134306   \n",
              "2022-07-17    6.349216    6.523621    6.698027    6.872432    7.046837   \n",
              "2022-07-24    8.524878    8.798234    9.071590    9.344946    9.618302   \n",
              "2022-07-31    3.253061    3.359402    3.465742    3.572083    3.678424   \n",
              "2022-08-07    2.571296    2.647580    2.723864    2.800147    2.876431   \n",
              "2022-08-14    1.954932    2.013719    2.072506    2.131292    2.190079   \n",
              "2022-08-21    2.149078    2.212131    2.275185    2.338238    2.401291   \n",
              "2022-08-28    3.043159    3.128158    3.213157    3.298156    3.383155   \n",
              "2022-09-04    2.786176    2.857850    2.929523    3.001197    3.072871   \n",
              "2022-09-11    2.348247    2.410654    2.473061    2.535469    2.597876   \n",
              "2022-09-18    2.818150    2.888971    2.959792    3.030613    3.101434   \n",
              "2022-09-25   11.918684   12.207416   12.496148   12.784880   13.073613   \n",
              "2022-10-02   -7.267464   -7.434839   -7.602214   -7.769589   -7.936963   \n",
              "2022-10-09   -8.374642   -8.563108   -8.751574   -8.940040   -9.128505   \n",
              "2022-10-16   -6.489337   -6.626837   -6.764336   -6.901836   -7.039336   \n",
              "2022-10-23   28.632927   29.196554   29.760180   30.323807   30.887434   \n",
              "2022-10-30    9.456122    9.664709    9.873297   10.081884   10.290471   \n",
              "2022-11-06   50.604996   51.657029   52.709063   53.761097   54.813131   \n",
              "2022-11-13    4.234770    4.329658    4.424546    4.519433    4.614321   \n",
              "2022-11-20    3.630978    3.710973    3.790967    3.870962    3.950957   \n",
              "2022-11-27    4.184729    4.280833    4.376937    4.473041    4.569146   \n",
              "2022-12-04    2.766284    2.834857    2.903430    2.972003    3.040576   \n",
              "2022-12-11  -35.784556  -36.656228  -37.527899  -38.399570  -39.271241   \n",
              "2022-12-18   -3.538136   -3.633770   -3.729403   -3.825036   -3.920670   \n",
              "2022-12-25  -10.213439  -10.477705  -10.741971  -11.006237  -11.270503   \n",
              "2023-01-01  253.240629  259.747498  266.254366  272.761235  279.268104   \n",
              "\n",
              "                 0.070       0.075       0.080       0.085       0.090  \\\n",
              "2022-01-23    0.677106    0.707345    0.737584    0.767823    0.798062   \n",
              "2022-01-30    0.647009    0.677309    0.707609    0.737909    0.768209   \n",
              "2022-02-06    0.565559    0.590375    0.615192    0.640008    0.664824   \n",
              "2022-02-13    0.633965    0.663403    0.692840    0.722278    0.751715   \n",
              "2022-02-20    0.576490    0.607474    0.638457    0.669440    0.700424   \n",
              "2022-02-27    0.713150    0.750005    0.786859    0.823713    0.860568   \n",
              "2022-03-06    0.666548    0.712947    0.759345    0.805743    0.852141   \n",
              "2022-03-13    0.999745    1.054166    1.108586    1.163007    1.217428   \n",
              "2022-03-20    0.771716    0.808792    0.845869    0.882946    0.920023   \n",
              "2022-03-27    0.789394    0.818365    0.847335    0.876305    0.905275   \n",
              "2022-04-03    0.827933    0.858283    0.888633    0.918983    0.949333   \n",
              "2022-04-10    0.938403    0.967355    0.996307    1.025259    1.054212   \n",
              "2022-04-17    1.082686    1.115215    1.147745    1.180275    1.212804   \n",
              "2022-04-24    1.286931    1.323809    1.360687    1.397566    1.434444   \n",
              "2022-05-01    1.619373    1.666499    1.713625    1.760751    1.807877   \n",
              "2022-05-08    1.647460    1.690564    1.733667    1.776771    1.819875   \n",
              "2022-05-15    2.291649    2.356797    2.421946    2.487094    2.552242   \n",
              "2022-05-22    5.162744    5.317147    5.471549    5.625952    5.780355   \n",
              "2022-05-29    1.867113    1.923140    1.979166    2.035192    2.091218   \n",
              "2022-06-05    1.742058    1.789434    1.836810    1.884186    1.931562   \n",
              "2022-06-12    3.533774    3.621007    3.708240    3.795473    3.882706   \n",
              "2022-06-19  -70.692874  -72.320373  -73.947873  -75.575372  -77.202871   \n",
              "2022-06-26    4.847047    4.963829    5.080611    5.197393    5.314175   \n",
              "2022-07-03    4.852258    4.973124    5.093991    5.214858    5.335725   \n",
              "2022-07-10    6.283317    6.432329    6.581341    6.730352    6.879364   \n",
              "2022-07-17    7.221242    7.395647    7.570052    7.744457    7.918862   \n",
              "2022-07-24    9.891658   10.165014   10.438371   10.711727   10.985083   \n",
              "2022-07-31    3.784764    3.891105    3.997445    4.103786    4.210127   \n",
              "2022-08-07    2.952715    3.028998    3.105282    3.181566    3.257850   \n",
              "2022-08-14    2.248866    2.307652    2.366439    2.425226    2.484012   \n",
              "2022-08-21    2.464345    2.527398    2.590451    2.653505    2.716558   \n",
              "2022-08-28    3.468154    3.553154    3.638153    3.723152    3.808151   \n",
              "2022-09-04    3.144545    3.216219    3.287893    3.359567    3.431241   \n",
              "2022-09-11    2.660283    2.722690    2.785098    2.847505    2.909912   \n",
              "2022-09-18    3.172254    3.243075    3.313896    3.384717    3.455538   \n",
              "2022-09-25   13.362345   13.651077   13.939809   14.228541   14.517273   \n",
              "2022-10-02   -8.104338   -8.271713   -8.439088   -8.606462   -8.773837   \n",
              "2022-10-09   -9.316971   -9.505437   -9.693903   -9.882369  -10.070834   \n",
              "2022-10-16   -7.176836   -7.314336   -7.451835   -7.589335   -7.726835   \n",
              "2022-10-23   31.451061   32.014688   32.578315   33.141941   33.705568   \n",
              "2022-10-30   10.499059   10.707646   10.916233   11.124821   11.333408   \n",
              "2022-11-06   55.865165   56.917198   57.969232   59.021266   60.073300   \n",
              "2022-11-13    4.709209    4.804097    4.898985    4.993873    5.088761   \n",
              "2022-11-20    4.030952    4.110947    4.190942    4.270936    4.350931   \n",
              "2022-11-27    4.665250    4.761354    4.857458    4.953562    5.049666   \n",
              "2022-12-04    3.109149    3.177722    3.246295    3.314868    3.383441   \n",
              "2022-12-11  -40.142913  -41.014584  -41.886255  -42.757926  -43.629597   \n",
              "2022-12-18   -4.016303   -4.111937   -4.207570   -4.303204   -4.398837   \n",
              "2022-12-25  -11.534769  -11.799036  -12.063302  -12.327568  -12.591834   \n",
              "2023-01-01  285.774972  292.281841  298.788709  305.295578  311.802447   \n",
              "\n",
              "                 0.095       0.100       0.105  \n",
              "2022-01-23    0.828301    0.858540    0.888780  \n",
              "2022-01-30    0.798509    0.828809    0.859109  \n",
              "2022-02-06    0.689641    0.714457    0.739274  \n",
              "2022-02-13    0.781153    0.810590    0.840028  \n",
              "2022-02-20    0.731407    0.762390    0.793374  \n",
              "2022-02-27    0.897422    0.934276    0.971130  \n",
              "2022-03-06    0.898539    0.944938    0.991336  \n",
              "2022-03-13    1.271849    1.326270    1.380690  \n",
              "2022-03-20    0.957099    0.994176    1.031253  \n",
              "2022-03-27    0.934246    0.963216    0.992186  \n",
              "2022-04-03    0.979683    1.010033    1.040383  \n",
              "2022-04-10    1.083164    1.112116    1.141068  \n",
              "2022-04-17    1.245334    1.277864    1.310394  \n",
              "2022-04-24    1.471322    1.508200    1.545078  \n",
              "2022-05-01    1.855004    1.902130    1.949256  \n",
              "2022-05-08    1.862979    1.906083    1.949187  \n",
              "2022-05-15    2.617390    2.682539    2.747687  \n",
              "2022-05-22    5.934758    6.089161    6.243563  \n",
              "2022-05-29    2.147245    2.203271    2.259297  \n",
              "2022-06-05    1.978938    2.026315    2.073691  \n",
              "2022-06-12    3.969939    4.057172    4.144405  \n",
              "2022-06-19  -78.830371  -80.457870  -82.085370  \n",
              "2022-06-26    5.430956    5.547738    5.664520  \n",
              "2022-07-03    5.456592    5.577458    5.698325  \n",
              "2022-07-10    7.028375    7.177387    7.326398  \n",
              "2022-07-17    8.093267    8.267672    8.442077  \n",
              "2022-07-24   11.258439   11.531795   11.805151  \n",
              "2022-07-31    4.316467    4.422808    4.529149  \n",
              "2022-08-07    3.334133    3.410417    3.486701  \n",
              "2022-08-14    2.542799    2.601586    2.660373  \n",
              "2022-08-21    2.779611    2.842665    2.905718  \n",
              "2022-08-28    3.893150    3.978149    4.063148  \n",
              "2022-09-04    3.502914    3.574588    3.646262  \n",
              "2022-09-11    2.972319    3.034726    3.097134  \n",
              "2022-09-18    3.526359    3.597180    3.668001  \n",
              "2022-09-25   14.806005   15.094737   15.383470  \n",
              "2022-10-02   -8.941212   -9.108586   -9.275961  \n",
              "2022-10-09  -10.259300  -10.447766  -10.636232  \n",
              "2022-10-16   -7.864335   -8.001835   -8.139334  \n",
              "2022-10-23   34.269195   34.832822   35.396449  \n",
              "2022-10-30   11.541995   11.750583   11.959170  \n",
              "2022-11-06   61.125333   62.177367   63.229401  \n",
              "2022-11-13    5.183649    5.278537    5.373424  \n",
              "2022-11-20    4.430926    4.510921    4.590916  \n",
              "2022-11-27    5.145770    5.241875    5.337979  \n",
              "2022-12-04    3.452014    3.520587    3.589160  \n",
              "2022-12-11  -44.501269  -45.372940  -46.244611  \n",
              "2022-12-18   -4.494470   -4.590104   -4.685737  \n",
              "2022-12-25  -12.856100  -13.120366  -13.384632  \n",
              "2023-01-01  318.309315  324.816184  331.323052  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfa0940c-b1c1-4d56-b6f7-d98b11fb86aa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.020</th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.030</th>\n",
              "      <th>0.035</th>\n",
              "      <th>0.040</th>\n",
              "      <th>0.045</th>\n",
              "      <th>0.050</th>\n",
              "      <th>0.055</th>\n",
              "      <th>0.060</th>\n",
              "      <th>0.065</th>\n",
              "      <th>0.070</th>\n",
              "      <th>0.075</th>\n",
              "      <th>0.080</th>\n",
              "      <th>0.085</th>\n",
              "      <th>0.090</th>\n",
              "      <th>0.095</th>\n",
              "      <th>0.100</th>\n",
              "      <th>0.105</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-23</th>\n",
              "      <td>0.374714</td>\n",
              "      <td>0.404953</td>\n",
              "      <td>0.435192</td>\n",
              "      <td>0.465431</td>\n",
              "      <td>0.495671</td>\n",
              "      <td>0.525910</td>\n",
              "      <td>0.556149</td>\n",
              "      <td>0.586388</td>\n",
              "      <td>0.616627</td>\n",
              "      <td>0.646866</td>\n",
              "      <td>0.677106</td>\n",
              "      <td>0.707345</td>\n",
              "      <td>0.737584</td>\n",
              "      <td>0.767823</td>\n",
              "      <td>0.798062</td>\n",
              "      <td>0.828301</td>\n",
              "      <td>0.858540</td>\n",
              "      <td>0.888780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-30</th>\n",
              "      <td>0.344008</td>\n",
              "      <td>0.374308</td>\n",
              "      <td>0.404608</td>\n",
              "      <td>0.434908</td>\n",
              "      <td>0.465208</td>\n",
              "      <td>0.495508</td>\n",
              "      <td>0.525808</td>\n",
              "      <td>0.556108</td>\n",
              "      <td>0.586408</td>\n",
              "      <td>0.616708</td>\n",
              "      <td>0.647009</td>\n",
              "      <td>0.677309</td>\n",
              "      <td>0.707609</td>\n",
              "      <td>0.737909</td>\n",
              "      <td>0.768209</td>\n",
              "      <td>0.798509</td>\n",
              "      <td>0.828809</td>\n",
              "      <td>0.859109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-06</th>\n",
              "      <td>0.317395</td>\n",
              "      <td>0.342211</td>\n",
              "      <td>0.367028</td>\n",
              "      <td>0.391844</td>\n",
              "      <td>0.416661</td>\n",
              "      <td>0.441477</td>\n",
              "      <td>0.466293</td>\n",
              "      <td>0.491110</td>\n",
              "      <td>0.515926</td>\n",
              "      <td>0.540742</td>\n",
              "      <td>0.565559</td>\n",
              "      <td>0.590375</td>\n",
              "      <td>0.615192</td>\n",
              "      <td>0.640008</td>\n",
              "      <td>0.664824</td>\n",
              "      <td>0.689641</td>\n",
              "      <td>0.714457</td>\n",
              "      <td>0.739274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-13</th>\n",
              "      <td>0.339591</td>\n",
              "      <td>0.369028</td>\n",
              "      <td>0.398466</td>\n",
              "      <td>0.427903</td>\n",
              "      <td>0.457340</td>\n",
              "      <td>0.486778</td>\n",
              "      <td>0.516215</td>\n",
              "      <td>0.545653</td>\n",
              "      <td>0.575090</td>\n",
              "      <td>0.604528</td>\n",
              "      <td>0.633965</td>\n",
              "      <td>0.663403</td>\n",
              "      <td>0.692840</td>\n",
              "      <td>0.722278</td>\n",
              "      <td>0.751715</td>\n",
              "      <td>0.781153</td>\n",
              "      <td>0.810590</td>\n",
              "      <td>0.840028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-20</th>\n",
              "      <td>0.266657</td>\n",
              "      <td>0.297640</td>\n",
              "      <td>0.328623</td>\n",
              "      <td>0.359607</td>\n",
              "      <td>0.390590</td>\n",
              "      <td>0.421573</td>\n",
              "      <td>0.452557</td>\n",
              "      <td>0.483540</td>\n",
              "      <td>0.514523</td>\n",
              "      <td>0.545507</td>\n",
              "      <td>0.576490</td>\n",
              "      <td>0.607474</td>\n",
              "      <td>0.638457</td>\n",
              "      <td>0.669440</td>\n",
              "      <td>0.700424</td>\n",
              "      <td>0.731407</td>\n",
              "      <td>0.762390</td>\n",
              "      <td>0.793374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-02-27</th>\n",
              "      <td>0.344608</td>\n",
              "      <td>0.381462</td>\n",
              "      <td>0.418316</td>\n",
              "      <td>0.455171</td>\n",
              "      <td>0.492025</td>\n",
              "      <td>0.528879</td>\n",
              "      <td>0.565733</td>\n",
              "      <td>0.602588</td>\n",
              "      <td>0.639442</td>\n",
              "      <td>0.676296</td>\n",
              "      <td>0.713150</td>\n",
              "      <td>0.750005</td>\n",
              "      <td>0.786859</td>\n",
              "      <td>0.823713</td>\n",
              "      <td>0.860568</td>\n",
              "      <td>0.897422</td>\n",
              "      <td>0.934276</td>\n",
              "      <td>0.971130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-06</th>\n",
              "      <td>0.202566</td>\n",
              "      <td>0.248964</td>\n",
              "      <td>0.295363</td>\n",
              "      <td>0.341761</td>\n",
              "      <td>0.388159</td>\n",
              "      <td>0.434557</td>\n",
              "      <td>0.480955</td>\n",
              "      <td>0.527354</td>\n",
              "      <td>0.573752</td>\n",
              "      <td>0.620150</td>\n",
              "      <td>0.666548</td>\n",
              "      <td>0.712947</td>\n",
              "      <td>0.759345</td>\n",
              "      <td>0.805743</td>\n",
              "      <td>0.852141</td>\n",
              "      <td>0.898539</td>\n",
              "      <td>0.944938</td>\n",
              "      <td>0.991336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-13</th>\n",
              "      <td>0.455537</td>\n",
              "      <td>0.509958</td>\n",
              "      <td>0.564378</td>\n",
              "      <td>0.618799</td>\n",
              "      <td>0.673220</td>\n",
              "      <td>0.727641</td>\n",
              "      <td>0.782062</td>\n",
              "      <td>0.836482</td>\n",
              "      <td>0.890903</td>\n",
              "      <td>0.945324</td>\n",
              "      <td>0.999745</td>\n",
              "      <td>1.054166</td>\n",
              "      <td>1.108586</td>\n",
              "      <td>1.163007</td>\n",
              "      <td>1.217428</td>\n",
              "      <td>1.271849</td>\n",
              "      <td>1.326270</td>\n",
              "      <td>1.380690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-20</th>\n",
              "      <td>0.400948</td>\n",
              "      <td>0.438025</td>\n",
              "      <td>0.475101</td>\n",
              "      <td>0.512178</td>\n",
              "      <td>0.549255</td>\n",
              "      <td>0.586332</td>\n",
              "      <td>0.623409</td>\n",
              "      <td>0.660485</td>\n",
              "      <td>0.697562</td>\n",
              "      <td>0.734639</td>\n",
              "      <td>0.771716</td>\n",
              "      <td>0.808792</td>\n",
              "      <td>0.845869</td>\n",
              "      <td>0.882946</td>\n",
              "      <td>0.920023</td>\n",
              "      <td>0.957099</td>\n",
              "      <td>0.994176</td>\n",
              "      <td>1.031253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-03-27</th>\n",
              "      <td>0.499691</td>\n",
              "      <td>0.528662</td>\n",
              "      <td>0.557632</td>\n",
              "      <td>0.586602</td>\n",
              "      <td>0.615573</td>\n",
              "      <td>0.644543</td>\n",
              "      <td>0.673513</td>\n",
              "      <td>0.702483</td>\n",
              "      <td>0.731454</td>\n",
              "      <td>0.760424</td>\n",
              "      <td>0.789394</td>\n",
              "      <td>0.818365</td>\n",
              "      <td>0.847335</td>\n",
              "      <td>0.876305</td>\n",
              "      <td>0.905275</td>\n",
              "      <td>0.934246</td>\n",
              "      <td>0.963216</td>\n",
              "      <td>0.992186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-03</th>\n",
              "      <td>0.524433</td>\n",
              "      <td>0.554783</td>\n",
              "      <td>0.585133</td>\n",
              "      <td>0.615483</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.676183</td>\n",
              "      <td>0.706533</td>\n",
              "      <td>0.736883</td>\n",
              "      <td>0.767233</td>\n",
              "      <td>0.797583</td>\n",
              "      <td>0.827933</td>\n",
              "      <td>0.858283</td>\n",
              "      <td>0.888633</td>\n",
              "      <td>0.918983</td>\n",
              "      <td>0.949333</td>\n",
              "      <td>0.979683</td>\n",
              "      <td>1.010033</td>\n",
              "      <td>1.040383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-10</th>\n",
              "      <td>0.648881</td>\n",
              "      <td>0.677833</td>\n",
              "      <td>0.706785</td>\n",
              "      <td>0.735738</td>\n",
              "      <td>0.764690</td>\n",
              "      <td>0.793642</td>\n",
              "      <td>0.822594</td>\n",
              "      <td>0.851546</td>\n",
              "      <td>0.880499</td>\n",
              "      <td>0.909451</td>\n",
              "      <td>0.938403</td>\n",
              "      <td>0.967355</td>\n",
              "      <td>0.996307</td>\n",
              "      <td>1.025259</td>\n",
              "      <td>1.054212</td>\n",
              "      <td>1.083164</td>\n",
              "      <td>1.112116</td>\n",
              "      <td>1.141068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-17</th>\n",
              "      <td>0.757388</td>\n",
              "      <td>0.789918</td>\n",
              "      <td>0.822448</td>\n",
              "      <td>0.854977</td>\n",
              "      <td>0.887507</td>\n",
              "      <td>0.920037</td>\n",
              "      <td>0.952567</td>\n",
              "      <td>0.985096</td>\n",
              "      <td>1.017626</td>\n",
              "      <td>1.050156</td>\n",
              "      <td>1.082686</td>\n",
              "      <td>1.115215</td>\n",
              "      <td>1.147745</td>\n",
              "      <td>1.180275</td>\n",
              "      <td>1.212804</td>\n",
              "      <td>1.245334</td>\n",
              "      <td>1.277864</td>\n",
              "      <td>1.310394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-04-24</th>\n",
              "      <td>0.918149</td>\n",
              "      <td>0.955027</td>\n",
              "      <td>0.991906</td>\n",
              "      <td>1.028784</td>\n",
              "      <td>1.065662</td>\n",
              "      <td>1.102540</td>\n",
              "      <td>1.139418</td>\n",
              "      <td>1.176296</td>\n",
              "      <td>1.213175</td>\n",
              "      <td>1.250053</td>\n",
              "      <td>1.286931</td>\n",
              "      <td>1.323809</td>\n",
              "      <td>1.360687</td>\n",
              "      <td>1.397566</td>\n",
              "      <td>1.434444</td>\n",
              "      <td>1.471322</td>\n",
              "      <td>1.508200</td>\n",
              "      <td>1.545078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-01</th>\n",
              "      <td>1.148111</td>\n",
              "      <td>1.195238</td>\n",
              "      <td>1.242364</td>\n",
              "      <td>1.289490</td>\n",
              "      <td>1.336616</td>\n",
              "      <td>1.383742</td>\n",
              "      <td>1.430868</td>\n",
              "      <td>1.477994</td>\n",
              "      <td>1.525121</td>\n",
              "      <td>1.572247</td>\n",
              "      <td>1.619373</td>\n",
              "      <td>1.666499</td>\n",
              "      <td>1.713625</td>\n",
              "      <td>1.760751</td>\n",
              "      <td>1.807877</td>\n",
              "      <td>1.855004</td>\n",
              "      <td>1.902130</td>\n",
              "      <td>1.949256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-08</th>\n",
              "      <td>1.216421</td>\n",
              "      <td>1.259524</td>\n",
              "      <td>1.302628</td>\n",
              "      <td>1.345732</td>\n",
              "      <td>1.388836</td>\n",
              "      <td>1.431940</td>\n",
              "      <td>1.475044</td>\n",
              "      <td>1.518148</td>\n",
              "      <td>1.561252</td>\n",
              "      <td>1.604356</td>\n",
              "      <td>1.647460</td>\n",
              "      <td>1.690564</td>\n",
              "      <td>1.733667</td>\n",
              "      <td>1.776771</td>\n",
              "      <td>1.819875</td>\n",
              "      <td>1.862979</td>\n",
              "      <td>1.906083</td>\n",
              "      <td>1.949187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-15</th>\n",
              "      <td>1.640166</td>\n",
              "      <td>1.705314</td>\n",
              "      <td>1.770463</td>\n",
              "      <td>1.835611</td>\n",
              "      <td>1.900759</td>\n",
              "      <td>1.965907</td>\n",
              "      <td>2.031056</td>\n",
              "      <td>2.096204</td>\n",
              "      <td>2.161352</td>\n",
              "      <td>2.226501</td>\n",
              "      <td>2.291649</td>\n",
              "      <td>2.356797</td>\n",
              "      <td>2.421946</td>\n",
              "      <td>2.487094</td>\n",
              "      <td>2.552242</td>\n",
              "      <td>2.617390</td>\n",
              "      <td>2.682539</td>\n",
              "      <td>2.747687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-22</th>\n",
              "      <td>3.618716</td>\n",
              "      <td>3.773119</td>\n",
              "      <td>3.927522</td>\n",
              "      <td>4.081925</td>\n",
              "      <td>4.236327</td>\n",
              "      <td>4.390730</td>\n",
              "      <td>4.545133</td>\n",
              "      <td>4.699536</td>\n",
              "      <td>4.853938</td>\n",
              "      <td>5.008341</td>\n",
              "      <td>5.162744</td>\n",
              "      <td>5.317147</td>\n",
              "      <td>5.471549</td>\n",
              "      <td>5.625952</td>\n",
              "      <td>5.780355</td>\n",
              "      <td>5.934758</td>\n",
              "      <td>6.089161</td>\n",
              "      <td>6.243563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-05-29</th>\n",
              "      <td>1.306851</td>\n",
              "      <td>1.362877</td>\n",
              "      <td>1.418903</td>\n",
              "      <td>1.474930</td>\n",
              "      <td>1.530956</td>\n",
              "      <td>1.586982</td>\n",
              "      <td>1.643008</td>\n",
              "      <td>1.699035</td>\n",
              "      <td>1.755061</td>\n",
              "      <td>1.811087</td>\n",
              "      <td>1.867113</td>\n",
              "      <td>1.923140</td>\n",
              "      <td>1.979166</td>\n",
              "      <td>2.035192</td>\n",
              "      <td>2.091218</td>\n",
              "      <td>2.147245</td>\n",
              "      <td>2.203271</td>\n",
              "      <td>2.259297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-05</th>\n",
              "      <td>1.268296</td>\n",
              "      <td>1.315672</td>\n",
              "      <td>1.363049</td>\n",
              "      <td>1.410425</td>\n",
              "      <td>1.457801</td>\n",
              "      <td>1.505177</td>\n",
              "      <td>1.552553</td>\n",
              "      <td>1.599929</td>\n",
              "      <td>1.647305</td>\n",
              "      <td>1.694682</td>\n",
              "      <td>1.742058</td>\n",
              "      <td>1.789434</td>\n",
              "      <td>1.836810</td>\n",
              "      <td>1.884186</td>\n",
              "      <td>1.931562</td>\n",
              "      <td>1.978938</td>\n",
              "      <td>2.026315</td>\n",
              "      <td>2.073691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-12</th>\n",
              "      <td>2.661445</td>\n",
              "      <td>2.748678</td>\n",
              "      <td>2.835911</td>\n",
              "      <td>2.923144</td>\n",
              "      <td>3.010377</td>\n",
              "      <td>3.097610</td>\n",
              "      <td>3.184842</td>\n",
              "      <td>3.272075</td>\n",
              "      <td>3.359308</td>\n",
              "      <td>3.446541</td>\n",
              "      <td>3.533774</td>\n",
              "      <td>3.621007</td>\n",
              "      <td>3.708240</td>\n",
              "      <td>3.795473</td>\n",
              "      <td>3.882706</td>\n",
              "      <td>3.969939</td>\n",
              "      <td>4.057172</td>\n",
              "      <td>4.144405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-19</th>\n",
              "      <td>-54.417880</td>\n",
              "      <td>-56.045379</td>\n",
              "      <td>-57.672879</td>\n",
              "      <td>-59.300378</td>\n",
              "      <td>-60.927878</td>\n",
              "      <td>-62.555377</td>\n",
              "      <td>-64.182876</td>\n",
              "      <td>-65.810376</td>\n",
              "      <td>-67.437875</td>\n",
              "      <td>-69.065374</td>\n",
              "      <td>-70.692874</td>\n",
              "      <td>-72.320373</td>\n",
              "      <td>-73.947873</td>\n",
              "      <td>-75.575372</td>\n",
              "      <td>-77.202871</td>\n",
              "      <td>-78.830371</td>\n",
              "      <td>-80.457870</td>\n",
              "      <td>-82.085370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-06-26</th>\n",
              "      <td>3.679229</td>\n",
              "      <td>3.796011</td>\n",
              "      <td>3.912792</td>\n",
              "      <td>4.029574</td>\n",
              "      <td>4.146356</td>\n",
              "      <td>4.263138</td>\n",
              "      <td>4.379920</td>\n",
              "      <td>4.496702</td>\n",
              "      <td>4.613483</td>\n",
              "      <td>4.730265</td>\n",
              "      <td>4.847047</td>\n",
              "      <td>4.963829</td>\n",
              "      <td>5.080611</td>\n",
              "      <td>5.197393</td>\n",
              "      <td>5.314175</td>\n",
              "      <td>5.430956</td>\n",
              "      <td>5.547738</td>\n",
              "      <td>5.664520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-03</th>\n",
              "      <td>3.643590</td>\n",
              "      <td>3.764457</td>\n",
              "      <td>3.885324</td>\n",
              "      <td>4.006190</td>\n",
              "      <td>4.127057</td>\n",
              "      <td>4.247924</td>\n",
              "      <td>4.368791</td>\n",
              "      <td>4.489657</td>\n",
              "      <td>4.610524</td>\n",
              "      <td>4.731391</td>\n",
              "      <td>4.852258</td>\n",
              "      <td>4.973124</td>\n",
              "      <td>5.093991</td>\n",
              "      <td>5.214858</td>\n",
              "      <td>5.335725</td>\n",
              "      <td>5.456592</td>\n",
              "      <td>5.577458</td>\n",
              "      <td>5.698325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-10</th>\n",
              "      <td>4.793202</td>\n",
              "      <td>4.942213</td>\n",
              "      <td>5.091225</td>\n",
              "      <td>5.240236</td>\n",
              "      <td>5.389248</td>\n",
              "      <td>5.538260</td>\n",
              "      <td>5.687271</td>\n",
              "      <td>5.836283</td>\n",
              "      <td>5.985294</td>\n",
              "      <td>6.134306</td>\n",
              "      <td>6.283317</td>\n",
              "      <td>6.432329</td>\n",
              "      <td>6.581341</td>\n",
              "      <td>6.730352</td>\n",
              "      <td>6.879364</td>\n",
              "      <td>7.028375</td>\n",
              "      <td>7.177387</td>\n",
              "      <td>7.326398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-17</th>\n",
              "      <td>5.477191</td>\n",
              "      <td>5.651596</td>\n",
              "      <td>5.826001</td>\n",
              "      <td>6.000406</td>\n",
              "      <td>6.174811</td>\n",
              "      <td>6.349216</td>\n",
              "      <td>6.523621</td>\n",
              "      <td>6.698027</td>\n",
              "      <td>6.872432</td>\n",
              "      <td>7.046837</td>\n",
              "      <td>7.221242</td>\n",
              "      <td>7.395647</td>\n",
              "      <td>7.570052</td>\n",
              "      <td>7.744457</td>\n",
              "      <td>7.918862</td>\n",
              "      <td>8.093267</td>\n",
              "      <td>8.267672</td>\n",
              "      <td>8.442077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-24</th>\n",
              "      <td>7.158097</td>\n",
              "      <td>7.431453</td>\n",
              "      <td>7.704809</td>\n",
              "      <td>7.978165</td>\n",
              "      <td>8.251521</td>\n",
              "      <td>8.524878</td>\n",
              "      <td>8.798234</td>\n",
              "      <td>9.071590</td>\n",
              "      <td>9.344946</td>\n",
              "      <td>9.618302</td>\n",
              "      <td>9.891658</td>\n",
              "      <td>10.165014</td>\n",
              "      <td>10.438371</td>\n",
              "      <td>10.711727</td>\n",
              "      <td>10.985083</td>\n",
              "      <td>11.258439</td>\n",
              "      <td>11.531795</td>\n",
              "      <td>11.805151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-07-31</th>\n",
              "      <td>2.721358</td>\n",
              "      <td>2.827698</td>\n",
              "      <td>2.934039</td>\n",
              "      <td>3.040380</td>\n",
              "      <td>3.146720</td>\n",
              "      <td>3.253061</td>\n",
              "      <td>3.359402</td>\n",
              "      <td>3.465742</td>\n",
              "      <td>3.572083</td>\n",
              "      <td>3.678424</td>\n",
              "      <td>3.784764</td>\n",
              "      <td>3.891105</td>\n",
              "      <td>3.997445</td>\n",
              "      <td>4.103786</td>\n",
              "      <td>4.210127</td>\n",
              "      <td>4.316467</td>\n",
              "      <td>4.422808</td>\n",
              "      <td>4.529149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-07</th>\n",
              "      <td>2.189878</td>\n",
              "      <td>2.266162</td>\n",
              "      <td>2.342445</td>\n",
              "      <td>2.418729</td>\n",
              "      <td>2.495013</td>\n",
              "      <td>2.571296</td>\n",
              "      <td>2.647580</td>\n",
              "      <td>2.723864</td>\n",
              "      <td>2.800147</td>\n",
              "      <td>2.876431</td>\n",
              "      <td>2.952715</td>\n",
              "      <td>3.028998</td>\n",
              "      <td>3.105282</td>\n",
              "      <td>3.181566</td>\n",
              "      <td>3.257850</td>\n",
              "      <td>3.334133</td>\n",
              "      <td>3.410417</td>\n",
              "      <td>3.486701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-14</th>\n",
              "      <td>1.660999</td>\n",
              "      <td>1.719785</td>\n",
              "      <td>1.778572</td>\n",
              "      <td>1.837359</td>\n",
              "      <td>1.896145</td>\n",
              "      <td>1.954932</td>\n",
              "      <td>2.013719</td>\n",
              "      <td>2.072506</td>\n",
              "      <td>2.131292</td>\n",
              "      <td>2.190079</td>\n",
              "      <td>2.248866</td>\n",
              "      <td>2.307652</td>\n",
              "      <td>2.366439</td>\n",
              "      <td>2.425226</td>\n",
              "      <td>2.484012</td>\n",
              "      <td>2.542799</td>\n",
              "      <td>2.601586</td>\n",
              "      <td>2.660373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-21</th>\n",
              "      <td>1.833811</td>\n",
              "      <td>1.896865</td>\n",
              "      <td>1.959918</td>\n",
              "      <td>2.022971</td>\n",
              "      <td>2.086025</td>\n",
              "      <td>2.149078</td>\n",
              "      <td>2.212131</td>\n",
              "      <td>2.275185</td>\n",
              "      <td>2.338238</td>\n",
              "      <td>2.401291</td>\n",
              "      <td>2.464345</td>\n",
              "      <td>2.527398</td>\n",
              "      <td>2.590451</td>\n",
              "      <td>2.653505</td>\n",
              "      <td>2.716558</td>\n",
              "      <td>2.779611</td>\n",
              "      <td>2.842665</td>\n",
              "      <td>2.905718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-28</th>\n",
              "      <td>2.618164</td>\n",
              "      <td>2.703163</td>\n",
              "      <td>2.788162</td>\n",
              "      <td>2.873161</td>\n",
              "      <td>2.958160</td>\n",
              "      <td>3.043159</td>\n",
              "      <td>3.128158</td>\n",
              "      <td>3.213157</td>\n",
              "      <td>3.298156</td>\n",
              "      <td>3.383155</td>\n",
              "      <td>3.468154</td>\n",
              "      <td>3.553154</td>\n",
              "      <td>3.638153</td>\n",
              "      <td>3.723152</td>\n",
              "      <td>3.808151</td>\n",
              "      <td>3.893150</td>\n",
              "      <td>3.978149</td>\n",
              "      <td>4.063148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-04</th>\n",
              "      <td>2.427806</td>\n",
              "      <td>2.499480</td>\n",
              "      <td>2.571154</td>\n",
              "      <td>2.642828</td>\n",
              "      <td>2.714502</td>\n",
              "      <td>2.786176</td>\n",
              "      <td>2.857850</td>\n",
              "      <td>2.929523</td>\n",
              "      <td>3.001197</td>\n",
              "      <td>3.072871</td>\n",
              "      <td>3.144545</td>\n",
              "      <td>3.216219</td>\n",
              "      <td>3.287893</td>\n",
              "      <td>3.359567</td>\n",
              "      <td>3.431241</td>\n",
              "      <td>3.502914</td>\n",
              "      <td>3.574588</td>\n",
              "      <td>3.646262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-11</th>\n",
              "      <td>2.036211</td>\n",
              "      <td>2.098618</td>\n",
              "      <td>2.161025</td>\n",
              "      <td>2.223432</td>\n",
              "      <td>2.285840</td>\n",
              "      <td>2.348247</td>\n",
              "      <td>2.410654</td>\n",
              "      <td>2.473061</td>\n",
              "      <td>2.535469</td>\n",
              "      <td>2.597876</td>\n",
              "      <td>2.660283</td>\n",
              "      <td>2.722690</td>\n",
              "      <td>2.785098</td>\n",
              "      <td>2.847505</td>\n",
              "      <td>2.909912</td>\n",
              "      <td>2.972319</td>\n",
              "      <td>3.034726</td>\n",
              "      <td>3.097134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-18</th>\n",
              "      <td>2.464046</td>\n",
              "      <td>2.534867</td>\n",
              "      <td>2.605688</td>\n",
              "      <td>2.676508</td>\n",
              "      <td>2.747329</td>\n",
              "      <td>2.818150</td>\n",
              "      <td>2.888971</td>\n",
              "      <td>2.959792</td>\n",
              "      <td>3.030613</td>\n",
              "      <td>3.101434</td>\n",
              "      <td>3.172254</td>\n",
              "      <td>3.243075</td>\n",
              "      <td>3.313896</td>\n",
              "      <td>3.384717</td>\n",
              "      <td>3.455538</td>\n",
              "      <td>3.526359</td>\n",
              "      <td>3.597180</td>\n",
              "      <td>3.668001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-09-25</th>\n",
              "      <td>10.475023</td>\n",
              "      <td>10.763755</td>\n",
              "      <td>11.052488</td>\n",
              "      <td>11.341220</td>\n",
              "      <td>11.629952</td>\n",
              "      <td>11.918684</td>\n",
              "      <td>12.207416</td>\n",
              "      <td>12.496148</td>\n",
              "      <td>12.784880</td>\n",
              "      <td>13.073613</td>\n",
              "      <td>13.362345</td>\n",
              "      <td>13.651077</td>\n",
              "      <td>13.939809</td>\n",
              "      <td>14.228541</td>\n",
              "      <td>14.517273</td>\n",
              "      <td>14.806005</td>\n",
              "      <td>15.094737</td>\n",
              "      <td>15.383470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-02</th>\n",
              "      <td>-6.430591</td>\n",
              "      <td>-6.597965</td>\n",
              "      <td>-6.765340</td>\n",
              "      <td>-6.932715</td>\n",
              "      <td>-7.100090</td>\n",
              "      <td>-7.267464</td>\n",
              "      <td>-7.434839</td>\n",
              "      <td>-7.602214</td>\n",
              "      <td>-7.769589</td>\n",
              "      <td>-7.936963</td>\n",
              "      <td>-8.104338</td>\n",
              "      <td>-8.271713</td>\n",
              "      <td>-8.439088</td>\n",
              "      <td>-8.606462</td>\n",
              "      <td>-8.773837</td>\n",
              "      <td>-8.941212</td>\n",
              "      <td>-9.108586</td>\n",
              "      <td>-9.275961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-09</th>\n",
              "      <td>-7.432313</td>\n",
              "      <td>-7.620779</td>\n",
              "      <td>-7.809245</td>\n",
              "      <td>-7.997711</td>\n",
              "      <td>-8.186176</td>\n",
              "      <td>-8.374642</td>\n",
              "      <td>-8.563108</td>\n",
              "      <td>-8.751574</td>\n",
              "      <td>-8.940040</td>\n",
              "      <td>-9.128505</td>\n",
              "      <td>-9.316971</td>\n",
              "      <td>-9.505437</td>\n",
              "      <td>-9.693903</td>\n",
              "      <td>-9.882369</td>\n",
              "      <td>-10.070834</td>\n",
              "      <td>-10.259300</td>\n",
              "      <td>-10.447766</td>\n",
              "      <td>-10.636232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-16</th>\n",
              "      <td>-5.801838</td>\n",
              "      <td>-5.939338</td>\n",
              "      <td>-6.076837</td>\n",
              "      <td>-6.214337</td>\n",
              "      <td>-6.351837</td>\n",
              "      <td>-6.489337</td>\n",
              "      <td>-6.626837</td>\n",
              "      <td>-6.764336</td>\n",
              "      <td>-6.901836</td>\n",
              "      <td>-7.039336</td>\n",
              "      <td>-7.176836</td>\n",
              "      <td>-7.314336</td>\n",
              "      <td>-7.451835</td>\n",
              "      <td>-7.589335</td>\n",
              "      <td>-7.726835</td>\n",
              "      <td>-7.864335</td>\n",
              "      <td>-8.001835</td>\n",
              "      <td>-8.139334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-23</th>\n",
              "      <td>25.814793</td>\n",
              "      <td>26.378419</td>\n",
              "      <td>26.942046</td>\n",
              "      <td>27.505673</td>\n",
              "      <td>28.069300</td>\n",
              "      <td>28.632927</td>\n",
              "      <td>29.196554</td>\n",
              "      <td>29.760180</td>\n",
              "      <td>30.323807</td>\n",
              "      <td>30.887434</td>\n",
              "      <td>31.451061</td>\n",
              "      <td>32.014688</td>\n",
              "      <td>32.578315</td>\n",
              "      <td>33.141941</td>\n",
              "      <td>33.705568</td>\n",
              "      <td>34.269195</td>\n",
              "      <td>34.832822</td>\n",
              "      <td>35.396449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-10-30</th>\n",
              "      <td>8.413185</td>\n",
              "      <td>8.621773</td>\n",
              "      <td>8.830360</td>\n",
              "      <td>9.038947</td>\n",
              "      <td>9.247535</td>\n",
              "      <td>9.456122</td>\n",
              "      <td>9.664709</td>\n",
              "      <td>9.873297</td>\n",
              "      <td>10.081884</td>\n",
              "      <td>10.290471</td>\n",
              "      <td>10.499059</td>\n",
              "      <td>10.707646</td>\n",
              "      <td>10.916233</td>\n",
              "      <td>11.124821</td>\n",
              "      <td>11.333408</td>\n",
              "      <td>11.541995</td>\n",
              "      <td>11.750583</td>\n",
              "      <td>11.959170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-06</th>\n",
              "      <td>45.344827</td>\n",
              "      <td>46.396861</td>\n",
              "      <td>47.448894</td>\n",
              "      <td>48.500928</td>\n",
              "      <td>49.552962</td>\n",
              "      <td>50.604996</td>\n",
              "      <td>51.657029</td>\n",
              "      <td>52.709063</td>\n",
              "      <td>53.761097</td>\n",
              "      <td>54.813131</td>\n",
              "      <td>55.865165</td>\n",
              "      <td>56.917198</td>\n",
              "      <td>57.969232</td>\n",
              "      <td>59.021266</td>\n",
              "      <td>60.073300</td>\n",
              "      <td>61.125333</td>\n",
              "      <td>62.177367</td>\n",
              "      <td>63.229401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-13</th>\n",
              "      <td>3.760330</td>\n",
              "      <td>3.855218</td>\n",
              "      <td>3.950106</td>\n",
              "      <td>4.044994</td>\n",
              "      <td>4.139882</td>\n",
              "      <td>4.234770</td>\n",
              "      <td>4.329658</td>\n",
              "      <td>4.424546</td>\n",
              "      <td>4.519433</td>\n",
              "      <td>4.614321</td>\n",
              "      <td>4.709209</td>\n",
              "      <td>4.804097</td>\n",
              "      <td>4.898985</td>\n",
              "      <td>4.993873</td>\n",
              "      <td>5.088761</td>\n",
              "      <td>5.183649</td>\n",
              "      <td>5.278537</td>\n",
              "      <td>5.373424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-20</th>\n",
              "      <td>3.231004</td>\n",
              "      <td>3.310999</td>\n",
              "      <td>3.390993</td>\n",
              "      <td>3.470988</td>\n",
              "      <td>3.550983</td>\n",
              "      <td>3.630978</td>\n",
              "      <td>3.710973</td>\n",
              "      <td>3.790967</td>\n",
              "      <td>3.870962</td>\n",
              "      <td>3.950957</td>\n",
              "      <td>4.030952</td>\n",
              "      <td>4.110947</td>\n",
              "      <td>4.190942</td>\n",
              "      <td>4.270936</td>\n",
              "      <td>4.350931</td>\n",
              "      <td>4.430926</td>\n",
              "      <td>4.510921</td>\n",
              "      <td>4.590916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-11-27</th>\n",
              "      <td>3.704208</td>\n",
              "      <td>3.800312</td>\n",
              "      <td>3.896416</td>\n",
              "      <td>3.992521</td>\n",
              "      <td>4.088625</td>\n",
              "      <td>4.184729</td>\n",
              "      <td>4.280833</td>\n",
              "      <td>4.376937</td>\n",
              "      <td>4.473041</td>\n",
              "      <td>4.569146</td>\n",
              "      <td>4.665250</td>\n",
              "      <td>4.761354</td>\n",
              "      <td>4.857458</td>\n",
              "      <td>4.953562</td>\n",
              "      <td>5.049666</td>\n",
              "      <td>5.145770</td>\n",
              "      <td>5.241875</td>\n",
              "      <td>5.337979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-04</th>\n",
              "      <td>2.423418</td>\n",
              "      <td>2.491991</td>\n",
              "      <td>2.560564</td>\n",
              "      <td>2.629137</td>\n",
              "      <td>2.697711</td>\n",
              "      <td>2.766284</td>\n",
              "      <td>2.834857</td>\n",
              "      <td>2.903430</td>\n",
              "      <td>2.972003</td>\n",
              "      <td>3.040576</td>\n",
              "      <td>3.109149</td>\n",
              "      <td>3.177722</td>\n",
              "      <td>3.246295</td>\n",
              "      <td>3.314868</td>\n",
              "      <td>3.383441</td>\n",
              "      <td>3.452014</td>\n",
              "      <td>3.520587</td>\n",
              "      <td>3.589160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-11</th>\n",
              "      <td>-31.426200</td>\n",
              "      <td>-32.297871</td>\n",
              "      <td>-33.169543</td>\n",
              "      <td>-34.041214</td>\n",
              "      <td>-34.912885</td>\n",
              "      <td>-35.784556</td>\n",
              "      <td>-36.656228</td>\n",
              "      <td>-37.527899</td>\n",
              "      <td>-38.399570</td>\n",
              "      <td>-39.271241</td>\n",
              "      <td>-40.142913</td>\n",
              "      <td>-41.014584</td>\n",
              "      <td>-41.886255</td>\n",
              "      <td>-42.757926</td>\n",
              "      <td>-43.629597</td>\n",
              "      <td>-44.501269</td>\n",
              "      <td>-45.372940</td>\n",
              "      <td>-46.244611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-18</th>\n",
              "      <td>-3.059969</td>\n",
              "      <td>-3.155603</td>\n",
              "      <td>-3.251236</td>\n",
              "      <td>-3.346869</td>\n",
              "      <td>-3.442503</td>\n",
              "      <td>-3.538136</td>\n",
              "      <td>-3.633770</td>\n",
              "      <td>-3.729403</td>\n",
              "      <td>-3.825036</td>\n",
              "      <td>-3.920670</td>\n",
              "      <td>-4.016303</td>\n",
              "      <td>-4.111937</td>\n",
              "      <td>-4.207570</td>\n",
              "      <td>-4.303204</td>\n",
              "      <td>-4.398837</td>\n",
              "      <td>-4.494470</td>\n",
              "      <td>-4.590104</td>\n",
              "      <td>-4.685737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-25</th>\n",
              "      <td>-8.892108</td>\n",
              "      <td>-9.156374</td>\n",
              "      <td>-9.420640</td>\n",
              "      <td>-9.684907</td>\n",
              "      <td>-9.949173</td>\n",
              "      <td>-10.213439</td>\n",
              "      <td>-10.477705</td>\n",
              "      <td>-10.741971</td>\n",
              "      <td>-11.006237</td>\n",
              "      <td>-11.270503</td>\n",
              "      <td>-11.534769</td>\n",
              "      <td>-11.799036</td>\n",
              "      <td>-12.063302</td>\n",
              "      <td>-12.327568</td>\n",
              "      <td>-12.591834</td>\n",
              "      <td>-12.856100</td>\n",
              "      <td>-13.120366</td>\n",
              "      <td>-13.384632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-01</th>\n",
              "      <td>220.706286</td>\n",
              "      <td>227.213155</td>\n",
              "      <td>233.720023</td>\n",
              "      <td>240.226892</td>\n",
              "      <td>246.733761</td>\n",
              "      <td>253.240629</td>\n",
              "      <td>259.747498</td>\n",
              "      <td>266.254366</td>\n",
              "      <td>272.761235</td>\n",
              "      <td>279.268104</td>\n",
              "      <td>285.774972</td>\n",
              "      <td>292.281841</td>\n",
              "      <td>298.788709</td>\n",
              "      <td>305.295578</td>\n",
              "      <td>311.802447</td>\n",
              "      <td>318.309315</td>\n",
              "      <td>324.816184</td>\n",
              "      <td>331.323052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfa0940c-b1c1-4d56-b6f7-d98b11fb86aa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfa0940c-b1c1-4d56-b6f7-d98b11fb86aa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfa0940c-b1c1-4d56-b6f7-d98b11fb86aa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_returns = pd.DataFrame(columns = ms)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  rets=[]\n",
        "  for m in ms:\n",
        "    # weight = calculate_markovitz_weights(r, cov, m)\n",
        "    high_risk_weight = mv_backtest_weights.loc[date][m]\n",
        "    high_risk_weight = adjust_weight_for_constraint(high_risk_weight)\n",
        "    ret = get_mv_backtest_return(date, high_risk_weight)\n",
        "    # weights.append(high_risk_weight)\n",
        "    rets.append(ret)\n",
        "  # mv_backtest_weights.loc[date] = weights\n",
        "  # print(rets)\n",
        "  mv_backtest_returns.loc[date] = rets\n",
        "  # print(weights)\n",
        "  # print(rets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik4FkUSA_jO2",
        "outputId": "97ed394b-b5d6-4b5c-8558-667d23feb948"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_returns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S5MJbCKQ4wot",
        "outputId": "4e3e3262-34fe-4dee-cc79-ebbe0e7b4894"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0.020     0.025     0.030     0.035     0.040     0.045  \\\n",
              "2003-09-21  0.011303  0.010575  0.009847  0.009120  0.008392  0.007664   \n",
              "2003-09-28 -0.008934 -0.007733 -0.006533 -0.005332 -0.004131 -0.002931   \n",
              "2003-10-05  0.001279  0.001623  0.001967  0.002312  0.002656  0.003000   \n",
              "2003-10-12 -0.009832 -0.009649 -0.009467 -0.009284 -0.009102 -0.008919   \n",
              "2003-10-19  0.010236  0.009530  0.008823  0.008116  0.007410  0.006703   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414   \n",
              "2022-12-11  0.003154  0.003154  0.003154  0.003154  0.003154  0.003154   \n",
              "2022-12-18 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259   \n",
              "2022-12-25 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573   \n",
              "2023-01-01  0.009652  0.009652  0.009652  0.009652  0.009652  0.009652   \n",
              "\n",
              "               0.050     0.055     0.060     0.065     0.070     0.075  \\\n",
              "2003-09-21  0.006937  0.006209  0.005481  0.004753  0.004026  0.003298   \n",
              "2003-09-28 -0.001730 -0.000529  0.000671  0.001872  0.003073  0.004273   \n",
              "2003-10-05  0.003345  0.003689  0.004033  0.004378  0.004722  0.005066   \n",
              "2003-10-12 -0.008737 -0.008554 -0.008371 -0.008189 -0.008006 -0.007824   \n",
              "2003-10-19  0.005997  0.005290  0.004583  0.003877  0.003170  0.002464   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414   \n",
              "2022-12-11  0.003154  0.003154  0.003154  0.003154  0.003154  0.003154   \n",
              "2022-12-18 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259   \n",
              "2022-12-25 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573   \n",
              "2023-01-01  0.009652  0.009652  0.009652  0.009652  0.009652  0.009652   \n",
              "\n",
              "               0.080     0.085     0.090     0.095     0.100     0.105  \n",
              "2003-09-21  0.002570  0.001843  0.001115  0.000387 -0.000340 -0.001068  \n",
              "2003-09-28  0.005474  0.006675  0.007876  0.009076  0.010277  0.011478  \n",
              "2003-10-05  0.005410  0.005755  0.006099  0.006443  0.006788  0.007132  \n",
              "2003-10-12 -0.007641 -0.007459 -0.007276 -0.007093 -0.006911 -0.006728  \n",
              "2003-10-19  0.001757  0.001051  0.000344 -0.000363 -0.001069 -0.001776  \n",
              "...              ...       ...       ...       ...       ...       ...  \n",
              "2022-12-04 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414 -0.026414  \n",
              "2022-12-11  0.003154  0.003154  0.003154  0.003154  0.003154  0.003154  \n",
              "2022-12-18 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259 -0.013259  \n",
              "2022-12-25 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573 -0.004573  \n",
              "2023-01-01  0.009652  0.009652  0.009652  0.009652  0.009652  0.009652  \n",
              "\n",
              "[1007 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d56574ea-a910-45c4-91e7-6d54855b6e98\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.020</th>\n",
              "      <th>0.025</th>\n",
              "      <th>0.030</th>\n",
              "      <th>0.035</th>\n",
              "      <th>0.040</th>\n",
              "      <th>0.045</th>\n",
              "      <th>0.050</th>\n",
              "      <th>0.055</th>\n",
              "      <th>0.060</th>\n",
              "      <th>0.065</th>\n",
              "      <th>0.070</th>\n",
              "      <th>0.075</th>\n",
              "      <th>0.080</th>\n",
              "      <th>0.085</th>\n",
              "      <th>0.090</th>\n",
              "      <th>0.095</th>\n",
              "      <th>0.100</th>\n",
              "      <th>0.105</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2003-09-21</th>\n",
              "      <td>0.011303</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>0.009847</td>\n",
              "      <td>0.009120</td>\n",
              "      <td>0.008392</td>\n",
              "      <td>0.007664</td>\n",
              "      <td>0.006937</td>\n",
              "      <td>0.006209</td>\n",
              "      <td>0.005481</td>\n",
              "      <td>0.004753</td>\n",
              "      <td>0.004026</td>\n",
              "      <td>0.003298</td>\n",
              "      <td>0.002570</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>0.001115</td>\n",
              "      <td>0.000387</td>\n",
              "      <td>-0.000340</td>\n",
              "      <td>-0.001068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-09-28</th>\n",
              "      <td>-0.008934</td>\n",
              "      <td>-0.007733</td>\n",
              "      <td>-0.006533</td>\n",
              "      <td>-0.005332</td>\n",
              "      <td>-0.004131</td>\n",
              "      <td>-0.002931</td>\n",
              "      <td>-0.001730</td>\n",
              "      <td>-0.000529</td>\n",
              "      <td>0.000671</td>\n",
              "      <td>0.001872</td>\n",
              "      <td>0.003073</td>\n",
              "      <td>0.004273</td>\n",
              "      <td>0.005474</td>\n",
              "      <td>0.006675</td>\n",
              "      <td>0.007876</td>\n",
              "      <td>0.009076</td>\n",
              "      <td>0.010277</td>\n",
              "      <td>0.011478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-05</th>\n",
              "      <td>0.001279</td>\n",
              "      <td>0.001623</td>\n",
              "      <td>0.001967</td>\n",
              "      <td>0.002312</td>\n",
              "      <td>0.002656</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.003345</td>\n",
              "      <td>0.003689</td>\n",
              "      <td>0.004033</td>\n",
              "      <td>0.004378</td>\n",
              "      <td>0.004722</td>\n",
              "      <td>0.005066</td>\n",
              "      <td>0.005410</td>\n",
              "      <td>0.005755</td>\n",
              "      <td>0.006099</td>\n",
              "      <td>0.006443</td>\n",
              "      <td>0.006788</td>\n",
              "      <td>0.007132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-12</th>\n",
              "      <td>-0.009832</td>\n",
              "      <td>-0.009649</td>\n",
              "      <td>-0.009467</td>\n",
              "      <td>-0.009284</td>\n",
              "      <td>-0.009102</td>\n",
              "      <td>-0.008919</td>\n",
              "      <td>-0.008737</td>\n",
              "      <td>-0.008554</td>\n",
              "      <td>-0.008371</td>\n",
              "      <td>-0.008189</td>\n",
              "      <td>-0.008006</td>\n",
              "      <td>-0.007824</td>\n",
              "      <td>-0.007641</td>\n",
              "      <td>-0.007459</td>\n",
              "      <td>-0.007276</td>\n",
              "      <td>-0.007093</td>\n",
              "      <td>-0.006911</td>\n",
              "      <td>-0.006728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-19</th>\n",
              "      <td>0.010236</td>\n",
              "      <td>0.009530</td>\n",
              "      <td>0.008823</td>\n",
              "      <td>0.008116</td>\n",
              "      <td>0.007410</td>\n",
              "      <td>0.006703</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>0.005290</td>\n",
              "      <td>0.004583</td>\n",
              "      <td>0.003877</td>\n",
              "      <td>0.003170</td>\n",
              "      <td>0.002464</td>\n",
              "      <td>0.001757</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>0.000344</td>\n",
              "      <td>-0.000363</td>\n",
              "      <td>-0.001069</td>\n",
              "      <td>-0.001776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-04</th>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "      <td>-0.026414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-11</th>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>0.003154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-18</th>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "      <td>-0.013259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-25</th>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "      <td>-0.004573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-01</th>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "      <td>0.009652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1007 rows √ó 18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d56574ea-a910-45c4-91e7-6d54855b6e98')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d56574ea-a910-45c4-91e7-6d54855b6e98 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d56574ea-a910-45c4-91e7-6d54855b6e98');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_mean = mv_backtest_returns.mean()\n",
        "mv_backtest_var = mv_backtest_returns.var()\n",
        "print(mv_backtest_mean)\n",
        "print(np.sqrt(mv_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdE0BXHf4Rur",
        "outputId": "d93f473c-f340-45e4-fff2-6ebb7a3560ce"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020    0.000742\n",
            "0.025    0.000704\n",
            "0.030    0.000722\n",
            "0.035    0.000673\n",
            "0.040    0.000598\n",
            "0.045    0.000596\n",
            "0.050    0.000635\n",
            "0.055    0.000678\n",
            "0.060    0.000688\n",
            "0.065    0.000711\n",
            "0.070    0.000695\n",
            "0.075    0.000721\n",
            "0.080    0.000747\n",
            "0.085    0.000794\n",
            "0.090    0.000824\n",
            "0.095    0.000828\n",
            "0.100    0.000825\n",
            "0.105    0.000814\n",
            "dtype: float64\n",
            "0.020    0.012021\n",
            "0.025    0.011950\n",
            "0.030    0.011901\n",
            "0.035    0.011823\n",
            "0.040    0.011776\n",
            "0.045    0.011744\n",
            "0.050    0.011778\n",
            "0.055    0.011798\n",
            "0.060    0.011870\n",
            "0.065    0.011975\n",
            "0.070    0.012114\n",
            "0.075    0.012278\n",
            "0.080    0.012590\n",
            "0.085    0.012826\n",
            "0.090    0.013042\n",
            "0.095    0.013239\n",
            "0.100    0.013480\n",
            "0.105    0.013660\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fG9H0VuB4H_i",
        "outputId": "d71533b1-ecbe-4284-e3bd-df0e88eb2417"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Portfolio"
      ],
      "metadata": {
        "id": "JoA9UX-AIaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thetas = np.arange(0, 1.05, 0.05)\n",
        "thetas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC0UiR1DIdtE",
        "outputId": "05efdea8-7096-434f-c2ac-1f1cb1065bdd"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_returns = pd.DataFrame(columns = thetas)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  rets=[]\n",
        "  for theta in thetas:\n",
        "    ret = get_mv_backtest_return(date, theta)\n",
        "    rets.append(ret)\n",
        "  naive_backtest_returns.loc[date] = rets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYsRgLjIZmr",
        "outputId": "752aeb7e-9973-4684-e5f8-05549f86777a"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_mean = naive_backtest_returns.mean()\n",
        "naive_backtest_var = naive_backtest_returns.var()\n",
        "print(naive_backtest_mean)\n",
        "print(np.sqrt(naive_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e4a98-facd-4559-890a-4b5cdd1a2305",
        "id": "OK8b3Re5JK4v"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00    0.000407\n",
            "0.05    0.000459\n",
            "0.10    0.000512\n",
            "0.15    0.000564\n",
            "0.20    0.000617\n",
            "0.25    0.000669\n",
            "0.30    0.000722\n",
            "0.35    0.000774\n",
            "0.40    0.000827\n",
            "0.45    0.000879\n",
            "0.50    0.000932\n",
            "0.55    0.000984\n",
            "0.60    0.001037\n",
            "0.65    0.001089\n",
            "0.70    0.001142\n",
            "0.75    0.001194\n",
            "0.80    0.001246\n",
            "0.85    0.001299\n",
            "0.90    0.001351\n",
            "0.95    0.001404\n",
            "1.00    0.001456\n",
            "dtype: float64\n",
            "0.00    0.008582\n",
            "0.05    0.007926\n",
            "0.10    0.007449\n",
            "0.15    0.007187\n",
            "0.20    0.007164\n",
            "0.25    0.007381\n",
            "0.30    0.007819\n",
            "0.35    0.008444\n",
            "0.40    0.009218\n",
            "0.45    0.010106\n",
            "0.50    0.011081\n",
            "0.55    0.012122\n",
            "0.60    0.013213\n",
            "0.65    0.014344\n",
            "0.70    0.015505\n",
            "0.75    0.016690\n",
            "0.80    0.017894\n",
            "0.85    0.019114\n",
            "0.90    0.020347\n",
            "0.95    0.021590\n",
            "1.00    0.022842\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "08cc11d4-c4ae-4d95-ac10-7fb508b0737b",
        "id": "QP0dekjMJK4v"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Graph"
      ],
      "metadata": {
        "id": "yyBQMceuJ_-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = 21\n",
        "\n",
        "area = np.pi*3\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=\"red\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "x2aGNhpuKEan",
        "outputId": "50c474db-7119-4863-8c61-99a8fc86473d"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59JkxM_-c9uk"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBobZ4qo53Lo"
      },
      "outputs": [],
      "source": [
        "# model = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "def train_epoch(dataloader):\n",
        "    train_loss,train_correct=0.0,0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "        loss = loss_fn(y_output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return train_loss\n",
        "  \n",
        "def valid_epoch(dataloader):\n",
        "\n",
        "    valid_loss, val_correct = 0.0, 0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "        loss = loss_fn(y_output, y)\n",
        "\n",
        "        valid_loss+=loss.item() * x.size(0)\n",
        "\n",
        "    return valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DeuyMHGu_Lmy",
        "outputId": "11c663c7-9cc6-41d6-d789-6e05591addaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c07c40cb1bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3768fb6a26b4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ],
      "source": [
        "history = {'train_loss': [], 'test_loss': []}\n",
        " \n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss=train_epoch(train_loader)\n",
        "        test_loss=valid_epoch(test_loader)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1,n_epochs,train_loss,test_loss))\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsd-ud7DWRC5"
      },
      "outputs": [],
      "source": [
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y7k33C-85KF"
      },
      "source": [
        "## Build efficient frontier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vazYH62WF8H4"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "  print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwtZLY8wFvv1"
      },
      "source": [
        "### Build ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1Fa8qX06tzT"
      },
      "outputs": [],
      "source": [
        "prob = pd.DataFrame(y_test).astype(\"float\")\n",
        "display(prob)\n",
        "rolling_prob = prob.rolling(25).mean().iloc[-1]\n",
        "display(rolling_prob.to_numpy()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjPZY76E93xQ"
      },
      "outputs": [],
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1\n",
        "\n",
        "for k in np.arange(0, 1, 0.1):\n",
        "  print(calculate_ml_portfolio_weights(rolling_prob.to_numpy()[0], k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvjJR_gI9A8T"
      },
      "outputs": [],
      "source": [
        "k = 0.5\n",
        "calculate_ml_portfolio_weights_lambda = lambda x: 0 if x < k else 1\n",
        "calculate_ml_portfolio_weights = np.vectorize(calculate_ml_portfolio_weights_lambda)\n",
        "# vfunc(x)\n",
        "# calculate_ml_portfolio_weights = functorch.vmap(ml_portfolio_weights, out_dims=1)\n",
        "# forecast = \n",
        "# portfolio_weights = calculate_ml_portfolio_weights(y_test.numpy())\n",
        "# print(portfolio_weights)\n",
        "\n",
        "portfolio_weights = y_test.apply_(calculate_ml_portfolio_weights_lambda)\n",
        "print(portfolio_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0Gjrcdn1YoM"
      },
      "outputs": [],
      "source": [
        "Xt = torch.from_numpy(to_X_train_features(low_risk, high_risk).T[-1])\n",
        "Xt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQDb3MWz4rzR"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(Xt, a)) / (torch.exp (torch.matmul(Xt, a)) + torch.exp(torch.matmul(Xt, b)))\n",
        "  print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo9vQZJS5BCK"
      },
      "outputs": [],
      "source": [
        "k = 0.5\n",
        "calculate_ml_portfolio_weights_lambda = lambda x: 0 if x < k else 1\n",
        "calculate_ml_portfolio_weights = np.vectorize(calculate_ml_portfolio_weights_lambda)\n",
        "\n",
        "portfolio_weights = y_test.apply_(calculate_ml_portfolio_weights_lambda)\n",
        "print(portfolio_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx3K4DmgFpd7"
      },
      "source": [
        "# MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vUNbKE2TUN2"
      },
      "outputs": [],
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Pct Return\"]  = market_data['Close'].pct_change()\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "s8neZvz8jlwa",
        "outputId": "7f97288f-1f6e-46f6-b1a4-6dbf3115c196"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f908cc87-e47e-4d40-ad37-74328a281d42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "      <th>Pct Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.008488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.013742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "      <td>0.007333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>380.640015</td>\n",
              "      <td>382.579987</td>\n",
              "      <td>378.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>0.903889</td>\n",
              "      <td>0.923099</td>\n",
              "      <td>-1.149319</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>-0.004210</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.002634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>384.369995</td>\n",
              "      <td>386.429993</td>\n",
              "      <td>377.829987</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>0.805676</td>\n",
              "      <td>-1.830743</td>\n",
              "      <td>-1.654172</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>0.007720</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.004210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>383.179993</td>\n",
              "      <td>385.880005</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>0.299117</td>\n",
              "      <td>-1.185467</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>-0.011413</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>381.720001</td>\n",
              "      <td>381.839996</td>\n",
              "      <td>378.760010</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>0.828493</td>\n",
              "      <td>-1.206745</td>\n",
              "      <td>-1.374945</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>0.022932</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.011413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>382.609985</td>\n",
              "      <td>389.250000</td>\n",
              "      <td>379.410004</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>1.119878</td>\n",
              "      <td>2.820901</td>\n",
              "      <td>-2.212630</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>0.022932</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows √ó 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f908cc87-e47e-4d40-ad37-74328a281d42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f908cc87-e47e-4d40-ad37-74328a281d42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f908cc87-e47e-4d40-ad37-74328a281d42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "25    2002-09-04   88.610001   90.250000   88.059998   89.540001   60.436001   \n",
              "26    2002-09-05   88.489998   89.430000   87.500000   88.779999   59.923054   \n",
              "27    2002-09-06   89.750000   90.570000   89.339996   90.000000   60.746498   \n",
              "28    2002-09-09   89.099998   91.349998   88.800003   90.660004   61.191929   \n",
              "29    2002-09-10   91.139999   91.779999   90.559998   91.699997   61.893936   \n",
              "...          ...         ...         ...         ...         ...         ...   \n",
              "5142  2022-12-30  380.640015  382.579987  378.429993  382.429993  382.429993   \n",
              "5143  2023-01-03  384.369995  386.429993  377.829987  380.820007  380.820007   \n",
              "5144  2023-01-04  383.179993  385.880005  380.000000  383.760010  383.760010   \n",
              "5145  2023-01-05  381.720001  381.839996  378.760010  379.380005  379.380005   \n",
              "5146  2023-01-06  382.609985  389.250000  379.410004  388.079987  388.079987   \n",
              "\n",
              "        Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \\\n",
              "25    0.550024      0.479605  0.276737   88.779999 -0.008488           0   \n",
              "26    0.723874      0.149555  0.229367   90.000000  0.013742           1   \n",
              "27    0.415721      0.128926  0.522307   90.660004  0.007333           1   \n",
              "28    0.365951      0.804501  0.929931   91.699997  0.011471           1   \n",
              "29    0.445799      0.288793  1.338801   91.129997 -0.006216           0   \n",
              "...        ...           ...       ...         ...       ...         ...   \n",
              "5142  0.903889      0.923099 -1.149319  380.820007 -0.004210           1   \n",
              "5143  0.805676     -1.830743 -1.654172  383.760010  0.007720           1   \n",
              "5144  0.924976      0.299117 -1.185467  379.380005 -0.011413           0   \n",
              "5145  0.828493     -1.206745 -1.374945  388.079987  0.022932           1   \n",
              "5146  1.119878      2.820901 -2.212630         NaN       NaN           1   \n",
              "\n",
              "      Pct Return  \n",
              "25           NaN  \n",
              "26     -0.008488  \n",
              "27      0.013742  \n",
              "28      0.007333  \n",
              "29      0.011471  \n",
              "...          ...  \n",
              "5142   -0.002634  \n",
              "5143   -0.004210  \n",
              "5144    0.007720  \n",
              "5145   -0.011413  \n",
              "5146    0.022932  \n",
              "\n",
              "[5122 rows x 13 columns]"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "high_risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Pw_6fyZUZLW",
        "outputId": "b889cde5-6bf0-454d-e20e-541ef89400ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.09088309481924065\n",
            "0.009396836284394002\n"
          ]
        }
      ],
      "source": [
        "high_risk_return_annual = high_risk[\"Pct Return\"].mean() * trading_days_in_year\n",
        "low_risk_return_annual = low_risk[\"Pct Return\"].mean() * trading_days_in_year\n",
        "print(high_risk_return_annual)\n",
        "print(low_risk_return_annual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHNvPvKeU552",
        "outputId": "0f0ad777-fbfa-471c-b99d-8a1302ba4dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.00014831962827593315\n",
            "1.840738816881264e-05\n"
          ]
        }
      ],
      "source": [
        "high_risk_var_daily = high_risk[\"Pct Return\"].var()\n",
        "low_risk_var_daily = low_risk[\"Pct Return\"].var()\n",
        "print(high_risk_var_daily)\n",
        "print(low_risk_var_daily)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1A4Jk4uWHDj"
      },
      "source": [
        "## Build data for high and low risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e5kg5IleWKbF",
        "outputId": "2e982058-88bd-4b35-c62e-dd25584258ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            high        low\n",
              "25     89.540001  85.199997\n",
              "26     88.779999  85.540001\n",
              "27     90.000000  84.879997\n",
              "28     90.660004  84.760002\n",
              "29     91.699997  85.059998\n",
              "...          ...        ...\n",
              "5142  382.429993  95.779999\n",
              "5143  380.820007  96.529999\n",
              "5144  383.760010  97.269997\n",
              "5145  379.380005  97.129997\n",
              "5146  388.079987  98.379997\n",
              "\n",
              "[5122 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-94e6e071-1955-45ae-a51f-3617a305e7a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>89.540001</td>\n",
              "      <td>85.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>88.779999</td>\n",
              "      <td>85.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>84.879997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>90.660004</td>\n",
              "      <td>84.760002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>91.699997</td>\n",
              "      <td>85.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>382.429993</td>\n",
              "      <td>95.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>380.820007</td>\n",
              "      <td>96.529999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>383.760010</td>\n",
              "      <td>97.269997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>379.380005</td>\n",
              "      <td>97.129997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>388.079987</td>\n",
              "      <td>98.379997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94e6e071-1955-45ae-a51f-3617a305e7a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94e6e071-1955-45ae-a51f-3617a305e7a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94e6e071-1955-45ae-a51f-3617a305e7a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "mv_data = pd.DataFrame(data={'high': high_risk['Close'], 'low':low_risk['Close']})\n",
        "mv_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "zI1us-ILNW0l",
        "outputId": "6a71ba9c-0151-4c75-eff0-12671436872e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "high    0.090883\n",
              "low     0.009397\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          high       low\n",
              "high  0.037377 -0.004467\n",
              "low  -0.004467  0.004639"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f545eb58-ad30-4b06-9cdd-0f64773dcdb8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0.037377</td>\n",
              "      <td>-0.004467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>-0.004467</td>\n",
              "      <td>0.004639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f545eb58-ad30-4b06-9cdd-0f64773dcdb8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f545eb58-ad30-4b06-9cdd-0f64773dcdb8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f545eb58-ad30-4b06-9cdd-0f64773dcdb8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "r, cov = get_annual_sample_return_and_covariance(mv_data)\n",
        "display(r)\n",
        "display(cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "SA4aHkEINXGO"
      },
      "outputs": [],
      "source": [
        "def get_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change().mean()\n",
        "    daily_covariance = data.pct_change().cov()\n",
        "    return daily_return * len(data), daily_covariance * len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "-7yPFP8lXtiM",
        "outputId": "dc76edf2-fa71-4583-9bd6-47e2de8b85ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "high    1.847235\n",
              "low     0.190994\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "          high       low\n",
              "high  0.759693 -0.090788\n",
              "low  -0.090788  0.094283"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0a1477c-519e-4cf4-ae52-86c817dd2d3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0.759693</td>\n",
              "      <td>-0.090788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>-0.090788</td>\n",
              "      <td>0.094283</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0a1477c-519e-4cf4-ae52-86c817dd2d3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0a1477c-519e-4cf4-ae52-86c817dd2d3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0a1477c-519e-4cf4-ae52-86c817dd2d3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "r, cov = get_sample_return_and_covariance(mv_data)\n",
        "display(r)\n",
        "display(cov)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BOYoifDBaqP"
      },
      "source": [
        "## Optimization using linear programming\n",
        "\n",
        "(Reference: https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "G_t1dGnAtHYV"
      },
      "outputs": [],
      "source": [
        "TERMINATION = 10**-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "65SYaxYzFVOi"
      },
      "outputs": [],
      "source": [
        "#function obtains maximal return portfolio using linear programming\n",
        "\n",
        "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
        "    \n",
        "    #dependencies\n",
        "    from scipy.optimize import linprog\n",
        "    import numpy as np\n",
        "    \n",
        "    c = (np.multiply(-1, MeanReturns))\n",
        "    A = np.ones([PortfolioSize,1]).T\n",
        "    b=[1] \n",
        "    res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n",
        "    \n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ESkZdqjLb_MH"
      },
      "outputs": [],
      "source": [
        "#function obtains minimal risk portfolio \n",
        "\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
        "    \n",
        "    def  f(x, CovarReturns):\n",
        "        func = np.matmul(np.matmul(x, CovarReturns), x.T) \n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b \n",
        "        return constraintVal\n",
        "    \n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
        "                             constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "i6r-NvbtYDDn"
      },
      "outputs": [],
      "source": [
        "def print_min_variance_portfolio(mean_returns, cov_returns):\n",
        "    number_of_assets = len(mean_returns)\n",
        "    result = MinimizeRisk(cov_returns, number_of_assets)\n",
        "\n",
        "    print()\n",
        "    minRiskWeights = result.x\n",
        "    minRiskExpPortfolioReturn = np.matmul(mean_returns.T, minRiskWeights)\n",
        "    print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)\n",
        "    minRisk = np.matmul(np.matmul(minRiskWeights, cov_returns), minRiskWeights.T) \n",
        "    print(\"Variance of Minimum Risk Portfolio : %7.6f\" % minRisk)\n",
        "    print(\"S.D. of Minimum Risk Portfolio : %7.6f\" % np.sqrt(minRisk))\n",
        "    threshold = 1e-3\n",
        "    print(\"Weights (showing only those > %.6f): \" % threshold)\n",
        "    for i in range(0, number_of_assets):\n",
        "        if result.x[i] > threshold:\n",
        "            print(f\"{mean_returns.index[i]}\\t{result.x[i]:.6f}\")\n",
        "    print('Assets Considered:')\n",
        "    print(mean_returns.index.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DNuu3KurcJDL"
      },
      "outputs": [],
      "source": [
        "#function obtains Minimal risk and Maximum return portfolios\n",
        "\n",
        "#dependencies\n",
        "import numpy as np\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkZ69QycGDx",
        "outputId": "4d4b8f16-cb7b-4c83-ccc8-68e9b8486e6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expected Return of Minimum Risk Portfolio:  0.000095\n",
            "Variance of Minimum Risk Portfolio : 0.000012\n",
            "S.D. of Minimum Risk Portfolio : 0.003457\n",
            "Weights (showing only those > 0.001000): \n",
            "high\t0.178717\n",
            "low\t0.821283\n",
            "Assets Considered:\n",
            "['high' 'low']\n"
          ]
        }
      ],
      "source": [
        "print_min_variance_portfolio(r, cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvkOfW5-GXpS",
        "outputId": "7e88f938-d856-4350-aecd-a847facd8321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:   0.000361\n"
          ]
        }
      ],
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnMjflTbGaO7",
        "outputId": "a9b29908-6ede-49ee-9954-bb2d5b7d65c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:  0.000095\n"
          ]
        }
      ],
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kw9InlwDh3v",
        "outputId": "ce4a60a2-5d9d-4b40-e28e-bc18165e821f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/optimize/_hessian_update_strategy.py:182: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
            "  warn('delta_grad == 0.0. Check if the approximated '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the  efficient set: (266, 2)\n",
            "Optimal weights of the efficient set portfolios: \n",
            " [[0.19147597 0.80852403]\n",
            " [0.19303935 0.80696065]\n",
            " [0.19949414 0.80050586]\n",
            " [0.20124187 0.79875813]\n",
            " [0.20309764 0.79690236]\n",
            " [0.20505857 0.79494143]\n",
            " [0.20712071 0.79287929]\n",
            " [0.2092793  0.7907207 ]\n",
            " [0.21152886 0.78847114]\n",
            " [0.21386345 0.78613655]\n",
            " [0.21627678 0.78372322]\n",
            " [0.21876244 0.78123756]\n",
            " [0.23163842 0.76836158]\n",
            " [0.23388388 0.76611612]\n",
            " [0.23618429 0.76381571]\n",
            " [0.23892453 0.76107547]\n",
            " [0.24130016 0.75869984]\n",
            " [0.24372328 0.75627672]\n",
            " [0.24619299 0.75380701]\n",
            " [0.24870346 0.75129654]\n",
            " [0.25122177 0.74877823]\n",
            " [0.25381337 0.74618663]\n",
            " [0.2564398  0.7435602 ]\n",
            " [0.25909879 0.74090121]\n",
            " [0.26179442 0.73820558]\n",
            " [0.2645222  0.7354778 ]\n",
            " [0.26727472 0.73272528]\n",
            " [0.27005015 0.72994985]\n",
            " [0.27284665 0.72715335]\n",
            " [0.27566273 0.72433727]\n",
            " [0.27849678 0.72150322]\n",
            " [0.28134749 0.71865251]\n",
            " [0.28421348 0.71578652]\n",
            " [0.28709361 0.71290639]\n",
            " [0.28998677 0.71001323]\n",
            " [0.29319427 0.70680573]\n",
            " [0.29580812 0.70419188]\n",
            " [0.29873455 0.70126545]\n",
            " [0.3016704  0.6983296 ]\n",
            " [0.30090936 0.69909064]\n",
            " [0.30392871 0.69607129]\n",
            " [0.30695381 0.69304619]\n",
            " [0.30998412 0.69001588]\n",
            " [0.31301918 0.68698082]\n",
            " [0.31605855 0.68394145]\n",
            " [0.31910184 0.68089816]\n",
            " [0.32214871 0.67785129]\n",
            " [0.32519882 0.67480118]\n",
            " [0.3282519  0.6717481 ]\n",
            " [0.33130768 0.66869232]\n",
            " [0.33436593 0.66563407]\n",
            " [0.33742642 0.66257358]\n",
            " [0.34048898 0.65951102]\n",
            " [0.34877007 0.65122993]\n",
            " [0.35168    0.64832   ]\n",
            " [0.3545982  0.6454018 ]\n",
            " [0.35752411 0.64247589]\n",
            " [0.36045749 0.63954251]\n",
            " [0.36339795 0.63660205]\n",
            " [0.36634505 0.63365495]\n",
            " [0.36929852 0.63070148]\n",
            " [0.37225805 0.62774195]\n",
            " [0.3752233  0.6247767 ]\n",
            " [0.37819403 0.62180597]\n",
            " [0.38116989 0.61883011]\n",
            " [0.38415069 0.61584931]\n",
            " [0.38713616 0.61286384]\n",
            " [0.3901261  0.6098739 ]\n",
            " [0.39312021 0.60687979]\n",
            " [0.39611836 0.60388164]\n",
            " [0.39912031 0.60087969]\n",
            " [0.4021259  0.5978741 ]\n",
            " [0.40513494 0.59486506]\n",
            " [0.40814725 0.59185275]\n",
            " [0.41116269 0.58883731]\n",
            " [0.41418112 0.58581888]\n",
            " [0.41720235 0.58279765]\n",
            " [0.42022629 0.57977371]\n",
            " [0.42325233 0.57674767]\n",
            " [0.42627937 0.57372063]\n",
            " [0.42930876 0.57069124]\n",
            " [0.43234042 0.56765958]\n",
            " [0.43537423 0.56462577]\n",
            " [0.43841011 0.56158989]\n",
            " [0.44144798 0.55855202]\n",
            " [0.44448774 0.55551226]\n",
            " [0.44752931 0.55247069]\n",
            " [0.49753134 0.50246866]\n",
            " [0.45361761 0.54638239]\n",
            " [0.45666418 0.54333582]\n",
            " [0.45971228 0.54028772]\n",
            " [0.46276185 0.53723815]\n",
            " [0.46581283 0.53418717]\n",
            " [0.46886515 0.53113485]\n",
            " [0.47191876 0.52808124]\n",
            " [0.47497361 0.52502639]\n",
            " [0.47802965 0.52197035]\n",
            " [0.48108683 0.51891317]\n",
            " [0.48414513 0.51585487]\n",
            " [0.48720443 0.51279557]\n",
            " [0.49026478 0.50973522]\n",
            " [0.49332608 0.50667392]\n",
            " [0.49638832 0.50361168]\n",
            " [0.49945145 0.50054855]\n",
            " [0.50251544 0.49748456]\n",
            " [0.50558027 0.49441973]\n",
            " [0.50864588 0.49135412]\n",
            " [0.51171227 0.48828773]\n",
            " [0.51477939 0.48522061]\n",
            " [0.51784722 0.48215278]\n",
            " [0.5209501  0.4790499 ]\n",
            " [0.52401943 0.47598057]\n",
            " [0.52708934 0.47291066]\n",
            " [0.5301598  0.4698402 ]\n",
            " [0.53323078 0.46676922]\n",
            " [0.53630226 0.46369774]\n",
            " [0.53937424 0.46062576]\n",
            " [0.54244669 0.45755331]\n",
            " [0.5455196  0.4544804 ]\n",
            " [0.54859294 0.45140706]\n",
            " [0.55166671 0.44833329]\n",
            " [0.55474088 0.44525912]\n",
            " [0.55781545 0.44218455]\n",
            " [0.5608904  0.4391096 ]\n",
            " [0.56396572 0.43603428]\n",
            " [0.5670414  0.4329586 ]\n",
            " [0.57011742 0.42988258]\n",
            " [0.57319377 0.42680623]\n",
            " [0.57627045 0.42372955]\n",
            " [0.57934744 0.42065256]\n",
            " [0.58242473 0.41757527]\n",
            " [0.58550232 0.41449768]\n",
            " [0.58858019 0.41141981]\n",
            " [0.59165834 0.40834166]\n",
            " [0.59473675 0.40526325]\n",
            " [0.59781542 0.40218458]\n",
            " [0.60089435 0.39910565]\n",
            " [0.60397356 0.39602644]\n",
            " [0.60705292 0.39294708]\n",
            " [0.61013256 0.38986744]\n",
            " [0.61321242 0.38678758]\n",
            " [0.61629249 0.38370751]\n",
            " [0.61937278 0.38062722]\n",
            " [0.62245328 0.37754672]\n",
            " [0.62553397 0.37446603]\n",
            " [0.63466872 0.36533128]\n",
            " [0.63769822 0.36230178]\n",
            " [0.64072871 0.35927129]\n",
            " [0.64376023 0.35623977]\n",
            " [0.64679252 0.35320748]\n",
            " [0.64982576 0.35017424]\n",
            " [0.65285988 0.34714012]\n",
            " [0.65513064 0.34486936]\n",
            " [0.65895358 0.34104642]\n",
            " [0.6619829  0.3380171 ]\n",
            " [0.6650132  0.3349868 ]\n",
            " [0.66804446 0.33195554]\n",
            " [0.67107668 0.32892332]\n",
            " [0.67410983 0.32589017]\n",
            " [0.6771439  0.3228561 ]\n",
            " [0.68017888 0.31982112]\n",
            " [0.68321474 0.31678526]\n",
            " [0.68625149 0.31374851]\n",
            " [0.68928909 0.31071091]\n",
            " [0.69232754 0.30767246]\n",
            " [0.69536683 0.30463317]\n",
            " [0.69840693 0.30159307]\n",
            " [0.70144784 0.29855216]\n",
            " [0.70448955 0.29551045]\n",
            " [0.70753203 0.29246797]\n",
            " [0.71057528 0.28942472]\n",
            " [0.71361929 0.28638071]\n",
            " [0.71666403 0.28333597]\n",
            " [0.7197095  0.2802905 ]\n",
            " [0.72275569 0.27724431]\n",
            " [0.72580259 0.27419741]\n",
            " [0.72885017 0.27114983]\n",
            " [0.73189843 0.26810157]\n",
            " [0.73489465 0.26510535]\n",
            " [0.73794584 0.26205416]\n",
            " [0.74099758 0.25900242]\n",
            " [0.74404988 0.25595012]\n",
            " [0.74710271 0.25289729]\n",
            " [0.75015606 0.24984394]\n",
            " [0.75320993 0.24679007]\n",
            " [0.7562643  0.2437357 ]\n",
            " [0.75931916 0.24068084]\n",
            " [0.76237451 0.23762549]\n",
            " [0.76543032 0.23456968]\n",
            " [0.7684866  0.2315134 ]\n",
            " [0.77154333 0.22845667]\n",
            " [0.77460051 0.22539949]\n",
            " [0.77765813 0.22234187]\n",
            " [0.78071617 0.21928383]\n",
            " [0.78377465 0.21622535]\n",
            " [0.78683355 0.21316645]\n",
            " [0.78989287 0.21010713]\n",
            " [0.79295262 0.20704738]\n",
            " [0.79214736 0.20785264]\n",
            " [0.79522708 0.20477292]\n",
            " [0.79830704 0.20169296]\n",
            " [0.80138777 0.19861223]\n",
            " [0.80447005 0.19552995]\n",
            " [0.80755263 0.19244737]\n",
            " [0.81063549 0.18936451]\n",
            " [0.81371864 0.18628136]\n",
            " [0.81680207 0.18319793]\n",
            " [0.81988577 0.18011423]\n",
            " [0.82296973 0.17703027]\n",
            " [0.82605397 0.17394603]\n",
            " [0.82913846 0.17086154]\n",
            " [0.83626279 0.16373721]\n",
            " [0.8390181  0.1609819 ]\n",
            " [0.84177342 0.15822658]\n",
            " [0.84452873 0.15547127]\n",
            " [0.84728404 0.15271596]\n",
            " [0.84765081 0.15234919]\n",
            " [0.8507371  0.1492629 ]\n",
            " [0.85382365 0.14617635]\n",
            " [0.85830531 0.14169469]\n",
            " [0.86002193 0.13997807]\n",
            " [0.86613053 0.13386947]\n",
            " [0.86619314 0.13380686]\n",
            " [0.87279815 0.12720185]\n",
            " [0.87573373 0.12426627]\n",
            " [0.8787993  0.1212007 ]\n",
            " [0.88186139 0.11813861]\n",
            " [0.88490606 0.11509394]\n",
            " [0.88793442 0.11206558]\n",
            " [0.89096277 0.10903723]\n",
            " [0.89399112 0.10600888]\n",
            " [0.89701948 0.10298052]\n",
            " [0.90004783 0.09995217]\n",
            " [0.90156742 0.09843258]\n",
            " [0.90446751 0.09553249]\n",
            " [0.9073676  0.0926324 ]\n",
            " [0.9102677  0.0897323 ]\n",
            " [0.9131678  0.0868322 ]\n",
            " [0.91557052 0.08442948]\n",
            " [0.9186614  0.0813386 ]\n",
            " [0.92175219 0.07824781]\n",
            " [0.92484284 0.07515716]\n",
            " [0.92793329 0.07206671]\n",
            " [0.93444858 0.06555142]\n",
            " [0.93714833 0.06285167]\n",
            " [0.93984807 0.06015193]\n",
            " [0.94254782 0.05745218]\n",
            " [0.9433711  0.0566289 ]\n",
            " [0.94924771 0.05075229]\n",
            " [0.95230884 0.04769116]\n",
            " [0.95536997 0.04463003]\n",
            " [0.9584311  0.0415689 ]\n",
            " [0.96149222 0.03850778]\n",
            " [0.96268267 0.03731733]\n",
            " [0.96520615 0.03479385]\n",
            " [0.96733112 0.03266888]\n",
            " [0.97078627 0.02921373]\n",
            " [0.97654727 0.02345273]\n",
            " [0.97926454 0.02073546]\n",
            " [0.98220441 0.01779559]\n",
            " [0.98345294 0.01654706]\n",
            " [0.9869469  0.0130531 ]\n",
            " [0.99046078 0.00953922]\n",
            " [0.99267546 0.00732454]\n",
            " [0.99550229 0.00449771]\n",
            " [0.99867034 0.00132966]]\n",
            "Annualized Risk and Return of the efficient set portfolios: \n",
            " [[0.05495152 0.02395981]\n",
            " [0.05497115 0.02421181]\n",
            " [0.05507604 0.02446381]\n",
            " [0.05511103 0.02471581]\n",
            " [0.05515125 0.02496781]\n",
            " [0.05519718 0.02521981]\n",
            " [0.05524925 0.02547181]\n",
            " [0.05530791 0.02572381]\n",
            " [0.05537353 0.02597581]\n",
            " [0.05544647 0.02622781]\n",
            " [0.05552703 0.02647981]\n",
            " [0.05561546 0.02673181]\n",
            " [0.05616108 0.02698381]\n",
            " [0.05627106 0.02723581]\n",
            " [0.05638824 0.02748781]\n",
            " [0.05653373 0.02773981]\n",
            " [0.05666502 0.02799181]\n",
            " [0.05680384 0.02824381]\n",
            " [0.05695038 0.02849581]\n",
            " [0.05710454 0.02874781]\n",
            " [0.05726439 0.02899981]\n",
            " [0.05743431 0.02925181]\n",
            " [0.05761206 0.02950381]\n",
            " [0.05779764 0.02975581]\n",
            " [0.05799152 0.03000781]\n",
            " [0.05819354 0.03025981]\n",
            " [0.05840325 0.03051181]\n",
            " [0.05862062 0.03076381]\n",
            " [0.05884558 0.03101581]\n",
            " [0.05907805 0.03126781]\n",
            " [0.05931797 0.03151981]\n",
            " [0.05956526 0.03177181]\n",
            " [0.05981982 0.03202381]\n",
            " [0.06008156 0.03227581]\n",
            " [0.0603504  0.03252781]\n",
            " [0.06065527 0.03277981]\n",
            " [0.06090895 0.03303181]\n",
            " [0.06119847 0.03328381]\n",
            " [0.06149468 0.03353581]\n",
            " [0.06141734 0.03378781]\n",
            " [0.0617264  0.03403981]\n",
            " [0.06204201 0.03429181]\n",
            " [0.06236406 0.03454381]\n",
            " [0.06269244 0.03479581]\n",
            " [0.06302703 0.03504781]\n",
            " [0.06336772 0.03529981]\n",
            " [0.06371441 0.03555181]\n",
            " [0.06406699 0.03580381]\n",
            " [0.06442534 0.03605581]\n",
            " [0.06478936 0.03630781]\n",
            " [0.06515896 0.03655981]\n",
            " [0.06553401 0.03681181]\n",
            " [0.06591443 0.03706381]\n",
            " [0.066968   0.03731581]\n",
            " [0.06734662 0.03756781]\n",
            " [0.06773059 0.03781981]\n",
            " [0.0681198  0.03807181]\n",
            " [0.06851417 0.03832381]\n",
            " [0.06891361 0.03857581]\n",
            " [0.06931803 0.03882781]\n",
            " [0.06972733 0.03907981]\n",
            " [0.07014143 0.03933181]\n",
            " [0.07056023 0.03958381]\n",
            " [0.07098366 0.03983581]\n",
            " [0.07141162 0.04008781]\n",
            " [0.07184403 0.04033981]\n",
            " [0.0722808  0.04059181]\n",
            " [0.07272185 0.04084381]\n",
            " [0.07316709 0.04109581]\n",
            " [0.07361645 0.04134781]\n",
            " [0.07406985 0.04159981]\n",
            " [0.0745272  0.04185181]\n",
            " [0.07498843 0.04210381]\n",
            " [0.07545347 0.04235581]\n",
            " [0.07592223 0.04260781]\n",
            " [0.07639465 0.04285981]\n",
            " [0.07687065 0.04311181]\n",
            " [0.07735016 0.04336381]\n",
            " [0.07783304 0.04361581]\n",
            " [0.07831906 0.04386781]\n",
            " [0.07880839 0.04411981]\n",
            " [0.07930096 0.04437181]\n",
            " [0.07979672 0.04462381]\n",
            " [0.08029559 0.04487581]\n",
            " [0.08079753 0.04512781]\n",
            " [0.08130246 0.04537981]\n",
            " [0.08181034 0.04563181]\n",
            " [0.09049824 0.04588381]\n",
            " [0.08283469 0.04613581]\n",
            " [0.08335106 0.04638781]\n",
            " [0.08387014 0.04663981]\n",
            " [0.08439189 0.04689181]\n",
            " [0.08491626 0.04714381]\n",
            " [0.0854432  0.04739581]\n",
            " [0.08597265 0.04764781]\n",
            " [0.08650456 0.04789981]\n",
            " [0.0870389  0.04815181]\n",
            " [0.08757561 0.04840381]\n",
            " [0.08811466 0.04865581]\n",
            " [0.08865598 0.04890781]\n",
            " [0.08919954 0.04915981]\n",
            " [0.0897453  0.04941181]\n",
            " [0.09029322 0.04966381]\n",
            " [0.09084326 0.04991581]\n",
            " [0.09139537 0.05016781]\n",
            " [0.09194951 0.05041981]\n",
            " [0.09250566 0.05067181]\n",
            " [0.09306376 0.05092381]\n",
            " [0.09362379 0.05117581]\n",
            " [0.09418571 0.05142781]\n",
            " [0.09475581 0.05167981]\n",
            " [0.09532146 0.05193181]\n",
            " [0.09588887 0.05218381]\n",
            " [0.09645803 0.05243581]\n",
            " [0.0970289  0.05268781]\n",
            " [0.09760145 0.05293981]\n",
            " [0.09817564 0.05319181]\n",
            " [0.09875146 0.05344381]\n",
            " [0.09932886 0.05369581]\n",
            " [0.09990783 0.05394781]\n",
            " [0.10048833 0.05419981]\n",
            " [0.10107033 0.05445181]\n",
            " [0.10165382 0.05470381]\n",
            " [0.10223875 0.05495581]\n",
            " [0.10282512 0.05520781]\n",
            " [0.10341289 0.05545981]\n",
            " [0.10400203 0.05571181]\n",
            " [0.10459254 0.05596381]\n",
            " [0.10518437 0.05621581]\n",
            " [0.10577751 0.05646781]\n",
            " [0.10637194 0.05671981]\n",
            " [0.10696763 0.05697181]\n",
            " [0.10756456 0.05722381]\n",
            " [0.10816271 0.05747581]\n",
            " [0.10876207 0.05772781]\n",
            " [0.10936261 0.05797981]\n",
            " [0.1099643  0.05823181]\n",
            " [0.11056715 0.05848381]\n",
            " [0.11117111 0.05873581]\n",
            " [0.11177617 0.05898781]\n",
            " [0.11238232 0.05923981]\n",
            " [0.11298955 0.05949181]\n",
            " [0.11359782 0.05974381]\n",
            " [0.11420712 0.05999581]\n",
            " [0.11481744 0.06024781]\n",
            " [0.11663274 0.06049981]\n",
            " [0.11723658 0.06075181]\n",
            " [0.11784149 0.06100381]\n",
            " [0.11844747 0.06125581]\n",
            " [0.11905445 0.06150781]\n",
            " [0.11966245 0.06175981]\n",
            " [0.12027146 0.06201181]\n",
            " [0.12072777 0.06226381]\n",
            " [0.12149702 0.06251581]\n",
            " [0.12210746 0.06276781]\n",
            " [0.12271888 0.06301981]\n",
            " [0.12333125 0.06327181]\n",
            " [0.12394456 0.06352381]\n",
            " [0.12455881 0.06377581]\n",
            " [0.12517397 0.06402781]\n",
            " [0.12579004 0.06427981]\n",
            " [0.126407   0.06453181]\n",
            " [0.12702484 0.06478381]\n",
            " [0.12764354 0.06503581]\n",
            " [0.1282631  0.06528781]\n",
            " [0.1288835  0.06553981]\n",
            " [0.12950472 0.06579181]\n",
            " [0.13012677 0.06604381]\n",
            " [0.13074962 0.06629581]\n",
            " [0.13137327 0.06654781]\n",
            " [0.1319977  0.06679981]\n",
            " [0.1326229  0.06705181]\n",
            " [0.13324887 0.06730381]\n",
            " [0.13387558 0.06755581]\n",
            " [0.13450304 0.06780781]\n",
            " [0.13513123 0.06805981]\n",
            " [0.13576013 0.06831181]\n",
            " [0.13638975 0.06856381]\n",
            " [0.13700917 0.06881581]\n",
            " [0.13764049 0.06906781]\n",
            " [0.13827249 0.06931981]\n",
            " [0.13890513 0.06957181]\n",
            " [0.13953843 0.06982381]\n",
            " [0.14017235 0.07007581]\n",
            " [0.14080691 0.07032781]\n",
            " [0.14144207 0.07057981]\n",
            " [0.14207785 0.07083181]\n",
            " [0.14271423 0.07108381]\n",
            " [0.1433512  0.07133581]\n",
            " [0.14398875 0.07158781]\n",
            " [0.14462688 0.07183981]\n",
            " [0.14526557 0.07209181]\n",
            " [0.14590482 0.07234381]\n",
            " [0.14654463 0.07259581]\n",
            " [0.14718498 0.07284781]\n",
            " [0.14782587 0.07309981]\n",
            " [0.14846729 0.07335181]\n",
            " [0.14910924 0.07360381]\n",
            " [0.14894025 0.07385581]\n",
            " [0.14958672 0.07410781]\n",
            " [0.15023367 0.07435981]\n",
            " [0.15088121 0.07461181]\n",
            " [0.1515295  0.07486381]\n",
            " [0.15217827 0.07511581]\n",
            " [0.15282752 0.07536781]\n",
            " [0.15347723 0.07561981]\n",
            " [0.15412741 0.07587181]\n",
            " [0.15477804 0.07612381]\n",
            " [0.15542912 0.07637581]\n",
            " [0.15608065 0.07662781]\n",
            " [0.15673262 0.07687981]\n",
            " [0.15823992 0.07713181]\n",
            " [0.1588234  0.07738381]\n",
            " [0.15940716 0.07763581]\n",
            " [0.15999122 0.07788781]\n",
            " [0.16057556 0.07813981]\n",
            " [0.16065336 0.07839181]\n",
            " [0.16130827 0.07864381]\n",
            " [0.16196358 0.07889581]\n",
            " [0.16291569 0.07914781]\n",
            " [0.16328058 0.07939981]\n",
            " [0.16457985 0.07965181]\n",
            " [0.16459317 0.07990381]\n",
            " [0.16599948 0.08015581]\n",
            " [0.16662499 0.08040781]\n",
            " [0.1672785  0.08065981]\n",
            " [0.16793157 0.08091181]\n",
            " [0.16858123 0.08116381]\n",
            " [0.1692277  0.08141581]\n",
            " [0.16987446 0.08166781]\n",
            " [0.17052151 0.08191981]\n",
            " [0.17116884 0.08217181]\n",
            " [0.17181646 0.08242381]\n",
            " [0.17214152 0.08267581]\n",
            " [0.1727621  0.08292781]\n",
            " [0.17338293 0.08317981]\n",
            " [0.174004   0.08343181]\n",
            " [0.17462532 0.08368381]\n",
            " [0.17514027 0.08393581]\n",
            " [0.17580294 0.08418781]\n",
            " [0.17646587 0.08443981]\n",
            " [0.17712903 0.08469181]\n",
            " [0.17779241 0.08494381]\n",
            " [0.1791918  0.08519581]\n",
            " [0.179772   0.08544781]\n",
            " [0.18035239 0.08569981]\n",
            " [0.18093297 0.08595181]\n",
            " [0.18111006 0.08620381]\n",
            " [0.1823746  0.08645581]\n",
            " [0.18303365 0.08670781]\n",
            " [0.18369294 0.08695981]\n",
            " [0.18435245 0.08721181]\n",
            " [0.1850122  0.08746381]\n",
            " [0.18526883 0.08771581]\n",
            " [0.18581294 0.08796781]\n",
            " [0.18627124 0.08821981]\n",
            " [0.18701666 0.08847181]\n",
            " [0.18826017 0.08872381]\n",
            " [0.18884696 0.08897581]\n",
            " [0.189482   0.08922781]\n",
            " [0.18975176 0.08947981]\n",
            " [0.19050685 0.08973181]\n",
            " [0.19126651 0.08998381]\n",
            " [0.19174544 0.09023581]\n",
            " [0.1923569  0.09048781]\n",
            " [0.19304238 0.09073981]]\n"
          ]
        }
      ],
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.000001\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "#initialize optimal weight set and risk-return point set\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "#repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "while (low < high):\n",
        "    \n",
        "    result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "    \n",
        "#gather optimal weight set    \n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "#obtain annualized risk for the efficient set portfolios \n",
        "#for trading days = 251\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint*trading_days_in_year) \n",
        "\n",
        "#obtain expected portfolio annualized return for the \n",
        "#efficient set portfolios, for trading days = 251\n",
        "retPoint = trading_days_in_year*np.array(expPortfolioReturnPoint) \n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.000001\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "#initialize optimal weight set and risk-return point set\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "#repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "while (low < high):\n",
        "    \n",
        "    result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "    \n",
        "#gather optimal weight set    \n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "#obtain annualized risk for the efficient set portfolios \n",
        "#for trading days = 251\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint*trading_days_in_year) \n",
        "\n",
        "#obtain expected portfolio annualized return for the \n",
        "#efficient set portfolios, for trading days = 251\n",
        "retPoint = trading_days_in_year*np.array(expPortfolioReturnPoint) \n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "id": "CWVcn0qldNvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2_0opIvqHAG1",
        "outputId": "1c470d55-802d-47ab-a481-762dff4185fa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Graph Efficient Frontier\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMoyxpN5dY_z"
      },
      "source": [
        "# Naive Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGhdT3AWHGa-",
        "outputId": "c8e28a4d-fbf1-4734-a17c-c6acea8cddea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annualized Risk and Return of the efficient set portfolios: \n",
            " [[0.06810772 0.00939684]\n",
            " [0.06679558 0.0102117 ]\n",
            " [0.06553492 0.01102656]\n",
            " [0.06432878 0.01184142]\n",
            " [0.06318029 0.01265629]\n",
            " [0.06209263 0.01347115]\n",
            " [0.06106907 0.01428601]\n",
            " [0.06011286 0.01510087]\n",
            " [0.05922729 0.01591574]\n",
            " [0.05841555 0.0167306 ]\n",
            " [0.05768077 0.01754546]\n",
            " [0.05702592 0.01836032]\n",
            " [0.05645379 0.01917519]\n",
            " [0.0559669  0.01999005]\n",
            " [0.0555675  0.02080491]\n",
            " [0.0552575  0.02161978]\n",
            " [0.05503839 0.02243464]\n",
            " [0.05491126 0.0232495 ]\n",
            " [0.05487677 0.02406436]\n",
            " [0.05493507 0.02487923]\n",
            " [0.05508588 0.02569409]\n",
            " [0.05532844 0.02650895]\n",
            " [0.05566154 0.02732381]\n",
            " [0.05608358 0.02813868]\n",
            " [0.05659257 0.02895354]\n",
            " [0.05718619 0.0297684 ]\n",
            " [0.05786182 0.03058326]\n",
            " [0.05861664 0.03139813]\n",
            " [0.05944763 0.03221299]\n",
            " [0.06035164 0.03302785]\n",
            " [0.06132544 0.03384271]\n",
            " [0.06236577 0.03465758]\n",
            " [0.06346934 0.03547244]\n",
            " [0.06463293 0.0362873 ]\n",
            " [0.06585336 0.03710216]\n",
            " [0.06712751 0.03791703]\n",
            " [0.06845239 0.03873189]\n",
            " [0.06982512 0.03954675]\n",
            " [0.07124293 0.04036161]\n",
            " [0.07270318 0.04117648]\n",
            " [0.07420336 0.04199134]\n",
            " [0.0757411  0.0428062 ]\n",
            " [0.07731417 0.04362106]\n",
            " [0.07892045 0.04443593]\n",
            " [0.08055794 0.04525079]\n",
            " [0.0822248  0.04606565]\n",
            " [0.08391926 0.04688052]\n",
            " [0.0856397  0.04769538]\n",
            " [0.08738456 0.04851024]\n",
            " [0.08915243 0.0493251 ]\n",
            " [0.09094196 0.05013997]\n",
            " [0.0927519  0.05095483]\n",
            " [0.09458106 0.05176969]\n",
            " [0.09642837 0.05258455]\n",
            " [0.0982928  0.05339942]\n",
            " [0.10017338 0.05421428]\n",
            " [0.10206923 0.05502914]\n",
            " [0.10397952 0.055844  ]\n",
            " [0.10590346 0.05665887]\n",
            " [0.10784032 0.05747373]\n",
            " [0.10978941 0.05828859]\n",
            " [0.11175011 0.05910345]\n",
            " [0.1137218  0.05991832]\n",
            " [0.11570392 0.06073318]\n",
            " [0.11769596 0.06154804]\n",
            " [0.1196974  0.0623629 ]\n",
            " [0.1217078  0.06317777]\n",
            " [0.1237267  0.06399263]\n",
            " [0.12575371 0.06480749]\n",
            " [0.12778844 0.06562235]\n",
            " [0.12983052 0.06643722]\n",
            " [0.13187961 0.06725208]\n",
            " [0.13393539 0.06806694]\n",
            " [0.13599756 0.06888181]\n",
            " [0.13806584 0.06969667]\n",
            " [0.14013994 0.07051153]\n",
            " [0.14221962 0.07132639]\n",
            " [0.14430463 0.07214126]\n",
            " [0.14639475 0.07295612]\n",
            " [0.14848976 0.07377098]\n",
            " [0.15058946 0.07458584]\n",
            " [0.15269365 0.07540071]\n",
            " [0.15480215 0.07621557]\n",
            " [0.15691479 0.07703043]\n",
            " [0.1590314  0.07784529]\n",
            " [0.16115182 0.07866016]\n",
            " [0.16327592 0.07947502]\n",
            " [0.16540353 0.08028988]\n",
            " [0.16753454 0.08110474]\n",
            " [0.16966881 0.08191961]\n",
            " [0.17180622 0.08273447]\n",
            " [0.17394666 0.08354933]\n",
            " [0.17609002 0.08436419]\n",
            " [0.17823618 0.08517906]\n",
            " [0.18038506 0.08599392]\n",
            " [0.18253655 0.08680878]\n",
            " [0.18469056 0.08762364]\n",
            " [0.18684701 0.08843851]\n",
            " [0.18900581 0.08925337]\n",
            " [0.19116688 0.09006823]]\n"
          ]
        }
      ],
      "source": [
        "naive_risks = []\n",
        "naive_returns = []\n",
        "\n",
        "for x in np.arange(0, 1, 0.01):\n",
        "  weights = [x, 1-x]\n",
        "  risk = np.matmul((np.matmul(weights,cov)),np.transpose(weights)) * trading_days_in_year\n",
        "  naive_risks.append(np.sqrt(risk))\n",
        "\n",
        "  #obtain expected portfolio annualized return for the \n",
        "  #efficient set portfolios, for trading days = 251\n",
        "  ret = trading_days_in_year*(np.matmul(weights,r))\n",
        "  naive_returns.append(ret)\n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[naive_risks, naive_returns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2wJgflp2eJ2c",
        "outputId": "3e2b9150-e1b1-4f79-f0c2-2504043629e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NoPoints = len(naive_risks)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(naive_risks, naive_returns, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-x_ZCjwg57n"
      },
      "source": [
        "# Combined Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "DpqNZRCtgYQK",
        "outputId": "90427990-9bd3-417a-9daa-7ea867419d5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(riskPoint, retPoint, s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(naive_risks, naive_returns, s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "3sTlOQOIhTCZ",
        "outputId": "83326b72-dfa4-452e-d9f9-01109cc46dd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          high       low\n",
              "high  0.000148 -0.000018\n",
              "low  -0.000018  0.000018"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-706ffbe3-9e9c-400f-b473-53af05007ede\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.000018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>-0.000018</td>\n",
              "      <td>0.000018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-706ffbe3-9e9c-400f-b473-53af05007ede')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-706ffbe3-9e9c-400f-b473-53af05007ede button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-706ffbe3-9e9c-400f-b473-53af05007ede');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5N-KuYQxAmQ",
        "outputId": "e88a72a7-87a2-4169-bae8-3f9e12705020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9864.007665920406\n",
            "2485729.9318119423\n",
            "0.00014831962827593315\n",
            "0.03737654632553515\n",
            "0.19333014851681862\n"
          ]
        }
      ],
      "source": [
        "print(high_risk[\"Close\"].var())\n",
        "print(high_risk[\"Close\"].var() * trading_days_in_year)\n",
        "print(high_risk[\"Close\"].pct_change().var())\n",
        "print(high_risk[\"Close\"].pct_change().var() * trading_days_in_year)\n",
        "print(np.sqrt(high_risk[\"Close\"].pct_change().var() * trading_days_in_year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "CU2640mM0RnU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOxwTTprqqmxsYXmmOXsyfl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}