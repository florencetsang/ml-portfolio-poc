{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4PiESSn5Wx4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import optimize \n",
        "from scipy import stats\n",
        "from scipy.optimize import linprog\n",
        "import numpy as np\n",
        "from os import path\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import date\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26v-Cnl1lg6t"
      },
      "outputs": [],
      "source": [
        "MA_DAYS = 25\n",
        "trading_days_in_year = 252"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRi8JtX9gAb0"
      },
      "source": [
        "# Import raw data from yahoo finance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puHUCbHEMIoP",
        "outputId": "9b030a8b-aff3-4bd3-fd70-55c4a613acdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_files_path_prefix = \"/content/drive/MyDrive\"\n",
        "data_files_path = \"ML-Portfolio-Data\"\n",
        "data_files_path = path.join(data_files_path_prefix, data_files_path)\n",
        "\n",
        "high_risk_file = 'SPY.csv'\n",
        "low_risk_file = 'IEF.csv'\n",
        "high_risk = pd.read_csv(path.join(data_files_path, high_risk_file))\n",
        "low_risk = pd.read_csv(path.join(data_files_path, low_risk_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmNxB-dXPdjh"
      },
      "outputs": [],
      "source": [
        "# Read files from the same directory\n",
        "#high_risk = pd.read_csv('SPY.csv')\n",
        "#low_risk = pd.read_csv('IEF.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEp0KCBSE3uX",
        "outputId": "c4ab18db-248a-4678-ba64-697b3eee1f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5147, 7)\n",
            "(5147, 7)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)\n",
        "print(low_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffmGB06pT8_q",
        "outputId": "6b5b4b36-5764-4e01-bb4e-bcc4bd9f7b4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939  47532200\n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453  44669900\n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054  66571900\n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895  51772900\n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496  47191300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DY4FPgNCEssV",
        "outputId": "e64d50dd-d52f-477e-98ab-c82d49d61ee3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300\n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600\n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400\n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300\n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d597fd2-2830-4196-88f7-940c75a27333\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d597fd2-2830-4196-88f7-940c75a27333')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d597fd2-2830-4196-88f7-940c75a27333 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d597fd2-2830-4196-88f7-940c75a27333');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnPRd0TkrMsN"
      },
      "source": [
        "# Build Dataset for ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvSntSIA4qiC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZ0sQ3rTgn4"
      },
      "source": [
        "## Enrich data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NraBWrzef4BA"
      },
      "source": [
        "### Calculate daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e03XXEgf1r4"
      },
      "outputs": [],
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Daily Return\"]  = market_data['Close'] - market_data['Open']\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dqBMvFWo4oQ"
      },
      "source": [
        "### Calculate moving average (MA) of daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9EW2Fzjo9ly"
      },
      "outputs": [],
      "source": [
        "def add_moving_average(market_data, ma_days):\n",
        "    temp_vars = []\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data[temp_var] = market_data[\"Daily Return\"].shift(i)\n",
        "        temp_vars.append(temp_var)\n",
        "\n",
        "    market_data[\"MA\"] = market_data[temp_vars].mean(axis=1)\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data.drop(temp_var, axis = 1, inplace = True)\n",
        "\n",
        "add_moving_average(high_risk, MA_DAYS)\n",
        "add_moving_average(low_risk, MA_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xp5iRKB4FeRZ",
        "outputId": "fab62ef6-69a0-44b8-9a88-7539e26ddcbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "5142  2022-12-30  380.640015  382.579987  378.429993  382.429993  382.429993   \n",
              "5143  2023-01-03  384.369995  386.429993  377.829987  380.820007  380.820007   \n",
              "5144  2023-01-04  383.179993  385.880005  380.000000  383.760010  383.760010   \n",
              "5145  2023-01-05  381.720001  381.839996  378.760010  379.380005  379.380005   \n",
              "5146  2023-01-06  382.609985  389.250000  379.410004  388.079987  388.079987   \n",
              "\n",
              "         Volume  Daily Return        MA  \n",
              "5142   83975100      1.789978 -0.368799  \n",
              "5143   74850700     -3.549988 -0.530798  \n",
              "5144   85934100      0.580017 -0.380398  \n",
              "5145   76970500     -2.339996 -0.441199  \n",
              "5146  104041300      5.470002 -0.709999  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76fc994d-cc76-4254-811d-9980b55f3c7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>380.640015</td>\n",
              "      <td>382.579987</td>\n",
              "      <td>378.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>83975100</td>\n",
              "      <td>1.789978</td>\n",
              "      <td>-0.368799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>384.369995</td>\n",
              "      <td>386.429993</td>\n",
              "      <td>377.829987</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>74850700</td>\n",
              "      <td>-3.549988</td>\n",
              "      <td>-0.530798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>383.179993</td>\n",
              "      <td>385.880005</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>85934100</td>\n",
              "      <td>0.580017</td>\n",
              "      <td>-0.380398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>381.720001</td>\n",
              "      <td>381.839996</td>\n",
              "      <td>378.760010</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>76970500</td>\n",
              "      <td>-2.339996</td>\n",
              "      <td>-0.441199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>382.609985</td>\n",
              "      <td>389.250000</td>\n",
              "      <td>379.410004</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>104041300</td>\n",
              "      <td>5.470002</td>\n",
              "      <td>-0.709999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76fc994d-cc76-4254-811d-9980b55f3c7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76fc994d-cc76-4254-811d-9980b55f3c7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76fc994d-cc76-4254-811d-9980b55f3c7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ],
      "source": [
        "high_risk.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtkml8ylGG47",
        "outputId": "430db8fc-9fe4-4b1c-a68a-d12228a2cabe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date       Open       High        Low      Close  Adj Close  \\\n",
              "5142  2022-12-30  95.860001  96.269997  95.620003  95.779999  95.779999   \n",
              "5143  2023-01-03  96.910004  97.000000  96.339996  96.529999  96.529999   \n",
              "5144  2023-01-04  97.339996  97.419998  96.989998  97.269997  97.269997   \n",
              "5145  2023-01-05  96.699997  97.220001  96.570000  97.129997  97.129997   \n",
              "5146  2023-01-06  97.169998  98.430000  97.080002  98.379997  98.379997   \n",
              "\n",
              "       Volume  Daily Return        MA  \n",
              "5142  5039800     -0.080002  0.050399  \n",
              "5143  6808300     -0.380005  0.025599  \n",
              "5144  7800100     -0.069999  0.025599  \n",
              "5145  3177900      0.430000  0.043600  \n",
              "5146  6807700      1.209999  0.050399  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f17aae12-720c-45cf-a8e3-b58228d1b59e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.860001</td>\n",
              "      <td>96.269997</td>\n",
              "      <td>95.620003</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>5039800</td>\n",
              "      <td>-0.080002</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.910004</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>96.339996</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>6808300</td>\n",
              "      <td>-0.380005</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.339996</td>\n",
              "      <td>97.419998</td>\n",
              "      <td>96.989998</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>7800100</td>\n",
              "      <td>-0.069999</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>96.699997</td>\n",
              "      <td>97.220001</td>\n",
              "      <td>96.570000</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>3177900</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.043600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>97.169998</td>\n",
              "      <td>98.430000</td>\n",
              "      <td>97.080002</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>6807700</td>\n",
              "      <td>1.209999</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f17aae12-720c-45cf-a8e3-b58228d1b59e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f17aae12-720c-45cf-a8e3-b58228d1b59e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f17aae12-720c-45cf-a8e3-b58228d1b59e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ],
      "source": [
        "low_risk.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6a-Fc3EZNxB"
      },
      "source": [
        "### Calculate ROE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42UscmnQZMpE"
      },
      "outputs": [],
      "source": [
        "def add_roe(market_data):    \n",
        "    market_data[\"Next Close\"] = market_data[\"Close\"].shift(-1)\n",
        "    market_data[\"ROE\"] = (market_data[\"Next Close\"] - market_data[\"Close\"]) / market_data['Close']\n",
        "\n",
        "add_roe(high_risk)\n",
        "add_roe(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5kEAXakgkCs"
      },
      "outputs": [],
      "source": [
        "def add_roe_binary(market_data, tau=-0.005):    \n",
        "    market_data[\"ROE Binary\"] = np.where(market_data[\"ROE\"].values < tau, 0, 1)\n",
        "\n",
        "add_roe_binary(high_risk)\n",
        "add_roe_binary(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKK4t3UVfl_6",
        "outputId": "5dee819f-f1d9-4358-97c0-5ad4314a930a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  \\\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939   \n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453   \n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054   \n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895   \n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496   \n",
              "\n",
              "     Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0  47532200      1.620002  1.620002   91.160004  0.002419           1  \n",
              "1  44669900      0.670006  1.145004   88.779999 -0.026108           0  \n",
              "2  66571900     -2.099998  0.063337   86.790001 -0.022415           0  \n",
              "3  51772900     -1.709999 -0.379997   83.769997 -0.034797           0  \n",
              "4  47191300     -2.720001 -0.847998   86.589996  0.033664           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978518de-7f05-4cc8-856c-c619ab4021b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>0.002419</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "      <td>0.670006</td>\n",
              "      <td>1.145004</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "      <td>-2.099998</td>\n",
              "      <td>0.063337</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>-0.022415</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "      <td>-1.709999</td>\n",
              "      <td>-0.379997</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>-0.034797</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "      <td>-2.720001</td>\n",
              "      <td>-0.847998</td>\n",
              "      <td>86.589996</td>\n",
              "      <td>0.033664</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978518de-7f05-4cc8-856c-c619ab4021b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-978518de-7f05-4cc8-856c-c619ab4021b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-978518de-7f05-4cc8-856c-c619ab4021b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uurD8aCKfmH3",
        "outputId": "a2ad0cca-e97e-41c9-f8f2-a6090714f114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume  \\\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300   \n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600   \n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400   \n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300   \n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300   \n",
              "\n",
              "   Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0     -0.170005 -0.170005   82.519997  0.009172           1  \n",
              "1      0.469994  0.149994   82.860001  0.004120           1  \n",
              "2      0.320000  0.206663   83.500000  0.007724           1  \n",
              "3      0.480003  0.274998   83.919998  0.005030           1  \n",
              "4      0.239998  0.267998   83.239998 -0.008103           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "      <td>0.469994</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>0.004120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.206663</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>0.007724</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "      <td>0.480003</td>\n",
              "      <td>0.274998</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "      <td>0.239998</td>\n",
              "      <td>0.267998</td>\n",
              "      <td>83.239998</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L1SeZ_ggNPL"
      },
      "source": [
        "## Build feature space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKS0pN_Ola5g"
      },
      "outputs": [],
      "source": [
        "def remove_for_ma(market_data, ma_days):\n",
        "  return market_data[ma_days:]\n",
        "\n",
        "high_risk = remove_for_ma(high_risk, MA_DAYS)\n",
        "low_risk = remove_for_ma(low_risk, MA_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnHuHNjPmrQO",
        "outputId": "edf5a6f6-554a-49e5-9027-313f0644fdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5122, 12)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9hQrj2LMVvF5",
        "outputId": "7990b60d-f780-4731-842f-0a7eb69865d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  51099500      0.930000  0.088801   88.779999 -0.008488           0  \n",
              "26  67250900      0.290001  0.073600   90.000000  0.013742           1  \n",
              "27  38622200      0.250000  0.167600   90.660004  0.007333           1  \n",
              "28  33998400      1.560006  0.298400   91.699997  0.011471           1  \n",
              "29  41416600      0.559998  0.429600   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>51099500</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.088801</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>67250900</td>\n",
              "      <td>0.290001</td>\n",
              "      <td>0.073600</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>38622200</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.167600</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>33998400</td>\n",
              "      <td>1.560006</td>\n",
              "      <td>0.298400</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>41416600</td>\n",
              "      <td>0.559998</td>\n",
              "      <td>0.429600</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p3olOzMyWVDI",
        "outputId": "fbef2ff8-6118-4cd5-efe6-23407b6473dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69d00051-9937-4bdf-973d-48b7591486b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69d00051-9937-4bdf-973d-48b7591486b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69d00051-9937-4bdf-973d-48b7591486b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69d00051-9937-4bdf-973d-48b7591486b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L7qIEJvdIvp"
      },
      "outputs": [],
      "source": [
        "def standardize_columns(market_data, columns):\n",
        "  for column in columns:\n",
        "    market_data.loc[:,column] = market_data[column]/market_data[column].std()\n",
        "\n",
        "standardize_columns(high_risk, ['Volume', 'Daily Return', 'MA'])\n",
        "standardize_columns(low_risk, ['Volume', 'Daily Return', 'MA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tqgwASZBIDOa",
        "outputId": "95b569b3-eb6f-4a68-c497-de0ad0cb7f38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.550024      0.479605  0.276737   88.779999 -0.008488           0  \n",
              "26  0.723874      0.149555  0.229367   90.000000  0.013742           1  \n",
              "27  0.415721      0.128926  0.522307   90.660004  0.007333           1  \n",
              "28  0.365951      0.804501  0.929931   91.699997  0.011471           1  \n",
              "29  0.445799      0.288793  1.338801   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-55dkiIJIal",
        "outputId": "2ea8db78-0839-4dbc-d3b4-4cf4c800620e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acaf1370-1b86-4c17-83e0-01426df1f30b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acaf1370-1b86-4c17-83e0-01426df1f30b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "49t7Zc8bKsUQ",
        "outputId": "93af6037-374b-48ef-dc35-1f3e3495a80f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date  l_Daily Return      l_MA  l_Volume  h_Daily Return  \\\n",
              "25    2002-09-04        0.135391  0.912126  0.023505        0.479605   \n",
              "26    2002-09-05       -0.203112  0.564337  0.017606        0.149555   \n",
              "27    2002-09-06       -0.710926  0.216542  0.009791        0.128926   \n",
              "28    2002-09-09       -0.609368 -0.216563  0.027002        0.804501   \n",
              "29    2002-09-10        1.184878 -0.144378  0.006507        0.288793   \n",
              "...          ...             ...       ...       ...             ...   \n",
              "5142  2022-12-30       -0.270837  0.826825  1.532486        0.923099   \n",
              "5143  2023-01-03       -1.286460  0.419968  2.070246       -1.830743   \n",
              "5144  2023-01-04       -0.236973  0.419968  2.371829        0.299117   \n",
              "5145  2023-01-05        1.455712  0.715269  0.966325       -1.206745   \n",
              "5146  2023-01-06        4.096301  0.826824  2.070063        2.820901   \n",
              "\n",
              "          h_MA  h_Volume  h_ROE Binary  \n",
              "25    0.276737  0.550024             0  \n",
              "26    0.229367  0.723874             1  \n",
              "27    0.522307  0.415721             1  \n",
              "28    0.929931  0.365951             1  \n",
              "29    1.338801  0.445799             0  \n",
              "...        ...       ...           ...  \n",
              "5142 -1.149319  0.903889             1  \n",
              "5143 -1.654172  0.805676             1  \n",
              "5144 -1.185467  0.924976             0  \n",
              "5145 -1.374945  0.828493             1  \n",
              "5146 -2.212630  1.119878             1  \n",
              "\n",
              "[5122 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Daily Return</th>\n",
              "      <th>l_MA</th>\n",
              "      <th>l_Volume</th>\n",
              "      <th>h_Daily Return</th>\n",
              "      <th>h_MA</th>\n",
              "      <th>h_Volume</th>\n",
              "      <th>h_ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>-0.270837</td>\n",
              "      <td>0.826825</td>\n",
              "      <td>1.532486</td>\n",
              "      <td>0.923099</td>\n",
              "      <td>-1.149319</td>\n",
              "      <td>0.903889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>-1.286460</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.070246</td>\n",
              "      <td>-1.830743</td>\n",
              "      <td>-1.654172</td>\n",
              "      <td>0.805676</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>-0.236973</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.371829</td>\n",
              "      <td>0.299117</td>\n",
              "      <td>-1.185467</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>1.455712</td>\n",
              "      <td>0.715269</td>\n",
              "      <td>0.966325</td>\n",
              "      <td>-1.206745</td>\n",
              "      <td>-1.374945</td>\n",
              "      <td>0.828493</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>4.096301</td>\n",
              "      <td>0.826824</td>\n",
              "      <td>2.070063</td>\n",
              "      <td>2.820901</td>\n",
              "      <td>-2.212630</td>\n",
              "      <td>1.119878</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows  8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "ml_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']]\n",
        "ml_master_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zmM8pF0Nxl4"
      },
      "source": [
        "## Build graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjzCkZxbRPke"
      },
      "outputs": [],
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 500\n",
        "torch.manual_seed(42)\n",
        "lambda1 = 1e-3 #0.5\n",
        "lambda2 = 1e-3 #0.5\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjgtH2co3IPg"
      },
      "outputs": [],
      "source": [
        "folds=10\n",
        "splits=KFold(n_splits=folds,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUEtsz9ZRRFN"
      },
      "outputs": [],
      "source": [
        "#no cross-validation\n",
        "\n",
        "def train_and_get_a_b(dataset):\n",
        "\n",
        "  a = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  b = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "\n",
        "  optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "  X_tensor = torch.from_numpy(dataset[:,:-1])\n",
        "  Y_tensor = torch.from_numpy(dataset[:,-1])\n",
        "    \n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "      yhat = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "\n",
        "      loss = loss_fn(yhat, Y_tensor)\n",
        "      loss.backward()   \n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "  return a,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R2xXpWs2tus"
      },
      "source": [
        "# Build Dataset for MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aqbtJ5LC2E7x",
        "outputId": "162f1b1e-5b87-4c52-a484-5d1c52738e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date    l_Close     h_Close\n",
              "25    2002-09-04  85.199997   89.540001\n",
              "26    2002-09-05  85.540001   88.779999\n",
              "27    2002-09-06  84.879997   90.000000\n",
              "28    2002-09-09  84.760002   90.660004\n",
              "29    2002-09-10  85.059998   91.699997\n",
              "...          ...        ...         ...\n",
              "5142  2022-12-30  95.779999  382.429993\n",
              "5143  2023-01-03  96.529999  380.820007\n",
              "5144  2023-01-04  97.269997  383.760010\n",
              "5145  2023-01-05  97.129997  379.380005\n",
              "5146  2023-01-06  98.379997  388.079987\n",
              "\n",
              "[5122 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2a34618-c657-430e-ac98-7c7dca5fc38d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Close</th>\n",
              "      <th>h_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>89.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>88.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>90.660004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>91.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>382.429993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>380.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>383.760010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>379.380005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>388.079987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows  3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a34618-c657-430e-ac98-7c7dca5fc38d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "mv_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Close','h_Close']]\n",
        "mv_master_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekt1011K23kV"
      },
      "outputs": [],
      "source": [
        "def get_mv_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(mv_master_dataset['l_Date']) > startdate) & (pd.to_datetime(mv_master_dataset['l_Date']) <= enddate)\n",
        "  subset = mv_master_dataset.loc[mask]\n",
        "  dataset = subset[['l_Close','h_Close']]\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ay84qKK3kSO"
      },
      "outputs": [],
      "source": [
        "def get_annual_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change()\n",
        "    annual_return = daily_return.mean() * trading_days_in_year\n",
        "    daily_covariance = daily_return.cov()\n",
        "    annual_covariance = daily_covariance * trading_days_in_year\n",
        "    return annual_return, annual_covariance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBzfeFvH32g4"
      },
      "outputs": [],
      "source": [
        "def get_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change().mean()\n",
        "    daily_covariance = data.pct_change().cov()\n",
        "    return daily_return * len(data), daily_covariance * len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65SYaxYzFVOi"
      },
      "outputs": [],
      "source": [
        "#function obtains maximal return portfolio using linear programming\n",
        "\n",
        "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
        "   \n",
        "    c = (np.multiply(-1, MeanReturns))\n",
        "    A = np.ones([PortfolioSize,1]).T\n",
        "    b=[1] \n",
        "    res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n",
        "    \n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESkZdqjLb_MH"
      },
      "outputs": [],
      "source": [
        "#function obtains minimal risk portfolio \n",
        "\n",
        "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
        "    \n",
        "    def  f(x, CovarReturns):\n",
        "        func = np.matmul(np.matmul(x, CovarReturns), x.T) \n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b \n",
        "        return constraintVal\n",
        "    \n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
        "                             constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw2-EUMt4Otu"
      },
      "outputs": [],
      "source": [
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WvoS-8a6YvW"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_data(date):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "    \n",
        "  low_risk_mask = (pd.to_datetime(low_risk['Date']) > startdate) & (pd.to_datetime(low_risk['Date']) <= enddate)\n",
        "  high_risk_mask = (pd.to_datetime(high_risk['Date']) > startdate) & (pd.to_datetime(high_risk['Date']) <= enddate)\n",
        "  low_risk_backtest_data = low_risk.loc[low_risk_mask]\n",
        "  high_risk_backtest_data = high_risk.loc[high_risk_mask]\n",
        "\n",
        "  return low_risk_backtest_data, high_risk_backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGK6T6AW7Yg4"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwpNskex6YvX"
      },
      "outputs": [],
      "source": [
        "def calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, low_risk_weight, high_risk_weight):\n",
        "  low_return = calculate_backtest_return(low_risk_backtest_data)\n",
        "  high_return = calculate_backtest_return(high_risk_backtest_data)\n",
        "  # print(low_return)\n",
        "  # print(high_return)\n",
        "  return low_return * low_risk_weight + high_return * high_risk_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otburto36YvX"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_return(date, low_risk_weight, high_risk_weight):\n",
        "  low_risk_backtest_data, high_risk_backtest_data = get_mv_backtest_data(date)\n",
        "  return calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, low_risk_weight, high_risk_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyH6QC07N4X"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbj-yDR504Fv"
      },
      "outputs": [],
      "source": [
        "first_date = date(2003,9,21)\n",
        "last_date = date(2023,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v4UTD431hJ4"
      },
      "outputs": [],
      "source": [
        "delta_50weeks = timedelta(weeks=50)\n",
        "delta_1week = timedelta(weeks=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKt0kekQ21Ts",
        "outputId": "6685a6b0-c03b-4b12-ca35-af29e1059a87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2003-09-21', '2003-09-28', '2003-10-05', '2003-10-12',\n",
              "               '2003-10-19', '2003-10-26', '2003-11-02', '2003-11-09',\n",
              "               '2003-11-16', '2003-11-23',\n",
              "               ...\n",
              "               '2022-10-30', '2022-11-06', '2022-11-13', '2022-11-20',\n",
              "               '2022-11-27', '2022-12-04', '2022-12-11', '2022-12-18',\n",
              "               '2022-12-25', '2023-01-01'],\n",
              "              dtype='datetime64[ns]', length=1007, freq='W-SUN')"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "daterange = pd.date_range(first_date, last_date, freq='1W')\n",
        "daterange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV3MvASZ7kOM"
      },
      "outputs": [],
      "source": [
        "def get_ml_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(ml_master_dataset['l_Date']) > startdate) & (pd.to_datetime(ml_master_dataset['l_Date']) <= enddate)\n",
        "  subset = ml_master_dataset.loc[mask]\n",
        "  # print(subset)\n",
        "  dataset = subset[['l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']].to_numpy()\n",
        "  # print(dataset)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Po5CtXBzyxS"
      },
      "source": [
        "### First date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fra6gOlGT1-v",
        "outputId": "cc4717b7-0df2-47ab-876b-91feddf8ee9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.10155789,  1.89647755,  0.02441736, ..., -0.97480731,\n",
              "         0.57250387,  1.        ],\n",
              "       [ 0.40625526,  1.88335059,  0.04092873, ..., -0.59959326,\n",
              "         0.8560541 ,  0.        ],\n",
              "       [ 0.16925525,  1.88991473,  0.02873525, ..., -0.83893149,\n",
              "         0.86063301,  1.        ],\n",
              "       ...,\n",
              "       [ 0.20311239,  0.702162  ,  0.02435655, ...,  0.53227856,\n",
              "         0.40786757,  1.        ],\n",
              "       [ 1.11718079,  1.03027115,  0.05385199, ...,  0.41510118,\n",
              "         0.3432117 ,  1.        ],\n",
              "       [-0.06772444,  1.33868853,  0.04019894, ...,  0.66191837,\n",
              "         0.32553542,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "dataset = get_ml_dataset_for_date(first_date)\n",
        "dataset[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWm27_faerS",
        "outputId": "4c142090-c425-46a0-f3e4-e1d54b752aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 1.2250968985965647\n",
            "Epoch: 10. Loss: 1.0422664556524388\n",
            "Epoch: 20. Loss: 0.9103199651473237\n",
            "Epoch: 30. Loss: 0.8211627365206585\n",
            "Epoch: 40. Loss: 0.7621501754153689\n",
            "Epoch: 50. Loss: 0.7225548587061368\n",
            "Epoch: 60. Loss: 0.6954737927837602\n",
            "Epoch: 70. Loss: 0.6767014150071979\n",
            "Epoch: 80. Loss: 0.6635699476207669\n",
            "Epoch: 90. Loss: 0.6543132706623938\n",
            "Epoch: 100. Loss: 0.6477360885029361\n",
            "Epoch: 110. Loss: 0.6430221585728905\n",
            "Epoch: 120. Loss: 0.6396116532648428\n",
            "Epoch: 130. Loss: 0.6371191459597229\n",
            "Epoch: 140. Loss: 0.635278073957452\n",
            "Epoch: 150. Loss: 0.6339030752274836\n",
            "Epoch: 160. Loss: 0.6328644511700781\n",
            "Epoch: 170. Loss: 0.6320708338895114\n",
            "Epoch: 180. Loss: 0.6314573915018703\n",
            "Epoch: 190. Loss: 0.6309777707686528\n",
            "Epoch: 200. Loss: 0.6305985665087154\n",
            "Epoch: 210. Loss: 0.6302955051416969\n",
            "Epoch: 220. Loss: 0.6300507962110538\n",
            "Epoch: 230. Loss: 0.6298512837528443\n",
            "Epoch: 240. Loss: 0.6296871483410416\n",
            "Epoch: 250. Loss: 0.6295509903413822\n",
            "Epoch: 260. Loss: 0.6294371785102312\n",
            "Epoch: 270. Loss: 0.6293413842983838\n",
            "Epoch: 280. Loss: 0.6292602468248716\n",
            "Epoch: 290. Loss: 0.6291911302889445\n",
            "Epoch: 300. Loss: 0.6291319471250912\n",
            "Epoch: 310. Loss: 0.6290810281684981\n",
            "Epoch: 320. Loss: 0.6290370266219606\n",
            "Epoch: 330. Loss: 0.6289988464656815\n",
            "Epoch: 340. Loss: 0.6289655886479608\n",
            "Epoch: 350. Loss: 0.6289365102917657\n",
            "Epoch: 360. Loss: 0.6289109934924184\n",
            "Epoch: 370. Loss: 0.628888521232558\n",
            "Epoch: 380. Loss: 0.6288686586180415\n",
            "Epoch: 390. Loss: 0.6288510381231767\n",
            "Epoch: 400. Loss: 0.628835347881967\n",
            "Epoch: 410. Loss: 0.6288213223134048\n",
            "Epoch: 420. Loss: 0.6288087345510793\n",
            "Epoch: 430. Loss: 0.628797390280147\n",
            "Epoch: 440. Loss: 0.6287871226819385\n",
            "Epoch: 450. Loss: 0.6287777882581012\n",
            "Epoch: 460. Loss: 0.6287692633592182\n",
            "Epoch: 470. Loss: 0.628761441282425\n",
            "Epoch: 480. Loss: 0.628754229832236\n",
            "Epoch: 490. Loss: 0.6287475492612717\n"
          ]
        }
      ],
      "source": [
        "a,b = train_and_get_a_b(dataset[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsYhNrSeoDv",
        "outputId": "61e19e31-8e53-4c5d-f6cb-78d1d19b50d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6920, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "  print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsH_YCVPyOer"
      },
      "outputs": [],
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJY6MNe079u",
        "outputId": "ccb5fecb-b23d-42e8-fbe7-48a0511ccc95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "weight = calculate_ml_portfolio_weights(y_test.numpy(), 0.5)\n",
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkX6whwN4KX0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_data(date, weight):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "\n",
        "  investment = low_risk if weight == 0 else high_risk\n",
        "    \n",
        "  backtest_mask = (pd.to_datetime(investment['Date']) > startdate) & (pd.to_datetime(investment['Date']) <= enddate)\n",
        "  backtest_data = investment.loc[backtest_mask]\n",
        "\n",
        "  return backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7grWmruL4LNu"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGPtDN524CA0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_return(date, weight):\n",
        "  backtest_data = get_backtest_data(date, weight)\n",
        "  return calculate_backtest_return(backtest_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWzbQZb01qHF",
        "outputId": "ab3858d6-c15f-4a08-9339-785658d211c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102.849998"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "backtest_data = get_backtest_data(first_date, weight)\n",
        "backtest_data.iloc[-1]['Close']\n",
        "backtest_data.iloc[0]['Open']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxw0Vpct44Bq",
        "outputId": "870a2d9c-6aaa-48e1-8ddf-107f586989d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.028196412799152443"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "get_backtest_return(first_date, weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5v5C2j_0IQw"
      },
      "source": [
        "## Back test for all range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgECBqg00_LI"
      },
      "source": [
        "### ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8zIjtzG4xOv",
        "outputId": "d8a6c399-4c4f-4cbd-f4e1-f2cecfaf72e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 430. Loss: 0.5791454423362592\n",
            "Epoch: 440. Loss: 0.579143105818223\n",
            "Epoch: 450. Loss: 0.5791411383938524\n",
            "Epoch: 460. Loss: 0.5791394816412584\n",
            "Epoch: 470. Loss: 0.5791380864125462\n",
            "Epoch: 480. Loss: 0.5791369113555456\n",
            "Epoch: 490. Loss: 0.5791359216725754\n",
            "tensor(0.9895, dtype=torch.float64)\n",
            "2021-03-07 00:00:00\n",
            "Epoch: 0. Loss: 1.9445291614467444\n",
            "Epoch: 10. Loss: 0.9326522619547405\n",
            "Epoch: 20. Loss: 0.6639824427146934\n",
            "Epoch: 30. Loss: 0.609756859566522\n",
            "Epoch: 40. Loss: 0.5981846293448686\n",
            "Epoch: 50. Loss: 0.5939786154194254\n",
            "Epoch: 60. Loss: 0.5911794486064991\n",
            "Epoch: 70. Loss: 0.5889668295230647\n",
            "Epoch: 80. Loss: 0.5871583291896727\n",
            "Epoch: 90. Loss: 0.5856703403978939\n",
            "Epoch: 100. Loss: 0.5844444590642718\n",
            "Epoch: 110. Loss: 0.5834341948722712\n",
            "Epoch: 120. Loss: 0.5826014073832411\n",
            "Epoch: 130. Loss: 0.5819146539729523\n",
            "Epoch: 140. Loss: 0.5813480336331658\n",
            "Epoch: 150. Loss: 0.5808802434342614\n",
            "Epoch: 160. Loss: 0.580493783231326\n",
            "Epoch: 170. Loss: 0.5801742862106741\n",
            "Epoch: 180. Loss: 0.5799099597924908\n",
            "Epoch: 190. Loss: 0.5796911222324412\n",
            "Epoch: 200. Loss: 0.5795098207942464\n",
            "Epoch: 210. Loss: 0.5793595184315664\n",
            "Epoch: 220. Loss: 0.5792348373722636\n",
            "Epoch: 230. Loss: 0.5791313495915988\n",
            "Epoch: 240. Loss: 0.5790454057150309\n",
            "Epoch: 250. Loss: 0.5789739953079607\n",
            "Epoch: 260. Loss: 0.5789146327478145\n",
            "Epoch: 270. Loss: 0.5788652639264986\n",
            "Epoch: 280. Loss: 0.5788241899099952\n",
            "Epoch: 290. Loss: 0.5787900044064661\n",
            "Epoch: 300. Loss: 0.5787615424868002\n",
            "Epoch: 310. Loss: 0.5787378384835916\n",
            "Epoch: 320. Loss: 0.5787180913853347\n",
            "Epoch: 330. Loss: 0.5787016363589093\n",
            "Epoch: 340. Loss: 0.5786879212891846\n",
            "Epoch: 350. Loss: 0.5786764874313958\n",
            "Epoch: 360. Loss: 0.5786669534392964\n",
            "Epoch: 370. Loss: 0.5786590021676276\n",
            "Epoch: 380. Loss: 0.5786523697573493\n",
            "Epoch: 390. Loss: 0.5786468366013298\n",
            "Epoch: 400. Loss: 0.5786422198607717\n",
            "Epoch: 410. Loss: 0.5786383672617709\n",
            "Epoch: 420. Loss: 0.5786351519496397\n",
            "Epoch: 430. Loss: 0.5786324682180315\n",
            "Epoch: 440. Loss: 0.5786302279621502\n",
            "Epoch: 450. Loss: 0.5786283577317628\n",
            "Epoch: 460. Loss: 0.5786267962814108\n",
            "Epoch: 470. Loss: 0.5786254925330483\n",
            "Epoch: 480. Loss: 0.5786244038809895\n",
            "Epoch: 490. Loss: 0.5786234947811353\n",
            "tensor(0.9008, dtype=torch.float64)\n",
            "2021-03-14 00:00:00\n",
            "Epoch: 0. Loss: 1.0781818763283175\n",
            "Epoch: 10. Loss: 0.8407164793493881\n",
            "Epoch: 20. Loss: 0.7163388609430892\n",
            "Epoch: 30. Loss: 0.6640743319014223\n",
            "Epoch: 40. Loss: 0.6397636113279277\n",
            "Epoch: 50. Loss: 0.6246174114146305\n",
            "Epoch: 60. Loss: 0.6139517528003869\n",
            "Epoch: 70. Loss: 0.6060302888832795\n",
            "Epoch: 80. Loss: 0.5999794757295349\n",
            "Epoch: 90. Loss: 0.5952776546362181\n",
            "Epoch: 100. Loss: 0.5915778873611792\n",
            "Epoch: 110. Loss: 0.5886354095762918\n",
            "Epoch: 120. Loss: 0.586272403834175\n",
            "Epoch: 130. Loss: 0.584357685437391\n",
            "Epoch: 140. Loss: 0.5827934721229269\n",
            "Epoch: 150. Loss: 0.5815062072562712\n",
            "Epoch: 160. Loss: 0.5804400268518546\n",
            "Epoch: 170. Loss: 0.5795520656122641\n",
            "Epoch: 180. Loss: 0.5788090727903747\n",
            "Epoch: 190. Loss: 0.5781849665308569\n",
            "Epoch: 200. Loss: 0.5776590607081278\n",
            "Epoch: 210. Loss: 0.5772147732741071\n",
            "Epoch: 220. Loss: 0.5768386793789797\n",
            "Epoch: 230. Loss: 0.5765198117083804\n",
            "Epoch: 240. Loss: 0.5762491386092209\n",
            "Epoch: 250. Loss: 0.5760191706544596\n",
            "Epoch: 260. Loss: 0.5758236605645373\n",
            "Epoch: 270. Loss: 0.575657371509943\n",
            "Epoch: 280. Loss: 0.5755158959650056\n",
            "Epoch: 290. Loss: 0.5753955123306774\n",
            "Epoch: 300. Loss: 0.575293070110332\n",
            "Epoch: 310. Loss: 0.5752058969452977\n",
            "Epoch: 320. Loss: 0.5751317226057145\n",
            "Epoch: 330. Loss: 0.5750686163055152\n",
            "Epoch: 340. Loss: 0.5750149346212773\n",
            "Epoch: 350. Loss: 0.5749692779508456\n",
            "Epoch: 360. Loss: 0.5749304539242551\n",
            "Epoch: 370. Loss: 0.5748974465291634\n",
            "Epoch: 380. Loss: 0.5748693899725498\n",
            "Epoch: 390. Loss: 0.57484554649553\n",
            "Epoch: 400. Loss: 0.5748252875068464\n",
            "Epoch: 410. Loss: 0.5748080775155405\n",
            "Epoch: 420. Loss: 0.5747934604334783\n",
            "Epoch: 430. Loss: 0.57478104789008\n",
            "Epoch: 440. Loss: 0.5747705092593551\n",
            "Epoch: 450. Loss: 0.5747615631464189\n",
            "Epoch: 460. Loss: 0.5747539701194403\n",
            "Epoch: 470. Loss: 0.5747475265051907\n",
            "Epoch: 480. Loss: 0.5747420590933536\n",
            "Epoch: 490. Loss: 0.574737420617484\n",
            "tensor(0.7068, dtype=torch.float64)\n",
            "2021-03-21 00:00:00\n",
            "Epoch: 0. Loss: 1.2948116358343182\n",
            "Epoch: 10. Loss: 0.9091606975025958\n",
            "Epoch: 20. Loss: 0.6970088886695688\n",
            "Epoch: 30. Loss: 0.6203575564409759\n",
            "Epoch: 40. Loss: 0.6021241768552128\n",
            "Epoch: 50. Loss: 0.5965691146980425\n",
            "Epoch: 60. Loss: 0.5932697580578785\n",
            "Epoch: 70. Loss: 0.5906892064067253\n",
            "Epoch: 80. Loss: 0.5885591902925318\n",
            "Epoch: 90. Loss: 0.5867809423235321\n",
            "Epoch: 100. Loss: 0.5852898958597864\n",
            "Epoch: 110. Loss: 0.5840361710853291\n",
            "Epoch: 120. Loss: 0.5829797239895006\n",
            "Epoch: 130. Loss: 0.5820879871247714\n",
            "Epoch: 140. Loss: 0.5813342719823631\n",
            "Epoch: 150. Loss: 0.5806965739947273\n",
            "Epoch: 160. Loss: 0.5801566512439124\n",
            "Epoch: 170. Loss: 0.5796993057069597\n",
            "Epoch: 180. Loss: 0.5793118186844184\n",
            "Epoch: 190. Loss: 0.5789835047308306\n",
            "Epoch: 200. Loss: 0.5787053569643964\n",
            "Epoch: 210. Loss: 0.5784697629806802\n",
            "Epoch: 220. Loss: 0.578270275475201\n",
            "Epoch: 230. Loss: 0.5781014254579816\n",
            "Epoch: 240. Loss: 0.5779585688523876\n",
            "Epoch: 250. Loss: 0.577837759488984\n",
            "Epoch: 260. Loss: 0.577735643179825\n",
            "Epoch: 270. Loss: 0.5776493688123026\n",
            "Epoch: 280. Loss: 0.5775765133349179\n",
            "Epoch: 290. Loss: 0.5775150182004009\n",
            "Epoch: 300. Loss: 0.5774631353470194\n",
            "Epoch: 310. Loss: 0.5774193811842516\n",
            "Epoch: 320. Loss: 0.5773824973397635\n",
            "Epoch: 330. Loss: 0.5773514171468437\n",
            "Epoch: 340. Loss: 0.5773252370239412\n",
            "Epoch: 350. Loss: 0.5773031920341543\n",
            "Epoch: 360. Loss: 0.5772846350220078\n",
            "Epoch: 370. Loss: 0.5772690188143398\n",
            "Epoch: 380. Loss: 0.5772558810463689\n",
            "Epoch: 390. Loss: 0.5772448312364156\n",
            "Epoch: 400. Loss: 0.5772355397856989\n",
            "Epoch: 410. Loss: 0.5772277286249178\n",
            "Epoch: 420. Loss: 0.5772211632682467\n",
            "Epoch: 430. Loss: 0.5772156460689399\n",
            "Epoch: 440. Loss: 0.5772110104997378\n",
            "Epoch: 450. Loss: 0.5772071163063397\n",
            "Epoch: 460. Loss: 0.5772038454038797\n",
            "Epoch: 470. Loss: 0.5772010984050572\n",
            "Epoch: 480. Loss: 0.5771987916847225\n",
            "Epoch: 490. Loss: 0.5771968548996379\n",
            "tensor(0.8432, dtype=torch.float64)\n",
            "2021-03-28 00:00:00\n",
            "Epoch: 0. Loss: 0.7757374720847875\n",
            "Epoch: 10. Loss: 0.6836953681061648\n",
            "Epoch: 20. Loss: 0.6457048697813805\n",
            "Epoch: 30. Loss: 0.6212309206153452\n",
            "Epoch: 40. Loss: 0.6052091188262738\n",
            "Epoch: 50. Loss: 0.594988192196489\n",
            "Epoch: 60. Loss: 0.5886361985520564\n",
            "Epoch: 70. Loss: 0.5847765873860333\n",
            "Epoch: 80. Loss: 0.5824726119272544\n",
            "Epoch: 90. Loss: 0.5811135399513889\n",
            "Epoch: 100. Loss: 0.5803166055639128\n",
            "Epoch: 110. Loss: 0.5798496193094304\n",
            "Epoch: 120. Loss: 0.5795749809381214\n",
            "Epoch: 130. Loss: 0.5794123100257021\n",
            "Epoch: 140. Loss: 0.5793149904046838\n",
            "Epoch: 150. Loss: 0.5792560407957229\n",
            "Epoch: 160. Loss: 0.5792198150330535\n",
            "Epoch: 170. Loss: 0.5791971956691616\n",
            "Epoch: 180. Loss: 0.5791828303690281\n",
            "Epoch: 190. Loss: 0.5791735467794837\n",
            "Epoch: 200. Loss: 0.5791674426436695\n",
            "Epoch: 210. Loss: 0.5791633618433004\n",
            "Epoch: 220. Loss: 0.5791605910965526\n",
            "Epoch: 230. Loss: 0.5791586831379152\n",
            "Epoch: 240. Loss: 0.579157352714656\n",
            "Epoch: 250. Loss: 0.5791564147570621\n",
            "Epoch: 260. Loss: 0.5791557471623698\n",
            "Epoch: 270. Loss: 0.5791552680783147\n",
            "Epoch: 280. Loss: 0.5791549218227489\n",
            "Epoch: 290. Loss: 0.5791546700124719\n",
            "Epoch: 300. Loss: 0.5791544858791112\n",
            "Epoch: 310. Loss: 0.5791543505652469\n",
            "Epoch: 320. Loss: 0.579154250671238\n",
            "Epoch: 330. Loss: 0.5791541766053496\n",
            "Epoch: 340. Loss: 0.5791541214585054\n",
            "Epoch: 350. Loss: 0.5791540802272188\n",
            "Epoch: 360. Loss: 0.5791540492711003\n",
            "Epoch: 370. Loss: 0.5791540259305747\n",
            "Epoch: 380. Loss: 0.5791540082553616\n",
            "Epoch: 390. Loss: 0.5791539948103334\n",
            "Epoch: 400. Loss: 0.5791539845359271\n",
            "Epoch: 410. Loss: 0.5791539766473047\n",
            "Epoch: 420. Loss: 0.5791539705612144\n",
            "Epoch: 430. Loss: 0.5791539658427578\n",
            "Epoch: 440. Loss: 0.5791539621665289\n",
            "Epoch: 450. Loss: 0.5791539592881632\n",
            "Epoch: 460. Loss: 0.5791539570234558\n",
            "Epoch: 470. Loss: 0.5791539552329963\n",
            "Epoch: 480. Loss: 0.5791539538108326\n",
            "Epoch: 490. Loss: 0.5791539526760894\n",
            "tensor(0.8079, dtype=torch.float64)\n",
            "2021-04-04 00:00:00\n",
            "Epoch: 0. Loss: 0.7227397279044386\n",
            "Epoch: 10. Loss: 0.6281506843382288\n",
            "Epoch: 20. Loss: 0.5965016387220066\n",
            "Epoch: 30. Loss: 0.5856662313245629\n",
            "Epoch: 40. Loss: 0.5807490209210319\n",
            "Epoch: 50. Loss: 0.5778134139731249\n",
            "Epoch: 60. Loss: 0.5757595157258348\n",
            "Epoch: 70. Loss: 0.5742189762515714\n",
            "Epoch: 80. Loss: 0.5730321755517951\n",
            "Epoch: 90. Loss: 0.5721089002971992\n",
            "Epoch: 100. Loss: 0.5713880037046405\n",
            "Epoch: 110. Loss: 0.5708242128888057\n",
            "Epoch: 120. Loss: 0.5703828237884897\n",
            "Epoch: 130. Loss: 0.5700369149515708\n",
            "Epoch: 140. Loss: 0.5697655282716901\n",
            "Epoch: 150. Loss: 0.5695523353467281\n",
            "Epoch: 160. Loss: 0.5693846141738609\n",
            "Epoch: 170. Loss: 0.5692524526441276\n",
            "Epoch: 180. Loss: 0.5691481267363775\n",
            "Epoch: 190. Loss: 0.5690656153629059\n",
            "Epoch: 200. Loss: 0.569000222334494\n",
            "Epoch: 210. Loss: 0.5689482821520845\n",
            "Epoch: 220. Loss: 0.5689069312426369\n",
            "Epoch: 230. Loss: 0.5688739301821145\n",
            "Epoch: 240. Loss: 0.5688475255794455\n",
            "Epoch: 250. Loss: 0.5688263427768245\n",
            "Epoch: 260. Loss: 0.5688093024766605\n",
            "Epoch: 270. Loss: 0.5687955559380262\n",
            "Epoch: 280. Loss: 0.5687844345824289\n",
            "Epoch: 290. Loss: 0.5687754107810307\n",
            "Epoch: 300. Loss: 0.5687680673201737\n",
            "Epoch: 310. Loss: 0.5687620736046326\n",
            "Epoch: 320. Loss: 0.5687571670942926\n",
            "Epoch: 330. Loss: 0.5687531388080627\n",
            "Epoch: 340. Loss: 0.568749821990762\n",
            "Epoch: 350. Loss: 0.5687470832416052\n",
            "Epoch: 360. Loss: 0.5687448155600497\n",
            "Epoch: 370. Loss: 0.5687429328864868\n",
            "Epoch: 380. Loss: 0.568741365809565\n",
            "Epoch: 390. Loss: 0.5687400581850244\n",
            "Epoch: 400. Loss: 0.5687389644675787\n",
            "Epoch: 410. Loss: 0.5687380476013376\n",
            "Epoch: 420. Loss: 0.5687372773483689\n",
            "Epoch: 430. Loss: 0.5687366289614829\n",
            "Epoch: 440. Loss: 0.5687360821279074\n",
            "Epoch: 450. Loss: 0.5687356201265169\n",
            "Epoch: 460. Loss: 0.5687352291537399\n",
            "Epoch: 470. Loss: 0.568734897782963\n",
            "Epoch: 480. Loss: 0.5687346165298163\n",
            "Epoch: 490. Loss: 0.5687343775016259\n",
            "tensor(0.8472, dtype=torch.float64)\n",
            "2021-04-11 00:00:00\n",
            "Epoch: 0. Loss: 1.7538968607700762\n",
            "Epoch: 10. Loss: 1.397410735485627\n",
            "Epoch: 20. Loss: 1.0974273501019227\n",
            "Epoch: 30. Loss: 0.863545423802477\n",
            "Epoch: 40. Loss: 0.7103243588996896\n",
            "Epoch: 50. Loss: 0.6342517710123092\n",
            "Epoch: 60. Loss: 0.6039907295801529\n",
            "Epoch: 70. Loss: 0.5913874582493759\n",
            "Epoch: 80. Loss: 0.5848344125570152\n",
            "Epoch: 90. Loss: 0.580662881988706\n",
            "Epoch: 100. Loss: 0.5776188989412299\n",
            "Epoch: 110. Loss: 0.5752147177810679\n",
            "Epoch: 120. Loss: 0.5732359919599309\n",
            "Epoch: 130. Loss: 0.5715744197404283\n",
            "Epoch: 140. Loss: 0.5701659617456154\n",
            "Epoch: 150. Loss: 0.568966858851122\n",
            "Epoch: 160. Loss: 0.5679439290921979\n",
            "Epoch: 170. Loss: 0.5670704224609469\n",
            "Epoch: 180. Loss: 0.5663240866060604\n",
            "Epoch: 190. Loss: 0.5656861366350644\n",
            "Epoch: 200. Loss: 0.5651406136401699\n",
            "Epoch: 210. Loss: 0.564673926273281\n",
            "Epoch: 220. Loss: 0.5642744913048651\n",
            "Epoch: 230. Loss: 0.5639324370413676\n",
            "Epoch: 240. Loss: 0.5636393525636415\n",
            "Epoch: 250. Loss: 0.563388073524518\n",
            "Epoch: 260. Loss: 0.5631724985617552\n",
            "Epoch: 270. Loss: 0.5629874319253122\n",
            "Epoch: 280. Loss: 0.5628284487405433\n",
            "Epoch: 290. Loss: 0.5626917798507355\n",
            "Epoch: 300. Loss: 0.5625742135715587\n",
            "Epoch: 310. Loss: 0.5624730120140614\n",
            "Epoch: 320. Loss: 0.5623858399186121\n",
            "Epoch: 330. Loss: 0.5623107041998427\n",
            "Epoch: 340. Loss: 0.5622459026358136\n",
            "Epoch: 350. Loss: 0.5621899803446436\n",
            "Epoch: 360. Loss: 0.5621416928794906\n",
            "Epoch: 370. Loss: 0.5620999749389461\n",
            "Epoch: 380. Loss: 0.5620639138357955\n",
            "Epoch: 390. Loss: 0.5620327269941715\n",
            "Epoch: 400. Loss: 0.5620057428550663\n",
            "Epoch: 410. Loss: 0.561982384664693\n",
            "Epoch: 420. Loss: 0.5619621567010646\n",
            "Epoch: 430. Loss: 0.5619446325630827\n",
            "Epoch: 440. Loss: 0.5619294452049173\n",
            "Epoch: 450. Loss: 0.5619162784480277\n",
            "Epoch: 460. Loss: 0.5619048597450141\n",
            "Epoch: 470. Loss: 0.5618949540048125\n",
            "Epoch: 480. Loss: 0.5618863583184913\n",
            "Epoch: 490. Loss: 0.5618788974499513\n",
            "tensor(0.8225, dtype=torch.float64)\n",
            "2021-04-18 00:00:00\n",
            "Epoch: 0. Loss: 1.615881094790505\n",
            "Epoch: 10. Loss: 0.9490578331605879\n",
            "Epoch: 20. Loss: 0.7715814261102466\n",
            "Epoch: 30. Loss: 0.7015382519865737\n",
            "Epoch: 40. Loss: 0.6607381989637708\n",
            "Epoch: 50. Loss: 0.6323313977545104\n",
            "Epoch: 60. Loss: 0.6113839462232368\n",
            "Epoch: 70. Loss: 0.5957002229423141\n",
            "Epoch: 80. Loss: 0.5839296430690712\n",
            "Epoch: 90. Loss: 0.5750996412824393\n",
            "Epoch: 100. Loss: 0.5684745754591997\n",
            "Epoch: 110. Loss: 0.5634958119932665\n",
            "Epoch: 120. Loss: 0.5597431373206271\n",
            "Epoch: 130. Loss: 0.5569036420437248\n",
            "Epoch: 140. Loss: 0.5547458379206804\n",
            "Epoch: 150. Loss: 0.5530988761065702\n",
            "Epoch: 160. Loss: 0.5518365294285535\n",
            "Epoch: 170. Loss: 0.5508652187684807\n",
            "Epoch: 180. Loss: 0.5501152323803549\n",
            "Epoch: 190. Loss: 0.5495343506937982\n",
            "Epoch: 200. Loss: 0.5490832332957837\n",
            "Epoch: 210. Loss: 0.54873207741391\n",
            "Epoch: 220. Loss: 0.5484581878548611\n",
            "Epoch: 230. Loss: 0.548244199728585\n",
            "Epoch: 240. Loss: 0.5480767700149644\n",
            "Epoch: 250. Loss: 0.5479456075974324\n",
            "Epoch: 260. Loss: 0.5478427492413719\n",
            "Epoch: 270. Loss: 0.5477620155834337\n",
            "Epoch: 280. Loss: 0.5476985998607524\n",
            "Epoch: 290. Loss: 0.547648755245925\n",
            "Epoch: 300. Loss: 0.5476095559485805\n",
            "Epoch: 310. Loss: 0.5475787138649862\n",
            "Epoch: 320. Loss: 0.5475544373088579\n",
            "Epoch: 330. Loss: 0.5475353217945788\n",
            "Epoch: 340. Loss: 0.5475202653521375\n",
            "Epoch: 350. Loss: 0.5475084026976665\n",
            "Epoch: 360. Loss: 0.5474990539506837\n",
            "Epoch: 370. Loss: 0.5474916846099731\n",
            "Epoch: 380. Loss: 0.5474858742674755\n",
            "Epoch: 390. Loss: 0.547481292120031\n",
            "Epoch: 400. Loss: 0.5474776777803833\n",
            "Epoch: 410. Loss: 0.5474748262263665\n",
            "Epoch: 420. Loss: 0.547472575986366\n",
            "Epoch: 430. Loss: 0.5474707998588599\n",
            "Epoch: 440. Loss: 0.5474693976183154\n",
            "Epoch: 450. Loss: 0.547468290279489\n",
            "Epoch: 460. Loss: 0.5474674155853088\n",
            "Epoch: 470. Loss: 0.5474667244560611\n",
            "Epoch: 480. Loss: 0.5474661781942387\n",
            "Epoch: 490. Loss: 0.5474657462836648\n",
            "tensor(0.8698, dtype=torch.float64)\n",
            "2021-04-25 00:00:00\n",
            "Epoch: 0. Loss: 1.5348101480956775\n",
            "Epoch: 10. Loss: 1.0009961194340182\n",
            "Epoch: 20. Loss: 0.8007616298453668\n",
            "Epoch: 30. Loss: 0.6970079575847422\n",
            "Epoch: 40. Loss: 0.639448913018636\n",
            "Epoch: 50. Loss: 0.6069838116882512\n",
            "Epoch: 60. Loss: 0.5881980512801939\n",
            "Epoch: 70. Loss: 0.5768350677985349\n",
            "Epoch: 80. Loss: 0.5696415846821421\n",
            "Epoch: 90. Loss: 0.5649237399561386\n",
            "Epoch: 100. Loss: 0.5617538667825619\n",
            "Epoch: 110. Loss: 0.559589406879445\n",
            "Epoch: 120. Loss: 0.5580936963839385\n",
            "Epoch: 130. Loss: 0.5570490062442407\n",
            "Epoch: 140. Loss: 0.5563111570278043\n",
            "Epoch: 150. Loss: 0.5557835338934539\n",
            "Epoch: 160. Loss: 0.5554010027609025\n",
            "Epoch: 170. Loss: 0.5551194724165022\n",
            "Epoch: 180. Loss: 0.5549089700120694\n",
            "Epoch: 190. Loss: 0.5547490117377474\n",
            "Epoch: 200. Loss: 0.5546255030493548\n",
            "Epoch: 210. Loss: 0.5545286635555082\n",
            "Epoch: 220. Loss: 0.554451637935872\n",
            "Epoch: 230. Loss: 0.5543895652512132\n",
            "Epoch: 240. Loss: 0.5543389540468444\n",
            "Epoch: 250. Loss: 0.5542972613325003\n",
            "Epoch: 260. Loss: 0.554262607573688\n",
            "Epoch: 270. Loss: 0.5542335825855547\n",
            "Epoch: 280. Loss: 0.5542091123627597\n",
            "Epoch: 290. Loss: 0.5541883669262286\n",
            "Epoch: 300. Loss: 0.5541706959241396\n",
            "Epoch: 310. Loss: 0.5541555831328494\n",
            "Epoch: 320. Loss: 0.5541426139249268\n",
            "Epoch: 330. Loss: 0.5541314517105868\n",
            "Epoch: 340. Loss: 0.5541218206490811\n",
            "Epoch: 350. Loss: 0.5541134927879248\n",
            "Epoch: 360. Loss: 0.554106278365202\n",
            "Epoch: 370. Loss: 0.5541000183991245\n",
            "Epoch: 380. Loss: 0.5540945789525618\n",
            "Epoch: 390. Loss: 0.5540898466400449\n",
            "Epoch: 400. Loss: 0.5540857250683293\n",
            "Epoch: 410. Loss: 0.5540821319872872\n",
            "Epoch: 420. Loss: 0.5540789969878672\n",
            "Epoch: 430. Loss: 0.5540762596262477\n",
            "Epoch: 440. Loss: 0.5540738678836022\n",
            "Epoch: 450. Loss: 0.5540717768927957\n",
            "Epoch: 460. Loss: 0.5540699478793226\n",
            "Epoch: 470. Loss: 0.554068347275636\n",
            "Epoch: 480. Loss: 0.5540669459768714\n",
            "Epoch: 490. Loss: 0.5540657187126597\n",
            "tensor(0.7923, dtype=torch.float64)\n",
            "2021-05-02 00:00:00\n",
            "Epoch: 0. Loss: 0.8567055893245583\n",
            "Epoch: 10. Loss: 0.7071947045405383\n",
            "Epoch: 20. Loss: 0.6367306490867636\n",
            "Epoch: 30. Loss: 0.6094249853348395\n",
            "Epoch: 40. Loss: 0.5984469541209472\n",
            "Epoch: 50. Loss: 0.592530111486825\n",
            "Epoch: 60. Loss: 0.5882969983305993\n",
            "Epoch: 70. Loss: 0.5848055170994719\n",
            "Epoch: 80. Loss: 0.5817622653278872\n",
            "Epoch: 90. Loss: 0.5790527311001382\n",
            "Epoch: 100. Loss: 0.5766180664325816\n",
            "Epoch: 110. Loss: 0.5744202174272934\n",
            "Epoch: 120. Loss: 0.5724308625949917\n",
            "Epoch: 130. Loss: 0.5706272931770807\n",
            "Epoch: 140. Loss: 0.5689905425383006\n",
            "Epoch: 150. Loss: 0.5675043633346625\n",
            "Epoch: 160. Loss: 0.5661545899452433\n",
            "Epoch: 170. Loss: 0.5649287088301345\n",
            "Epoch: 180. Loss: 0.5638155551713465\n",
            "Epoch: 190. Loss: 0.5628050915578794\n",
            "Epoch: 200. Loss: 0.5618882420143606\n",
            "Epoch: 210. Loss: 0.5610567642839027\n",
            "Epoch: 220. Loss: 0.5603031490910086\n",
            "Epoch: 230. Loss: 0.5596205388130002\n",
            "Epoch: 240. Loss: 0.5590026604029373\n",
            "Epoch: 250. Loss: 0.55844376900007\n",
            "Epoch: 260. Loss: 0.5579385997234886\n",
            "Epoch: 270. Loss: 0.557482325855656\n",
            "Epoch: 280. Loss: 0.5570705221054223\n",
            "Epoch: 290. Loss: 0.5566991319736664\n",
            "Epoch: 300. Loss: 0.5563644384800795\n",
            "Epoch: 310. Loss: 0.5560630376799204\n",
            "Epoch: 320. Loss: 0.5557918145260646\n",
            "Epoch: 330. Loss: 0.5555479207278634\n",
            "Epoch: 340. Loss: 0.5553287543328637\n",
            "Epoch: 350. Loss: 0.5551319408158343\n",
            "Epoch: 360. Loss: 0.5549553155055282\n",
            "Epoch: 370. Loss: 0.5547969072156095\n",
            "Epoch: 380. Loss: 0.5546549229741876\n",
            "Epoch: 390. Loss: 0.554527733767759\n",
            "Epoch: 400. Loss: 0.5544138612313925\n",
            "Epoch: 410. Loss: 0.554311965228666\n",
            "Epoch: 420. Loss: 0.5542208322731212\n",
            "Epoch: 430. Loss: 0.5541393647486306\n",
            "Epoch: 440. Loss: 0.5540665708897056\n",
            "Epoch: 450. Loss: 0.5540015554850295\n",
            "Epoch: 460. Loss: 0.5539435112687557\n",
            "Epoch: 470. Loss: 0.553891710964812\n",
            "Epoch: 480. Loss: 0.5538454999497945\n",
            "Epoch: 490. Loss: 0.5538042895002728\n",
            "tensor(0.8255, dtype=torch.float64)\n",
            "2021-05-09 00:00:00\n",
            "Epoch: 0. Loss: 2.5295988597364683\n",
            "Epoch: 10. Loss: 0.8001685882846828\n",
            "Epoch: 20. Loss: 0.6752381461078775\n",
            "Epoch: 30. Loss: 0.6402439120992576\n",
            "Epoch: 40. Loss: 0.6176994448544794\n",
            "Epoch: 50. Loss: 0.6008358361070134\n",
            "Epoch: 60. Loss: 0.5881277348351281\n",
            "Epoch: 70. Loss: 0.5786361255863542\n",
            "Epoch: 80. Loss: 0.571588932128855\n",
            "Epoch: 90. Loss: 0.5663601084110357\n",
            "Epoch: 100. Loss: 0.5624645596864493\n",
            "Epoch: 110. Loss: 0.5595395078362249\n",
            "Epoch: 120. Loss: 0.5573199239980299\n",
            "Epoch: 130. Loss: 0.555614842600626\n",
            "Epoch: 140. Loss: 0.5542875685331202\n",
            "Epoch: 150. Loss: 0.5532403735359651\n",
            "Epoch: 160. Loss: 0.5524031897397355\n",
            "Epoch: 170. Loss: 0.5517254813666506\n",
            "Epoch: 180. Loss: 0.551170494781149\n",
            "Epoch: 190. Loss: 0.5507112267775391\n",
            "Epoch: 200. Loss: 0.5503276084218265\n",
            "Epoch: 210. Loss: 0.5500045383376794\n",
            "Epoch: 220. Loss: 0.5497305057127729\n",
            "Epoch: 230. Loss: 0.5494966216534599\n",
            "Epoch: 240. Loss: 0.5492959333850088\n",
            "Epoch: 250. Loss: 0.5491229348651492\n",
            "Epoch: 260. Loss: 0.5489732143823998\n",
            "Epoch: 270. Loss: 0.548843198248462\n",
            "Epoch: 280. Loss: 0.5487299623773129\n",
            "Epoch: 290. Loss: 0.5486310922138194\n",
            "Epoch: 300. Loss: 0.5485445774075974\n",
            "Epoch: 310. Loss: 0.5484687316980386\n",
            "Epoch: 320. Loss: 0.5484021312794989\n",
            "Epoch: 330. Loss: 0.5483435668556496\n",
            "Epoch: 340. Loss: 0.5482920059426583\n",
            "Epoch: 350. Loss: 0.5482465629276485\n",
            "Epoch: 360. Loss: 0.5482064750575446\n",
            "Epoch: 370. Loss: 0.5481710830095405\n",
            "Epoch: 380. Loss: 0.5481398150363836\n",
            "Epoch: 390. Loss: 0.5481121739274961\n",
            "Epoch: 400. Loss: 0.5480877262082147\n",
            "Epoch: 410. Loss: 0.5480660931332562\n",
            "Epoch: 420. Loss: 0.5480469431302214\n",
            "Epoch: 430. Loss: 0.5480299854239367\n",
            "Epoch: 440. Loss: 0.5480149646293085\n",
            "Epoch: 450. Loss: 0.5480016561438981\n",
            "Epoch: 460. Loss: 0.5479898622050079\n",
            "Epoch: 470. Loss: 0.5479794085021891\n",
            "Epoch: 480. Loss: 0.5479701412565435\n",
            "Epoch: 490. Loss: 0.5479619246943532\n",
            "tensor(0.7799, dtype=torch.float64)\n",
            "2021-05-16 00:00:00\n",
            "Epoch: 0. Loss: 3.2195588086311253\n",
            "Epoch: 10. Loss: 1.5426899200801503\n",
            "Epoch: 20. Loss: 1.0766850533428363\n",
            "Epoch: 30. Loss: 0.9225093522146511\n",
            "Epoch: 40. Loss: 0.8316472541171099\n",
            "Epoch: 50. Loss: 0.766626861708439\n",
            "Epoch: 60. Loss: 0.7169567661435374\n",
            "Epoch: 70. Loss: 0.6777949825641224\n",
            "Epoch: 80. Loss: 0.6467645453674555\n",
            "Epoch: 90. Loss: 0.6225471922270156\n",
            "Epoch: 100. Loss: 0.6041362568167111\n",
            "Epoch: 110. Loss: 0.590553421538151\n",
            "Epoch: 120. Loss: 0.5808191733372874\n",
            "Epoch: 130. Loss: 0.5740164928592735\n",
            "Epoch: 140. Loss: 0.5693566901951662\n",
            "Epoch: 150. Loss: 0.566211315630605\n",
            "Epoch: 160. Loss: 0.5641092826987291\n",
            "Epoch: 170. Loss: 0.5627131815203904\n",
            "Epoch: 180. Loss: 0.5617889904478033\n",
            "Epoch: 190. Loss: 0.5611778811567606\n",
            "Epoch: 200. Loss: 0.560773567147426\n",
            "Epoch: 210. Loss: 0.5605055457330874\n",
            "Epoch: 220. Loss: 0.5603272945710527\n",
            "Epoch: 230. Loss: 0.5602082028518144\n",
            "Epoch: 240. Loss: 0.5601281552070967\n",
            "Epoch: 250. Loss: 0.5600739361039093\n",
            "Epoch: 260. Loss: 0.560036858360898\n",
            "Epoch: 270. Loss: 0.5600112048563838\n",
            "Epoch: 280. Loss: 0.5599932066040652\n",
            "Epoch: 290. Loss: 0.5599803731686104\n",
            "Epoch: 300. Loss: 0.5599710540249246\n",
            "Epoch: 310. Loss: 0.5599641511328339\n",
            "Epoch: 320. Loss: 0.5599589304899077\n",
            "Epoch: 330. Loss: 0.5599548984769478\n",
            "Epoch: 340. Loss: 0.5599517206338553\n",
            "Epoch: 350. Loss: 0.5599491682374435\n",
            "Epoch: 360. Loss: 0.559947083109217\n",
            "Epoch: 370. Loss: 0.559945354386989\n",
            "Epoch: 380. Loss: 0.55994390315603\n",
            "Epoch: 390. Loss: 0.5599426722497218\n",
            "Epoch: 400. Loss: 0.5599416194553293\n",
            "Epoch: 410. Loss: 0.5599407129666842\n",
            "Epoch: 420. Loss: 0.55993992832276\n",
            "Epoch: 430. Loss: 0.5599392463315359\n",
            "Epoch: 440. Loss: 0.5599386516494171\n",
            "Epoch: 450. Loss: 0.5599381317986581\n",
            "Epoch: 460. Loss: 0.559937676478982\n",
            "Epoch: 470. Loss: 0.5599372770780856\n",
            "Epoch: 480. Loss: 0.559936926317682\n",
            "Epoch: 490. Loss: 0.5599366179928051\n",
            "tensor(0.7881, dtype=torch.float64)\n",
            "2021-05-23 00:00:00\n",
            "Epoch: 0. Loss: 0.8044555795022019\n",
            "Epoch: 10. Loss: 0.7155082836476354\n",
            "Epoch: 20. Loss: 0.6647691133106547\n",
            "Epoch: 30. Loss: 0.6368981576651201\n",
            "Epoch: 40. Loss: 0.620225687672211\n",
            "Epoch: 50. Loss: 0.6090027034101185\n",
            "Epoch: 60. Loss: 0.600833435958436\n",
            "Epoch: 70. Loss: 0.5946320039095113\n",
            "Epoch: 80. Loss: 0.5898003706577692\n",
            "Epoch: 90. Loss: 0.5859561909102112\n",
            "Epoch: 100. Loss: 0.5828377164395511\n",
            "Epoch: 110. Loss: 0.5802615445226047\n",
            "Epoch: 120. Loss: 0.5780981152976905\n",
            "Epoch: 130. Loss: 0.576255303379366\n",
            "Epoch: 140. Loss: 0.5746669687425522\n",
            "Epoch: 150. Loss: 0.573284965509096\n",
            "Epoch: 160. Loss: 0.5720736153146775\n",
            "Epoch: 170. Loss: 0.5710059171647863\n",
            "Epoch: 180. Loss: 0.5700609614936651\n",
            "Epoch: 190. Loss: 0.5692221687990785\n",
            "Epoch: 200. Loss: 0.5684760881691042\n",
            "Epoch: 210. Loss: 0.5678115741596418\n",
            "Epoch: 220. Loss: 0.5672192188395748\n",
            "Epoch: 230. Loss: 0.5666909559596656\n",
            "Epoch: 240. Loss: 0.5662197814529364\n",
            "Epoch: 250. Loss: 0.5657995528317383\n",
            "Epoch: 260. Loss: 0.5654248423600075\n",
            "Epoch: 270. Loss: 0.5650908271233736\n",
            "Epoch: 280. Loss: 0.5647932046384764\n",
            "Epoch: 290. Loss: 0.5645281263401375\n",
            "Epoch: 300. Loss: 0.5642921437653998\n",
            "Epoch: 310. Loss: 0.564082163919869\n",
            "Epoch: 320. Loss: 0.5638954114328021\n",
            "Epoch: 330. Loss: 0.5637293958621648\n",
            "Epoch: 340. Loss: 0.5635818830192356\n",
            "Epoch: 350. Loss: 0.5634508695246417\n",
            "Epoch: 360. Loss: 0.5633345600380736\n",
            "Epoch: 370. Loss: 0.5632313467587973\n",
            "Epoch: 380. Loss: 0.5631397908982069\n",
            "Epoch: 390. Loss: 0.5630586058956842\n",
            "Epoch: 400. Loss: 0.5629866421963361\n",
            "Epoch: 410. Loss: 0.5629228734413724\n",
            "Epoch: 420. Loss: 0.5628663839441472\n",
            "Epoch: 430. Loss: 0.5628163573406735\n",
            "Epoch: 440. Loss: 0.562772066315006\n",
            "Epoch: 450. Loss: 0.5627328633088331\n",
            "Epoch: 460. Loss: 0.562698172131852\n",
            "Epoch: 470. Loss: 0.5626674803956885\n",
            "Epoch: 480. Loss: 0.5626403326996378\n",
            "Epoch: 490. Loss: 0.5626163245015658\n",
            "tensor(0.7075, dtype=torch.float64)\n",
            "2021-05-30 00:00:00\n",
            "Epoch: 0. Loss: 1.82779392863295\n",
            "Epoch: 10. Loss: 1.1698965926808564\n",
            "Epoch: 20. Loss: 0.8340242075911918\n",
            "Epoch: 30. Loss: 0.6777504018131252\n",
            "Epoch: 40. Loss: 0.6103432735195451\n",
            "Epoch: 50. Loss: 0.5821127686674484\n",
            "Epoch: 60. Loss: 0.5692067798100499\n",
            "Epoch: 70. Loss: 0.562114131473364\n",
            "Epoch: 80. Loss: 0.5576129523220512\n",
            "Epoch: 90. Loss: 0.5545574983011223\n",
            "Epoch: 100. Loss: 0.552434324864308\n",
            "Epoch: 110. Loss: 0.550949829148781\n",
            "Epoch: 120. Loss: 0.5499105724146042\n",
            "Epoch: 130. Loss: 0.5491822095858995\n",
            "Epoch: 140. Loss: 0.5486703985448116\n",
            "Epoch: 150. Loss: 0.5483090785093185\n",
            "Epoch: 160. Loss: 0.5480522582958507\n",
            "Epoch: 170. Loss: 0.547868079379537\n",
            "Epoch: 180. Loss: 0.5477345454363907\n",
            "Epoch: 190. Loss: 0.5476364912224329\n",
            "Epoch: 200. Loss: 0.5475634581195828\n",
            "Epoch: 210. Loss: 0.54750821978404\n",
            "Epoch: 220. Loss: 0.5474657661978514\n",
            "Epoch: 230. Loss: 0.5474326069314579\n",
            "Epoch: 240. Loss: 0.5474062947151455\n",
            "Epoch: 250. Loss: 0.5473851001277604\n",
            "Epoch: 260. Loss: 0.5473677895209433\n",
            "Epoch: 270. Loss: 0.5473534732929787\n",
            "Epoch: 280. Loss: 0.5473415020414577\n",
            "Epoch: 290. Loss: 0.5473313952924593\n",
            "Epoch: 300. Loss: 0.5473227924073585\n",
            "Epoch: 310. Loss: 0.547315418608207\n",
            "Epoch: 320. Loss: 0.5473090613311602\n",
            "Epoch: 330. Loss: 0.5473035536555577\n",
            "Epoch: 340. Loss: 0.5472987625982507\n",
            "Epoch: 350. Loss: 0.547294580768419\n",
            "Epoch: 360. Loss: 0.5472909203561782\n",
            "Epoch: 370. Loss: 0.5472877087523996\n",
            "Epoch: 380. Loss: 0.5472848853172074\n",
            "Epoch: 390. Loss: 0.5472823989643036\n",
            "Epoch: 400. Loss: 0.5472802063303006\n",
            "Epoch: 410. Loss: 0.547278270368034\n",
            "Epoch: 420. Loss: 0.547276559250711\n",
            "Epoch: 430. Loss: 0.5472750455067611\n",
            "Epoch: 440. Loss: 0.5472737053281206\n",
            "Epoch: 450. Loss: 0.5472725180106157\n",
            "Epoch: 460. Loss: 0.5472714654962915\n",
            "Epoch: 470. Loss: 0.5472705319954272\n",
            "Epoch: 480. Loss: 0.5472697036716203\n",
            "Epoch: 490. Loss: 0.5472689683773698\n",
            "tensor(0.6959, dtype=torch.float64)\n",
            "2021-06-06 00:00:00\n",
            "Epoch: 0. Loss: 1.0023862098761833\n",
            "Epoch: 10. Loss: 0.8415146596648796\n",
            "Epoch: 20. Loss: 0.7981172947118801\n",
            "Epoch: 30. Loss: 0.7750127189674113\n",
            "Epoch: 40. Loss: 0.7576946861106076\n",
            "Epoch: 50. Loss: 0.7428149202480819\n",
            "Epoch: 60. Loss: 0.7293843932308909\n",
            "Epoch: 70. Loss: 0.7170406620587069\n",
            "Epoch: 80. Loss: 0.7056119238803568\n",
            "Epoch: 90. Loss: 0.6949922754255684\n",
            "Epoch: 100. Loss: 0.6851028867321112\n",
            "Epoch: 110. Loss: 0.6758789729126999\n",
            "Epoch: 120. Loss: 0.6672649412205536\n",
            "Epoch: 130. Loss: 0.6592122254500422\n",
            "Epoch: 140. Loss: 0.6516780411481062\n",
            "Epoch: 150. Loss: 0.6446244888170453\n",
            "Epoch: 160. Loss: 0.6380178219683494\n",
            "Epoch: 170. Loss: 0.631827822471865\n",
            "Epoch: 180. Loss: 0.6260272639663417\n",
            "Epoch: 190. Loss: 0.6205914543113771\n",
            "Epoch: 200. Loss: 0.6154978498742463\n",
            "Epoch: 210. Loss: 0.6107257342409266\n",
            "Epoch: 220. Loss: 0.6062559535984808\n",
            "Epoch: 230. Loss: 0.602070701012862\n",
            "Epoch: 240. Loss: 0.5981533421281175\n",
            "Epoch: 250. Loss: 0.5944882753529079\n",
            "Epoch: 260. Loss: 0.5910608202814349\n",
            "Epoch: 270. Loss: 0.5878571288419852\n",
            "Epoch: 280. Loss: 0.5848641144233664\n",
            "Epoch: 290. Loss: 0.582069394960147\n",
            "Epoch: 300. Loss: 0.5794612466387606\n",
            "Epoch: 310. Loss: 0.5770285655045614\n",
            "Epoch: 320. Loss: 0.5747608347982767\n",
            "Epoch: 330. Loss: 0.5726480963276148\n",
            "Epoch: 340. Loss: 0.5706809245877067\n",
            "Epoch: 350. Loss: 0.5688504026867293\n",
            "Epoch: 360. Loss: 0.5671480994157778\n",
            "Epoch: 370. Loss: 0.5655660470307797\n",
            "Epoch: 380. Loss: 0.5640967194951431\n",
            "Epoch: 390. Loss: 0.5627330110707834\n",
            "Epoch: 400. Loss: 0.5614682152477706\n",
            "Epoch: 410. Loss: 0.560296004074131\n",
            "Epoch: 420. Loss: 0.5592104079919573\n",
            "Epoch: 430. Loss: 0.5582057963081319\n",
            "Epoch: 440. Loss: 0.5572768584316262\n",
            "Epoch: 450. Loss: 0.5564185859982106\n",
            "Epoch: 460. Loss: 0.5556262559812024\n",
            "Epoch: 470. Loss: 0.5548954148571087\n",
            "Epoch: 480. Loss: 0.5542218638611307\n",
            "Epoch: 490. Loss: 0.5536016453326947\n",
            "tensor(0.8366, dtype=torch.float64)\n",
            "2021-06-13 00:00:00\n",
            "Epoch: 0. Loss: 1.4658925394341895\n",
            "Epoch: 10. Loss: 0.7582331291798987\n",
            "Epoch: 20. Loss: 0.6531123379115248\n",
            "Epoch: 30. Loss: 0.6115440081589417\n",
            "Epoch: 40. Loss: 0.5889818464866374\n",
            "Epoch: 50. Loss: 0.5757169762546183\n",
            "Epoch: 60. Loss: 0.5672208664173101\n",
            "Epoch: 70. Loss: 0.5613507849802221\n",
            "Epoch: 80. Loss: 0.5570752171845971\n",
            "Epoch: 90. Loss: 0.5538558767264449\n",
            "Epoch: 100. Loss: 0.5513805269240926\n",
            "Epoch: 110. Loss: 0.5494497758030106\n",
            "Epoch: 120. Loss: 0.5479271623683916\n",
            "Epoch: 130. Loss: 0.5467151654936424\n",
            "Epoch: 140. Loss: 0.545742271462802\n",
            "Epoch: 150. Loss: 0.5449551833407422\n",
            "Epoch: 160. Loss: 0.5443137218387453\n",
            "Epoch: 170. Loss: 0.543787311616433\n",
            "Epoch: 180. Loss: 0.5433524886180721\n",
            "Epoch: 190. Loss: 0.5429911020536833\n",
            "Epoch: 200. Loss: 0.5426890034103644\n",
            "Epoch: 210. Loss: 0.5424350825505636\n",
            "Epoch: 220. Loss: 0.542220553623839\n",
            "Epoch: 230. Loss: 0.5420384221106882\n",
            "Epoch: 240. Loss: 0.5418830840800677\n",
            "Epoch: 250. Loss: 0.5417500226051347\n",
            "Epoch: 260. Loss: 0.5416355760774348\n",
            "Epoch: 270. Loss: 0.5415367601136283\n",
            "Epoch: 280. Loss: 0.5414511297056201\n",
            "Epoch: 290. Loss: 0.5413766718140632\n",
            "Epoch: 300. Loss: 0.5413117211595061\n",
            "Epoch: 310. Loss: 0.5412548938145975\n",
            "Epoch: 320. Loss: 0.5412050345480822\n",
            "Epoch: 330. Loss: 0.5411611748598492\n",
            "Epoch: 340. Loss: 0.5411224993768458\n",
            "Epoch: 350. Loss: 0.5410883188236164\n",
            "Epoch: 360. Loss: 0.5410580481892203\n",
            "Epoch: 370. Loss: 0.5410311890205972\n",
            "Epoch: 380. Loss: 0.5410073150070507\n",
            "Epoch: 390. Loss: 0.5409860602002804\n",
            "Epoch: 400. Loss: 0.5409671093529858\n",
            "Epoch: 410. Loss: 0.5409501899665696\n",
            "Epoch: 420. Loss: 0.5409350657223049\n",
            "Epoch: 430. Loss: 0.5409215310360437\n",
            "Epoch: 440. Loss: 0.5409094065282883\n",
            "Epoch: 450. Loss: 0.5408985352423504\n",
            "Epoch: 460. Loss: 0.540888779475795\n",
            "Epoch: 470. Loss: 0.5408800181162144\n",
            "Epoch: 480. Loss: 0.5408721443930368\n",
            "Epoch: 490. Loss: 0.5408650639736103\n",
            "tensor(0.6090, dtype=torch.float64)\n",
            "2021-06-20 00:00:00\n",
            "Epoch: 0. Loss: 2.6270434977255186\n",
            "Epoch: 10. Loss: 1.0349313028611762\n",
            "Epoch: 20. Loss: 0.7859343086251562\n",
            "Epoch: 30. Loss: 0.7165255333433579\n",
            "Epoch: 40. Loss: 0.6801942358423156\n",
            "Epoch: 50. Loss: 0.6564055951305957\n",
            "Epoch: 60. Loss: 0.6388664749601861\n",
            "Epoch: 70. Loss: 0.6248708391591337\n",
            "Epoch: 80. Loss: 0.613214902356294\n",
            "Epoch: 90. Loss: 0.6033399284726327\n",
            "Epoch: 100. Loss: 0.5949475899541071\n",
            "Epoch: 110. Loss: 0.5878403340553018\n",
            "Epoch: 120. Loss: 0.5818592842500968\n",
            "Epoch: 130. Loss: 0.5768622210755021\n",
            "Epoch: 140. Loss: 0.5727173285908521\n",
            "Epoch: 150. Loss: 0.5693026025422026\n",
            "Epoch: 160. Loss: 0.5665068035712013\n",
            "Epoch: 170. Loss: 0.5642303761291172\n",
            "Epoch: 180. Loss: 0.562385832871511\n",
            "Epoch: 190. Loss: 0.5608975529736034\n",
            "Epoch: 200. Loss: 0.5597011114875847\n",
            "Epoch: 210. Loss: 0.5587422996142041\n",
            "Epoch: 220. Loss: 0.5579759839243424\n",
            "Epoch: 230. Loss: 0.5573649207015953\n",
            "Epoch: 240. Loss: 0.5568786064727246\n",
            "Epoch: 250. Loss: 0.5564922149792378\n",
            "Epoch: 260. Loss: 0.5561856469053009\n",
            "Epoch: 270. Loss: 0.555942701680334\n",
            "Epoch: 280. Loss: 0.5557503695739395\n",
            "Epoch: 290. Loss: 0.5555982357256353\n",
            "Epoch: 300. Loss: 0.5554779843996794\n",
            "Epoch: 310. Loss: 0.5553829905519503\n",
            "Epoch: 320. Loss: 0.5553079859290714\n",
            "Epoch: 330. Loss: 0.5552487878134388\n",
            "Epoch: 340. Loss: 0.5552020797941364\n",
            "Epoch: 350. Loss: 0.5551652353361562\n",
            "Epoch: 360. Loss: 0.5551361762912023\n",
            "Epoch: 370. Loss: 0.5551132597616918\n",
            "Epoch: 380. Loss: 0.5550951878575132\n",
            "Epoch: 390. Loss: 0.555080935861288\n",
            "Epoch: 400. Loss: 0.5550696951463221\n",
            "Epoch: 410. Loss: 0.5550608278842694\n",
            "Epoch: 420. Loss: 0.5550538311524921\n",
            "Epoch: 430. Loss: 0.5550483085207971\n",
            "Epoch: 440. Loss: 0.5550439475795999\n",
            "Epoch: 450. Loss: 0.5550405021811106\n",
            "Epoch: 460. Loss: 0.5550377784145935\n",
            "Epoch: 470. Loss: 0.5550356235370166\n",
            "Epoch: 480. Loss: 0.5550339172407228\n",
            "Epoch: 490. Loss: 0.5550325647677089\n",
            "tensor(0.9131, dtype=torch.float64)\n",
            "2021-06-27 00:00:00\n",
            "Epoch: 0. Loss: 1.5243049121956902\n",
            "Epoch: 10. Loss: 1.2015692433242895\n",
            "Epoch: 20. Loss: 0.9924232288533225\n",
            "Epoch: 30. Loss: 0.8410690675406629\n",
            "Epoch: 40. Loss: 0.7327132398079294\n",
            "Epoch: 50. Loss: 0.6633292304656476\n",
            "Epoch: 60. Loss: 0.6240955183376142\n",
            "Epoch: 70. Loss: 0.6019523571879177\n",
            "Epoch: 80. Loss: 0.5878834799059014\n",
            "Epoch: 90. Loss: 0.5779112848653765\n",
            "Epoch: 100. Loss: 0.5704467876112587\n",
            "Epoch: 110. Loss: 0.564748566877748\n",
            "Epoch: 120. Loss: 0.5603769995269527\n",
            "Epoch: 130. Loss: 0.5570227424882397\n",
            "Epoch: 140. Loss: 0.554450962103406\n",
            "Epoch: 150. Loss: 0.552479571705614\n",
            "Epoch: 160. Loss: 0.5509674459067355\n",
            "Epoch: 170. Loss: 0.5498059148608925\n",
            "Epoch: 180. Loss: 0.5489118494522384\n",
            "Epoch: 190. Loss: 0.5482219602985405\n",
            "Epoch: 200. Loss: 0.5476881882192898\n",
            "Epoch: 210. Loss: 0.5472740647657028\n",
            "Epoch: 220. Loss: 0.5469518947177089\n",
            "Epoch: 230. Loss: 0.5467006057213598\n",
            "Epoch: 240. Loss: 0.5465041223433291\n",
            "Epoch: 250. Loss: 0.5463501432963427\n",
            "Epoch: 260. Loss: 0.5462292241062106\n",
            "Epoch: 270. Loss: 0.5461340890849631\n",
            "Epoch: 280. Loss: 0.5460591145904329\n",
            "Epoch: 290. Loss: 0.5459999399710506\n",
            "Epoch: 300. Loss: 0.5459531737032632\n",
            "Epoch: 310. Loss: 0.5459161706144466\n",
            "Epoch: 320. Loss: 0.545886862334238\n",
            "Epoch: 330. Loss: 0.5458636277411086\n",
            "Epoch: 340. Loss: 0.5458451935788842\n",
            "Epoch: 350. Loss: 0.5458305579266657\n",
            "Epoch: 360. Loss: 0.5458189310537851\n",
            "Epoch: 370. Loss: 0.5458096895558603\n",
            "Epoch: 380. Loss: 0.5458023406784497\n",
            "Epoch: 390. Loss: 0.5457964944859534\n",
            "Epoch: 400. Loss: 0.5457918420941981\n",
            "Epoch: 410. Loss: 0.5457881386057329\n",
            "Epoch: 420. Loss: 0.5457851897037935\n",
            "Epoch: 430. Loss: 0.5457828411008322\n",
            "Epoch: 440. Loss: 0.545780970220014\n",
            "Epoch: 450. Loss: 0.5457794796275075\n",
            "Epoch: 460. Loss: 0.5457782918403806\n",
            "Epoch: 470. Loss: 0.5457773452173169\n",
            "Epoch: 480. Loss: 0.545776590703089\n",
            "Epoch: 490. Loss: 0.5457759892471613\n",
            "tensor(0.6468, dtype=torch.float64)\n",
            "2021-07-04 00:00:00\n",
            "Epoch: 0. Loss: 3.613237866378534\n",
            "Epoch: 10. Loss: 1.2202436493983306\n",
            "Epoch: 20. Loss: 0.8488555178139331\n",
            "Epoch: 30. Loss: 0.7693689808468934\n",
            "Epoch: 40. Loss: 0.7246620089757153\n",
            "Epoch: 50. Loss: 0.6909118140871626\n",
            "Epoch: 60. Loss: 0.6634388390551175\n",
            "Epoch: 70. Loss: 0.6406795282101908\n",
            "Epoch: 80. Loss: 0.6218949195502298\n",
            "Epoch: 90. Loss: 0.6065791642037657\n",
            "Epoch: 100. Loss: 0.5942761073952494\n",
            "Epoch: 110. Loss: 0.5845347274420158\n",
            "Epoch: 120. Loss: 0.5769147989638229\n",
            "Epoch: 130. Loss: 0.5710061409996217\n",
            "Epoch: 140. Loss: 0.5664457030185561\n",
            "Epoch: 150. Loss: 0.5629268929678577\n",
            "Epoch: 160. Loss: 0.5602008766764538\n",
            "Epoch: 170. Loss: 0.558072035329643\n",
            "Epoch: 180. Loss: 0.5563903123399367\n",
            "Epoch: 190. Loss: 0.5550426705734808\n",
            "Epoch: 200. Loss: 0.5539450461969347\n",
            "Epoch: 210. Loss: 0.553035456039581\n",
            "Epoch: 220. Loss: 0.5522684322440339\n",
            "Epoch: 230. Loss: 0.5516106994454173\n",
            "Epoch: 240. Loss: 0.5510379033135068\n",
            "Epoch: 250. Loss: 0.5505321781810469\n",
            "Epoch: 260. Loss: 0.5500803603252077\n",
            "Epoch: 270. Loss: 0.5496726863896949\n",
            "Epoch: 280. Loss: 0.5493018506039975\n",
            "Epoch: 290. Loss: 0.5489623245224903\n",
            "Epoch: 300. Loss: 0.5486498674305166\n",
            "Epoch: 310. Loss: 0.5483611745275956\n",
            "Epoch: 320. Loss: 0.5480936243173578\n",
            "Epoch: 330. Loss: 0.5478450972555342\n",
            "Epoch: 340. Loss: 0.5476138454936288\n",
            "Epoch: 350. Loss: 0.5473983992183037\n",
            "Epoch: 360. Loss: 0.547197499181796\n",
            "Epoch: 370. Loss: 0.5470100479692447\n",
            "Epoch: 380. Loss: 0.5468350746688504\n",
            "Epoch: 390. Loss: 0.5466717091310952\n",
            "Epoch: 400. Loss: 0.5465191630919313\n",
            "Epoch: 410. Loss: 0.546376716213581\n",
            "Epoch: 420. Loss: 0.5462437056531907\n",
            "Epoch: 430. Loss: 0.5461195181671352\n",
            "Epoch: 440. Loss: 0.546003584042611\n",
            "Epoch: 450. Loss: 0.5458953723507111\n",
            "Epoch: 460. Loss: 0.5457943871596987\n",
            "Epoch: 470. Loss: 0.5457001644502861\n",
            "Epoch: 480. Loss: 0.5456122695482546\n",
            "Epoch: 490. Loss: 0.5455302949421923\n",
            "tensor(0.8015, dtype=torch.float64)\n",
            "2021-07-11 00:00:00\n",
            "Epoch: 0. Loss: 1.334098817251211\n",
            "Epoch: 10. Loss: 1.114326548669071\n",
            "Epoch: 20. Loss: 0.9284098156507586\n",
            "Epoch: 30. Loss: 0.785280727623609\n",
            "Epoch: 40. Loss: 0.6896861008939437\n",
            "Epoch: 50. Loss: 0.6360286810051673\n",
            "Epoch: 60. Loss: 0.6090098686022664\n",
            "Epoch: 70. Loss: 0.5944809637927465\n",
            "Epoch: 80. Loss: 0.5852197530912522\n",
            "Epoch: 90. Loss: 0.5785218068590265\n",
            "Epoch: 100. Loss: 0.5733808111095411\n",
            "Epoch: 110. Loss: 0.5693247493745783\n",
            "Epoch: 120. Loss: 0.5660685010973009\n",
            "Epoch: 130. Loss: 0.5634147662782525\n",
            "Epoch: 140. Loss: 0.561220109747448\n",
            "Epoch: 150. Loss: 0.559378659911659\n",
            "Epoch: 160. Loss: 0.557811842221218\n",
            "Epoch: 170. Loss: 0.5564611043341317\n",
            "Epoch: 180. Loss: 0.5552825938845612\n",
            "Epoch: 190. Loss: 0.5542432522104003\n",
            "Epoch: 200. Loss: 0.5533179567158917\n",
            "Epoch: 210. Loss: 0.5524874368723235\n",
            "Epoch: 220. Loss: 0.5517367564845741\n",
            "Epoch: 230. Loss: 0.551054207794246\n",
            "Epoch: 240. Loss: 0.5504305039444247\n",
            "Epoch: 250. Loss: 0.5498581872598242\n",
            "Epoch: 260. Loss: 0.5493311936864852\n",
            "Epoch: 270. Loss: 0.5488445304344253\n",
            "Epoch: 280. Loss: 0.5483940359340154\n",
            "Epoch: 290. Loss: 0.5479761998865859\n",
            "Epoch: 300. Loss: 0.5475880273990467\n",
            "Epoch: 310. Loss: 0.5472269356344245\n",
            "Epoch: 320. Loss: 0.5468906745892882\n",
            "Epoch: 330. Loss: 0.5465772658877034\n",
            "Epoch: 340. Loss: 0.5462849551187275\n",
            "Epoch: 350. Loss: 0.5460121744248719\n",
            "Epoch: 360. Loss: 0.5457575129033593\n",
            "Epoch: 370. Loss: 0.5455196930032614\n",
            "Epoch: 380. Loss: 0.5452975515556655\n",
            "Epoch: 390. Loss: 0.5450900244077453\n",
            "Epoch: 400. Loss: 0.5448961338783885\n",
            "Epoch: 410. Loss: 0.5447149784366495\n",
            "Epoch: 420. Loss: 0.5445457241418448\n",
            "Epoch: 430. Loss: 0.5443875974878271\n",
            "Epoch: 440. Loss: 0.5442398793727201\n",
            "Epoch: 450. Loss: 0.5441018999755808\n",
            "Epoch: 460. Loss: 0.5439730343677593\n",
            "Epoch: 470. Loss: 0.5438526987225752\n",
            "Epoch: 480. Loss: 0.5437403470148393\n",
            "Epoch: 490. Loss: 0.5436354681236186\n",
            "tensor(0.7767, dtype=torch.float64)\n",
            "2021-07-18 00:00:00\n",
            "Epoch: 0. Loss: 1.8810583418323392\n",
            "Epoch: 10. Loss: 1.1786304538664003\n",
            "Epoch: 20. Loss: 0.9279059329962069\n",
            "Epoch: 30. Loss: 0.7823096065501516\n",
            "Epoch: 40. Loss: 0.6853695046426277\n",
            "Epoch: 50. Loss: 0.6263049077819183\n",
            "Epoch: 60. Loss: 0.5957466676944229\n",
            "Epoch: 70. Loss: 0.5814859298423831\n",
            "Epoch: 80. Loss: 0.5745211160166204\n",
            "Epoch: 90. Loss: 0.5705223612625256\n",
            "Epoch: 100. Loss: 0.5677965236490774\n",
            "Epoch: 110. Loss: 0.5657086630647334\n",
            "Epoch: 120. Loss: 0.5640021338786272\n",
            "Epoch: 130. Loss: 0.5625557100514396\n",
            "Epoch: 140. Loss: 0.5613010627463942\n",
            "Epoch: 150. Loss: 0.5601940871388252\n",
            "Epoch: 160. Loss: 0.5592039926821359\n",
            "Epoch: 170. Loss: 0.5583084263621145\n",
            "Epoch: 180. Loss: 0.5574908356323518\n",
            "Epoch: 190. Loss: 0.5567388085655497\n",
            "Epoch: 200. Loss: 0.5560429342758476\n",
            "Epoch: 210. Loss: 0.5553959894957393\n",
            "Epoch: 220. Loss: 0.5547923497453944\n",
            "Epoch: 230. Loss: 0.5542275616541837\n",
            "Epoch: 240. Loss: 0.5536980325282295\n",
            "Epoch: 250. Loss: 0.5532008054139823\n",
            "Epoch: 260. Loss: 0.552733396381033\n",
            "Epoch: 270. Loss: 0.5522936769381036\n",
            "Epoch: 280. Loss: 0.5518797890799134\n",
            "Epoch: 290. Loss: 0.551490083855924\n",
            "Epoch: 300. Loss: 0.5511230768524932\n",
            "Epoch: 310. Loss: 0.5507774158124391\n",
            "Epoch: 320. Loss: 0.5504518569518915\n",
            "Epoch: 330. Loss: 0.5501452475036522\n",
            "Epoch: 340. Loss: 0.5498565127168619\n",
            "Epoch: 350. Loss: 0.5495846460473611\n",
            "Epoch: 360. Loss: 0.5493287016354865\n",
            "Epoch: 370. Loss: 0.5490877884275968\n",
            "Epoch: 380. Loss: 0.54886106548311\n",
            "Epoch: 390. Loss: 0.5486477381411413\n",
            "Epoch: 400. Loss: 0.5484470548150321\n",
            "Epoch: 410. Loss: 0.548258304250043\n",
            "Epoch: 420. Loss: 0.5480808131270245\n",
            "Epoch: 430. Loss: 0.5479139439286148\n",
            "Epoch: 440. Loss: 0.547757093008397\n",
            "Epoch: 450. Loss: 0.5476096888203763\n",
            "Epoch: 460. Loss: 0.547471190278103\n",
            "Epoch: 470. Loss: 0.5473410852212485\n",
            "Epoch: 480. Loss: 0.547218888973428\n",
            "Epoch: 490. Loss: 0.5471041429793218\n",
            "tensor(0.7142, dtype=torch.float64)\n",
            "2021-07-25 00:00:00\n",
            "Epoch: 0. Loss: 1.0006125180898453\n",
            "Epoch: 10. Loss: 0.8288811941570291\n",
            "Epoch: 20. Loss: 0.7102120505073815\n",
            "Epoch: 30. Loss: 0.6424545000342482\n",
            "Epoch: 40. Loss: 0.6094561443437024\n",
            "Epoch: 50. Loss: 0.5930017321793212\n",
            "Epoch: 60. Loss: 0.583144504859078\n",
            "Epoch: 70. Loss: 0.5762759263168157\n",
            "Epoch: 80. Loss: 0.5711521518861071\n",
            "Epoch: 90. Loss: 0.567222204950104\n",
            "Epoch: 100. Loss: 0.5641608231818556\n",
            "Epoch: 110. Loss: 0.561745264066864\n",
            "Epoch: 120. Loss: 0.5598150398135843\n",
            "Epoch: 130. Loss: 0.5582527061577469\n",
            "Epoch: 140. Loss: 0.5569717603165791\n",
            "Epoch: 150. Loss: 0.5559081509589111\n",
            "Epoch: 160. Loss: 0.5550141624811596\n",
            "Epoch: 170. Loss: 0.554253996102189\n",
            "Epoch: 180. Loss: 0.5536005801387032\n",
            "Epoch: 190. Loss: 0.553033267552536\n",
            "Epoch: 200. Loss: 0.552536170835253\n",
            "Epoch: 210. Loss: 0.5520969534612827\n",
            "Epoch: 220. Loss: 0.5517059483499495\n",
            "Epoch: 230. Loss: 0.5513555109945173\n",
            "Epoch: 240. Loss: 0.5510395415975532\n",
            "Epoch: 250. Loss: 0.5507531295155902\n",
            "Epoch: 260. Loss: 0.5504922867327423\n",
            "Epoch: 270. Loss: 0.5502537465598013\n",
            "Epoch: 280. Loss: 0.550034810453246\n",
            "Epoch: 290. Loss: 0.5498332305930407\n",
            "Epoch: 300. Loss: 0.5496471192305903\n",
            "Epoch: 310. Loss: 0.54947487822636\n",
            "Epoch: 320. Loss: 0.5493151439253269\n",
            "Epoch: 330. Loss: 0.5491667437667896\n",
            "Epoch: 340. Loss: 0.549028661932411\n",
            "Epoch: 350. Loss: 0.548900012000408\n",
            "Epoch: 360. Loss: 0.5487800150632896\n",
            "Epoch: 370. Loss: 0.548667982129972\n",
            "Epoch: 380. Loss: 0.5485632999049749\n",
            "Epoch: 390. Loss: 0.5484654192422246\n",
            "Epoch: 400. Loss: 0.5483738457264474\n",
            "Epoch: 410. Loss: 0.5482881319539054\n",
            "Epoch: 420. Loss: 0.5482078711755735\n",
            "Epoch: 430. Loss: 0.5481326920365499\n",
            "Epoch: 440. Loss: 0.5480622542004984\n",
            "Epoch: 450. Loss: 0.5479962446909563\n",
            "Epoch: 460. Loss: 0.547934374815179\n",
            "Epoch: 470. Loss: 0.5478763775628864\n",
            "Epoch: 480. Loss: 0.5478220053934483\n",
            "Epoch: 490. Loss: 0.5477710283418742\n",
            "tensor(0.8443, dtype=torch.float64)\n",
            "2021-08-01 00:00:00\n",
            "Epoch: 0. Loss: 1.3486728063474411\n",
            "Epoch: 10. Loss: 1.0568798069745462\n",
            "Epoch: 20. Loss: 0.8895005125941182\n",
            "Epoch: 30. Loss: 0.7738079753079098\n",
            "Epoch: 40. Loss: 0.6952171519793766\n",
            "Epoch: 50. Loss: 0.6471207548656585\n",
            "Epoch: 60. Loss: 0.620324455163984\n",
            "Epoch: 70. Loss: 0.6054625537982261\n",
            "Epoch: 80. Loss: 0.5964210737214425\n",
            "Epoch: 90. Loss: 0.5902058125350086\n",
            "Epoch: 100. Loss: 0.5855088256462951\n",
            "Epoch: 110. Loss: 0.58174222737628\n",
            "Epoch: 120. Loss: 0.5786081838397803\n",
            "Epoch: 130. Loss: 0.5759328471426347\n",
            "Epoch: 140. Loss: 0.5736030930446209\n",
            "Epoch: 150. Loss: 0.571540463193394\n",
            "Epoch: 160. Loss: 0.5696887264475544\n",
            "Epoch: 170. Loss: 0.5680068822418194\n",
            "Epoch: 180. Loss: 0.5664647040972225\n",
            "Epoch: 190. Loss: 0.5650396942155302\n",
            "Epoch: 200. Loss: 0.5637149329297857\n",
            "Epoch: 210. Loss: 0.5624775394217394\n",
            "Epoch: 220. Loss: 0.5613175644330682\n",
            "Epoch: 230. Loss: 0.5602271924416197\n",
            "Epoch: 240. Loss: 0.5592001665813296\n",
            "Epoch: 250. Loss: 0.5582313740968436\n",
            "Epoch: 260. Loss: 0.557316547508147\n",
            "Epoch: 270. Loss: 0.5564520491504279\n",
            "Epoch: 280. Loss: 0.5556347157632521\n",
            "Epoch: 290. Loss: 0.554861746306472\n",
            "Epoch: 300. Loss: 0.5541306208744916\n",
            "Epoch: 310. Loss: 0.5534390419682076\n",
            "Epoch: 320. Loss: 0.5527848918282973\n",
            "Epoch: 330. Loss: 0.5521662012969452\n",
            "Epoch: 340. Loss: 0.5515811269470754\n",
            "Epoch: 350. Loss: 0.5510279341353396\n",
            "Epoch: 360. Loss: 0.5505049842962146\n",
            "Epoch: 370. Loss: 0.5500107252707921\n",
            "Epoch: 380. Loss: 0.5495436838066238\n",
            "Epoch: 390. Loss: 0.5491024596114945\n",
            "Epoch: 400. Loss: 0.5486857205210316\n",
            "Epoch: 410. Loss: 0.5482921984670395\n",
            "Epoch: 420. Loss: 0.5479206860243759\n",
            "Epoch: 430. Loss: 0.5475700333791546\n",
            "Epoch: 440. Loss: 0.547239145607393\n",
            "Epoch: 450. Loss: 0.5469269801861628\n",
            "Epoch: 460. Loss: 0.5466325446826648\n",
            "Epoch: 470. Loss: 0.5463548945831423\n",
            "Epoch: 480. Loss: 0.5460931312351517\n",
            "Epoch: 490. Loss: 0.5458463998848334\n",
            "tensor(0.7998, dtype=torch.float64)\n",
            "2021-08-08 00:00:00\n",
            "Epoch: 0. Loss: 1.3488103465385146\n",
            "Epoch: 10. Loss: 0.8471091649055832\n",
            "Epoch: 20. Loss: 0.707970998369161\n",
            "Epoch: 30. Loss: 0.6398483544427724\n",
            "Epoch: 40. Loss: 0.6024037845737941\n",
            "Epoch: 50. Loss: 0.5816093569245506\n",
            "Epoch: 60. Loss: 0.5692682288832499\n",
            "Epoch: 70. Loss: 0.5612747137659161\n",
            "Epoch: 80. Loss: 0.5557596969903265\n",
            "Epoch: 90. Loss: 0.5518174092916882\n",
            "Epoch: 100. Loss: 0.54894598823952\n",
            "Epoch: 110. Loss: 0.5468311135885522\n",
            "Epoch: 120. Loss: 0.5452602751916148\n",
            "Epoch: 130. Loss: 0.5440843258350775\n",
            "Epoch: 140. Loss: 0.543196911419005\n",
            "Epoch: 150. Loss: 0.5425216641401603\n",
            "Epoch: 160. Loss: 0.5420035107773913\n",
            "Epoch: 170. Loss: 0.54160256279893\n",
            "Epoch: 180. Loss: 0.5412897783103899\n",
            "Epoch: 190. Loss: 0.5410438792500503\n",
            "Epoch: 200. Loss: 0.5408491628190387\n",
            "Epoch: 210. Loss: 0.5406939481791638\n",
            "Epoch: 220. Loss: 0.5405694726934708\n",
            "Epoch: 230. Loss: 0.5404691054601102\n",
            "Epoch: 240. Loss: 0.5403877846259054\n",
            "Epoch: 250. Loss: 0.5403216126801974\n",
            "Epoch: 260. Loss: 0.5402675635516512\n",
            "Epoch: 270. Loss: 0.5402232691220834\n",
            "Epoch: 280. Loss: 0.5401868624217708\n",
            "Epoch: 290. Loss: 0.5401568615091518\n",
            "Epoch: 300. Loss: 0.5401320827414232\n",
            "Epoch: 310. Loss: 0.5401115754290969\n",
            "Epoch: 320. Loss: 0.5400945721688858\n",
            "Epoch: 330. Loss: 0.5400804507655523\n",
            "Epoch: 340. Loss: 0.540068704792776\n",
            "Epoch: 350. Loss: 0.5400589206499868\n",
            "Epoch: 360. Loss: 0.5400507595464501\n",
            "Epoch: 370. Loss: 0.5400439432550569\n",
            "Epoch: 380. Loss: 0.5400382427745277\n",
            "Epoch: 390. Loss: 0.5400334692536518\n",
            "Epoch: 400. Loss: 0.5400294666882709\n",
            "Epoch: 410. Loss: 0.5400261060174378\n",
            "Epoch: 420. Loss: 0.5400232803311271\n",
            "Epoch: 430. Loss: 0.5400209009662551\n",
            "Epoch: 440. Loss: 0.5400188943163986\n",
            "Epoch: 450. Loss: 0.5400171992176648\n",
            "Epoch: 460. Loss: 0.5400157648016279\n",
            "Epoch: 470. Loss: 0.5400145487283098\n",
            "Epoch: 480. Loss: 0.5400135157293916\n",
            "Epoch: 490. Loss: 0.5400126364053787\n",
            "tensor(0.7700, dtype=torch.float64)\n",
            "2021-08-15 00:00:00\n",
            "Epoch: 0. Loss: 1.7337438548748547\n",
            "Epoch: 10. Loss: 0.6577416548587175\n",
            "Epoch: 20. Loss: 0.620844279830236\n",
            "Epoch: 30. Loss: 0.6071873271083523\n",
            "Epoch: 40. Loss: 0.5968595157391071\n",
            "Epoch: 50. Loss: 0.5881843662805403\n",
            "Epoch: 60. Loss: 0.580742147004394\n",
            "Epoch: 70. Loss: 0.5743337429936315\n",
            "Epoch: 80. Loss: 0.5688266189735262\n",
            "Epoch: 90. Loss: 0.5641123175206748\n",
            "Epoch: 100. Loss: 0.560093427612026\n",
            "Epoch: 110. Loss: 0.5566803390721589\n",
            "Epoch: 120. Loss: 0.5537910121172982\n",
            "Epoch: 130. Loss: 0.551351356236035\n",
            "Epoch: 140. Loss: 0.5492954453088018\n",
            "Epoch: 150. Loss: 0.5475654009664436\n",
            "Epoch: 160. Loss: 0.5461109841254024\n",
            "Epoch: 170. Loss: 0.5448889892743426\n",
            "Epoch: 180. Loss: 0.5438625339398431\n",
            "Epoch: 190. Loss: 0.5430003157029475\n",
            "Epoch: 200. Loss: 0.5422758866784106\n",
            "Epoch: 210. Loss: 0.5416669761649077\n",
            "Epoch: 220. Loss: 0.5411548776797457\n",
            "Epoch: 230. Loss: 0.5407239065376995\n",
            "Epoch: 240. Loss: 0.5403609276655864\n",
            "Epoch: 250. Loss: 0.5400549495265108\n",
            "Epoch: 260. Loss: 0.5397967780469106\n",
            "Epoch: 270. Loss: 0.539578723661968\n",
            "Epoch: 280. Loss: 0.5393943545601199\n",
            "Epoch: 290. Loss: 0.5392382895974739\n",
            "Epoch: 300. Loss: 0.5391060249582\n",
            "Epoch: 310. Loss: 0.5389937893250981\n",
            "Epoch: 320. Loss: 0.5388984230163057\n",
            "Epoch: 330. Loss: 0.5388172771954096\n",
            "Epoch: 340. Loss: 0.538748129851358\n",
            "Epoch: 350. Loss: 0.5386891157636131\n",
            "Epoch: 360. Loss: 0.5386386681170576\n",
            "Epoch: 370. Loss: 0.5385954698147404\n",
            "Epoch: 380. Loss: 0.5385584128611621\n",
            "Epoch: 390. Loss: 0.5385265644617131\n",
            "Epoch: 400. Loss: 0.5384991387121917\n",
            "Epoch: 410. Loss: 0.5384754729427338\n",
            "Epoch: 420. Loss: 0.5384550079388416\n",
            "Epoch: 430. Loss: 0.5384372713937526\n",
            "Epoch: 440. Loss: 0.5384218640555213\n",
            "Epoch: 450. Loss: 0.5384084481227076\n",
            "Epoch: 460. Loss: 0.5383967375176285\n",
            "Epoch: 470. Loss: 0.5383864897283647\n",
            "Epoch: 480. Loss: 0.5383774989623643\n",
            "Epoch: 490. Loss: 0.5383695903973416\n",
            "tensor(0.7840, dtype=torch.float64)\n",
            "2021-08-22 00:00:00\n",
            "Epoch: 0. Loss: 1.3153470152711313\n",
            "Epoch: 10. Loss: 0.8121639110229063\n",
            "Epoch: 20. Loss: 0.7056369215674764\n",
            "Epoch: 30. Loss: 0.6460897596586113\n",
            "Epoch: 40. Loss: 0.6095156069448447\n",
            "Epoch: 50. Loss: 0.5889282607720018\n",
            "Epoch: 60. Loss: 0.5773867683532317\n",
            "Epoch: 70. Loss: 0.5701104400840376\n",
            "Epoch: 80. Loss: 0.564796896983625\n",
            "Epoch: 90. Loss: 0.5605171574918023\n",
            "Epoch: 100. Loss: 0.5569033605690962\n",
            "Epoch: 110. Loss: 0.5537926237012861\n",
            "Epoch: 120. Loss: 0.551096263252724\n",
            "Epoch: 130. Loss: 0.5487543002698297\n",
            "Epoch: 140. Loss: 0.5467196997983961\n",
            "Epoch: 150. Loss: 0.5449527702224878\n",
            "Epoch: 160. Loss: 0.543419027179694\n",
            "Epoch: 170. Loss: 0.5420882380323928\n",
            "Epoch: 180. Loss: 0.5409338684802395\n",
            "Epoch: 190. Loss: 0.5399326695802136\n",
            "Epoch: 200. Loss: 0.5390643207176934\n",
            "Epoch: 210. Loss: 0.5383111038311942\n",
            "Epoch: 220. Loss: 0.5376576032480358\n",
            "Epoch: 230. Loss: 0.5370904306849447\n",
            "Epoch: 240. Loss: 0.5365979756966309\n",
            "Epoch: 250. Loss: 0.5361701813536859\n",
            "Epoch: 260. Loss: 0.5357983442642177\n",
            "Epoch: 270. Loss: 0.5354749375288824\n",
            "Epoch: 280. Loss: 0.5351934548884153\n",
            "Epoch: 290. Loss: 0.5349482741605139\n",
            "Epoch: 300. Loss: 0.5347345380264107\n",
            "Epoch: 310. Loss: 0.5345480502770499\n",
            "Epoch: 320. Loss: 0.5343851857328588\n",
            "Epoch: 330. Loss: 0.5342428121862339\n",
            "Epoch: 340. Loss: 0.5341182228654877\n",
            "Epoch: 350. Loss: 0.5340090780718522\n",
            "Epoch: 360. Loss: 0.5339133547899482\n",
            "Epoch: 370. Loss: 0.5338293032124415\n",
            "Epoch: 380. Loss: 0.5337554092489852\n",
            "Epoch: 390. Loss: 0.5336903622069135\n",
            "Epoch: 400. Loss: 0.5336330269363085\n",
            "Epoch: 410. Loss: 0.533582419825418\n",
            "Epoch: 420. Loss: 0.5335376881146611\n",
            "Epoch: 430. Loss: 0.5334980920695392\n",
            "Epoch: 440. Loss: 0.5334629896156471\n",
            "Epoch: 450. Loss: 0.533431823093625\n",
            "Epoch: 460. Loss: 0.5334041078392642\n",
            "Epoch: 470. Loss: 0.5333794223349443\n",
            "Epoch: 480. Loss: 0.5333573997139504\n",
            "Epoch: 490. Loss: 0.5333377204297101\n",
            "tensor(0.8188, dtype=torch.float64)\n",
            "2021-08-29 00:00:00\n",
            "Epoch: 0. Loss: 1.7309666050600805\n",
            "Epoch: 10. Loss: 0.7104055695181417\n",
            "Epoch: 20. Loss: 0.6204430654121217\n",
            "Epoch: 30. Loss: 0.5910454917391877\n",
            "Epoch: 40. Loss: 0.5767193617115997\n",
            "Epoch: 50. Loss: 0.568376904481974\n",
            "Epoch: 60. Loss: 0.5626322092676895\n",
            "Epoch: 70. Loss: 0.5581843858372189\n",
            "Epoch: 80. Loss: 0.5545162883685935\n",
            "Epoch: 90. Loss: 0.5514010352444882\n",
            "Epoch: 100. Loss: 0.5487214958385722\n",
            "Epoch: 110. Loss: 0.5464044258073458\n",
            "Epoch: 120. Loss: 0.5443961743099307\n",
            "Epoch: 130. Loss: 0.5426535191965814\n",
            "Epoch: 140. Loss: 0.5411400219400827\n",
            "Epoch: 150. Loss: 0.5398243987481999\n",
            "Epoch: 160. Loss: 0.538679634046344\n",
            "Epoch: 170. Loss: 0.5376823782662055\n",
            "Epoch: 180. Loss: 0.5368124684326737\n",
            "Epoch: 190. Loss: 0.5360525160558653\n",
            "Epoch: 200. Loss: 0.5353875434866265\n",
            "Epoch: 210. Loss: 0.5348046617647604\n",
            "Epoch: 220. Loss: 0.534292786337509\n",
            "Epoch: 230. Loss: 0.5338423876718325\n",
            "Epoch: 240. Loss: 0.5334452737351357\n",
            "Epoch: 250. Loss: 0.5330944012130744\n",
            "Epoch: 260. Loss: 0.5327837123320728\n",
            "Epoch: 270. Loss: 0.5325079942670504\n",
            "Epoch: 280. Loss: 0.5322627583100344\n",
            "Epoch: 290. Loss: 0.5320441362180585\n",
            "Epoch: 300. Loss: 0.5318487914213604\n",
            "Epoch: 310. Loss: 0.5316738430360776\n",
            "Epoch: 320. Loss: 0.531516800877194\n",
            "Epoch: 330. Loss: 0.5313755099004078\n",
            "Epoch: 340. Loss: 0.5312481027124775\n",
            "Epoch: 350. Loss: 0.5311329589775291\n",
            "Epoch: 360. Loss: 0.5310286707122379\n",
            "Epoch: 370. Loss: 0.5309340126071593\n",
            "Epoch: 380. Loss: 0.5308479166365806\n",
            "Epoch: 390. Loss: 0.5307694503271294\n",
            "Epoch: 400. Loss: 0.5306977981479948\n",
            "Epoch: 410. Loss: 0.5306322455649312\n",
            "Epoch: 420. Loss: 0.5305721653679691\n",
            "Epoch: 430. Loss: 0.5305170059405536\n",
            "Epoch: 440. Loss: 0.5304662811870682\n",
            "Epoch: 450. Loss: 0.5304195618776195\n",
            "Epoch: 460. Loss: 0.5303764682046243\n",
            "Epoch: 470. Loss: 0.530336663376083\n",
            "Epoch: 480. Loss: 0.5302998480962242\n",
            "Epoch: 490. Loss: 0.5302657558061693\n",
            "tensor(0.8696, dtype=torch.float64)\n",
            "2021-09-05 00:00:00\n",
            "Epoch: 0. Loss: 5.92801288953838\n",
            "Epoch: 10. Loss: 1.570333164867508\n",
            "Epoch: 20. Loss: 0.735541323189478\n",
            "Epoch: 30. Loss: 0.6466938577854957\n",
            "Epoch: 40. Loss: 0.6047749141653338\n",
            "Epoch: 50. Loss: 0.5772181367796664\n",
            "Epoch: 60. Loss: 0.5589867779793931\n",
            "Epoch: 70. Loss: 0.5467778916919636\n",
            "Epoch: 80. Loss: 0.5383662400303513\n",
            "Epoch: 90. Loss: 0.5324000384005457\n",
            "Epoch: 100. Loss: 0.5280789957429021\n",
            "Epoch: 110. Loss: 0.5249117062651272\n",
            "Epoch: 120. Loss: 0.5225766422227738\n",
            "Epoch: 130. Loss: 0.5208507152594558\n",
            "Epoch: 140. Loss: 0.51957303718599\n",
            "Epoch: 150. Loss: 0.5186253484928557\n",
            "Epoch: 160. Loss: 0.517920206683317\n",
            "Epoch: 170. Loss: 0.5173930182289465\n",
            "Epoch: 180. Loss: 0.5169962479682481\n",
            "Epoch: 190. Loss: 0.516695065288572\n",
            "Epoch: 200. Loss: 0.5164640446789154\n",
            "Epoch: 210. Loss: 0.5162846767703064\n",
            "Epoch: 220. Loss: 0.5161435075521114\n",
            "Epoch: 230. Loss: 0.5160307603688641\n",
            "Epoch: 240. Loss: 0.5159393240219169\n",
            "Epoch: 250. Loss: 0.5158640148273866\n",
            "Epoch: 260. Loss: 0.5158010413339805\n",
            "Epoch: 270. Loss: 0.5157476175713682\n",
            "Epoch: 280. Loss: 0.5157016843706741\n",
            "Epoch: 290. Loss: 0.5156617088877087\n",
            "Epoch: 300. Loss: 0.5156265404861091\n",
            "Epoch: 310. Loss: 0.5155953071223809\n",
            "Epoch: 320. Loss: 0.5155673407822287\n",
            "Epoch: 330. Loss: 0.5155421237331156\n",
            "Epoch: 340. Loss: 0.5155192496876192\n",
            "Epoch: 350. Loss: 0.5154983956511108\n",
            "Epoch: 360. Loss: 0.5154793014326311\n",
            "Epoch: 370. Loss: 0.5154617546607109\n",
            "Epoch: 380. Loss: 0.5154455797623648\n",
            "Epoch: 390. Loss: 0.5154306298033474\n",
            "Epoch: 400. Loss: 0.5154167804013556\n",
            "Epoch: 410. Loss: 0.5154039251473838\n",
            "Epoch: 420. Loss: 0.5153919721297705\n",
            "Epoch: 430. Loss: 0.5153808412691341\n",
            "Epoch: 440. Loss: 0.5153704622535267\n",
            "Epoch: 450. Loss: 0.5153607729211599\n",
            "Epoch: 460. Loss: 0.5153517179795972\n",
            "Epoch: 470. Loss: 0.5153432479801427\n",
            "Epoch: 480. Loss: 0.5153353184876245\n",
            "Epoch: 490. Loss: 0.5153278894012832\n",
            "tensor(0.8000, dtype=torch.float64)\n",
            "2021-09-12 00:00:00\n",
            "Epoch: 0. Loss: 2.5577082669032856\n",
            "Epoch: 10. Loss: 0.8460627273090667\n",
            "Epoch: 20. Loss: 0.7073065998751193\n",
            "Epoch: 30. Loss: 0.6637543153294985\n",
            "Epoch: 40. Loss: 0.6327649574081932\n",
            "Epoch: 50. Loss: 0.6071065769101159\n",
            "Epoch: 60. Loss: 0.5860660806694469\n",
            "Epoch: 70. Loss: 0.5692120880641183\n",
            "Epoch: 80. Loss: 0.5560139704676602\n",
            "Epoch: 90. Loss: 0.5458832766202397\n",
            "Epoch: 100. Loss: 0.538234796344991\n",
            "Epoch: 110. Loss: 0.532533533283953\n",
            "Epoch: 120. Loss: 0.5283216439610793\n",
            "Epoch: 130. Loss: 0.5252269663875482\n",
            "Epoch: 140. Loss: 0.5229585977246215\n",
            "Epoch: 150. Loss: 0.5212956027432379\n",
            "Epoch: 160. Loss: 0.5200735682805463\n",
            "Epoch: 170. Loss: 0.5191718208166277\n",
            "Epoch: 180. Loss: 0.5185025719046479\n",
            "Epoch: 190. Loss: 0.5180022899217701\n",
            "Epoch: 200. Loss: 0.517625116978203\n",
            "Epoch: 210. Loss: 0.5173379749602055\n",
            "Epoch: 220. Loss: 0.5171169866463601\n",
            "Epoch: 230. Loss: 0.5169448851960327\n",
            "Epoch: 240. Loss: 0.5168091505352517\n",
            "Epoch: 250. Loss: 0.5167006732221904\n",
            "Epoch: 260. Loss: 0.5166127979749024\n",
            "Epoch: 270. Loss: 0.5165406391713393\n",
            "Epoch: 280. Loss: 0.5164805906871499\n",
            "Epoch: 290. Loss: 0.5164299744537042\n",
            "Epoch: 300. Loss: 0.5163867880323906\n",
            "Epoch: 310. Loss: 0.5163495229113081\n",
            "Epoch: 320. Loss: 0.5163170333733895\n",
            "Epoch: 330. Loss: 0.5162884415817237\n",
            "Epoch: 340. Loss: 0.5162630686497939\n",
            "Epoch: 350. Loss: 0.5162403843947961\n",
            "Epoch: 360. Loss: 0.5162199705563517\n",
            "Epoch: 370. Loss: 0.5162014937463475\n",
            "Epoch: 380. Loss: 0.5161846854525511\n",
            "Epoch: 390. Loss: 0.5161693271726225\n",
            "Epoch: 400. Loss: 0.5161552392937263\n",
            "Epoch: 410. Loss: 0.5161422727182783\n",
            "Epoch: 420. Loss: 0.5161303025124694\n",
            "Epoch: 430. Loss: 0.5161192230524491\n",
            "Epoch: 440. Loss: 0.5161089442856376\n",
            "Epoch: 450. Loss: 0.5160993888274411\n",
            "Epoch: 460. Loss: 0.5160904896879436\n",
            "Epoch: 470. Loss: 0.5160821884769937\n",
            "Epoch: 480. Loss: 0.5160744339752577\n",
            "Epoch: 490. Loss: 0.5160671809873673\n",
            "tensor(0.7885, dtype=torch.float64)\n",
            "2021-09-19 00:00:00\n",
            "Epoch: 0. Loss: 1.0863449261671099\n",
            "Epoch: 10. Loss: 0.9595692143753772\n",
            "Epoch: 20. Loss: 0.8679332492855238\n",
            "Epoch: 30. Loss: 0.800111267860407\n",
            "Epoch: 40. Loss: 0.7478666784369122\n",
            "Epoch: 50. Loss: 0.706262784255965\n",
            "Epoch: 60. Loss: 0.6724451133630017\n",
            "Epoch: 70. Loss: 0.6446804708407038\n",
            "Epoch: 80. Loss: 0.6218534545286926\n",
            "Epoch: 90. Loss: 0.6031710003438151\n",
            "Epoch: 100. Loss: 0.5879946512997075\n",
            "Epoch: 110. Loss: 0.575762929310438\n",
            "Epoch: 120. Loss: 0.565967663676901\n",
            "Epoch: 130. Loss: 0.5581545118167632\n",
            "Epoch: 140. Loss: 0.5519288693800948\n",
            "Epoch: 150. Loss: 0.5469586459807471\n",
            "Epoch: 160. Loss: 0.5429720598031823\n",
            "Epoch: 170. Loss: 0.5397516409929909\n",
            "Epoch: 180. Loss: 0.5371263347893576\n",
            "Epoch: 190. Loss: 0.53496325296024\n",
            "Epoch: 200. Loss: 0.5331600272643989\n",
            "Epoch: 210. Loss: 0.5316382127352899\n",
            "Epoch: 220. Loss: 0.5303378555019392\n",
            "Epoch: 230. Loss: 0.5292131572960004\n",
            "Epoch: 240. Loss: 0.5282290884573001\n",
            "Epoch: 250. Loss: 0.5273587805251481\n",
            "Epoch: 260. Loss: 0.5265815389827687\n",
            "Epoch: 270. Loss: 0.5258813387189823\n",
            "Epoch: 280. Loss: 0.5252456897407067\n",
            "Epoch: 290. Loss: 0.5246647840498294\n",
            "Epoch: 300. Loss: 0.524130854606649\n",
            "Epoch: 310. Loss: 0.523637693578593\n",
            "Epoch: 320. Loss: 0.5231802899045092\n",
            "Epoch: 330. Loss: 0.5227545561160765\n",
            "Epoch: 340. Loss: 0.5223571219093909\n",
            "Epoch: 350. Loss: 0.5219851776601507\n",
            "Epoch: 360. Loss: 0.521636355351774\n",
            "Epoch: 370. Loss: 0.5213086375795576\n",
            "Epoch: 380. Loss: 0.5210002876729719\n",
            "Epoch: 390. Loss: 0.520709795747255\n",
            "Epoch: 400. Loss: 0.5204358368099454\n",
            "Epoch: 410. Loss: 0.5201772380244827\n",
            "Epoch: 420. Loss: 0.5199329529587096\n",
            "Epoch: 430. Loss: 0.5197020411858573\n",
            "Epoch: 440. Loss: 0.5194836520075564\n",
            "Epoch: 450. Loss: 0.5192770113682349\n",
            "Epoch: 460. Loss: 0.5190814112543627\n",
            "Epoch: 470. Loss: 0.518896201039895\n",
            "Epoch: 480. Loss: 0.5187207803653976\n",
            "Epoch: 490. Loss: 0.5185545932334032\n",
            "tensor(0.7583, dtype=torch.float64)\n",
            "2021-09-26 00:00:00\n",
            "Epoch: 0. Loss: 0.8528407910851868\n",
            "Epoch: 10. Loss: 0.7448604307852961\n",
            "Epoch: 20. Loss: 0.6625195540931936\n",
            "Epoch: 30. Loss: 0.6041863795026681\n",
            "Epoch: 40. Loss: 0.5669893158115263\n",
            "Epoch: 50. Loss: 0.5453360087191165\n",
            "Epoch: 60. Loss: 0.5332219294174017\n",
            "Epoch: 70. Loss: 0.5263806436037474\n",
            "Epoch: 80. Loss: 0.5223777765908113\n",
            "Epoch: 90. Loss: 0.519931554236551\n",
            "Epoch: 100. Loss: 0.5183718164184166\n",
            "Epoch: 110. Loss: 0.5173392808250844\n",
            "Epoch: 120. Loss: 0.5166338511735394\n",
            "Epoch: 130. Loss: 0.5161392325452251\n",
            "Epoch: 140. Loss: 0.5157849036889461\n",
            "Epoch: 150. Loss: 0.5155263988083605\n",
            "Epoch: 160. Loss: 0.5153347230165765\n",
            "Epoch: 170. Loss: 0.5151904428504354\n",
            "Epoch: 180. Loss: 0.5150802470341943\n",
            "Epoch: 190. Loss: 0.5149948616241803\n",
            "Epoch: 200. Loss: 0.5149277383145129\n",
            "Epoch: 210. Loss: 0.5148742025990372\n",
            "Epoch: 220. Loss: 0.5148308862300514\n",
            "Epoch: 230. Loss: 0.5147953415016692\n",
            "Epoch: 240. Loss: 0.5147657751177519\n",
            "Epoch: 250. Loss: 0.5147408624561006\n",
            "Epoch: 260. Loss: 0.5147196167934313\n",
            "Epoch: 270. Loss: 0.5147012965761043\n",
            "Epoch: 280. Loss: 0.5146853392761067\n",
            "Epoch: 290. Loss: 0.5146713139582723\n",
            "Epoch: 300. Loss: 0.514658887092556\n",
            "Epoch: 310. Loss: 0.5146477977872868\n",
            "Epoch: 320. Loss: 0.5146378397522889\n",
            "Epoch: 330. Loss: 0.5146288480891759\n",
            "Epoch: 340. Loss: 0.5146206895582508\n",
            "Epoch: 350. Loss: 0.51461325536001\n",
            "Epoch: 360. Loss: 0.5146064557437348\n",
            "Epoch: 370. Loss: 0.5146002159502034\n",
            "Epoch: 380. Loss: 0.5145944731338271\n",
            "Epoch: 390. Loss: 0.5145891740080595\n",
            "Epoch: 400. Loss: 0.5145842730283545\n",
            "Epoch: 410. Loss: 0.5145797309774018\n",
            "Epoch: 420. Loss: 0.5145755138536502\n",
            "Epoch: 430. Loss: 0.5145715919902745\n",
            "Epoch: 440. Loss: 0.5145679393506742\n",
            "Epoch: 450. Loss: 0.5145645329603388\n",
            "Epoch: 460. Loss: 0.5145613524449597\n",
            "Epoch: 470. Loss: 0.5145583796520209\n",
            "Epoch: 480. Loss: 0.5145555983385381\n",
            "Epoch: 490. Loss: 0.5145529939116382\n",
            "tensor(0.8196, dtype=torch.float64)\n",
            "2021-10-03 00:00:00\n",
            "Epoch: 0. Loss: 1.5957093242951597\n",
            "Epoch: 10. Loss: 0.9945096383901431\n",
            "Epoch: 20. Loss: 0.8326463922232122\n",
            "Epoch: 30. Loss: 0.7431741777886038\n",
            "Epoch: 40. Loss: 0.6773821472503968\n",
            "Epoch: 50. Loss: 0.6280935447794248\n",
            "Epoch: 60. Loss: 0.5924037028528583\n",
            "Epoch: 70. Loss: 0.5674363970591385\n",
            "Epoch: 80. Loss: 0.5503609512528495\n",
            "Epoch: 90. Loss: 0.5387538014129234\n",
            "Epoch: 100. Loss: 0.5307909842795381\n",
            "Epoch: 110. Loss: 0.5252256782566844\n",
            "Epoch: 120. Loss: 0.5212514439107369\n",
            "Epoch: 130. Loss: 0.5183556517157234\n",
            "Epoch: 140. Loss: 0.5162089420687255\n",
            "Epoch: 150. Loss: 0.5145940815668956\n",
            "Epoch: 160. Loss: 0.513363354237105\n",
            "Epoch: 170. Loss: 0.5124135418357731\n",
            "Epoch: 180. Loss: 0.5116710075368183\n",
            "Epoch: 190. Loss: 0.5110824697307071\n",
            "Epoch: 200. Loss: 0.510609030088845\n",
            "Epoch: 210. Loss: 0.5102221382991591\n",
            "Epoch: 220. Loss: 0.5099007711351561\n",
            "Epoch: 230. Loss: 0.5096294137058854\n",
            "Epoch: 240. Loss: 0.5093965939034532\n",
            "Epoch: 250. Loss: 0.5091938101350606\n",
            "Epoch: 260. Loss: 0.5090147439997793\n",
            "Epoch: 270. Loss: 0.5088546815697723\n",
            "Epoch: 280. Loss: 0.5087100881193068\n",
            "Epoch: 290. Loss: 0.5085782958903498\n",
            "Epoch: 300. Loss: 0.5084572750926662\n",
            "Epoch: 310. Loss: 0.5083454661144071\n",
            "Epoch: 320. Loss: 0.508241656673265\n",
            "Epoch: 330. Loss: 0.5081448919080976\n",
            "Epoch: 340. Loss: 0.5080544085786104\n",
            "Epoch: 350. Loss: 0.5079695868863751\n",
            "Epoch: 360. Loss: 0.5078899151630317\n",
            "Epoch: 370. Loss: 0.507814963947773\n",
            "Epoch: 380. Loss: 0.5077443669138976\n",
            "Epoch: 390. Loss: 0.5076778067915014\n",
            "Epoch: 400. Loss: 0.5076150049361071\n",
            "Epoch: 410. Loss: 0.5075557135600753\n",
            "Epoch: 420. Loss: 0.5074997099112422\n",
            "Epoch: 430. Loss: 0.5074467918780713\n",
            "Epoch: 440. Loss: 0.5073967746423541\n",
            "Epoch: 450. Loss: 0.5073494881035184\n",
            "Epoch: 460. Loss: 0.5073047748734736\n",
            "Epoch: 470. Loss: 0.5072624886952933\n",
            "Epoch: 480. Loss: 0.5072224931785471\n",
            "Epoch: 490. Loss: 0.5071846607727871\n",
            "tensor(0.9304, dtype=torch.float64)\n",
            "2021-10-10 00:00:00\n",
            "Epoch: 0. Loss: 2.841713536164846\n",
            "Epoch: 10. Loss: 1.0609292105964954\n",
            "Epoch: 20. Loss: 0.7611248174837101\n",
            "Epoch: 30. Loss: 0.662067823510243\n",
            "Epoch: 40. Loss: 0.6068110592592936\n",
            "Epoch: 50. Loss: 0.5752672367949894\n",
            "Epoch: 60. Loss: 0.5566991415865606\n",
            "Epoch: 70. Loss: 0.544673015185744\n",
            "Epoch: 80. Loss: 0.536217664704088\n",
            "Epoch: 90. Loss: 0.5300122860265961\n",
            "Epoch: 100. Loss: 0.5253832013814691\n",
            "Epoch: 110. Loss: 0.5219170256109085\n",
            "Epoch: 120. Loss: 0.5193241397101116\n",
            "Epoch: 130. Loss: 0.5173883038294094\n",
            "Epoch: 140. Loss: 0.5159447290587068\n",
            "Epoch: 150. Loss: 0.5148677647526774\n",
            "Epoch: 160. Loss: 0.5140622662909504\n",
            "Epoch: 170. Loss: 0.5134568308532598\n",
            "Epoch: 180. Loss: 0.5129983378290299\n",
            "Epoch: 190. Loss: 0.5126475684830029\n",
            "Epoch: 200. Loss: 0.5123757503735462\n",
            "Epoch: 210. Loss: 0.5121618803730696\n",
            "Epoch: 220. Loss: 0.5119906843689622\n",
            "Epoch: 230. Loss: 0.5118510833447194\n",
            "Epoch: 240. Loss: 0.5117350529682491\n",
            "Epoch: 250. Loss: 0.5116367833372145\n",
            "Epoch: 260. Loss: 0.5115520643351975\n",
            "Epoch: 270. Loss: 0.5114778386144235\n",
            "Epoch: 280. Loss: 0.5114118779906419\n",
            "Epoch: 290. Loss: 0.511352550042596\n",
            "Epoch: 300. Loss: 0.511298650264721\n",
            "Epoch: 310. Loss: 0.5112492816388304\n",
            "Epoch: 320. Loss: 0.5112037683796722\n",
            "Epoch: 330. Loss: 0.5111615942348958\n",
            "Epoch: 340. Loss: 0.5111223583848117\n",
            "Epoch: 350. Loss: 0.5110857439323413\n",
            "Epoch: 360. Loss: 0.5110514953853575\n",
            "Epoch: 370. Loss: 0.5110194025538473\n",
            "Epoch: 380. Loss: 0.5109892890189598\n",
            "Epoch: 390. Loss: 0.5109610038584436\n",
            "Epoch: 400. Loss: 0.5109344156907286\n",
            "Epoch: 410. Loss: 0.5109094083699464\n",
            "Epoch: 420. Loss: 0.5108858778568622\n",
            "Epoch: 430. Loss: 0.5108637299280222\n",
            "Epoch: 440. Loss: 0.5108428784831469\n",
            "Epoch: 450. Loss: 0.5108232442803123\n",
            "Epoch: 460. Loss: 0.5108047539778388\n",
            "Epoch: 470. Loss: 0.5107873393968715\n",
            "Epoch: 480. Loss: 0.5107709369435259\n",
            "Epoch: 490. Loss: 0.5107554871471152\n",
            "tensor(0.6530, dtype=torch.float64)\n",
            "2021-10-17 00:00:00\n",
            "Epoch: 0. Loss: 0.7469052790236145\n",
            "Epoch: 10. Loss: 0.5333235502211541\n",
            "Epoch: 20. Loss: 0.5248819744193163\n",
            "Epoch: 30. Loss: 0.5205226280075547\n",
            "Epoch: 40. Loss: 0.5175306493869601\n",
            "Epoch: 50. Loss: 0.5153794500999758\n",
            "Epoch: 60. Loss: 0.5137975748096819\n",
            "Epoch: 70. Loss: 0.5126152353122412\n",
            "Epoch: 80. Loss: 0.5117179169498026\n",
            "Epoch: 90. Loss: 0.5110258218268974\n",
            "Epoch: 100. Loss: 0.5104825634387307\n",
            "Epoch: 110. Loss: 0.5100480340398321\n",
            "Epoch: 120. Loss: 0.5096935908604284\n",
            "Epoch: 130. Loss: 0.5093987123658253\n",
            "Epoch: 140. Loss: 0.50914864742515\n",
            "Epoch: 150. Loss: 0.5089327535388269\n",
            "Epoch: 160. Loss: 0.5087433187983428\n",
            "Epoch: 170. Loss: 0.5085747252353968\n",
            "Epoch: 180. Loss: 0.5084228537823654\n",
            "Epoch: 190. Loss: 0.5082846605388195\n",
            "Epoch: 200. Loss: 0.5081578746661292\n",
            "Epoch: 210. Loss: 0.5080407827425295\n",
            "Epoch: 220. Loss: 0.5079320746470569\n",
            "Epoch: 230. Loss: 0.5078307332751538\n",
            "Epoch: 240. Loss: 0.5077359555093599\n",
            "Epoch: 250. Loss: 0.507647095497859\n",
            "Epoch: 260. Loss: 0.5075636238692607\n",
            "Epoch: 270. Loss: 0.507485098341988\n",
            "Epoch: 280. Loss: 0.507411142488306\n",
            "Epoch: 290. Loss: 0.5073414303398405\n",
            "Epoch: 300. Loss: 0.5072756751819641\n",
            "Epoch: 310. Loss: 0.5072136213555651\n",
            "Epoch: 320. Loss: 0.5071550382209981\n",
            "Epoch: 330. Loss: 0.5070997156792255\n",
            "Epoch: 340. Loss: 0.5070474608168062\n",
            "Epoch: 350. Loss: 0.5069980953641269\n",
            "Epoch: 360. Loss: 0.5069514537440697\n",
            "Epoch: 370. Loss: 0.5069073815511388\n",
            "Epoch: 380. Loss: 0.5068657343460489\n",
            "Epoch: 390. Loss: 0.5068263766830003\n",
            "Epoch: 400. Loss: 0.5067891813099463\n",
            "Epoch: 410. Loss: 0.5067540284987155\n",
            "Epoch: 420. Loss: 0.5067208054737259\n",
            "Epoch: 430. Loss: 0.5066894059165529\n",
            "Epoch: 440. Loss: 0.5066597295297448\n",
            "Epoch: 450. Loss: 0.5066316816476858\n",
            "Epoch: 460. Loss: 0.506605172885491\n",
            "Epoch: 470. Loss: 0.5065801188192082\n",
            "Epoch: 480. Loss: 0.5065564396922675\n",
            "Epoch: 490. Loss: 0.5065340601443251\n",
            "tensor(0.7448, dtype=torch.float64)\n",
            "2021-10-24 00:00:00\n",
            "Epoch: 0. Loss: 0.9672051120973044\n",
            "Epoch: 10. Loss: 0.7872425718685373\n",
            "Epoch: 20. Loss: 0.659949835529054\n",
            "Epoch: 30. Loss: 0.5870501682181783\n",
            "Epoch: 40. Loss: 0.55378611122565\n",
            "Epoch: 50. Loss: 0.5399162578143473\n",
            "Epoch: 60. Loss: 0.5332750674764972\n",
            "Epoch: 70. Loss: 0.5291679864589166\n",
            "Epoch: 80. Loss: 0.5260974016871186\n",
            "Epoch: 90. Loss: 0.5235925948166529\n",
            "Epoch: 100. Loss: 0.5214832138221354\n",
            "Epoch: 110. Loss: 0.5196876186458452\n",
            "Epoch: 120. Loss: 0.5181535380693695\n",
            "Epoch: 130. Loss: 0.5168411278570745\n",
            "Epoch: 140. Loss: 0.5157176887894722\n",
            "Epoch: 150. Loss: 0.5147556603363416\n",
            "Epoch: 160. Loss: 0.5139316001014178\n",
            "Epoch: 170. Loss: 0.5132255078472172\n",
            "Epoch: 180. Loss: 0.512620303946307\n",
            "Epoch: 190. Loss: 0.5121013993022508\n",
            "Epoch: 200. Loss: 0.5116563316019863\n",
            "Epoch: 210. Loss: 0.511274454963042\n",
            "Epoch: 220. Loss: 0.5109466744968476\n",
            "Epoch: 230. Loss: 0.5106652192720468\n",
            "Epoch: 240. Loss: 0.5104234482599802\n",
            "Epoch: 250. Loss: 0.5102156846129484\n",
            "Epoch: 260. Loss: 0.5100370742462853\n",
            "Epoch: 270. Loss: 0.5098834652304772\n",
            "Epoch: 280. Loss: 0.5097513049715112\n",
            "Epoch: 290. Loss: 0.5096375525748704\n",
            "Epoch: 300. Loss: 0.5095396041557099\n",
            "Epoch: 310. Loss: 0.5094552291786685\n",
            "Epoch: 320. Loss: 0.5093825161895106\n",
            "Epoch: 330. Loss: 0.5093198265415395\n",
            "Epoch: 340. Loss: 0.5092657549267279\n",
            "Epoch: 350. Loss: 0.5092190956988183\n",
            "Epoch: 360. Loss: 0.5091788141271282\n",
            "Epoch: 370. Loss: 0.5091440218488853\n",
            "Epoch: 380. Loss: 0.5091139558977915\n",
            "Epoch: 390. Loss: 0.5090879607798903\n",
            "Epoch: 400. Loss: 0.5090654731471277\n",
            "Epoch: 410. Loss: 0.5090460086863257\n",
            "Epoch: 420. Loss: 0.5090291508984178\n",
            "Epoch: 430. Loss: 0.5090145414913022\n",
            "Epoch: 440. Loss: 0.5090018721508068\n",
            "Epoch: 450. Loss: 0.5089908774892138\n",
            "Epoch: 460. Loss: 0.5089813290004485\n",
            "Epoch: 470. Loss: 0.5089730298762493\n",
            "Epoch: 480. Loss: 0.5089658105590557\n",
            "Epoch: 490. Loss: 0.5089595249255644\n",
            "tensor(0.8248, dtype=torch.float64)\n",
            "2021-10-31 00:00:00\n",
            "Epoch: 0. Loss: 0.9715947039792242\n",
            "Epoch: 10. Loss: 0.8699879552022917\n",
            "Epoch: 20. Loss: 0.7826031748388554\n",
            "Epoch: 30. Loss: 0.7086902473376656\n",
            "Epoch: 40. Loss: 0.649118633418959\n",
            "Epoch: 50. Loss: 0.6040298233010487\n",
            "Epoch: 60. Loss: 0.5721752326110963\n",
            "Epoch: 70. Loss: 0.5510113035324695\n",
            "Epoch: 80. Loss: 0.5374687951881013\n",
            "Epoch: 90. Loss: 0.5288346936259646\n",
            "Epoch: 100. Loss: 0.5231747633479281\n",
            "Epoch: 110. Loss: 0.5192882563650074\n",
            "Epoch: 120. Loss: 0.5164831166661181\n",
            "Epoch: 130. Loss: 0.5143693928650712\n",
            "Epoch: 140. Loss: 0.5127234775138013\n",
            "Epoch: 150. Loss: 0.5114111580619989\n",
            "Epoch: 160. Loss: 0.5103469152665102\n",
            "Epoch: 170. Loss: 0.5094728917023045\n",
            "Epoch: 180. Loss: 0.508747915540157\n",
            "Epoch: 190. Loss: 0.5081415543905101\n",
            "Epoch: 200. Loss: 0.5076307023114663\n",
            "Epoch: 210. Loss: 0.5071974839354594\n",
            "Epoch: 220. Loss: 0.5068278813496438\n",
            "Epoch: 230. Loss: 0.5065107854949695\n",
            "Epoch: 240. Loss: 0.5062373149915879\n",
            "Epoch: 250. Loss: 0.5060003139622311\n",
            "Epoch: 260. Loss: 0.5057939752690063\n",
            "Epoch: 270. Loss: 0.5056135544058803\n",
            "Epoch: 280. Loss: 0.5054551502592479\n",
            "Epoch: 290. Loss: 0.5053155358382474\n",
            "Epoch: 300. Loss: 0.5051920266811788\n",
            "Epoch: 310. Loss: 0.5050823778628138\n",
            "Epoch: 320. Loss: 0.5049847028423338\n",
            "Epoch: 330. Loss: 0.5048974090853029\n",
            "Epoch: 340. Loss: 0.5048191466443358\n",
            "Epoch: 350. Loss: 0.5047487668127927\n",
            "Epoch: 360. Loss: 0.5046852886591201\n",
            "Epoch: 370. Loss: 0.504627871768018\n",
            "Epoch: 380. Loss: 0.5045757939036157\n",
            "Epoch: 390. Loss: 0.5045284326026347\n",
            "Epoch: 400. Loss: 0.5044852499267414\n",
            "Epoch: 410. Loss: 0.5044457797711925\n",
            "Epoch: 420. Loss: 0.5044096172549666\n",
            "Epoch: 430. Loss: 0.504376409815833\n",
            "Epoch: 440. Loss: 0.5043458497096666\n",
            "Epoch: 450. Loss: 0.5043176676722482\n",
            "Epoch: 460. Loss: 0.5042916275479068\n",
            "Epoch: 470. Loss: 0.5042675217256766\n",
            "Epoch: 480. Loss: 0.5042451672524677\n",
            "Epoch: 490. Loss: 0.5042244025157743\n",
            "tensor(0.8892, dtype=torch.float64)\n",
            "2021-11-07 00:00:00\n",
            "Epoch: 0. Loss: 1.0728582783909668\n",
            "Epoch: 10. Loss: 0.823842757445491\n",
            "Epoch: 20. Loss: 0.7271502977241096\n",
            "Epoch: 30. Loss: 0.6663857176412152\n",
            "Epoch: 40. Loss: 0.6275698339000196\n",
            "Epoch: 50. Loss: 0.6028193044094716\n",
            "Epoch: 60. Loss: 0.5860446822535771\n",
            "Epoch: 70. Loss: 0.5736039417045274\n",
            "Epoch: 80. Loss: 0.5636727585166112\n",
            "Epoch: 90. Loss: 0.5553801457845349\n",
            "Epoch: 100. Loss: 0.5482859860512489\n",
            "Epoch: 110. Loss: 0.5421386604999123\n",
            "Epoch: 120. Loss: 0.5367726943474724\n",
            "Epoch: 130. Loss: 0.5320661926884962\n",
            "Epoch: 140. Loss: 0.5279225902376175\n",
            "Epoch: 150. Loss: 0.5242622662048293\n",
            "Epoch: 160. Loss: 0.5210182507735741\n",
            "Epoch: 170. Loss: 0.5181336977325564\n",
            "Epoch: 180. Loss: 0.5155601690530854\n",
            "Epoch: 190. Loss: 0.5132563317860368\n",
            "Epoch: 200. Loss: 0.5111868962897715\n",
            "Epoch: 210. Loss: 0.5093217200323662\n",
            "Epoch: 220. Loss: 0.5076350406311481\n",
            "Epoch: 230. Loss: 0.5061048177141185\n",
            "Epoch: 240. Loss: 0.5047121694133605\n",
            "Epoch: 250. Loss: 0.5034408917573944\n",
            "Epoch: 260. Loss: 0.5022770504005903\n",
            "Epoch: 270. Loss: 0.5012086349806926\n",
            "Epoch: 280. Loss: 0.5002252672481139\n",
            "Epoch: 290. Loss: 0.4993179550210306\n",
            "Epoch: 300. Loss: 0.4984788849589188\n",
            "Epoch: 310. Loss: 0.4977012480675341\n",
            "Epoch: 320. Loss: 0.49697909271246593\n",
            "Epoch: 330. Loss: 0.49630720070265694\n",
            "Epoch: 340. Loss: 0.49568098269897265\n",
            "Epoch: 350. Loss: 0.49509638980473886\n",
            "Epoch: 360. Loss: 0.4945498387098137\n",
            "Epoch: 370. Loss: 0.4940381481952038\n",
            "Epoch: 380. Loss: 0.49355848517078965\n",
            "Epoch: 390. Loss: 0.4931083187239475\n",
            "Epoch: 400. Loss: 0.49268538091074215\n",
            "Epoch: 410. Loss: 0.4922876332320696\n",
            "Epoch: 420. Loss: 0.4919132379117807\n",
            "Epoch: 430. Loss: 0.4915605332385409\n",
            "Epoch: 440. Loss: 0.49122801235314595\n",
            "Epoch: 450. Loss: 0.49091430496254573\n",
            "Epoch: 460. Loss: 0.4906181615445091\n",
            "Epoch: 470. Loss: 0.49033843967566765\n",
            "Epoch: 480. Loss: 0.49007409217302145\n",
            "Epoch: 490. Loss: 0.4898241567868918\n",
            "tensor(0.9172, dtype=torch.float64)\n",
            "2021-11-14 00:00:00\n",
            "Epoch: 0. Loss: 1.517991355484759\n",
            "Epoch: 10. Loss: 0.8085512055972521\n",
            "Epoch: 20. Loss: 0.7117122177412278\n",
            "Epoch: 30. Loss: 0.6634855742918001\n",
            "Epoch: 40. Loss: 0.6321157014926659\n",
            "Epoch: 50. Loss: 0.6108641405385112\n",
            "Epoch: 60. Loss: 0.5957559778210729\n",
            "Epoch: 70. Loss: 0.5843557981191103\n",
            "Epoch: 80. Loss: 0.5752731454933144\n",
            "Epoch: 90. Loss: 0.5677285985093906\n",
            "Epoch: 100. Loss: 0.5612752021801625\n",
            "Epoch: 110. Loss: 0.5556440652785064\n",
            "Epoch: 120. Loss: 0.55066300585339\n",
            "Epoch: 130. Loss: 0.5462141535757549\n",
            "Epoch: 140. Loss: 0.542211694303978\n",
            "Epoch: 150. Loss: 0.5385899496581105\n",
            "Epoch: 160. Loss: 0.5352967700641952\n",
            "Epoch: 170. Loss: 0.5322896852412468\n",
            "Epoch: 180. Loss: 0.5295335136115712\n",
            "Epoch: 190. Loss: 0.5269987701758039\n",
            "Epoch: 200. Loss: 0.5246605345766351\n",
            "Epoch: 210. Loss: 0.5224976029978446\n",
            "Epoch: 220. Loss: 0.5204918287306448\n",
            "Epoch: 230. Loss: 0.5186275971054148\n",
            "Epoch: 240. Loss: 0.5168914013986996\n",
            "Epoch: 250. Loss: 0.5152714974252964\n",
            "Epoch: 260. Loss: 0.5137576207975709\n",
            "Epoch: 270. Loss: 0.5123407546945885\n",
            "Epoch: 280. Loss: 0.511012938589992\n",
            "Epoch: 290. Loss: 0.5097671102924929\n",
            "Epoch: 300. Loss: 0.5085969751235258\n",
            "Epoch: 310. Loss: 0.5074968972281351\n",
            "Epoch: 320. Loss: 0.5064618089620463\n",
            "Epoch: 330. Loss: 0.5054871350668861\n",
            "Epoch: 340. Loss: 0.5045687289699644\n",
            "Epoch: 350. Loss: 0.5037028190509912\n",
            "Epoch: 360. Loss: 0.5028859631269603\n",
            "Epoch: 370. Loss: 0.5021150097360683\n",
            "Epoch: 380. Loss: 0.5013870650668694\n",
            "Epoch: 390. Loss: 0.5006994645922993\n",
            "Epoch: 400. Loss: 0.500049748639894\n",
            "Epoch: 410. Loss: 0.499435641267798\n",
            "Epoch: 420. Loss: 0.49885503192769765\n",
            "Epoch: 430. Loss: 0.49830595948601153\n",
            "Epoch: 440. Loss: 0.4977865982478288\n",
            "Epoch: 450. Loss: 0.4972952456876269\n",
            "Epoch: 460. Loss: 0.49683031163943536\n",
            "Epoch: 470. Loss: 0.49639030873900236\n",
            "Epoch: 480. Loss: 0.4959738439433713\n",
            "Epoch: 490. Loss: 0.49557961098043124\n",
            "tensor(0.8885, dtype=torch.float64)\n",
            "2021-11-21 00:00:00\n",
            "Epoch: 0. Loss: 1.4399987045031155\n",
            "Epoch: 10. Loss: 0.7524507810855072\n",
            "Epoch: 20. Loss: 0.6708666240769537\n",
            "Epoch: 30. Loss: 0.626354179597896\n",
            "Epoch: 40. Loss: 0.5917446066399807\n",
            "Epoch: 50. Loss: 0.5648291128427121\n",
            "Epoch: 60. Loss: 0.5443468317158018\n",
            "Epoch: 70. Loss: 0.5290627120257857\n",
            "Epoch: 80. Loss: 0.5178349695869469\n",
            "Epoch: 90. Loss: 0.5096803894751271\n",
            "Epoch: 100. Loss: 0.503798987166821\n",
            "Epoch: 110. Loss: 0.4995689128769111\n",
            "Epoch: 120. Loss: 0.49652373498716146\n",
            "Epoch: 130. Loss: 0.49432264568927603\n",
            "Epoch: 140. Loss: 0.4927210254790269\n",
            "Epoch: 150. Loss: 0.4915452286681719\n",
            "Epoch: 160. Loss: 0.49067273074992357\n",
            "Epoch: 170. Loss: 0.49001728529336336\n",
            "Epoch: 180. Loss: 0.4895181719533238\n",
            "Epoch: 190. Loss: 0.48913255419432927\n",
            "Epoch: 200. Loss: 0.48883010631498486\n",
            "Epoch: 210. Loss: 0.48858925799675335\n",
            "Epoch: 220. Loss: 0.4883945764594805\n",
            "Epoch: 230. Loss: 0.4882349428598404\n",
            "Epoch: 240. Loss: 0.4881022811906774\n",
            "Epoch: 250. Loss: 0.48799067097968796\n",
            "Epoch: 260. Loss: 0.48789572658922076\n",
            "Epoch: 270. Loss: 0.48781416185827625\n",
            "Epoch: 280. Loss: 0.48774348377065857\n",
            "Epoch: 290. Loss: 0.48768177610153557\n",
            "Epoch: 300. Loss: 0.48762754594106206\n",
            "Epoch: 310. Loss: 0.4875796142607135\n",
            "Epoch: 320. Loss: 0.4875370374136198\n",
            "Epoch: 330. Loss: 0.4874990504302666\n",
            "Epoch: 340. Loss: 0.4874650257271996\n",
            "Epoch: 350. Loss: 0.48743444276251563\n",
            "Epoch: 360. Loss: 0.487406865505812\n",
            "Epoch: 370. Loss: 0.4873819255201218\n",
            "Epoch: 380. Loss: 0.48735930910251124\n",
            "Epoch: 390. Loss: 0.4873387473839019\n",
            "Epoch: 400. Loss: 0.48732000860661134\n",
            "Epoch: 410. Loss: 0.48730289202125043\n",
            "Epoch: 420. Loss: 0.4872872230016211\n",
            "Epoch: 430. Loss: 0.48727284908704094\n",
            "Epoch: 440. Loss: 0.48725963673997785\n",
            "Epoch: 450. Loss: 0.48724746866267665\n",
            "Epoch: 460. Loss: 0.4872362415563399\n",
            "Epoch: 470. Loss: 0.4872258642351304\n",
            "Epoch: 480. Loss: 0.48721625602804797\n",
            "Epoch: 490. Loss: 0.4872073454169323\n",
            "tensor(0.8555, dtype=torch.float64)\n",
            "2021-11-28 00:00:00\n",
            "Epoch: 0. Loss: 1.1197709585657039\n",
            "Epoch: 10. Loss: 0.8051338551175858\n",
            "Epoch: 20. Loss: 0.6203348909657167\n",
            "Epoch: 30. Loss: 0.553500067369359\n",
            "Epoch: 40. Loss: 0.532261766320548\n",
            "Epoch: 50. Loss: 0.5226772921220276\n",
            "Epoch: 60. Loss: 0.5168507122092701\n",
            "Epoch: 70. Loss: 0.5126210500324466\n",
            "Epoch: 80. Loss: 0.509245965175533\n",
            "Epoch: 90. Loss: 0.5064335157660423\n",
            "Epoch: 100. Loss: 0.5040454778418094\n",
            "Epoch: 110. Loss: 0.5020005305073173\n",
            "Epoch: 120. Loss: 0.5002418432747769\n",
            "Epoch: 130. Loss: 0.4987255198127441\n",
            "Epoch: 140. Loss: 0.49741593982720256\n",
            "Epoch: 150. Loss: 0.4962835083176607\n",
            "Epoch: 160. Loss: 0.4953033343873852\n",
            "Epoch: 170. Loss: 0.4944543298143334\n",
            "Epoch: 180. Loss: 0.4937185361659187\n",
            "Epoch: 190. Loss: 0.4930805985226775\n",
            "Epoch: 200. Loss: 0.49252734400428116\n",
            "Epoch: 210. Loss: 0.4920474397316663\n",
            "Epoch: 220. Loss: 0.49163111274633603\n",
            "Epoch: 230. Loss: 0.49126991893767535\n",
            "Epoch: 240. Loss: 0.49095655105204894\n",
            "Epoch: 250. Loss: 0.49068467806935406\n",
            "Epoch: 260. Loss: 0.490448809922185\n",
            "Epoch: 270. Loss: 0.4902441828418061\n",
            "Epoch: 280. Loss: 0.4900666616303872\n",
            "Epoch: 290. Loss: 0.48991265594341515\n",
            "Epoch: 300. Loss: 0.4897790482698005\n",
            "Epoch: 310. Loss: 0.4896631317604887\n",
            "Epoch: 320. Loss: 0.48956255641205904\n",
            "Epoch: 330. Loss: 0.48947528238578547\n",
            "Epoch: 340. Loss: 0.4893995394550663\n",
            "Epoch: 350. Loss: 0.48933379174044767\n",
            "Epoch: 360. Loss: 0.4892767070231986\n",
            "Epoch: 370. Loss: 0.4892271300341946\n",
            "Epoch: 380. Loss: 0.4891840592010293\n",
            "Epoch: 390. Loss: 0.4891466264074599\n",
            "Epoch: 400. Loss: 0.4891140793788714\n",
            "Epoch: 410. Loss: 0.4890857663578934\n",
            "Epoch: 420. Loss: 0.48906112277744623\n",
            "Epoch: 430. Loss: 0.48903965967567475\n",
            "Epoch: 440. Loss: 0.48902095362946946\n",
            "Epoch: 450. Loss: 0.4890046380113605\n",
            "Epoch: 460. Loss: 0.48899039539910943\n",
            "Epoch: 470. Loss: 0.48897795098880786\n",
            "Epoch: 480. Loss: 0.4889670668811245\n",
            "Epoch: 490. Loss: 0.48895753712686274\n",
            "tensor(0.8828, dtype=torch.float64)\n",
            "2021-12-05 00:00:00\n",
            "Epoch: 0. Loss: 1.1745629181795105\n",
            "Epoch: 10. Loss: 0.9829380872843421\n",
            "Epoch: 20. Loss: 0.8519351326795007\n",
            "Epoch: 30. Loss: 0.7584831469316043\n",
            "Epoch: 40. Loss: 0.6924575695076141\n",
            "Epoch: 50. Loss: 0.6471065969576152\n",
            "Epoch: 60. Loss: 0.6166484885160168\n",
            "Epoch: 70. Loss: 0.5964141202893103\n",
            "Epoch: 80. Loss: 0.5828571283310313\n",
            "Epoch: 90. Loss: 0.5734802877608547\n",
            "Epoch: 100. Loss: 0.5666749402013384\n",
            "Epoch: 110. Loss: 0.5614711236062886\n",
            "Epoch: 120. Loss: 0.557299733410183\n",
            "Epoch: 130. Loss: 0.5538243076393641\n",
            "Epoch: 140. Loss: 0.5508397594240979\n",
            "Epoch: 150. Loss: 0.5482159317431701\n",
            "Epoch: 160. Loss: 0.5458668449492533\n",
            "Epoch: 170. Loss: 0.5437337129520134\n",
            "Epoch: 180. Loss: 0.5417752131839795\n",
            "Epoch: 190. Loss: 0.5399616418717738\n",
            "Epoch: 200. Loss: 0.5382712335025934\n",
            "Epoch: 210. Loss: 0.5366877488565317\n",
            "Epoch: 220. Loss: 0.5351988463853626\n",
            "Epoch: 230. Loss: 0.5337949596485381\n",
            "Epoch: 240. Loss: 0.532468513165918\n",
            "Epoch: 250. Loss: 0.5312133701017525\n",
            "Epoch: 260. Loss: 0.5300244412756535\n",
            "Epoch: 270. Loss: 0.5288974075291173\n",
            "Epoch: 280. Loss: 0.5278285221924701\n",
            "Epoch: 290. Loss: 0.526814470327717\n",
            "Epoch: 300. Loss: 0.5258522682734227\n",
            "Epoch: 310. Loss: 0.5249391918104414\n",
            "Epoch: 320. Loss: 0.5240727246490327\n",
            "Epoch: 330. Loss: 0.5232505213358873\n",
            "Epoch: 340. Loss: 0.5224703803846217\n",
            "Epoch: 350. Loss: 0.5217302246471712\n",
            "Epoch: 360. Loss: 0.5210280868080732\n",
            "Epoch: 370. Loss: 0.5203620984992977\n",
            "Epoch: 380. Loss: 0.5197304819714885\n",
            "Epoch: 390. Loss: 0.5191315435691137\n",
            "Epoch: 400. Loss: 0.5185636684784537\n",
            "Epoch: 410. Loss: 0.518025316374498\n",
            "Epoch: 420. Loss: 0.5175150177042033\n",
            "Epoch: 430. Loss: 0.5170313704223991\n",
            "Epoch: 440. Loss: 0.5165730370523235\n",
            "Epoch: 450. Loss: 0.5161387419820482\n",
            "Epoch: 460. Loss: 0.5157272689356838\n",
            "Epoch: 470. Loss: 0.5153374585776285\n",
            "Epoch: 480. Loss: 0.5149682062216686\n",
            "Epoch: 490. Loss: 0.514618459626144\n",
            "tensor(0.8684, dtype=torch.float64)\n",
            "2021-12-12 00:00:00\n",
            "Epoch: 0. Loss: 1.3614582560597914\n",
            "Epoch: 10. Loss: 1.0666451455543329\n",
            "Epoch: 20. Loss: 0.8704930227979388\n",
            "Epoch: 30. Loss: 0.7222863408908211\n",
            "Epoch: 40. Loss: 0.6251136100040657\n",
            "Epoch: 50. Loss: 0.57472661172643\n",
            "Epoch: 60. Loss: 0.5526612251133001\n",
            "Epoch: 70. Loss: 0.5424454566581793\n",
            "Epoch: 80. Loss: 0.5366073330991082\n",
            "Epoch: 90. Loss: 0.5326277681941859\n",
            "Epoch: 100. Loss: 0.5296512781463286\n",
            "Epoch: 110. Loss: 0.5273231491510547\n",
            "Epoch: 120. Loss: 0.5254547549836812\n",
            "Epoch: 130. Loss: 0.5239267111389294\n",
            "Epoch: 140. Loss: 0.5226566753809532\n",
            "Epoch: 150. Loss: 0.5215856636394445\n",
            "Epoch: 160. Loss: 0.520670606189721\n",
            "Epoch: 170. Loss: 0.5198796278399734\n",
            "Epoch: 180. Loss: 0.5191888435148965\n",
            "Epoch: 190. Loss: 0.5185801247575665\n",
            "Epoch: 200. Loss: 0.5180395264463472\n",
            "Epoch: 210. Loss: 0.5175561720526503\n",
            "Epoch: 220. Loss: 0.5171214596794855\n",
            "Epoch: 230. Loss: 0.5167284932043739\n",
            "Epoch: 240. Loss: 0.5163716717783708\n",
            "Epoch: 250. Loss: 0.5160463910683383\n",
            "Epoch: 260. Loss: 0.5157488236759713\n",
            "Epoch: 270. Loss: 0.5154757559597454\n",
            "Epoch: 280. Loss: 0.5152244653062561\n",
            "Epoch: 290. Loss: 0.5149926266447294\n",
            "Epoch: 300. Loss: 0.5147782403029872\n",
            "Epoch: 310. Loss: 0.5145795756051283\n",
            "Epoch: 320. Loss: 0.5143951262173562\n",
            "Epoch: 330. Loss: 0.5142235743718748\n",
            "Epoch: 340. Loss: 0.5140637618874404\n",
            "Epoch: 350. Loss: 0.5139146664613828\n",
            "Epoch: 360. Loss: 0.5137753821025604\n",
            "Epoch: 370. Loss: 0.5136451028567656\n",
            "Epoch: 380. Loss: 0.5135231091794716\n",
            "Epoch: 390. Loss: 0.5134087564589057\n",
            "Epoch: 400. Loss: 0.5133014653015413\n",
            "Epoch: 410. Loss: 0.5132007132734537\n",
            "Epoch: 420. Loss: 0.5131060278524592\n",
            "Epoch: 430. Loss: 0.5130169803930311\n",
            "Epoch: 440. Loss: 0.5129331809425143\n",
            "Epoch: 450. Loss: 0.5128542737758742\n",
            "Epoch: 460. Loss: 0.5127799335390636\n",
            "Epoch: 470. Loss: 0.5127098619094594\n",
            "Epoch: 480. Loss: 0.5126437846967564\n",
            "Epoch: 490. Loss: 0.512581449319922\n",
            "tensor(0.6556, dtype=torch.float64)\n",
            "2021-12-19 00:00:00\n",
            "Epoch: 0. Loss: 1.428673184096938\n",
            "Epoch: 10. Loss: 1.0198517526406898\n",
            "Epoch: 20. Loss: 0.8461079733051315\n",
            "Epoch: 30. Loss: 0.7645457964734635\n",
            "Epoch: 40. Loss: 0.7035879199022527\n",
            "Epoch: 50. Loss: 0.654743111050988\n",
            "Epoch: 60. Loss: 0.6166215886008943\n",
            "Epoch: 70. Loss: 0.5880062697574727\n",
            "Epoch: 80. Loss: 0.5673201403235648\n",
            "Epoch: 90. Loss: 0.5528369438227495\n",
            "Epoch: 100. Loss: 0.5429354428116009\n",
            "Epoch: 110. Loss: 0.5362659697922303\n",
            "Epoch: 120. Loss: 0.5318027538937532\n",
            "Epoch: 130. Loss: 0.5288147530021075\n",
            "Epoch: 140. Loss: 0.5268023816622741\n",
            "Epoch: 150. Loss: 0.5254326946250878\n",
            "Epoch: 160. Loss: 0.5244867658074257\n",
            "Epoch: 170. Loss: 0.5238214814196113\n",
            "Epoch: 180. Loss: 0.5233433871291412\n",
            "Epoch: 190. Loss: 0.5229913384393878\n",
            "Epoch: 200. Loss: 0.5227251726979911\n",
            "Epoch: 210. Loss: 0.5225183654610392\n",
            "Epoch: 220. Loss: 0.5223532802427223\n",
            "Epoch: 230. Loss: 0.5222180940623754\n",
            "Epoch: 240. Loss: 0.5221048034650163\n",
            "Epoch: 250. Loss: 0.5220079275415901\n",
            "Epoch: 260. Loss: 0.5219236614484546\n",
            "Epoch: 270. Loss: 0.5218493218696724\n",
            "Epoch: 280. Loss: 0.5217829822270869\n",
            "Epoch: 290. Loss: 0.5217232315963976\n",
            "Epoch: 300. Loss: 0.5216690145301187\n",
            "Epoch: 310. Loss: 0.5216195239727359\n",
            "Epoch: 320. Loss: 0.5215741291419512\n",
            "Epoch: 330. Loss: 0.5215323265319528\n",
            "Epoch: 340. Loss: 0.521493706278565\n",
            "Epoch: 350. Loss: 0.5214579287874661\n",
            "Epoch: 360. Loss: 0.521424708264879\n",
            "Epoch: 370. Loss: 0.5213938009278806\n",
            "Epoch: 380. Loss: 0.5213649964178586\n",
            "Epoch: 390. Loss: 0.5213381114314083\n",
            "Epoch: 400. Loss: 0.5213129849065499\n",
            "Epoch: 410. Loss: 0.5212894743161482\n",
            "Epoch: 420. Loss: 0.5212674527625123\n",
            "Epoch: 430. Loss: 0.521246806661916\n",
            "Epoch: 440. Loss: 0.52122743387138\n",
            "Epoch: 450. Loss: 0.5212092421530098\n",
            "Epoch: 460. Loss: 0.5211921479004696\n",
            "Epoch: 470. Loss: 0.5211760750723408\n",
            "Epoch: 480. Loss: 0.521160954291164\n",
            "Epoch: 490. Loss: 0.5211467220769033\n",
            "tensor(0.7162, dtype=torch.float64)\n",
            "2021-12-26 00:00:00\n",
            "Epoch: 0. Loss: 2.610990183760723\n",
            "Epoch: 10. Loss: 0.7434901756262492\n",
            "Epoch: 20. Loss: 0.6597626825923292\n",
            "Epoch: 30. Loss: 0.6171660917471392\n",
            "Epoch: 40. Loss: 0.5871680225031022\n",
            "Epoch: 50. Loss: 0.5661340361981594\n",
            "Epoch: 60. Loss: 0.5517366486545718\n",
            "Epoch: 70. Loss: 0.5421135597637401\n",
            "Epoch: 80. Loss: 0.5357814363043605\n",
            "Epoch: 90. Loss: 0.5316359161700008\n",
            "Epoch: 100. Loss: 0.5289091324125809\n",
            "Epoch: 110. Loss: 0.5270925209882785\n",
            "Epoch: 120. Loss: 0.5258587113067374\n",
            "Epoch: 130. Loss: 0.5249998204804778\n",
            "Epoch: 140. Loss: 0.5243843735858041\n",
            "Epoch: 150. Loss: 0.5239290714784307\n",
            "Epoch: 160. Loss: 0.5235808556058147\n",
            "Epoch: 170. Loss: 0.5233056679194432\n",
            "Epoch: 180. Loss: 0.5230814353886108\n",
            "Epoch: 190. Loss: 0.5228936872004433\n",
            "Epoch: 200. Loss: 0.5227328070761592\n",
            "Epoch: 210. Loss: 0.5225923024397268\n",
            "Epoch: 220. Loss: 0.5224677082027724\n",
            "Epoch: 230. Loss: 0.5223558884186791\n",
            "Epoch: 240. Loss: 0.5222545886060381\n",
            "Epoch: 250. Loss: 0.5221621467932972\n",
            "Epoch: 260. Loss: 0.522077305573054\n",
            "Epoch: 270. Loss: 0.5219990887732316\n",
            "Epoch: 280. Loss: 0.5219267196927352\n",
            "Epoch: 290. Loss: 0.5218595662359388\n",
            "Epoch: 300. Loss: 0.5217971035755397\n",
            "Epoch: 310. Loss: 0.521738888329804\n",
            "Epoch: 320. Loss: 0.5216845403757171\n",
            "Epoch: 330. Loss: 0.5216337297830768\n",
            "Epoch: 340. Loss: 0.5215861672283607\n",
            "Epoch: 350. Loss: 0.5215415968093229\n",
            "Epoch: 360. Loss: 0.5214997905444606\n",
            "Epoch: 370. Loss: 0.5214605440773238\n",
            "Epoch: 380. Loss: 0.5214236732596851\n",
            "Epoch: 390. Loss: 0.5213890113889411\n",
            "Epoch: 400. Loss: 0.521356406942371\n",
            "Epoch: 410. Loss: 0.5213257216959829\n",
            "Epoch: 420. Loss: 0.5212968291462957\n",
            "Epoch: 430. Loss: 0.5212696131744933\n",
            "Epoch: 440. Loss: 0.5212439669071455\n",
            "Epoch: 450. Loss: 0.5212197917382072\n",
            "Epoch: 460. Loss: 0.5211969964846471\n",
            "Epoch: 470. Loss: 0.5211754966537017\n",
            "Epoch: 480. Loss: 0.5211552138040302\n",
            "Epoch: 490. Loss: 0.5211360749863145\n",
            "tensor(0.7147, dtype=torch.float64)\n",
            "2022-01-02 00:00:00\n",
            "Epoch: 0. Loss: 0.9629142802237551\n",
            "Epoch: 10. Loss: 0.7736261246499296\n",
            "Epoch: 20. Loss: 0.712547517858249\n",
            "Epoch: 30. Loss: 0.6760437729621059\n",
            "Epoch: 40. Loss: 0.6468683657507945\n",
            "Epoch: 50. Loss: 0.6229509896836851\n",
            "Epoch: 60. Loss: 0.6033880981958682\n",
            "Epoch: 70. Loss: 0.5874607888772502\n",
            "Epoch: 80. Loss: 0.5745437427661091\n",
            "Epoch: 90. Loss: 0.5640911222480054\n",
            "Epoch: 100. Loss: 0.555636026434636\n",
            "Epoch: 110. Loss: 0.5487886641353594\n",
            "Epoch: 120. Loss: 0.5432302872494332\n",
            "Epoch: 130. Loss: 0.5387041692910622\n",
            "Epoch: 140. Loss: 0.5350055757299158\n",
            "Epoch: 150. Loss: 0.5319721264782007\n",
            "Epoch: 160. Loss: 0.5294752829155113\n",
            "Epoch: 170. Loss: 0.5274132135964867\n",
            "Epoch: 180. Loss: 0.5257050169633088\n",
            "Epoch: 190. Loss: 0.5242861473914584\n",
            "Epoch: 200. Loss: 0.5231048458316396\n",
            "Epoch: 210. Loss: 0.5221193777859015\n",
            "Epoch: 220. Loss: 0.5212959041629146\n",
            "Epoch: 230. Loss: 0.5206068403580232\n",
            "Epoch: 240. Loss: 0.5200295883312289\n",
            "Epoch: 250. Loss: 0.519545552268741\n",
            "Epoch: 260. Loss: 0.5191393696235955\n",
            "Epoch: 270. Loss: 0.5187983060663373\n",
            "Epoch: 280. Loss: 0.5185117757346906\n",
            "Epoch: 290. Loss: 0.5182709578758046\n",
            "Epoch: 300. Loss: 0.5180684882148922\n",
            "Epoch: 310. Loss: 0.5178982087485114\n",
            "Epoch: 320. Loss: 0.5177549636229387\n",
            "Epoch: 330. Loss: 0.5176344316847724\n",
            "Epoch: 340. Loss: 0.5175329884588955\n",
            "Epoch: 350. Loss: 0.5174475919233253\n",
            "Epoch: 360. Loss: 0.5173756876614664\n",
            "Epoch: 370. Loss: 0.5173151298887879\n",
            "Epoch: 380. Loss: 0.5172641155516211\n",
            "Epoch: 390. Loss: 0.5172211292372343\n",
            "Epoch: 400. Loss: 0.5171848970573826\n",
            "Epoch: 410. Loss: 0.5171543480016028\n",
            "Epoch: 420. Loss: 0.5171285815230043\n",
            "Epoch: 430. Loss: 0.5171068403338464\n",
            "Epoch: 440. Loss: 0.5170884875623046\n",
            "Epoch: 450. Loss: 0.5170729875641573\n",
            "Epoch: 460. Loss: 0.5170598898001298\n",
            "Epoch: 470. Loss: 0.5170488152863209\n",
            "Epoch: 480. Loss: 0.5170394452053481\n",
            "Epoch: 490. Loss: 0.5170315113325931\n",
            "tensor(0.7230, dtype=torch.float64)\n",
            "2022-01-09 00:00:00\n",
            "Epoch: 0. Loss: 1.2634738803982504\n",
            "Epoch: 10. Loss: 1.0852182080316655\n",
            "Epoch: 20. Loss: 0.9380693577451468\n",
            "Epoch: 30. Loss: 0.8168803816340457\n",
            "Epoch: 40. Loss: 0.7215028358140021\n",
            "Epoch: 50. Loss: 0.650862912010928\n",
            "Epoch: 60. Loss: 0.6019133541954276\n",
            "Epoch: 70. Loss: 0.5702086271828446\n",
            "Epoch: 80. Loss: 0.5506713539007112\n",
            "Epoch: 90. Loss: 0.5388741458160654\n",
            "Epoch: 100. Loss: 0.5317410909671589\n",
            "Epoch: 110. Loss: 0.5273848693039939\n",
            "Epoch: 120. Loss: 0.5246939150274705\n",
            "Epoch: 130. Loss: 0.5230137427384757\n",
            "Epoch: 140. Loss: 0.5219543168016362\n",
            "Epoch: 150. Loss: 0.5212800820673044\n",
            "Epoch: 160. Loss: 0.5208470803347061\n",
            "Epoch: 170. Loss: 0.5205664245673223\n",
            "Epoch: 180. Loss: 0.5203827368772266\n",
            "Epoch: 190. Loss: 0.5202612395668944\n",
            "Epoch: 200. Loss: 0.5201799331257637\n",
            "Epoch: 210. Loss: 0.5201248070515093\n",
            "Epoch: 220. Loss: 0.520086880836644\n",
            "Epoch: 230. Loss: 0.5200603610994667\n",
            "Epoch: 240. Loss: 0.5200414857540722\n",
            "Epoch: 250. Loss: 0.5200277945514088\n",
            "Epoch: 260. Loss: 0.5200176661270861\n",
            "Epoch: 270. Loss: 0.5200100226839903\n",
            "Epoch: 280. Loss: 0.5200041407055846\n",
            "Epoch: 290. Loss: 0.519999529066745\n",
            "Epoch: 300. Loss: 0.5199958501770808\n",
            "Epoch: 310. Loss: 0.5199928687139584\n",
            "Epoch: 320. Loss: 0.5199904181145901\n",
            "Epoch: 330. Loss: 0.5199883785446071\n",
            "Epoch: 340. Loss: 0.5199866623135788\n",
            "Epoch: 350. Loss: 0.5199852041442031\n",
            "Epoch: 360. Loss: 0.5199839546206143\n",
            "Epoch: 370. Loss: 0.5199828757307803\n",
            "Epoch: 380. Loss: 0.5199819377973455\n",
            "Epoch: 390. Loss: 0.5199811173361236\n",
            "Epoch: 400. Loss: 0.5199803955399329\n",
            "Epoch: 410. Loss: 0.5199797571883511\n",
            "Epoch: 420. Loss: 0.5199791898510081\n",
            "Epoch: 430. Loss: 0.5199786832958584\n",
            "Epoch: 440. Loss: 0.5199782290426814\n",
            "Epoch: 450. Loss: 0.5199778200210661\n",
            "Epoch: 460. Loss: 0.5199774503047805\n",
            "Epoch: 470. Loss: 0.5199771149028821\n",
            "Epoch: 480. Loss: 0.519976809593643\n",
            "Epoch: 490. Loss: 0.5199765307912642\n",
            "tensor(0.8289, dtype=torch.float64)\n",
            "2022-01-16 00:00:00\n",
            "Epoch: 0. Loss: 2.9470092953149347\n",
            "Epoch: 10. Loss: 1.441717659992843\n",
            "Epoch: 20. Loss: 1.019090805448919\n",
            "Epoch: 30. Loss: 0.8154696090398111\n",
            "Epoch: 40. Loss: 0.6771150181529042\n",
            "Epoch: 50. Loss: 0.5940136030976669\n",
            "Epoch: 60. Loss: 0.5565266939405538\n",
            "Epoch: 70. Loss: 0.5423562354764868\n",
            "Epoch: 80. Loss: 0.5361129004681581\n",
            "Epoch: 90. Loss: 0.5323028062862369\n",
            "Epoch: 100. Loss: 0.5294381084188734\n",
            "Epoch: 110. Loss: 0.5271129084828101\n",
            "Epoch: 120. Loss: 0.5251841622631738\n",
            "Epoch: 130. Loss: 0.5235763621283935\n",
            "Epoch: 140. Loss: 0.5222358084652071\n",
            "Epoch: 150. Loss: 0.521119211830824\n",
            "Epoch: 160. Loss: 0.5201903108569566\n",
            "Epoch: 170. Loss: 0.519418464262595\n",
            "Epoch: 180. Loss: 0.5187777831475937\n",
            "Epoch: 190. Loss: 0.5182464494171497\n",
            "Epoch: 200. Loss: 0.5178061300332442\n",
            "Epoch: 210. Loss: 0.5174414630268319\n",
            "Epoch: 220. Loss: 0.5171396072510274\n",
            "Epoch: 230. Loss: 0.5168898509500474\n",
            "Epoch: 240. Loss: 0.5166832742493294\n",
            "Epoch: 250. Loss: 0.5165124602827835\n",
            "Epoch: 260. Loss: 0.5163712494923463\n",
            "Epoch: 270. Loss: 0.5162545317311094\n",
            "Epoch: 280. Loss: 0.5161580711053502\n",
            "Epoch: 290. Loss: 0.5160783589190945\n",
            "Epoch: 300. Loss: 0.5160124905704027\n",
            "Epoch: 310. Loss: 0.5159580627449379\n",
            "Epoch: 320. Loss: 0.515913087730256\n",
            "Epoch: 330. Loss: 0.5158759221169134\n",
            "Epoch: 340. Loss: 0.5158452075517278\n",
            "Epoch: 350. Loss: 0.5158198215618082\n",
            "Epoch: 360. Loss: 0.5157988367761294\n",
            "Epoch: 370. Loss: 0.5157814871373375\n",
            "Epoch: 380. Loss: 0.5157671399239925\n",
            "Epoch: 390. Loss: 0.5157552725968342\n",
            "Epoch: 400. Loss: 0.5157454536461538\n",
            "Epoch: 410. Loss: 0.5157373267549925\n",
            "Epoch: 420. Loss: 0.5157305977083645\n",
            "Epoch: 430. Loss: 0.5157250235753031\n",
            "Epoch: 440. Loss: 0.5157204037711666\n",
            "Epoch: 450. Loss: 0.515716572674808\n",
            "Epoch: 460. Loss: 0.5157133935310932\n",
            "Epoch: 470. Loss: 0.5157107534156617\n",
            "Epoch: 480. Loss: 0.515708559077336\n",
            "Epoch: 490. Loss: 0.515706733505525\n",
            "tensor(0.8961, dtype=torch.float64)\n",
            "2022-01-23 00:00:00\n",
            "Epoch: 0. Loss: 2.950057213681049\n",
            "Epoch: 10. Loss: 0.923043283584442\n",
            "Epoch: 20. Loss: 0.6888340294608389\n",
            "Epoch: 30. Loss: 0.5923330750927016\n",
            "Epoch: 40. Loss: 0.5561994587724182\n",
            "Epoch: 50. Loss: 0.5442309874504893\n",
            "Epoch: 60. Loss: 0.5397820645602724\n",
            "Epoch: 70. Loss: 0.5376952093344807\n",
            "Epoch: 80. Loss: 0.5364534773134871\n",
            "Epoch: 90. Loss: 0.535581321688924\n",
            "Epoch: 100. Loss: 0.5349128378673776\n",
            "Epoch: 110. Loss: 0.5343798207158382\n",
            "Epoch: 120. Loss: 0.533947465181957\n",
            "Epoch: 130. Loss: 0.5335939727626201\n",
            "Epoch: 140. Loss: 0.5333036943926883\n",
            "Epoch: 150. Loss: 0.5330645803829707\n",
            "Epoch: 160. Loss: 0.5328670596552413\n",
            "Epoch: 170. Loss: 0.5327034308599687\n",
            "Epoch: 180. Loss: 0.5325674639574064\n",
            "Epoch: 190. Loss: 0.5324541074732464\n",
            "Epoch: 200. Loss: 0.5323592607757972\n",
            "Epoch: 210. Loss: 0.5322795925188215\n",
            "Epoch: 220. Loss: 0.5322123944507775\n",
            "Epoch: 230. Loss: 0.5321554632554827\n",
            "Epoch: 240. Loss: 0.5321070049205971\n",
            "Epoch: 250. Loss: 0.5320655573061801\n",
            "Epoch: 260. Loss: 0.5320299274431811\n",
            "Epoch: 270. Loss: 0.531999140758729\n",
            "Epoch: 280. Loss: 0.5319723999582999\n",
            "Epoch: 290. Loss: 0.5319490517256458\n",
            "Epoch: 300. Loss: 0.5319285597506247\n",
            "Epoch: 310. Loss: 0.5319104828784094\n",
            "Epoch: 320. Loss: 0.5318944574033534\n",
            "Epoch: 330. Loss: 0.5318801827170575\n",
            "Epoch: 340. Loss: 0.5318674096710666\n",
            "Epoch: 350. Loss: 0.5318559311367862\n",
            "Epoch: 360. Loss: 0.5318455743440804\n",
            "Epoch: 370. Loss: 0.531836194659991\n",
            "Epoch: 380. Loss: 0.531827670533718\n",
            "Epoch: 390. Loss: 0.5318198993863226\n",
            "Epoch: 400. Loss: 0.531812794265915\n",
            "Epoch: 410. Loss: 0.5318062811233144\n",
            "Epoch: 420. Loss: 0.5318002965908144\n",
            "Epoch: 430. Loss: 0.5317947861690729\n",
            "Epoch: 440. Loss: 0.5317897027452286\n",
            "Epoch: 450. Loss: 0.5317850053799775\n",
            "Epoch: 460. Loss: 0.5317806583131818\n",
            "Epoch: 470. Loss: 0.5317766301471564\n",
            "Epoch: 480. Loss: 0.5317728931745216\n",
            "Epoch: 490. Loss: 0.5317694228237884\n",
            "tensor(0.4808, dtype=torch.float64)\n",
            "2022-01-30 00:00:00\n",
            "Epoch: 0. Loss: 2.225714897863984\n",
            "Epoch: 10. Loss: 0.9670287696697175\n",
            "Epoch: 20. Loss: 0.7974447027441217\n",
            "Epoch: 30. Loss: 0.6974436558054541\n",
            "Epoch: 40. Loss: 0.6368864106550122\n",
            "Epoch: 50. Loss: 0.603353342106867\n",
            "Epoch: 60. Loss: 0.5849395401341131\n",
            "Epoch: 70. Loss: 0.5741259243967197\n",
            "Epoch: 80. Loss: 0.5671635257567973\n",
            "Epoch: 90. Loss: 0.5623265733586307\n",
            "Epoch: 100. Loss: 0.5587918916411008\n",
            "Epoch: 110. Loss: 0.5561265325474726\n",
            "Epoch: 120. Loss: 0.5540767743415058\n",
            "Epoch: 130. Loss: 0.552479978488237\n",
            "Epoch: 140. Loss: 0.5512248803560389\n",
            "Epoch: 150. Loss: 0.5502318590851356\n",
            "Epoch: 160. Loss: 0.5494421481234595\n",
            "Epoch: 170. Loss: 0.5488114297889592\n",
            "Epoch: 180. Loss: 0.5483057725038816\n",
            "Epoch: 190. Loss: 0.5478989156989346\n",
            "Epoch: 200. Loss: 0.5475703788980576\n",
            "Epoch: 210. Loss: 0.5473041012003349\n",
            "Epoch: 220. Loss: 0.5470874371504272\n",
            "Epoch: 230. Loss: 0.5469104010210931\n",
            "Epoch: 240. Loss: 0.5467650896431153\n",
            "Epoch: 250. Loss: 0.5466452368136384\n",
            "Epoch: 260. Loss: 0.5465458665957453\n",
            "Epoch: 270. Loss: 0.5464630220648298\n",
            "Epoch: 280. Loss: 0.546393552257771\n",
            "Epoch: 290. Loss: 0.5463349443837471\n",
            "Epoch: 300. Loss: 0.5462851914334353\n",
            "Epoch: 310. Loss: 0.5462426875824521\n",
            "Epoch: 320. Loss: 0.5462061454777319\n",
            "Epoch: 330. Loss: 0.5461745307845284\n",
            "Epoch: 340. Loss: 0.5461470103649337\n",
            "Epoch: 350. Loss: 0.5461229112307293\n",
            "Epoch: 360. Loss: 0.5461016880169329\n",
            "Epoch: 370. Loss: 0.5460828971963163\n",
            "Epoch: 380. Loss: 0.5460661766283046\n",
            "Epoch: 390. Loss: 0.5460512293300501\n",
            "Epoch: 400. Loss: 0.5460378105899588\n",
            "Epoch: 410. Loss: 0.5460257177277421\n",
            "Epoch: 420. Loss: 0.54601478195039\n",
            "Epoch: 430. Loss: 0.5460048618684233\n",
            "Epoch: 440. Loss: 0.5459958383277292\n",
            "Epoch: 450. Loss: 0.5459876102842286\n",
            "Epoch: 460. Loss: 0.5459800915055504\n",
            "Epoch: 470. Loss: 0.5459732079289128\n",
            "Epoch: 480. Loss: 0.5459668955400312\n",
            "Epoch: 490. Loss: 0.5459610986660551\n",
            "tensor(0.6964, dtype=torch.float64)\n",
            "2022-02-06 00:00:00\n",
            "Epoch: 0. Loss: 1.60860593652213\n",
            "Epoch: 10. Loss: 0.8110066842265456\n",
            "Epoch: 20. Loss: 0.675684023201584\n",
            "Epoch: 30. Loss: 0.6104845683215725\n",
            "Epoch: 40. Loss: 0.5804062864461694\n",
            "Epoch: 50. Loss: 0.5662056850411188\n",
            "Epoch: 60. Loss: 0.5586653381802139\n",
            "Epoch: 70. Loss: 0.554245162308161\n",
            "Epoch: 80. Loss: 0.5515013356414505\n",
            "Epoch: 90. Loss: 0.5497367145550592\n",
            "Epoch: 100. Loss: 0.5485681226815601\n",
            "Epoch: 110. Loss: 0.5477708826370358\n",
            "Epoch: 120. Loss: 0.5472094110782657\n",
            "Epoch: 130. Loss: 0.5468006008315489\n",
            "Epoch: 140. Loss: 0.546492858099176\n",
            "Epoch: 150. Loss: 0.5462537134639256\n",
            "Epoch: 160. Loss: 0.5460624081918279\n",
            "Epoch: 170. Loss: 0.5459054270806687\n",
            "Epoch: 180. Loss: 0.5457737893860927\n",
            "Epoch: 190. Loss: 0.5456613932632212\n",
            "Epoch: 200. Loss: 0.5455639944152272\n",
            "Epoch: 210. Loss: 0.5454785687825767\n",
            "Epoch: 220. Loss: 0.5454029095416251\n",
            "Epoch: 230. Loss: 0.545335368390549\n",
            "Epoch: 240. Loss: 0.5452746866759185\n",
            "Epoch: 250. Loss: 0.5452198831818257\n",
            "Epoch: 260. Loss: 0.5451701781786372\n",
            "Epoch: 270. Loss: 0.5451249410481276\n",
            "Epoch: 280. Loss: 0.5450836535013055\n",
            "Epoch: 290. Loss: 0.5450458832919041\n",
            "Epoch: 300. Loss: 0.5450112651204646\n",
            "Epoch: 310. Loss: 0.5449794865500351\n",
            "Epoch: 320. Loss: 0.5449502774720454\n",
            "Epoch: 330. Loss: 0.5449234021251542\n",
            "Epoch: 340. Loss: 0.5448986529751726\n",
            "Epoch: 350. Loss: 0.5448758459683882\n",
            "Epoch: 360. Loss: 0.5448548168095609\n",
            "Epoch: 370. Loss: 0.5448354180119755\n",
            "Epoch: 380. Loss: 0.5448175165344613\n",
            "Epoch: 390. Loss: 0.5448009918684124\n",
            "Epoch: 400. Loss: 0.5447857344725757\n",
            "Epoch: 410. Loss: 0.5447716444787246\n",
            "Epoch: 420. Loss: 0.5447586306100047\n",
            "Epoch: 430. Loss: 0.5447466092676226\n",
            "Epoch: 440. Loss: 0.5447355037519076\n",
            "Epoch: 450. Loss: 0.5447252435915975\n",
            "Epoch: 460. Loss: 0.544715763961082\n",
            "Epoch: 470. Loss: 0.5447070051698317\n",
            "Epoch: 480. Loss: 0.5446989122116472\n",
            "Epoch: 490. Loss: 0.5446914343639793\n",
            "tensor(0.6759, dtype=torch.float64)\n",
            "2022-02-13 00:00:00\n",
            "Epoch: 0. Loss: 3.622755332980974\n",
            "Epoch: 10. Loss: 0.9330227847407835\n",
            "Epoch: 20. Loss: 0.7662438659548904\n",
            "Epoch: 30. Loss: 0.7078903202364252\n",
            "Epoch: 40. Loss: 0.6750949393359543\n",
            "Epoch: 50. Loss: 0.6543513344912397\n",
            "Epoch: 60. Loss: 0.6396293300489819\n",
            "Epoch: 70. Loss: 0.6283266245564902\n",
            "Epoch: 80. Loss: 0.6192976984046528\n",
            "Epoch: 90. Loss: 0.611919940858908\n",
            "Epoch: 100. Loss: 0.6057820651544915\n",
            "Epoch: 110. Loss: 0.6005868766012886\n",
            "Epoch: 120. Loss: 0.5961139780576858\n",
            "Epoch: 130. Loss: 0.592199419661137\n",
            "Epoch: 140. Loss: 0.5887215545590981\n",
            "Epoch: 150. Loss: 0.585590345843455\n",
            "Epoch: 160. Loss: 0.5827391885567649\n",
            "Epoch: 170. Loss: 0.5801187129819606\n",
            "Epoch: 180. Loss: 0.5776921485074855\n",
            "Epoch: 190. Loss: 0.5754318943809824\n",
            "Epoch: 200. Loss: 0.5733170062541012\n",
            "Epoch: 210. Loss: 0.571331366732943\n",
            "Epoch: 220. Loss: 0.5694623605654963\n",
            "Epoch: 230. Loss: 0.5676999186910888\n",
            "Epoch: 240. Loss: 0.5660358300666606\n",
            "Epoch: 250. Loss: 0.5644632469338945\n",
            "Epoch: 260. Loss: 0.562976329356126\n",
            "Epoch: 270. Loss: 0.5615699898073728\n",
            "Epoch: 280. Loss: 0.5602397095521523\n",
            "Epoch: 290. Loss: 0.5589814065122751\n",
            "Epoch: 300. Loss: 0.5577913400599045\n",
            "Epoch: 310. Loss: 0.5566660423029052\n",
            "Epoch: 320. Loss: 0.5556022683853057\n",
            "Epoch: 330. Loss: 0.5545969604409209\n",
            "Epoch: 340. Loss: 0.5536472213505804\n",
            "Epoch: 350. Loss: 0.5527502955352309\n",
            "Epoch: 360. Loss: 0.5519035547919217\n",
            "Epoch: 370. Loss: 0.5511044877355151\n",
            "Epoch: 380. Loss: 0.5503506918086645\n",
            "Epoch: 390. Loss: 0.5496398671107916\n",
            "Epoch: 400. Loss: 0.5489698115051682\n",
            "Epoch: 410. Loss: 0.5483384166142886\n",
            "Epoch: 420. Loss: 0.5477436644235564\n",
            "Epoch: 430. Loss: 0.547183624293321\n",
            "Epoch: 440. Loss: 0.5466564502376715\n",
            "Epoch: 450. Loss: 0.5461603783710197\n",
            "Epoch: 460. Loss: 0.545693724454571\n",
            "Epoch: 470. Loss: 0.5452548814974123\n",
            "Epoch: 480. Loss: 0.5448423173833221\n",
            "Epoch: 490. Loss: 0.5444545725061908\n",
            "tensor(0.8185, dtype=torch.float64)\n",
            "2022-02-20 00:00:00\n",
            "Epoch: 0. Loss: 1.284627259373319\n",
            "Epoch: 10. Loss: 0.5954709656277014\n",
            "Epoch: 20. Loss: 0.5525420410109348\n",
            "Epoch: 30. Loss: 0.5436887469241362\n",
            "Epoch: 40. Loss: 0.540185144584028\n",
            "Epoch: 50. Loss: 0.5380682093103373\n",
            "Epoch: 60. Loss: 0.5366224824643699\n",
            "Epoch: 70. Loss: 0.5356026365404687\n",
            "Epoch: 80. Loss: 0.5348736963114448\n",
            "Epoch: 90. Loss: 0.5343479372520481\n",
            "Epoch: 100. Loss: 0.5339657153062493\n",
            "Epoch: 110. Loss: 0.533685838125421\n",
            "Epoch: 120. Loss: 0.5334795723760825\n",
            "Epoch: 130. Loss: 0.533326688611599\n",
            "Epoch: 140. Loss: 0.533212810955531\n",
            "Epoch: 150. Loss: 0.5331276290968678\n",
            "Epoch: 160. Loss: 0.5330636838586529\n",
            "Epoch: 170. Loss: 0.5330155354922402\n",
            "Epoch: 180. Loss: 0.5329791885905198\n",
            "Epoch: 190. Loss: 0.532951690303147\n",
            "Epoch: 200. Loss: 0.5329308466547793\n",
            "Epoch: 210. Loss: 0.5329150201860109\n",
            "Epoch: 220. Loss: 0.5329029842094737\n",
            "Epoch: 230. Loss: 0.5328938169188757\n",
            "Epoch: 240. Loss: 0.5328868238534753\n",
            "Epoch: 250. Loss: 0.5328814807404149\n",
            "Epoch: 260. Loss: 0.5328773911155671\n",
            "Epoch: 270. Loss: 0.532874254748937\n",
            "Epoch: 280. Loss: 0.532871844024854\n",
            "Epoch: 290. Loss: 0.5328699862140297\n",
            "Epoch: 300. Loss: 0.5328685501315973\n",
            "Epoch: 310. Loss: 0.53286743607387\n",
            "Epoch: 320. Loss: 0.5328665682145686\n",
            "Epoch: 330. Loss: 0.532865888851189\n",
            "Epoch: 340. Loss: 0.5328653540463318\n",
            "Epoch: 350. Loss: 0.5328649303227396\n",
            "Epoch: 360. Loss: 0.5328645921554577\n",
            "Epoch: 370. Loss: 0.5328643200677218\n",
            "Epoch: 380. Loss: 0.5328640991845374\n",
            "Epoch: 390. Loss: 0.5328639181334973\n",
            "Epoch: 400. Loss: 0.5328637682091999\n",
            "Epoch: 410. Loss: 0.53286364273787\n",
            "Epoch: 420. Loss: 0.5328635365940925\n",
            "Epoch: 430. Loss: 0.5328634458331534\n",
            "Epoch: 440. Loss: 0.5328633674112687\n",
            "Epoch: 450. Loss: 0.5328632989726385\n",
            "Epoch: 460. Loss: 0.5328632386873245\n",
            "Epoch: 470. Loss: 0.5328631851277831\n",
            "Epoch: 480. Loss: 0.5328631371748065\n",
            "Epoch: 490. Loss: 0.5328630939458374\n",
            "tensor(0.6063, dtype=torch.float64)\n",
            "2022-02-27 00:00:00\n",
            "Epoch: 0. Loss: 0.7647152365511827\n",
            "Epoch: 10. Loss: 0.6086136520435097\n",
            "Epoch: 20. Loss: 0.57666362516554\n",
            "Epoch: 30. Loss: 0.5650735311055851\n",
            "Epoch: 40. Loss: 0.5578682033541673\n",
            "Epoch: 50. Loss: 0.5527490002501323\n",
            "Epoch: 60. Loss: 0.54903022728628\n",
            "Epoch: 70. Loss: 0.5463160445681551\n",
            "Epoch: 80. Loss: 0.5443286015125249\n",
            "Epoch: 90. Loss: 0.5428674131808282\n",
            "Epoch: 100. Loss: 0.5417879496813872\n",
            "Epoch: 110. Loss: 0.5409862495463146\n",
            "Epoch: 120. Loss: 0.5403875079461841\n",
            "Epoch: 130. Loss: 0.5399377588228542\n",
            "Epoch: 140. Loss: 0.5395979113260088\n",
            "Epoch: 150. Loss: 0.5393395139564328\n",
            "Epoch: 160. Loss: 0.5391417555404118\n",
            "Epoch: 170. Loss: 0.5389893395998078\n",
            "Epoch: 180. Loss: 0.5388709720122841\n",
            "Epoch: 190. Loss: 0.5387782792341674\n",
            "Epoch: 200. Loss: 0.538705029805122\n",
            "Epoch: 210. Loss: 0.5386465706419786\n",
            "Epoch: 220. Loss: 0.5385994164449229\n",
            "Epoch: 230. Loss: 0.5385609490048963\n",
            "Epoch: 240. Loss: 0.5385291959323139\n",
            "Epoch: 250. Loss: 0.538502667145573\n",
            "Epoch: 260. Loss: 0.5384802336071794\n",
            "Epoch: 270. Loss: 0.5384610371174969\n",
            "Epoch: 280. Loss: 0.5384444230394043\n",
            "Epoch: 290. Loss: 0.5384298900161552\n",
            "Epoch: 300. Loss: 0.538417052321212\n",
            "Epoch: 310. Loss: 0.5384056116222545\n",
            "Epoch: 320. Loss: 0.538395335776154\n",
            "Epoch: 330. Loss: 0.5383860428842109\n",
            "Epoch: 340. Loss: 0.5383775892885999\n",
            "Epoch: 350. Loss: 0.538369860525294\n",
            "Epoch: 360. Loss: 0.5383627644970442\n",
            "Epoch: 370. Loss: 0.5383562263149028\n",
            "Epoch: 380. Loss: 0.5383501843947784\n",
            "Epoch: 390. Loss: 0.5383445874986986\n",
            "Epoch: 400. Loss: 0.5383393924876956\n",
            "Epoch: 410. Loss: 0.5383345626111559\n",
            "Epoch: 420. Loss: 0.5383300662009105\n",
            "Epoch: 430. Loss: 0.5383258756709701\n",
            "Epoch: 440. Loss: 0.5383219667483191\n",
            "Epoch: 450. Loss: 0.5383183178786038\n",
            "Epoch: 460. Loss: 0.5383149097644014\n",
            "Epoch: 470. Loss: 0.5383117250041773\n",
            "Epoch: 480. Loss: 0.5383087478078805\n",
            "Epoch: 490. Loss: 0.5383059637710234\n",
            "tensor(0.8084, dtype=torch.float64)\n",
            "2022-03-06 00:00:00\n",
            "Epoch: 0. Loss: 1.0081681528601016\n",
            "Epoch: 10. Loss: 0.834484125977824\n",
            "Epoch: 20. Loss: 0.7214150952818383\n",
            "Epoch: 30. Loss: 0.6571940904125311\n",
            "Epoch: 40. Loss: 0.6201391145721143\n",
            "Epoch: 50. Loss: 0.595920009613504\n",
            "Epoch: 60. Loss: 0.5788933599660273\n",
            "Epoch: 70. Loss: 0.5668165449585714\n",
            "Epoch: 80. Loss: 0.5583806975026295\n",
            "Epoch: 90. Loss: 0.5525925902598764\n",
            "Epoch: 100. Loss: 0.5486720051079972\n",
            "Epoch: 110. Loss: 0.546032161725331\n",
            "Epoch: 120. Loss: 0.544253436174605\n",
            "Epoch: 130. Loss: 0.5430473905476424\n",
            "Epoch: 140. Loss: 0.5422209714164311\n",
            "Epoch: 150. Loss: 0.5416469297503165\n",
            "Epoch: 160. Loss: 0.5412419175936751\n",
            "Epoch: 170. Loss: 0.5409513126382723\n",
            "Epoch: 180. Loss: 0.5407391188631621\n",
            "Epoch: 190. Loss: 0.5405813996043252\n",
            "Epoch: 200. Loss: 0.5404620569932949\n",
            "Epoch: 210. Loss: 0.5403701288819083\n",
            "Epoch: 220. Loss: 0.5402980535007536\n",
            "Epoch: 230. Loss: 0.5402405479284791\n",
            "Epoch: 240. Loss: 0.5401938761813136\n",
            "Epoch: 250. Loss: 0.5401553659326064\n",
            "Epoch: 260. Loss: 0.5401230852740867\n",
            "Epoch: 270. Loss: 0.5400956236428447\n",
            "Epoch: 280. Loss: 0.5400719414087155\n",
            "Epoch: 290. Loss: 0.5400512653312769\n",
            "Epoch: 300. Loss: 0.5400330150793446\n",
            "Epoch: 310. Loss: 0.5400167510638487\n",
            "Epoch: 320. Loss: 0.5400021370754514\n",
            "Epoch: 330. Loss: 0.5399889133210726\n",
            "Epoch: 340. Loss: 0.5399768768370329\n",
            "Epoch: 350. Loss: 0.5399658671798446\n",
            "Epoch: 360. Loss: 0.5399557559206022\n",
            "Epoch: 370. Loss: 0.539946438897584\n",
            "Epoch: 380. Loss: 0.5399378304793873\n",
            "Epoch: 390. Loss: 0.5399298592999963\n",
            "Epoch: 400. Loss: 0.5399224650754596\n",
            "Epoch: 410. Loss: 0.539915596217907\n",
            "Epoch: 420. Loss: 0.5399092080390163\n",
            "Epoch: 430. Loss: 0.5399032613903897\n",
            "Epoch: 440. Loss: 0.539897721628599\n",
            "Epoch: 450. Loss: 0.5398925578221148\n",
            "Epoch: 460. Loss: 0.5398877421389403\n",
            "Epoch: 470. Loss: 0.539883249369655\n",
            "Epoch: 480. Loss: 0.5398790565522784\n",
            "Epoch: 490. Loss: 0.5398751426740052\n",
            "tensor(0.9459, dtype=torch.float64)\n",
            "2022-03-13 00:00:00\n",
            "Epoch: 0. Loss: 3.2380179528458504\n",
            "Epoch: 10. Loss: 0.8250088140150907\n",
            "Epoch: 20. Loss: 0.7087795647603493\n",
            "Epoch: 30. Loss: 0.667564024521985\n",
            "Epoch: 40. Loss: 0.6424442136727857\n",
            "Epoch: 50. Loss: 0.6241692974457422\n",
            "Epoch: 60. Loss: 0.6100482097837968\n",
            "Epoch: 70. Loss: 0.5989547461754646\n",
            "Epoch: 80. Loss: 0.5902336066185413\n",
            "Epoch: 90. Loss: 0.5834012107721777\n",
            "Epoch: 100. Loss: 0.5780637639712904\n",
            "Epoch: 110. Loss: 0.57389640889667\n",
            "Epoch: 120. Loss: 0.5706354801102929\n",
            "Epoch: 130. Loss: 0.5680713778477786\n",
            "Epoch: 140. Loss: 0.5660404386496759\n",
            "Epoch: 150. Loss: 0.5644166080485061\n",
            "Epoch: 160. Loss: 0.5631037530477321\n",
            "Epoch: 170. Loss: 0.5620290524660472\n",
            "Epoch: 180. Loss: 0.5611375768728292\n",
            "Epoch: 190. Loss: 0.5603879837876183\n",
            "Epoch: 200. Loss: 0.5597491726783459\n",
            "Epoch: 210. Loss: 0.5591977248375534\n",
            "Epoch: 220. Loss: 0.5587159645178278\n",
            "Epoch: 230. Loss: 0.558290501309693\n",
            "Epoch: 240. Loss: 0.5579111398827046\n",
            "Epoch: 250. Loss: 0.5575700673495578\n",
            "Epoch: 260. Loss: 0.5572612489753286\n",
            "Epoch: 270. Loss: 0.5569799794823092\n",
            "Epoch: 280. Loss: 0.556722550161481\n",
            "Epoch: 290. Loss: 0.5564860019719201\n",
            "Epoch: 300. Loss: 0.5562679423822513\n",
            "Epoch: 310. Loss: 0.5560664094106281\n",
            "Epoch: 320. Loss: 0.5558797705881234\n",
            "Epoch: 330. Loss: 0.5557066477522082\n",
            "Epoch: 340. Loss: 0.5555458609418737\n",
            "Epoch: 350. Loss: 0.5553963864199496\n",
            "Epoch: 360. Loss: 0.5552573251471489\n",
            "Epoch: 370. Loss: 0.5551278789932634\n",
            "Epoch: 380. Loss: 0.5550073326811755\n",
            "Epoch: 390. Loss: 0.5548950399839606\n",
            "Epoch: 400. Loss: 0.5547904130826962\n",
            "Epoch: 410. Loss: 0.5546929142784435\n",
            "Epoch: 420. Loss: 0.5546020494627762\n",
            "Epoch: 430. Loss: 0.5545173629068108\n",
            "Epoch: 440. Loss: 0.5544384330434273\n",
            "Epoch: 450. Loss: 0.554364869001991\n",
            "Epoch: 460. Loss: 0.5542963077172738\n",
            "Epoch: 470. Loss: 0.5542324114802973\n",
            "Epoch: 480. Loss: 0.5541728658327472\n",
            "Epoch: 490. Loss: 0.5541173777316422\n",
            "tensor(0.4383, dtype=torch.float64)\n",
            "2022-03-20 00:00:00\n",
            "Epoch: 0. Loss: 3.8416739777247777\n",
            "Epoch: 10. Loss: 0.6855784168409196\n",
            "Epoch: 20. Loss: 0.5888397373346601\n",
            "Epoch: 30. Loss: 0.5725033036760763\n",
            "Epoch: 40. Loss: 0.5665889338551746\n",
            "Epoch: 50. Loss: 0.5631301936113886\n",
            "Epoch: 60. Loss: 0.5607182105705133\n",
            "Epoch: 70. Loss: 0.558955880271848\n",
            "Epoch: 80. Loss: 0.557652914055842\n",
            "Epoch: 90. Loss: 0.5566861247941347\n",
            "Epoch: 100. Loss: 0.5559676361512396\n",
            "Epoch: 110. Loss: 0.5554331302940101\n",
            "Epoch: 120. Loss: 0.555035173855238\n",
            "Epoch: 130. Loss: 0.554738674154679\n",
            "Epoch: 140. Loss: 0.5545176191168054\n",
            "Epoch: 150. Loss: 0.5543527015152064\n",
            "Epoch: 160. Loss: 0.554229576346513\n",
            "Epoch: 170. Loss: 0.5541375774852644\n",
            "Epoch: 180. Loss: 0.5540687697912151\n",
            "Epoch: 190. Loss: 0.5540172474099572\n",
            "Epoch: 200. Loss: 0.5539786134354739\n",
            "Epoch: 210. Loss: 0.553949593566567\n",
            "Epoch: 220. Loss: 0.5539277489831541\n",
            "Epoch: 230. Loss: 0.5539112628173017\n",
            "Epoch: 240. Loss: 0.5538987812801508\n",
            "Epoch: 250. Loss: 0.5538892954162917\n",
            "Epoch: 260. Loss: 0.5538820530771261\n",
            "Epoch: 270. Loss: 0.5538764933812345\n",
            "Epoch: 280. Loss: 0.5538721979130516\n",
            "Epoch: 290. Loss: 0.5538688543831097\n",
            "Epoch: 300. Loss: 0.5538662295668916\n",
            "Epoch: 310. Loss: 0.5538641491527403\n",
            "Epoch: 320. Loss: 0.5538624827345311\n",
            "Epoch: 330. Loss: 0.5538611326353524\n",
            "Epoch: 340. Loss: 0.5538600255838886\n",
            "Epoch: 350. Loss: 0.5538591065149947\n",
            "Epoch: 360. Loss: 0.5538583339519798\n",
            "Epoch: 370. Loss: 0.5538576765666376\n",
            "Epoch: 380. Loss: 0.5538571106162435\n",
            "Epoch: 390. Loss: 0.5538566180335568\n",
            "Epoch: 400. Loss: 0.553856185003076\n",
            "Epoch: 410. Loss: 0.5538558008993999\n",
            "Epoch: 420. Loss: 0.5538554574952539\n",
            "Epoch: 430. Loss: 0.5538551483703701\n",
            "Epoch: 440. Loss: 0.5538548684699812\n",
            "Epoch: 450. Loss: 0.5538546137747822\n",
            "Epoch: 460. Loss: 0.5538543810539583\n",
            "Epoch: 470. Loss: 0.5538541676801331\n",
            "Epoch: 480. Loss: 0.5538539714904854\n",
            "Epoch: 490. Loss: 0.5538537906823149\n",
            "tensor(0.7689, dtype=torch.float64)\n",
            "2022-03-27 00:00:00\n",
            "Epoch: 0. Loss: 2.7598253698576003\n",
            "Epoch: 10. Loss: 0.7615868418871937\n",
            "Epoch: 20. Loss: 0.609064344807096\n",
            "Epoch: 30. Loss: 0.5800081174424628\n",
            "Epoch: 40. Loss: 0.5717881589821019\n",
            "Epoch: 50. Loss: 0.5681368109333144\n",
            "Epoch: 60. Loss: 0.5659393485889543\n",
            "Epoch: 70. Loss: 0.5644491044385198\n",
            "Epoch: 80. Loss: 0.5633917806388256\n",
            "Epoch: 90. Loss: 0.5626213698347973\n",
            "Epoch: 100. Loss: 0.5620466338657973\n",
            "Epoch: 110. Loss: 0.5616076296471921\n",
            "Epoch: 120. Loss: 0.561264240220083\n",
            "Epoch: 130. Loss: 0.5609892968988944\n",
            "Epoch: 140. Loss: 0.5607641946065279\n",
            "Epoch: 150. Loss: 0.5605760469025177\n",
            "Epoch: 160. Loss: 0.5604158233570578\n",
            "Epoch: 170. Loss: 0.5602771195799437\n",
            "Epoch: 180. Loss: 0.560155337376081\n",
            "Epoch: 190. Loss: 0.5600471328609579\n",
            "Epoch: 200. Loss: 0.559950041281821\n",
            "Epoch: 210. Loss: 0.5598622195515388\n",
            "Epoch: 220. Loss: 0.5597822680088631\n",
            "Epoch: 230. Loss: 0.559709106036356\n",
            "Epoch: 240. Loss: 0.559641884632051\n",
            "Epoch: 250. Loss: 0.5595799245502361\n",
            "Epoch: 260. Loss: 0.559522672266031\n",
            "Epoch: 270. Loss: 0.5594696684454128\n",
            "Epoch: 280. Loss: 0.559420525238731\n",
            "Epoch: 290. Loss: 0.5593749098303707\n",
            "Epoch: 300. Loss: 0.559332532443458\n",
            "Epoch: 310. Loss: 0.5592931375295094\n",
            "Epoch: 320. Loss: 0.5592564972434972\n",
            "Epoch: 330. Loss: 0.5592224065649108\n",
            "Epoch: 340. Loss: 0.5591906796088845\n",
            "Epoch: 350. Loss: 0.5591611468014116\n",
            "Epoch: 360. Loss: 0.5591336526850131\n",
            "Epoch: 370. Loss: 0.5591080541870259\n",
            "Epoch: 380. Loss: 0.5590842192296755\n",
            "Epoch: 390. Loss: 0.5590620255947156\n",
            "Epoch: 400. Loss: 0.5590413599795208\n",
            "Epoch: 410. Loss: 0.5590221171988109\n",
            "Epoch: 420. Loss: 0.5590041994986215\n",
            "Epoch: 430. Loss: 0.558987515958075\n",
            "Epoch: 440. Loss: 0.558971981960963\n",
            "Epoch: 450. Loss: 0.558957518723801\n",
            "Epoch: 460. Loss: 0.5589440528703862\n",
            "Epoch: 470. Loss: 0.5589315160453292\n",
            "Epoch: 480. Loss: 0.558919844560809\n",
            "Epoch: 490. Loss: 0.5589089790720912\n",
            "tensor(0.7575, dtype=torch.float64)\n",
            "2022-04-03 00:00:00\n",
            "Epoch: 0. Loss: 2.2371161292016106\n",
            "Epoch: 10. Loss: 1.5628318885599681\n",
            "Epoch: 20. Loss: 1.081133703203894\n",
            "Epoch: 30. Loss: 0.7766408891944357\n",
            "Epoch: 40. Loss: 0.6721430387148722\n",
            "Epoch: 50. Loss: 0.6489310175645583\n",
            "Epoch: 60. Loss: 0.6399391249452637\n",
            "Epoch: 70. Loss: 0.6333704929505306\n",
            "Epoch: 80. Loss: 0.6276810083509841\n",
            "Epoch: 90. Loss: 0.6225873762254293\n",
            "Epoch: 100. Loss: 0.6179781780298564\n",
            "Epoch: 110. Loss: 0.6137823956315143\n",
            "Epoch: 120. Loss: 0.6099475705231074\n",
            "Epoch: 130. Loss: 0.6064327508126458\n",
            "Epoch: 140. Loss: 0.6032048001882747\n",
            "Epoch: 150. Loss: 0.600236122595314\n",
            "Epoch: 160. Loss: 0.5975031842425071\n",
            "Epoch: 170. Loss: 0.5949855261927289\n",
            "Epoch: 180. Loss: 0.5926650888822156\n",
            "Epoch: 190. Loss: 0.5905257392111781\n",
            "Epoch: 200. Loss: 0.5885529317438193\n",
            "Epoch: 210. Loss: 0.5867334603581315\n",
            "Epoch: 220. Loss: 0.5850552719555823\n",
            "Epoch: 230. Loss: 0.5835073233981164\n",
            "Epoch: 240. Loss: 0.5820794689474476\n",
            "Epoch: 250. Loss: 0.5807623694777878\n",
            "Epoch: 260. Loss: 0.5795474174096947\n",
            "Epoch: 270. Loss: 0.578426673141805\n",
            "Epoch: 280. Loss: 0.5773928100258364\n",
            "Epoch: 290. Loss: 0.5764390658178841\n",
            "Epoch: 300. Loss: 0.5755591991619243\n",
            "Epoch: 310. Loss: 0.5747474500976643\n",
            "Epoch: 320. Loss: 0.5739985038884207\n",
            "Epoch: 330. Loss: 0.5733074576739765\n",
            "Epoch: 340. Loss: 0.5726697895958341\n",
            "Epoch: 350. Loss: 0.5720813301379333\n",
            "Epoch: 360. Loss: 0.5715382354890871\n",
            "Epoch: 370. Loss: 0.5710369627744692\n",
            "Epoch: 380. Loss: 0.5705742470297647\n",
            "Epoch: 390. Loss: 0.5701470798082606\n",
            "Epoch: 400. Loss: 0.5697526893217084\n",
            "Epoch: 410. Loss: 0.5693885220226567\n",
            "Epoch: 420. Loss: 0.5690522255407027\n",
            "Epoch: 430. Loss: 0.5687416328887476\n",
            "Epoch: 440. Loss: 0.5684547478584867\n",
            "Epoch: 450. Loss: 0.5681897315273821\n",
            "Epoch: 460. Loss: 0.5679448898024199\n",
            "Epoch: 470. Loss: 0.5677186619291431\n",
            "Epoch: 480. Loss: 0.5675096098977763\n",
            "Epoch: 490. Loss: 0.567316408681699\n",
            "tensor(0.6802, dtype=torch.float64)\n",
            "2022-04-10 00:00:00\n",
            "Epoch: 0. Loss: 1.8483980730110239\n",
            "Epoch: 10. Loss: 0.778967246657756\n",
            "Epoch: 20. Loss: 0.6848283398788392\n",
            "Epoch: 30. Loss: 0.634762390113069\n",
            "Epoch: 40. Loss: 0.606931636117421\n",
            "Epoch: 50. Loss: 0.5914288716594363\n",
            "Epoch: 60. Loss: 0.5826959463021772\n",
            "Epoch: 70. Loss: 0.5776767947029271\n",
            "Epoch: 80. Loss: 0.5746885863160405\n",
            "Epoch: 90. Loss: 0.5728132541661021\n",
            "Epoch: 100. Loss: 0.5715549671407149\n",
            "Epoch: 110. Loss: 0.5706466568999108\n",
            "Epoch: 120. Loss: 0.5699437612160388\n",
            "Epoch: 130. Loss: 0.5693671608434171\n",
            "Epoch: 140. Loss: 0.56887283706354\n",
            "Epoch: 150. Loss: 0.5684357510065202\n",
            "Epoch: 160. Loss: 0.5680412403646463\n",
            "Epoch: 170. Loss: 0.567680393309853\n",
            "Epoch: 180. Loss: 0.5673475373284392\n",
            "Epoch: 190. Loss: 0.567038860982879\n",
            "Epoch: 200. Loss: 0.5667516479337285\n",
            "Epoch: 210. Loss: 0.5664838451671785\n",
            "Epoch: 220. Loss: 0.5662338157015138\n",
            "Epoch: 230. Loss: 0.5660001943956395\n",
            "Epoch: 240. Loss: 0.5657818021712724\n",
            "Epoch: 250. Loss: 0.5655775938240449\n",
            "Epoch: 260. Loss: 0.5653866254568705\n",
            "Epoch: 270. Loss: 0.5652080335683117\n",
            "Epoch: 280. Loss: 0.5650410211834421\n",
            "Epoch: 290. Loss: 0.5648848483155087\n",
            "Epoch: 300. Loss: 0.5647388251392143\n",
            "Epoch: 310. Loss: 0.5646023068938864\n",
            "Epoch: 320. Loss: 0.5644746899125217\n",
            "Epoch: 330. Loss: 0.5643554083999609\n",
            "Epoch: 340. Loss: 0.5642439317222113\n",
            "Epoch: 350. Loss: 0.564139762054825\n",
            "Epoch: 360. Loss: 0.5640424322920324\n",
            "Epoch: 370. Loss: 0.5639515041524173\n",
            "Epoch: 380. Loss: 0.5638665664386525\n",
            "Epoch: 390. Loss: 0.5637872334228324\n",
            "Epoch: 400. Loss: 0.5637131433379712\n",
            "Epoch: 410. Loss: 0.5636439569621281\n",
            "Epoch: 420. Loss: 0.5635793562854423\n",
            "Epoch: 430. Loss: 0.5635190432528682\n",
            "Epoch: 440. Loss: 0.5634627385770363\n",
            "Epoch: 450. Loss: 0.5634101806167454\n",
            "Epoch: 460. Loss: 0.5633611243173058\n",
            "Epoch: 470. Loss: 0.5633153402094316\n",
            "Epoch: 480. Loss: 0.5632726134637023\n",
            "Epoch: 490. Loss: 0.5632327429978483\n",
            "tensor(0.6027, dtype=torch.float64)\n",
            "2022-04-17 00:00:00\n",
            "Epoch: 0. Loss: 1.9311961574801024\n",
            "Epoch: 10. Loss: 1.2938665337343005\n",
            "Epoch: 20. Loss: 0.9002156716636707\n",
            "Epoch: 30. Loss: 0.6907721835346149\n",
            "Epoch: 40. Loss: 0.6185977299616742\n",
            "Epoch: 50. Loss: 0.5936944616208107\n",
            "Epoch: 60. Loss: 0.5822096463212144\n",
            "Epoch: 70. Loss: 0.5763369525854514\n",
            "Epoch: 80. Loss: 0.5732650049015645\n",
            "Epoch: 90. Loss: 0.571631539218649\n",
            "Epoch: 100. Loss: 0.5707416168856538\n",
            "Epoch: 110. Loss: 0.5702394992798829\n",
            "Epoch: 120. Loss: 0.5699425532551939\n",
            "Epoch: 130. Loss: 0.5697563074508372\n",
            "Epoch: 140. Loss: 0.5696313312570138\n",
            "Epoch: 150. Loss: 0.5695413794024389\n",
            "Epoch: 160. Loss: 0.5694722687895983\n",
            "Epoch: 170. Loss: 0.5694161731357732\n",
            "Epoch: 180. Loss: 0.5693686666585912\n",
            "Epoch: 190. Loss: 0.569327173752497\n",
            "Epoch: 200. Loss: 0.5692901448013269\n",
            "Epoch: 210. Loss: 0.5692566112529095\n",
            "Epoch: 220. Loss: 0.5692259413211609\n",
            "Epoch: 230. Loss: 0.569197703346099\n",
            "Epoch: 240. Loss: 0.5691715878471566\n",
            "Epoch: 250. Loss: 0.5691473621339068\n",
            "Epoch: 260. Loss: 0.5691248433133603\n",
            "Epoch: 270. Loss: 0.5691038818937898\n",
            "Epoch: 280. Loss: 0.5690843516116807\n",
            "Epoch: 290. Loss: 0.5690661429835912\n",
            "Epoch: 300. Loss: 0.5690491591285749\n",
            "Epoch: 310. Loss: 0.5690333129985908\n",
            "Epoch: 320. Loss: 0.5690185254961407\n",
            "Epoch: 330. Loss: 0.5690047241595247\n",
            "Epoch: 340. Loss: 0.5689918422166323\n",
            "Epoch: 350. Loss: 0.5689798178816093\n",
            "Epoch: 360. Loss: 0.5689685938141562\n",
            "Epoch: 370. Loss: 0.5689581166896815\n",
            "Epoch: 380. Loss: 0.5689483368465724\n",
            "Epoch: 390. Loss: 0.5689392079883995\n",
            "Epoch: 400. Loss: 0.5689306869263242\n",
            "Epoch: 410. Loss: 0.5689227333518208\n",
            "Epoch: 420. Loss: 0.5689153096329981\n",
            "Epoch: 430. Loss: 0.5689083806298765\n",
            "Epoch: 440. Loss: 0.5689019135253689\n",
            "Epoch: 450. Loss: 0.5688958776696181\n",
            "Epoch: 460. Loss: 0.5688902444359605\n",
            "Epoch: 470. Loss: 0.5688849870872048\n",
            "Epoch: 480. Loss: 0.5688800806511948\n",
            "Epoch: 490. Loss: 0.5688755018048187\n",
            "tensor(0.4815, dtype=torch.float64)\n",
            "2022-04-24 00:00:00\n",
            "Epoch: 0. Loss: 4.748501300036013\n",
            "Epoch: 10. Loss: 0.778863167004744\n",
            "Epoch: 20. Loss: 0.62255164156675\n",
            "Epoch: 30. Loss: 0.5949312062410615\n",
            "Epoch: 40. Loss: 0.5883988959703308\n",
            "Epoch: 50. Loss: 0.5855884241970464\n",
            "Epoch: 60. Loss: 0.5836433957259602\n",
            "Epoch: 70. Loss: 0.5820547504772834\n",
            "Epoch: 80. Loss: 0.5806839123823072\n",
            "Epoch: 90. Loss: 0.5794686196887956\n",
            "Epoch: 100. Loss: 0.5783721642143361\n",
            "Epoch: 110. Loss: 0.5773706299248988\n",
            "Epoch: 120. Loss: 0.5764477225764526\n",
            "Epoch: 130. Loss: 0.5755919694672649\n",
            "Epoch: 140. Loss: 0.5747950280786898\n",
            "Epoch: 150. Loss: 0.5740506235892578\n",
            "Epoch: 160. Loss: 0.5733538687154391\n",
            "Epoch: 170. Loss: 0.5727008228313192\n",
            "Epoch: 180. Loss: 0.5720882033796453\n",
            "Epoch: 190. Loss: 0.5715131953922968\n",
            "Epoch: 200. Loss: 0.5709733248112053\n",
            "Epoch: 210. Loss: 0.57046637360296\n",
            "Epoch: 220. Loss: 0.5699903224048756\n",
            "Epoch: 230. Loss: 0.5695433113837854\n",
            "Epoch: 240. Loss: 0.5691236131806914\n",
            "Epoch: 250. Loss: 0.5687296138944649\n",
            "Epoch: 260. Loss: 0.568359799423263\n",
            "Epoch: 270. Loss: 0.5680127453836721\n",
            "Epoch: 280. Loss: 0.5676871094250161\n",
            "Epoch: 290. Loss: 0.5673816251533248\n",
            "Epoch: 300. Loss: 0.5670950971437942\n",
            "Epoch: 310. Loss: 0.5668263966966567\n",
            "Epoch: 320. Loss: 0.5665744581086275\n",
            "Epoch: 330. Loss: 0.5663382753100848\n",
            "Epoch: 340. Loss: 0.5661168987698826\n",
            "Epoch: 350. Loss: 0.5659094326039101\n",
            "Epoch: 360. Loss: 0.5657150318460354\n",
            "Epoch: 370. Loss: 0.5655328998547808\n",
            "Epoch: 380. Loss: 0.5653622858386241\n",
            "Epoch: 390. Loss: 0.565202482488913\n",
            "Epoch: 400. Loss: 0.5650528237132245\n",
            "Epoch: 410. Loss: 0.5649126824643597\n",
            "Epoch: 420. Loss: 0.5647814686615586\n",
            "Epoch: 430. Loss: 0.5646586272013047\n",
            "Epoch: 440. Loss: 0.5645436360554831\n",
            "Epoch: 450. Loss: 0.5644360044548224\n",
            "Epoch: 460. Loss: 0.5643352711555623\n",
            "Epoch: 470. Loss: 0.564241002787247\n",
            "Epoch: 480. Loss: 0.564152792279453\n",
            "Epoch: 490. Loss: 0.5640702573651617\n",
            "tensor(0.2567, dtype=torch.float64)\n",
            "2022-05-01 00:00:00\n",
            "Epoch: 0. Loss: 3.7931559045982572\n",
            "Epoch: 10. Loss: 1.455831736376112\n",
            "Epoch: 20. Loss: 0.8666057990171624\n",
            "Epoch: 30. Loss: 0.6816130054038718\n",
            "Epoch: 40. Loss: 0.6333195762064768\n",
            "Epoch: 50. Loss: 0.6119900053853696\n",
            "Epoch: 60. Loss: 0.5979281378809734\n",
            "Epoch: 70. Loss: 0.5882750760952559\n",
            "Epoch: 80. Loss: 0.5816675998416598\n",
            "Epoch: 90. Loss: 0.5771468607212557\n",
            "Epoch: 100. Loss: 0.5740404528901059\n",
            "Epoch: 110. Loss: 0.5718877047468747\n",
            "Epoch: 120. Loss: 0.5703775083322943\n",
            "Epoch: 130. Loss: 0.5693012432440862\n",
            "Epoch: 140. Loss: 0.5685193568900608\n",
            "Epoch: 150. Loss: 0.5679384658860278\n",
            "Epoch: 160. Loss: 0.5674959545842466\n",
            "Epoch: 170. Loss: 0.5671497078151403\n",
            "Epoch: 180. Loss: 0.5668712894215712\n",
            "Epoch: 190. Loss: 0.5666414114283922\n",
            "Epoch: 200. Loss: 0.5664469204565763\n",
            "Epoch: 210. Loss: 0.5662787888231422\n",
            "Epoch: 220. Loss: 0.5661307719249955\n",
            "Epoch: 230. Loss: 0.565998508546947\n",
            "Epoch: 240. Loss: 0.565878916422679\n",
            "Epoch: 250. Loss: 0.5657697851617197\n",
            "Epoch: 260. Loss: 0.5656695014604572\n",
            "Epoch: 270. Loss: 0.5655768631936106\n",
            "Epoch: 280. Loss: 0.5654909533554962\n",
            "Epoch: 290. Loss: 0.5654110543818855\n",
            "Epoch: 300. Loss: 0.5653365897644356\n",
            "Epoch: 310. Loss: 0.5652670841410309\n",
            "Epoch: 320. Loss: 0.5652021359120513\n",
            "Epoch: 330. Loss: 0.5651413983609817\n",
            "Epoch: 340. Loss: 0.5650845665576051\n",
            "Epoch: 350. Loss: 0.565031368199641\n",
            "Epoch: 360. Loss: 0.56498155714209\n",
            "Epoch: 370. Loss: 0.5649349087652489\n",
            "Epoch: 380. Loss: 0.5648912166045591\n",
            "Epoch: 390. Loss: 0.5648502898500405\n",
            "Epoch: 400. Loss: 0.5648119514483325\n",
            "Epoch: 410. Loss: 0.5647760366254108\n",
            "Epoch: 420. Loss: 0.5647423917058286\n",
            "Epoch: 430. Loss: 0.5647108731435875\n",
            "Epoch: 440. Loss: 0.5646813467064385\n",
            "Epoch: 450. Loss: 0.5646536867735723\n",
            "Epoch: 460. Loss: 0.5646277757190042\n",
            "Epoch: 470. Loss: 0.5646035033613864\n",
            "Epoch: 480. Loss: 0.5645807664667033\n",
            "Epoch: 490. Loss: 0.5645594682942343\n",
            "tensor(0.4281, dtype=torch.float64)\n",
            "2022-05-08 00:00:00\n",
            "Epoch: 0. Loss: 2.69414171896898\n",
            "Epoch: 10. Loss: 0.8432001373273312\n",
            "Epoch: 20. Loss: 0.6966105891286202\n",
            "Epoch: 30. Loss: 0.6413022161609047\n",
            "Epoch: 40. Loss: 0.6120990353498668\n",
            "Epoch: 50. Loss: 0.5951284228279887\n",
            "Epoch: 60. Loss: 0.5850955282438323\n",
            "Epoch: 70. Loss: 0.5791995289020515\n",
            "Epoch: 80. Loss: 0.5757341088859569\n",
            "Epoch: 90. Loss: 0.5736630055371307\n",
            "Epoch: 100. Loss: 0.5723825399492873\n",
            "Epoch: 110. Loss: 0.5715523911682173\n",
            "Epoch: 120. Loss: 0.5709835789599365\n",
            "Epoch: 130. Loss: 0.5705710675932271\n",
            "Epoch: 140. Loss: 0.5702556752750997\n",
            "Epoch: 150. Loss: 0.5700032717299696\n",
            "Epoch: 160. Loss: 0.5697935794828123\n",
            "Epoch: 170. Loss: 0.5696141445791131\n",
            "Epoch: 180. Loss: 0.5694570535582003\n",
            "Epoch: 190. Loss: 0.5693171094789836\n",
            "Epoch: 200. Loss: 0.5691907913708799\n",
            "Epoch: 210. Loss: 0.5690756425048072\n",
            "Epoch: 220. Loss: 0.5689698995473573\n",
            "Epoch: 230. Loss: 0.5688722611662019\n",
            "Epoch: 240. Loss: 0.5687817399486936\n",
            "Epoch: 250. Loss: 0.5686975656167466\n",
            "Epoch: 260. Loss: 0.5686191206800129\n",
            "Epoch: 270. Loss: 0.5685458970635626\n",
            "Epoch: 280. Loss: 0.5684774665391061\n",
            "Epoch: 290. Loss: 0.5684134603643555\n",
            "Epoch: 300. Loss: 0.5683535551282582\n",
            "Epoch: 310. Loss: 0.5682974628115061\n",
            "Epoch: 320. Loss: 0.5682449237280327\n",
            "Epoch: 330. Loss: 0.5681957014460325\n",
            "Epoch: 340. Loss: 0.5681495790759534\n",
            "Epoch: 350. Loss: 0.5681063565075049\n",
            "Epoch: 360. Loss: 0.5680658483095631\n",
            "Epoch: 370. Loss: 0.5680278820965852\n",
            "Epoch: 380. Loss: 0.5679922972263872\n",
            "Epoch: 390. Loss: 0.5679589437360427\n",
            "Epoch: 400. Loss: 0.5679276814513503\n",
            "Epoch: 410. Loss: 0.5678983792250275\n",
            "Epoch: 420. Loss: 0.5678709142723014\n",
            "Epoch: 430. Loss: 0.5678451715818804\n",
            "Epoch: 440. Loss: 0.5678210433866961\n",
            "Epoch: 450. Loss: 0.5677984286832306\n",
            "Epoch: 460. Loss: 0.5677772327913067\n",
            "Epoch: 470. Loss: 0.5677573669483446\n",
            "Epoch: 480. Loss: 0.5677387479335708\n",
            "Epoch: 490. Loss: 0.5677212977187078\n",
            "tensor(0.6202, dtype=torch.float64)\n",
            "2022-05-15 00:00:00\n",
            "Epoch: 0. Loss: 2.1508486170723975\n",
            "Epoch: 10. Loss: 1.4538486865220215\n",
            "Epoch: 20. Loss: 0.9964795829874723\n",
            "Epoch: 30. Loss: 0.8127746220168875\n",
            "Epoch: 40. Loss: 0.7246271352712085\n",
            "Epoch: 50. Loss: 0.6702424710680888\n",
            "Epoch: 60. Loss: 0.6387329229127281\n",
            "Epoch: 70. Loss: 0.6216442706225633\n",
            "Epoch: 80. Loss: 0.6124446709359507\n",
            "Epoch: 90. Loss: 0.6072044855677105\n",
            "Epoch: 100. Loss: 0.6038945153465175\n",
            "Epoch: 110. Loss: 0.6015381143754465\n",
            "Epoch: 120. Loss: 0.5996760347196018\n",
            "Epoch: 130. Loss: 0.5980919099237568\n",
            "Epoch: 140. Loss: 0.5966819234529521\n",
            "Epoch: 150. Loss: 0.5953945407122758\n",
            "Epoch: 160. Loss: 0.5942027814747175\n",
            "Epoch: 170. Loss: 0.5930914068692871\n",
            "Epoch: 180. Loss: 0.5920509408681726\n",
            "Epoch: 190. Loss: 0.5910748413921727\n",
            "Epoch: 200. Loss: 0.5901581363058889\n",
            "Epoch: 210. Loss: 0.5892967493297897\n",
            "Epoch: 220. Loss: 0.5884871563068714\n",
            "Epoch: 230. Loss: 0.5877262030904314\n",
            "Epoch: 240. Loss: 0.5870110046680364\n",
            "Epoch: 250. Loss: 0.5863388864581883\n",
            "Epoch: 260. Loss: 0.5857073483073583\n",
            "Epoch: 270. Loss: 0.5851140411746506\n",
            "Epoch: 280. Loss: 0.5845567511695733\n",
            "Epoch: 290. Loss: 0.5840333879924983\n",
            "Epoch: 300. Loss: 0.5835419760860626\n",
            "Epoch: 310. Loss: 0.5830806474963554\n",
            "Epoch: 320. Loss: 0.5826476358364755\n",
            "Epoch: 330. Loss: 0.5822412709775361\n",
            "Epoch: 340. Loss: 0.5818599742334789\n",
            "Epoch: 350. Loss: 0.5815022538937873\n",
            "Epoch: 360. Loss: 0.5811667010133897\n",
            "Epoch: 370. Loss: 0.5808519854040108\n",
            "Epoch: 380. Loss: 0.5805568517933285\n",
            "Epoch: 390. Loss: 0.5802801161321709\n",
            "Epoch: 400. Loss: 0.5800206620385253\n",
            "Epoch: 410. Loss: 0.5797774373722515\n",
            "Epoch: 420. Loss: 0.5795494509373051\n",
            "Epoch: 430. Loss: 0.5793357693097972\n",
            "Epoch: 440. Loss: 0.5791355137908735\n",
            "Epoch: 450. Loss: 0.5789478574835276\n",
            "Epoch: 460. Loss: 0.5787720224923039\n",
            "Epoch: 470. Loss: 0.5786072772445172\n",
            "Epoch: 480. Loss: 0.5784529339312502\n",
            "Epoch: 490. Loss: 0.5783083460659783\n",
            "tensor(0.6435, dtype=torch.float64)\n",
            "2022-05-22 00:00:00\n",
            "Epoch: 0. Loss: 4.855901710121368\n",
            "Epoch: 10. Loss: 0.6362959332495427\n",
            "Epoch: 20. Loss: 0.5838002574248181\n",
            "Epoch: 30. Loss: 0.5817229774556754\n",
            "Epoch: 40. Loss: 0.5810597782220999\n",
            "Epoch: 50. Loss: 0.5806787272757503\n",
            "Epoch: 60. Loss: 0.5804419891590823\n",
            "Epoch: 70. Loss: 0.5802905765721215\n",
            "Epoch: 80. Loss: 0.5801918048328734\n",
            "Epoch: 90. Loss: 0.5801263925294294\n",
            "Epoch: 100. Loss: 0.5800825271819751\n",
            "Epoch: 110. Loss: 0.5800527689550844\n",
            "Epoch: 120. Loss: 0.580032338119778\n",
            "Epoch: 130. Loss: 0.5800181211369934\n",
            "Epoch: 140. Loss: 0.5800080703509478\n",
            "Epoch: 150. Loss: 0.5800008300717835\n",
            "Epoch: 160. Loss: 0.5799954983735776\n",
            "Epoch: 170. Loss: 0.5799914729341756\n",
            "Epoch: 180. Loss: 0.5799883501796874\n",
            "Epoch: 190. Loss: 0.5799858588164855\n",
            "Epoch: 200. Loss: 0.5799838158079811\n",
            "Epoch: 210. Loss: 0.5799820971180935\n",
            "Epoch: 220. Loss: 0.5799806182223226\n",
            "Epoch: 230. Loss: 0.5799793211033556\n",
            "Epoch: 240. Loss: 0.5799781655624205\n",
            "Epoch: 250. Loss: 0.5799771234079792\n",
            "Epoch: 260. Loss: 0.579976174565144\n",
            "Epoch: 270. Loss: 0.5799753044684336\n",
            "Epoch: 280. Loss: 0.5799745023126059\n",
            "Epoch: 290. Loss: 0.579973759877576\n",
            "Epoch: 300. Loss: 0.5799730707376248\n",
            "Epoch: 310. Loss: 0.5799724297279986\n",
            "Epoch: 320. Loss: 0.5799718325840068\n",
            "Epoch: 330. Loss: 0.5799712756958179\n",
            "Epoch: 340. Loss: 0.5799707559409253\n",
            "Epoch: 350. Loss: 0.5799702705688223\n",
            "Epoch: 360. Loss: 0.5799698171208342\n",
            "Epoch: 370. Loss: 0.5799693933736734\n",
            "Epoch: 380. Loss: 0.5799689972990588\n",
            "Epoch: 390. Loss: 0.5799686270342576\n",
            "Epoch: 400. Loss: 0.5799682808600936\n",
            "Epoch: 410. Loss: 0.5799679571841037\n",
            "Epoch: 420. Loss: 0.5799676545272795\n",
            "Epoch: 430. Loss: 0.579967371513332\n",
            "Epoch: 440. Loss: 0.5799671068597733\n",
            "Epoch: 450. Loss: 0.579966859370321\n",
            "Epoch: 460. Loss: 0.5799666279282961\n",
            "Epoch: 470. Loss: 0.5799664114907838\n",
            "Epoch: 480. Loss: 0.5799662090833977\n",
            "Epoch: 490. Loss: 0.5799660197955324\n",
            "tensor(0.6014, dtype=torch.float64)\n",
            "2022-05-29 00:00:00\n",
            "Epoch: 0. Loss: 3.667224472791127\n",
            "Epoch: 10. Loss: 1.6863473169554688\n",
            "Epoch: 20. Loss: 0.8759500989349663\n",
            "Epoch: 30. Loss: 0.6783793950948189\n",
            "Epoch: 40. Loss: 0.6539404674704491\n",
            "Epoch: 50. Loss: 0.6442240764588342\n",
            "Epoch: 60. Loss: 0.6372465354856264\n",
            "Epoch: 70. Loss: 0.6318484292976327\n",
            "Epoch: 80. Loss: 0.6275192305980145\n",
            "Epoch: 90. Loss: 0.6239340566838065\n",
            "Epoch: 100. Loss: 0.6208793119014374\n",
            "Epoch: 110. Loss: 0.618213057236318\n",
            "Epoch: 120. Loss: 0.6158400007395441\n",
            "Epoch: 130. Loss: 0.6136954361006046\n",
            "Epoch: 140. Loss: 0.6117348369291282\n",
            "Epoch: 150. Loss: 0.6099270646869469\n",
            "Epoch: 160. Loss: 0.6082499077376606\n",
            "Epoch: 170. Loss: 0.6066871369531028\n",
            "Epoch: 180. Loss: 0.6052265549576062\n",
            "Epoch: 190. Loss: 0.6038587000988199\n",
            "Epoch: 200. Loss: 0.6025759837109614\n",
            "Epoch: 210. Loss: 0.6013721150334951\n",
            "Epoch: 220. Loss: 0.6002417174976434\n",
            "Epoch: 230. Loss: 0.5991800724662315\n",
            "Epoch: 240. Loss: 0.5981829478793164\n",
            "Epoch: 250. Loss: 0.5972464834288952\n",
            "Epoch: 260. Loss: 0.5963671133188597\n",
            "Epoch: 270. Loss: 0.5955415139620424\n",
            "Epoch: 280. Loss: 0.5947665681754075\n",
            "Epoch: 290. Loss: 0.5940393402512911\n",
            "Epoch: 300. Loss: 0.5933570581680481\n",
            "Epoch: 310. Loss: 0.5927171004648637\n",
            "Epoch: 320. Loss: 0.5921169861484022\n",
            "Epoch: 330. Loss: 0.5915543665611551\n",
            "Epoch: 340. Loss: 0.5910270185153315\n",
            "Epoch: 350. Loss: 0.5905328382439943\n",
            "Epoch: 360. Loss: 0.5900698358846471\n",
            "Epoch: 370. Loss: 0.5896361303176587\n",
            "Epoch: 380. Loss: 0.5892299442515699\n",
            "Epoch: 390. Loss: 0.5888495994921219\n",
            "Epoch: 400. Loss: 0.5884935123601611\n",
            "Epoch: 410. Loss: 0.5881601892411253\n",
            "Epoch: 420. Loss: 0.5878482222593003\n",
            "Epoch: 430. Loss: 0.5875562850759964\n",
            "Epoch: 440. Loss: 0.5872831288138535\n",
            "Epoch: 450. Loss: 0.5870275781107581\n",
            "Epoch: 460. Loss: 0.5867885273070284\n",
            "Epoch: 470. Loss: 0.5865649367690857\n",
            "Epoch: 480. Loss: 0.586355829352054\n",
            "Epoch: 490. Loss: 0.5861602870028164\n",
            "tensor(0.6858, dtype=torch.float64)\n",
            "2022-06-05 00:00:00\n",
            "Epoch: 0. Loss: 6.222701948800143\n",
            "Epoch: 10. Loss: 0.669326255875729\n",
            "Epoch: 20. Loss: 0.6148197093934732\n",
            "Epoch: 30. Loss: 0.6101302810561592\n",
            "Epoch: 40. Loss: 0.6076009140865608\n",
            "Epoch: 50. Loss: 0.6058538591835839\n",
            "Epoch: 60. Loss: 0.6045176520990645\n",
            "Epoch: 70. Loss: 0.603419221165751\n",
            "Epoch: 80. Loss: 0.6024719628850719\n",
            "Epoch: 90. Loss: 0.6016302908733264\n",
            "Epoch: 100. Loss: 0.6008686753439296\n",
            "Epoch: 110. Loss: 0.6001717719797588\n",
            "Epoch: 120. Loss: 0.599529653546397\n",
            "Epoch: 130. Loss: 0.5989354251322552\n",
            "Epoch: 140. Loss: 0.5983839807963102\n",
            "Epoch: 150. Loss: 0.5978713255082407\n",
            "Epoch: 160. Loss: 0.5973941885908972\n",
            "Epoch: 170. Loss: 0.5969497941977345\n",
            "Epoch: 180. Loss: 0.5965357201072099\n",
            "Epoch: 190. Loss: 0.5961498081526688\n",
            "Epoch: 200. Loss: 0.5957901058368741\n",
            "Epoch: 210. Loss: 0.5954548272683587\n",
            "Epoch: 220. Loss: 0.595142326305999\n",
            "Epoch: 230. Loss: 0.5948510775342987\n",
            "Epoch: 240. Loss: 0.5945796623240642\n",
            "Epoch: 250. Loss: 0.5943267582339448\n",
            "Epoch: 260. Loss: 0.5940911306345341\n",
            "Epoch: 270. Loss: 0.5938716258341253\n",
            "Epoch: 280. Loss: 0.593667165239707\n",
            "Epoch: 290. Loss: 0.5934767402506717\n",
            "Epoch: 300. Loss: 0.5932994076885114\n",
            "Epoch: 310. Loss: 0.5931342856341132\n",
            "Epoch: 320. Loss: 0.5929805495883801\n",
            "Epoch: 330. Loss: 0.5928374289002906\n",
            "Epoch: 340. Loss: 0.5927042034247332\n",
            "Epoch: 350. Loss: 0.5925802003840825\n",
            "Epoch: 360. Loss: 0.5924647914148938\n",
            "Epoch: 370. Loss: 0.5923573897857606\n",
            "Epoch: 380. Loss: 0.5922574477753356\n",
            "Epoch: 390. Loss: 0.5921644542013628\n",
            "Epoch: 400. Loss: 0.592077932092738\n",
            "Epoch: 410. Loss: 0.5919974364973601\n",
            "Epoch: 420. Loss: 0.5919225524190307\n",
            "Epoch: 430. Loss: 0.5918528928770015\n",
            "Epoch: 440. Loss: 0.591788097082034\n",
            "Epoch: 450. Loss: 0.5917278287230437\n",
            "Epoch: 460. Loss: 0.5916717743586111\n",
            "Epoch: 470. Loss: 0.5916196419078164\n",
            "Epoch: 480. Loss: 0.5915711592350568\n",
            "Epoch: 490. Loss: 0.5915260728236873\n",
            "tensor(0.5631, dtype=torch.float64)\n",
            "2022-06-12 00:00:00\n",
            "Epoch: 0. Loss: 2.544003143144682\n",
            "Epoch: 10. Loss: 1.1683078255597241\n",
            "Epoch: 20. Loss: 0.6136021880672561\n",
            "Epoch: 30. Loss: 0.6038737057370801\n",
            "Epoch: 40. Loss: 0.6022246329241759\n",
            "Epoch: 50. Loss: 0.6012215144931783\n",
            "Epoch: 60. Loss: 0.6005772432964405\n",
            "Epoch: 70. Loss: 0.6001617096714474\n",
            "Epoch: 80. Loss: 0.5998930918369232\n",
            "Epoch: 90. Loss: 0.5997190837564104\n",
            "Epoch: 100. Loss: 0.599606131788156\n",
            "Epoch: 110. Loss: 0.5995326553462311\n",
            "Epoch: 120. Loss: 0.5994847435726325\n",
            "Epoch: 130. Loss: 0.5994534125128499\n",
            "Epoch: 140. Loss: 0.5994328507668787\n",
            "Epoch: 150. Loss: 0.5994192939655858\n",
            "Epoch: 160. Loss: 0.5994103007985739\n",
            "Epoch: 170. Loss: 0.5994042863087469\n",
            "Epoch: 180. Loss: 0.5994002204784997\n",
            "Epoch: 190. Loss: 0.5993974332680835\n",
            "Epoch: 200. Loss: 0.5993954883493002\n",
            "Epoch: 210. Loss: 0.5993941012433374\n",
            "Epoch: 220. Loss: 0.5993930862007152\n",
            "Epoch: 230. Loss: 0.5993923217067397\n",
            "Epoch: 240. Loss: 0.599391728067978\n",
            "Epoch: 250. Loss: 0.5993912528408473\n",
            "Epoch: 260. Loss: 0.5993908613539584\n",
            "Epoch: 270. Loss: 0.5993905305407752\n",
            "Epoch: 280. Loss: 0.5993902449245233\n",
            "Epoch: 290. Loss: 0.5993899940029354\n",
            "Epoch: 300. Loss: 0.599389770543763\n",
            "Epoch: 310. Loss: 0.5993895694730352\n",
            "Epoch: 320. Loss: 0.5993893871492113\n",
            "Epoch: 330. Loss: 0.5993892208886376\n",
            "Epoch: 340. Loss: 0.5993890686547316\n",
            "Epoch: 350. Loss: 0.5993889288538791\n",
            "Epoch: 360. Loss: 0.5993888002009305\n",
            "Epoch: 370. Loss: 0.5993886816301318\n",
            "Epoch: 380. Loss: 0.5993885722357415\n",
            "Epoch: 390. Loss: 0.5993884712320838\n",
            "Epoch: 400. Loss: 0.5993883779263491\n",
            "Epoch: 410. Loss: 0.5993882916997851\n",
            "Epoch: 420. Loss: 0.5993882119944309\n",
            "Epoch: 430. Loss: 0.5993881383035383\n",
            "Epoch: 440. Loss: 0.5993880701644635\n",
            "Epoch: 450. Loss: 0.5993880071532323\n",
            "Epoch: 460. Loss: 0.5993879488802555\n",
            "Epoch: 470. Loss: 0.5993878949868482\n",
            "Epoch: 480. Loss: 0.5993878451423276\n",
            "Epoch: 490. Loss: 0.5993877990415291\n",
            "tensor(0.6228, dtype=torch.float64)\n",
            "2022-06-19 00:00:00\n",
            "Epoch: 0. Loss: 3.0738508616806968\n",
            "Epoch: 10. Loss: 1.701167722457947\n",
            "Epoch: 20. Loss: 0.9560862758035661\n",
            "Epoch: 30. Loss: 0.7131594579457686\n",
            "Epoch: 40. Loss: 0.6739908927000482\n",
            "Epoch: 50. Loss: 0.6578650439219853\n",
            "Epoch: 60. Loss: 0.6470914614472792\n",
            "Epoch: 70. Loss: 0.63953797698378\n",
            "Epoch: 80. Loss: 0.6341152259688849\n",
            "Epoch: 90. Loss: 0.6301098018940391\n",
            "Epoch: 100. Loss: 0.6270542983041485\n",
            "Epoch: 110. Loss: 0.6246442796968669\n",
            "Epoch: 120. Loss: 0.622681702994584\n",
            "Epoch: 130. Loss: 0.6210373835409114\n",
            "Epoch: 140. Loss: 0.6196264990835547\n",
            "Epoch: 150. Loss: 0.6183927515963449\n",
            "Epoch: 160. Loss: 0.6172981859947401\n",
            "Epoch: 170. Loss: 0.6163166692222287\n",
            "Epoch: 180. Loss: 0.6154297227739214\n",
            "Epoch: 190. Loss: 0.6146238618407335\n",
            "Epoch: 200. Loss: 0.6138888961467166\n",
            "Epoch: 210. Loss: 0.6132168434586525\n",
            "Epoch: 220. Loss: 0.6126012329362811\n",
            "Epoch: 230. Loss: 0.6120366563678266\n",
            "Epoch: 240. Loss: 0.6115184769973117\n",
            "Epoch: 250. Loss: 0.6110426385768999\n",
            "Epoch: 260. Loss: 0.6106055382310174\n",
            "Epoch: 270. Loss: 0.6102039400377279\n",
            "Epoch: 280. Loss: 0.6098349146902758\n",
            "Epoch: 290. Loss: 0.6094957959671038\n",
            "Epoch: 300. Loss: 0.6091841481390066\n",
            "Epoch: 310. Loss: 0.6088977405946288\n",
            "Epoch: 320. Loss: 0.6086345273264683\n",
            "Epoch: 330. Loss: 0.6083926297788123\n",
            "Epoch: 340. Loss: 0.6081703221007627\n",
            "Epoch: 350. Loss: 0.6079660181885612\n",
            "Epoch: 360. Loss: 0.6077782601158846\n",
            "Epoch: 370. Loss: 0.6076057076855268\n",
            "Epoch: 380. Loss: 0.6074471289205918\n",
            "Epoch: 390. Loss: 0.6073013913666725\n",
            "Epoch: 400. Loss: 0.607167454110266\n",
            "Epoch: 410. Loss: 0.6070443604402826\n",
            "Epoch: 420. Loss: 0.6069312310935395\n",
            "Epoch: 430. Loss: 0.6068272580345152\n",
            "Epoch: 440. Loss: 0.6067316987261201\n",
            "Epoch: 450. Loss: 0.6066438708529627\n",
            "Epoch: 460. Loss: 0.606563147462192\n",
            "Epoch: 470. Loss: 0.6064889524899296\n",
            "Epoch: 480. Loss: 0.6064207566437771\n",
            "Epoch: 490. Loss: 0.6063580736140705\n",
            "tensor(0.6219, dtype=torch.float64)\n",
            "2022-06-26 00:00:00\n",
            "Epoch: 0. Loss: 2.2609704229310075\n",
            "Epoch: 10. Loss: 0.8268775644999253\n",
            "Epoch: 20. Loss: 0.6649725907687322\n",
            "Epoch: 30. Loss: 0.639770142645675\n",
            "Epoch: 40. Loss: 0.6270517415000442\n",
            "Epoch: 50. Loss: 0.6188754015941363\n",
            "Epoch: 60. Loss: 0.6134936280971618\n",
            "Epoch: 70. Loss: 0.6099321970501514\n",
            "Epoch: 80. Loss: 0.6075711716945754\n",
            "Epoch: 90. Loss: 0.6060070209706169\n",
            "Epoch: 100. Loss: 0.604973003532284\n",
            "Epoch: 110. Loss: 0.6042912696811487\n",
            "Epoch: 120. Loss: 0.6038429799525332\n",
            "Epoch: 130. Loss: 0.6035488711770232\n",
            "Epoch: 140. Loss: 0.6033562675537273\n",
            "Epoch: 150. Loss: 0.6032303032003833\n",
            "Epoch: 160. Loss: 0.603147987350352\n",
            "Epoch: 170. Loss: 0.6030942089274863\n",
            "Epoch: 180. Loss: 0.6030590624919625\n",
            "Epoch: 190. Loss: 0.6030360688939949\n",
            "Epoch: 200. Loss: 0.6030209972889243\n",
            "Epoch: 210. Loss: 0.6030110885667683\n",
            "Epoch: 220. Loss: 0.6030045451567428\n",
            "Epoch: 230. Loss: 0.6030001967478119\n",
            "Epoch: 240. Loss: 0.6029972817399373\n",
            "Epoch: 250. Loss: 0.6029953046007192\n",
            "Epoch: 260. Loss: 0.6029939428879793\n",
            "Epoch: 270. Loss: 0.6029929867085044\n",
            "Epoch: 280. Loss: 0.6029922993291904\n",
            "Epoch: 290. Loss: 0.6029917915661911\n",
            "Epoch: 300. Loss: 0.6029914051404576\n",
            "Epoch: 310. Loss: 0.6029911018642132\n",
            "Epoch: 320. Loss: 0.6029908566172306\n",
            "Epoch: 330. Loss: 0.6029906527852154\n",
            "Epoch: 340. Loss: 0.602990479297216\n",
            "Epoch: 350. Loss: 0.6029903287012776\n",
            "Epoch: 360. Loss: 0.6029901959141175\n",
            "Epoch: 370. Loss: 0.6029900774083373\n",
            "Epoch: 380. Loss: 0.6029899706836523\n",
            "Epoch: 390. Loss: 0.6029898739225035\n",
            "Epoch: 400. Loss: 0.6029897857653886\n",
            "Epoch: 410. Loss: 0.6029897051639533\n",
            "Epoch: 420. Loss: 0.6029896312846114\n",
            "Epoch: 430. Loss: 0.6029895634450255\n",
            "Epoch: 440. Loss: 0.6029895010719796\n",
            "Epoch: 450. Loss: 0.6029894436731973\n",
            "Epoch: 460. Loss: 0.6029893908182732\n",
            "Epoch: 470. Loss: 0.602989342125575\n",
            "Epoch: 480. Loss: 0.6029892972530768\n",
            "Epoch: 490. Loss: 0.6029892558917921\n",
            "tensor(0.6260, dtype=torch.float64)\n",
            "2022-07-03 00:00:00\n",
            "Epoch: 0. Loss: 2.2356507110337667\n",
            "Epoch: 10. Loss: 1.0818888306178605\n",
            "Epoch: 20. Loss: 0.6980368264447118\n",
            "Epoch: 30. Loss: 0.6406111294212654\n",
            "Epoch: 40. Loss: 0.6223988235939792\n",
            "Epoch: 50. Loss: 0.6141286922510176\n",
            "Epoch: 60. Loss: 0.6102244760988577\n",
            "Epoch: 70. Loss: 0.6082399116686555\n",
            "Epoch: 80. Loss: 0.6071292009703892\n",
            "Epoch: 90. Loss: 0.606449036216776\n",
            "Epoch: 100. Loss: 0.6060012813456066\n",
            "Epoch: 110. Loss: 0.6056893686341546\n",
            "Epoch: 120. Loss: 0.6054617510627907\n",
            "Epoch: 130. Loss: 0.6052887681280449\n",
            "Epoch: 140. Loss: 0.6051524199588337\n",
            "Epoch: 150. Loss: 0.6050413909841936\n",
            "Epoch: 160. Loss: 0.6049483949773875\n",
            "Epoch: 170. Loss: 0.6048686528461575\n",
            "Epoch: 180. Loss: 0.604798976314221\n",
            "Epoch: 190. Loss: 0.6047371994819521\n",
            "Epoch: 200. Loss: 0.604681819846141\n",
            "Epoch: 210. Loss: 0.604631769165097\n",
            "Epoch: 220. Loss: 0.6045862662025467\n",
            "Epoch: 230. Loss: 0.6045447216178448\n",
            "Epoch: 240. Loss: 0.6045066762633147\n",
            "Epoch: 250. Loss: 0.6044717609639839\n",
            "Epoch: 260. Loss: 0.6044396701486051\n",
            "Epoch: 270. Loss: 0.6044101444318999\n",
            "Epoch: 280. Loss: 0.6043829589947854\n",
            "Epoch: 290. Loss: 0.6043579157303663\n",
            "Epoch: 300. Loss: 0.6043348378443738\n",
            "Epoch: 310. Loss: 0.6043135660629587\n",
            "Epoch: 320. Loss: 0.6042939558999368\n",
            "Epoch: 330. Loss: 0.6042758756285671\n",
            "Epoch: 340. Loss: 0.6042592047274659\n",
            "Epoch: 350. Loss: 0.6042438326506723\n",
            "Epoch: 360. Loss: 0.6042296578238202\n",
            "Epoch: 370. Loss: 0.6042165868019717\n",
            "Epoch: 380. Loss: 0.6042045335463991\n",
            "Epoch: 390. Loss: 0.6041934187917125\n",
            "Epoch: 400. Loss: 0.6041831694838822\n",
            "Epoch: 410. Loss: 0.6041737182756899\n",
            "Epoch: 420. Loss: 0.604165003070055\n",
            "Epoch: 430. Loss: 0.6041569666042694\n",
            "Epoch: 440. Loss: 0.6041495560698986\n",
            "Epoch: 450. Loss: 0.604142722764271\n",
            "Epoch: 460. Loss: 0.6041364217702779\n",
            "Epoch: 470. Loss: 0.6041306116617716\n",
            "Epoch: 480. Loss: 0.6041252542322512\n",
            "Epoch: 490. Loss: 0.6041203142448389\n",
            "tensor(0.9981, dtype=torch.float64)\n",
            "2022-07-10 00:00:00\n",
            "Epoch: 0. Loss: 3.4780601281422765\n",
            "Epoch: 10. Loss: 0.8945722504972901\n",
            "Epoch: 20. Loss: 0.823674858550916\n",
            "Epoch: 30. Loss: 0.7878883459371039\n",
            "Epoch: 40. Loss: 0.7643112466831933\n",
            "Epoch: 50. Loss: 0.747622112426262\n",
            "Epoch: 60. Loss: 0.7345579240087152\n",
            "Epoch: 70. Loss: 0.7234173117487435\n",
            "Epoch: 80. Loss: 0.7134111960671851\n",
            "Epoch: 90. Loss: 0.7041894222126551\n",
            "Epoch: 100. Loss: 0.6955957414922733\n",
            "Epoch: 110. Loss: 0.6875584762983402\n",
            "Epoch: 120. Loss: 0.6800446741631929\n",
            "Epoch: 130. Loss: 0.673040676358866\n",
            "Epoch: 140. Loss: 0.6665425680389598\n",
            "Epoch: 150. Loss: 0.660549786431425\n",
            "Epoch: 160. Loss: 0.6550598410607241\n",
            "Epoch: 170. Loss: 0.650064319472126\n",
            "Epoch: 180. Loss: 0.6455468919782364\n",
            "Epoch: 190. Loss: 0.6414834567306296\n",
            "Epoch: 200. Loss: 0.6378438074595003\n",
            "Epoch: 210. Loss: 0.6345939245881792\n",
            "Epoch: 220. Loss: 0.631698185601767\n",
            "Epoch: 230. Loss: 0.6291211395598774\n",
            "Epoch: 240. Loss: 0.6268287620295188\n",
            "Epoch: 250. Loss: 0.6247892471823349\n",
            "Epoch: 260. Loss: 0.6229734395134031\n",
            "Epoch: 270. Loss: 0.6213550059433638\n",
            "Epoch: 280. Loss: 0.6199104308954962\n",
            "Epoch: 290. Loss: 0.6186188968855899\n",
            "Epoch: 300. Loss: 0.6174620962172742\n",
            "Epoch: 310. Loss: 0.6164240063023286\n",
            "Epoch: 320. Loss: 0.6154906513236935\n",
            "Epoch: 330. Loss: 0.6146498656410486\n",
            "Epoch: 340. Loss: 0.6138910688776295\n",
            "Epoch: 350. Loss: 0.6132050585822325\n",
            "Epoch: 360. Loss: 0.6125838234225562\n",
            "Epoch: 370. Loss: 0.6120203778018097\n",
            "Epoch: 380. Loss: 0.6115086174102149\n",
            "Epoch: 390. Loss: 0.6110431943659795\n",
            "Epoch: 400. Loss: 0.6106194101302785\n",
            "Epoch: 410. Loss: 0.6102331241849155\n",
            "Epoch: 420. Loss: 0.6098806764495442\n",
            "Epoch: 430. Loss: 0.6095588215186194\n",
            "Epoch: 440. Loss: 0.6092646729660167\n",
            "Epoch: 450. Loss: 0.6089956561622583\n",
            "Epoch: 460. Loss: 0.6087494682521172\n",
            "Epoch: 470. Loss: 0.6085240441347035\n",
            "Epoch: 480. Loss: 0.6083175274659176\n",
            "Epoch: 490. Loss: 0.6081282458607687\n",
            "tensor(0.6154, dtype=torch.float64)\n",
            "2022-07-17 00:00:00\n",
            "Epoch: 0. Loss: 3.925306525040432\n",
            "Epoch: 10. Loss: 0.9923906934859642\n",
            "Epoch: 20. Loss: 0.7776766706721986\n",
            "Epoch: 30. Loss: 0.6923363552950488\n",
            "Epoch: 40. Loss: 0.6480894930546257\n",
            "Epoch: 50. Loss: 0.6279466307417231\n",
            "Epoch: 60. Loss: 0.6197142846762105\n",
            "Epoch: 70. Loss: 0.6163056514194702\n",
            "Epoch: 80. Loss: 0.6147412850799402\n",
            "Epoch: 90. Loss: 0.6139289774616389\n",
            "Epoch: 100. Loss: 0.613464832630212\n",
            "Epoch: 110. Loss: 0.6131835519311549\n",
            "Epoch: 120. Loss: 0.6130073432830504\n",
            "Epoch: 130. Loss: 0.6128947491370887\n",
            "Epoch: 140. Loss: 0.6128217539697213\n",
            "Epoch: 150. Loss: 0.612773778439282\n",
            "Epoch: 160. Loss: 0.6127417547947779\n",
            "Epoch: 170. Loss: 0.6127199727964796\n",
            "Epoch: 180. Loss: 0.6127048118978848\n",
            "Epoch: 190. Loss: 0.6126939664096455\n",
            "Epoch: 200. Loss: 0.6126859627839457\n",
            "Epoch: 210. Loss: 0.6126798559312608\n",
            "Epoch: 220. Loss: 0.612675037165375\n",
            "Epoch: 230. Loss: 0.612671112371487\n",
            "Epoch: 240. Loss: 0.6126678245654591\n",
            "Epoch: 250. Loss: 0.6126650045959615\n",
            "Epoch: 260. Loss: 0.6126625397224326\n",
            "Epoch: 270. Loss: 0.6126603535629727\n",
            "Epoch: 280. Loss: 0.6126583932818549\n",
            "Epoch: 290. Loss: 0.6126566213909008\n",
            "Epoch: 300. Loss: 0.6126550104937117\n",
            "Epoch: 310. Loss: 0.6126535399084392\n",
            "Epoch: 320. Loss: 0.6126521934907124\n",
            "Epoch: 330. Loss: 0.6126509582240828\n",
            "Epoch: 340. Loss: 0.6126498233018902\n",
            "Epoch: 350. Loss: 0.612648779524281\n",
            "Epoch: 360. Loss: 0.6126478188977609\n",
            "Epoch: 370. Loss: 0.6126469343652926\n",
            "Epoch: 380. Loss: 0.6126461196208766\n",
            "Epoch: 390. Loss: 0.6126453689791184\n",
            "Epoch: 400. Loss: 0.6126446772808589\n",
            "Epoch: 410. Loss: 0.6126440398227108\n",
            "Epoch: 420. Loss: 0.6126434523026657\n",
            "Epoch: 430. Loss: 0.6126429107767047\n",
            "Epoch: 440. Loss: 0.6126424116231161\n",
            "Epoch: 450. Loss: 0.6126419515123638\n",
            "Epoch: 460. Loss: 0.6126415273810754\n",
            "Epoch: 470. Loss: 0.612641136409195\n",
            "Epoch: 480. Loss: 0.6126407759996457\n",
            "Epoch: 490. Loss: 0.6126404437600458\n",
            "tensor(0.5756, dtype=torch.float64)\n",
            "2022-07-24 00:00:00\n",
            "Epoch: 0. Loss: 2.359925491427986\n",
            "Epoch: 10. Loss: 1.4075517760431036\n",
            "Epoch: 20. Loss: 0.7901739564280239\n",
            "Epoch: 30. Loss: 0.6471031770921658\n",
            "Epoch: 40. Loss: 0.6350090727533877\n",
            "Epoch: 50. Loss: 0.6316209310410408\n",
            "Epoch: 60. Loss: 0.6295681326889192\n",
            "Epoch: 70. Loss: 0.6280769418195703\n",
            "Epoch: 80. Loss: 0.6269027012773755\n",
            "Epoch: 90. Loss: 0.6259353988557446\n",
            "Epoch: 100. Loss: 0.6251157441219193\n",
            "Epoch: 110. Loss: 0.6244072822405884\n",
            "Epoch: 120. Loss: 0.6237857141398914\n",
            "Epoch: 130. Loss: 0.6232340761537125\n",
            "Epoch: 140. Loss: 0.6227401621972722\n",
            "Epoch: 150. Loss: 0.6222949661751099\n",
            "Epoch: 160. Loss: 0.6218916763563381\n",
            "Epoch: 170. Loss: 0.6215250062644139\n",
            "Epoch: 180. Loss: 0.6211907438091918\n",
            "Epoch: 190. Loss: 0.6208854456987243\n",
            "Epoch: 200. Loss: 0.6206062294436088\n",
            "Epoch: 210. Loss: 0.6203506310645537\n",
            "Epoch: 220. Loss: 0.6201165070332302\n",
            "Epoch: 230. Loss: 0.6199019659866883\n",
            "Epoch: 240. Loss: 0.619705320494936\n",
            "Epoch: 250. Loss: 0.6195250523621527\n",
            "Epoch: 260. Loss: 0.6193597870976101\n",
            "Epoch: 270. Loss: 0.6192082746393417\n",
            "Epoch: 280. Loss: 0.6190693743819801\n",
            "Epoch: 290. Loss: 0.6189420432065482\n",
            "Epoch: 300. Loss: 0.6188253256404924\n",
            "Epoch: 310. Loss: 0.6187183455624901\n",
            "Epoch: 320. Loss: 0.6186202990566676\n",
            "Epoch: 330. Loss: 0.6185304481470413\n",
            "Epoch: 340. Loss: 0.6184481152267627\n",
            "Epoch: 350. Loss: 0.6183726780524286\n",
            "Epoch: 360. Loss: 0.6183035652107992\n",
            "Epoch: 370. Loss: 0.618240251990102\n",
            "Epoch: 380. Loss: 0.618182256604799\n",
            "Epoch: 390. Loss: 0.6181291367340691\n",
            "Epoch: 400. Loss: 0.6180804863420908\n",
            "Epoch: 410. Loss: 0.6180359327537068\n",
            "Epoch: 420. Loss: 0.617995133963008\n",
            "Epoch: 430. Loss: 0.6179577761552904\n",
            "Epoch: 440. Loss: 0.6179235714250745\n",
            "Epoch: 450. Loss: 0.6178922556746327\n",
            "Epoch: 460. Loss: 0.6178635866789138\n",
            "Epoch: 470. Loss: 0.6178373423039657\n",
            "Epoch: 480. Loss: 0.6178133188670024\n",
            "Epoch: 490. Loss: 0.6177913296272007\n",
            "tensor(0.5932, dtype=torch.float64)\n",
            "2022-07-31 00:00:00\n",
            "Epoch: 0. Loss: 2.643823145988823\n",
            "Epoch: 10. Loss: 1.4060332936730222\n",
            "Epoch: 20. Loss: 0.9215411579805218\n",
            "Epoch: 30. Loss: 0.8041817031075347\n",
            "Epoch: 40. Loss: 0.7394571284409017\n",
            "Epoch: 50. Loss: 0.7011930931474695\n",
            "Epoch: 60. Loss: 0.6780444273843104\n",
            "Epoch: 70. Loss: 0.6633569463478067\n",
            "Epoch: 80. Loss: 0.6535641125508128\n",
            "Epoch: 90. Loss: 0.6467702256533858\n",
            "Epoch: 100. Loss: 0.641905155180126\n",
            "Epoch: 110. Loss: 0.6383203858538586\n",
            "Epoch: 120. Loss: 0.6356033724724035\n",
            "Epoch: 130. Loss: 0.6334847606136905\n",
            "Epoch: 140. Loss: 0.6317863138148296\n",
            "Epoch: 150. Loss: 0.6303890816922639\n",
            "Epoch: 160. Loss: 0.6292130489272211\n",
            "Epoch: 170. Loss: 0.6282038758612247\n",
            "Epoch: 180. Loss: 0.6273242011276824\n",
            "Epoch: 190. Loss: 0.626547924967925\n",
            "Epoch: 200. Loss: 0.6258564492520319\n",
            "Epoch: 210. Loss: 0.6252362031460353\n",
            "Epoch: 220. Loss: 0.62467701337173\n",
            "Epoch: 230. Loss: 0.6241710291581242\n",
            "Epoch: 240. Loss: 0.6237120114341771\n",
            "Epoch: 250. Loss: 0.6232948612046558\n",
            "Epoch: 260. Loss: 0.6229153050181164\n",
            "Epoch: 270. Loss: 0.6225696836562424\n",
            "Epoch: 280. Loss: 0.6222548087041374\n",
            "Epoch: 290. Loss: 0.6219678638265635\n",
            "Epoch: 300. Loss: 0.6217063355596324\n",
            "Epoch: 310. Loss: 0.6214679636655926\n",
            "Epoch: 320. Loss: 0.6212507045325578\n",
            "Epoch: 330. Loss: 0.6210527033505786\n",
            "Epoch: 340. Loss: 0.6208722722675267\n",
            "Epoch: 350. Loss: 0.6207078726903817\n",
            "Epoch: 360. Loss: 0.6205581005255635\n",
            "Epoch: 370. Loss: 0.6204216735614221\n",
            "Epoch: 380. Loss: 0.6202974204626502\n",
            "Epoch: 390. Loss: 0.6201842710199088\n",
            "Epoch: 400. Loss: 0.6200812474108542\n",
            "Epoch: 410. Loss: 0.6199874563022774\n",
            "Epoch: 420. Loss: 0.6199020816710564\n",
            "Epoch: 430. Loss: 0.6198243782531244\n",
            "Epoch: 440. Loss: 0.6197536655504841\n",
            "Epoch: 450. Loss: 0.6196893223402924\n",
            "Epoch: 460. Loss: 0.6196307816396006\n",
            "Epoch: 470. Loss: 0.6195775260860771\n",
            "Epoch: 480. Loss: 0.6195290836999343\n",
            "Epoch: 490. Loss: 0.6194850239960208\n",
            "tensor(0.5770, dtype=torch.float64)\n",
            "2022-08-07 00:00:00\n",
            "Epoch: 0. Loss: 4.70432946512677\n",
            "Epoch: 10. Loss: 2.5989000906062625\n",
            "Epoch: 20. Loss: 1.2355622868566214\n",
            "Epoch: 30. Loss: 0.6715325413596199\n",
            "Epoch: 40. Loss: 0.6277843069595264\n",
            "Epoch: 50. Loss: 0.6239207202273072\n",
            "Epoch: 60. Loss: 0.6217795366534895\n",
            "Epoch: 70. Loss: 0.6204351503212842\n",
            "Epoch: 80. Loss: 0.619538906847382\n",
            "Epoch: 90. Loss: 0.618912735401451\n",
            "Epoch: 100. Loss: 0.6184567700742941\n",
            "Epoch: 110. Loss: 0.6181117245960256\n",
            "Epoch: 120. Loss: 0.6178411938916784\n",
            "Epoch: 130. Loss: 0.617622310593598\n",
            "Epoch: 140. Loss: 0.6174404354571811\n",
            "Epoch: 150. Loss: 0.617286013743648\n",
            "Epoch: 160. Loss: 0.6171526717694148\n",
            "Epoch: 170. Loss: 0.6170360489391776\n",
            "Epoch: 180. Loss: 0.6169330744482181\n",
            "Epoch: 190. Loss: 0.6168415159270453\n",
            "Epoch: 200. Loss: 0.616759695687135\n",
            "Epoch: 210. Loss: 0.6166863108830724\n",
            "Epoch: 220. Loss: 0.6166203184463807\n",
            "Epoch: 230. Loss: 0.6165608606010786\n",
            "Epoch: 240. Loss: 0.6165072159459025\n",
            "Epoch: 250. Loss: 0.6164587667459429\n",
            "Epoch: 260. Loss: 0.6164149765799883\n",
            "Epoch: 270. Loss: 0.6163753746671071\n",
            "Epoch: 280. Loss: 0.6163395445533548\n",
            "Epoch: 290. Loss: 0.6163071156881992\n",
            "Epoch: 300. Loss: 0.6162777569525226\n",
            "Epoch: 310. Loss: 0.6162511715348966\n",
            "Epoch: 320. Loss: 0.6162270927642247\n",
            "Epoch: 330. Loss: 0.616205280640863\n",
            "Epoch: 340. Loss: 0.6161855188937492\n",
            "Epoch: 350. Loss: 0.6161676124458624\n",
            "Epoch: 360. Loss: 0.6161513852057973\n",
            "Epoch: 370. Loss: 0.6161366781264347\n",
            "Epoch: 380. Loss: 0.6161233474870874\n",
            "Epoch: 390. Loss: 0.6161112633658916\n",
            "Epoch: 400. Loss: 0.6161003082763915\n",
            "Epoch: 410. Loss: 0.6160903759473279\n",
            "Epoch: 420. Loss: 0.6160813702283375\n",
            "Epoch: 430. Loss: 0.6160732041070199\n",
            "Epoch: 440. Loss: 0.6160657988249584\n",
            "Epoch: 450. Loss: 0.6160590830819662\n",
            "Epoch: 460. Loss: 0.616052992319192\n",
            "Epoch: 470. Loss: 0.6160474680728544\n",
            "Epoch: 480. Loss: 0.6160424573913321\n",
            "Epoch: 490. Loss: 0.6160379123091545\n",
            "tensor(0.7353, dtype=torch.float64)\n",
            "2022-08-14 00:00:00\n",
            "Epoch: 0. Loss: 6.567699016304897\n",
            "Epoch: 10. Loss: 1.1732207147018698\n",
            "Epoch: 20. Loss: 0.6263516134160895\n",
            "Epoch: 30. Loss: 0.6171587740950233\n",
            "Epoch: 40. Loss: 0.6145822160275908\n",
            "Epoch: 50. Loss: 0.6131182281921597\n",
            "Epoch: 60. Loss: 0.6122113890634961\n",
            "Epoch: 70. Loss: 0.6116317133502748\n",
            "Epoch: 80. Loss: 0.6112567355595605\n",
            "Epoch: 90. Loss: 0.6110131008083955\n",
            "Epoch: 100. Loss: 0.6108544690835893\n",
            "Epoch: 110. Loss: 0.6107509727788121\n",
            "Epoch: 120. Loss: 0.6106832456388355\n",
            "Epoch: 130. Loss: 0.6106387210376155\n",
            "Epoch: 140. Loss: 0.6106092516772785\n",
            "Epoch: 150. Loss: 0.6105895613536385\n",
            "Epoch: 160. Loss: 0.6105762361557303\n",
            "Epoch: 170. Loss: 0.6105670680931151\n",
            "Epoch: 180. Loss: 0.6105606289574187\n",
            "Epoch: 190. Loss: 0.6105559942342171\n",
            "Epoch: 200. Loss: 0.6105525645422875\n",
            "Epoch: 210. Loss: 0.6105499503086163\n",
            "Epoch: 220. Loss: 0.6105478973628493\n",
            "Epoch: 230. Loss: 0.6105462389681728\n",
            "Epoch: 240. Loss: 0.6105448649103518\n",
            "Epoch: 250. Loss: 0.610543701582944\n",
            "Epoch: 260. Loss: 0.6105426991558303\n",
            "Epoch: 270. Loss: 0.6105418233041743\n",
            "Epoch: 280. Loss: 0.6105410498725631\n",
            "Epoch: 290. Loss: 0.6105403614280235\n",
            "Epoch: 300. Loss: 0.6105397450286719\n",
            "Epoch: 310. Loss: 0.6105391907749549\n",
            "Epoch: 320. Loss: 0.6105386908650046\n",
            "Epoch: 330. Loss: 0.610538238975045\n",
            "Epoch: 340. Loss: 0.6105378298497044\n",
            "Epoch: 350. Loss: 0.610537459028175\n",
            "Epoch: 360. Loss: 0.6105371226585649\n",
            "Epoch: 370. Loss: 0.6105368173697573\n",
            "Epoch: 380. Loss: 0.6105365401809955\n",
            "Epoch: 390. Loss: 0.6105362884364232\n",
            "Epoch: 400. Loss: 0.6105360597563151\n",
            "Epoch: 410. Loss: 0.6105358519996312\n",
            "Epoch: 420. Loss: 0.6105356632343979\n",
            "Epoch: 430. Loss: 0.6105354917136173\n",
            "Epoch: 440. Loss: 0.6105353358551869\n",
            "Epoch: 450. Loss: 0.6105351942248115\n",
            "Epoch: 460. Loss: 0.610535065521218\n",
            "Epoch: 470. Loss: 0.6105349485631927\n",
            "Epoch: 480. Loss: 0.6105348422781077\n",
            "Epoch: 490. Loss: 0.6105347456916845\n",
            "tensor(0.6458, dtype=torch.float64)\n",
            "2022-08-21 00:00:00\n",
            "Epoch: 0. Loss: 1.686674460535367\n",
            "Epoch: 10. Loss: 1.1139625143206118\n",
            "Epoch: 20. Loss: 0.9158626736866826\n",
            "Epoch: 30. Loss: 0.8399423454306919\n",
            "Epoch: 40. Loss: 0.7916456057324083\n",
            "Epoch: 50. Loss: 0.7569047473980853\n",
            "Epoch: 60. Loss: 0.731159919297797\n",
            "Epoch: 70. Loss: 0.7117392844230769\n",
            "Epoch: 80. Loss: 0.6968710125467169\n",
            "Epoch: 90. Loss: 0.685312544475345\n",
            "Epoch: 100. Loss: 0.6761703506823085\n",
            "Epoch: 110. Loss: 0.6687996035116108\n",
            "Epoch: 120. Loss: 0.6627373105402573\n",
            "Epoch: 130. Loss: 0.6576529862100219\n",
            "Epoch: 140. Loss: 0.653311518415913\n",
            "Epoch: 150. Loss: 0.649545592212286\n",
            "Epoch: 160. Loss: 0.6462356196467633\n",
            "Epoch: 170. Loss: 0.6432953886472342\n",
            "Epoch: 180. Loss: 0.640661939051426\n",
            "Epoch: 190. Loss: 0.6382884908491079\n",
            "Epoch: 200. Loss: 0.6361395397499775\n",
            "Epoch: 210. Loss: 0.6341874736913614\n",
            "Epoch: 220. Loss: 0.6324102476230548\n",
            "Epoch: 230. Loss: 0.6307897898812509\n",
            "Epoch: 240. Loss: 0.6293109116271232\n",
            "Epoch: 250. Loss: 0.6279605605850878\n",
            "Epoch: 260. Loss: 0.6267273093825492\n",
            "Epoch: 270. Loss: 0.6256010030607698\n",
            "Epoch: 280. Loss: 0.624572514131197\n",
            "Epoch: 290. Loss: 0.6236335700135217\n",
            "Epoch: 300. Loss: 0.622776629027751\n",
            "Epoch: 310. Loss: 0.6219947888849927\n",
            "Epoch: 320. Loss: 0.6212817169258624\n",
            "Epoch: 330. Loss: 0.6206315949564728\n",
            "Epoch: 340. Loss: 0.6200390739624531\n",
            "Epoch: 350. Loss: 0.6194992356109276\n",
            "Epoch: 360. Loss: 0.6190075585344869\n",
            "Epoch: 370. Loss: 0.6185598881060038\n",
            "Epoch: 380. Loss: 0.6181524088795337\n",
            "Epoch: 390. Loss: 0.6177816191730208\n",
            "Epoch: 400. Loss: 0.6174443074591743\n",
            "Epoch: 410. Loss: 0.6171375303495551\n",
            "Epoch: 420. Loss: 0.6168585920290124\n",
            "Epoch: 430. Loss: 0.6166050250400655\n",
            "Epoch: 440. Loss: 0.6163745723407434\n",
            "Epoch: 450. Loss: 0.6161651705720954\n",
            "Epoch: 460. Loss: 0.6159749344777113\n",
            "Epoch: 470. Loss: 0.6158021424201098\n",
            "Epoch: 480. Loss: 0.6156452229395892\n",
            "Epoch: 490. Loss: 0.6155027423011817\n",
            "tensor(0.6127, dtype=torch.float64)\n",
            "2022-08-28 00:00:00\n",
            "Epoch: 0. Loss: 2.8907783436833063\n",
            "Epoch: 10. Loss: 0.6738242719120391\n",
            "Epoch: 20. Loss: 0.6294436102937198\n",
            "Epoch: 30. Loss: 0.6259267216712747\n",
            "Epoch: 40. Loss: 0.6243322129310439\n",
            "Epoch: 50. Loss: 0.6232185548757714\n",
            "Epoch: 60. Loss: 0.6223150673002156\n",
            "Epoch: 70. Loss: 0.6215419026602323\n",
            "Epoch: 80. Loss: 0.6208678028295053\n",
            "Epoch: 90. Loss: 0.6202756510185479\n",
            "Epoch: 100. Loss: 0.6197534337112465\n",
            "Epoch: 110. Loss: 0.6192916519238663\n",
            "Epoch: 120. Loss: 0.6188824339531099\n",
            "Epoch: 130. Loss: 0.6185191308022198\n",
            "Epoch: 140. Loss: 0.6181960719990274\n",
            "Epoch: 150. Loss: 0.6179083908584396\n",
            "Epoch: 160. Loss: 0.6176518894971815\n",
            "Epoch: 170. Loss: 0.6174229311576239\n",
            "Epoch: 180. Loss: 0.6172183529786041\n",
            "Epoch: 190. Loss: 0.617035394645156\n",
            "Epoch: 200. Loss: 0.6168716395824281\n",
            "Epoch: 210. Loss: 0.6167249661609533\n",
            "Epoch: 220. Loss: 0.6165935069542662\n",
            "Epoch: 230. Loss: 0.6164756145180983\n",
            "Epoch: 240. Loss: 0.6163698324860647\n",
            "Epoch: 250. Loss: 0.6162748710270293\n",
            "Epoch: 260. Loss: 0.6161895859029626\n",
            "Epoch: 270. Loss: 0.6161129605168008\n",
            "Epoch: 280. Loss: 0.6160440904577216\n",
            "Epoch: 290. Loss: 0.6159821701439868\n",
            "Epoch: 300. Loss: 0.6159264812368404\n",
            "Epoch: 310. Loss: 0.6158763825572604\n",
            "Epoch: 320. Loss: 0.6158313012839755\n",
            "Epoch: 330. Loss: 0.6157907252486446\n",
            "Epoch: 340. Loss: 0.6157541961744039\n",
            "Epoch: 350. Loss: 0.6157213037286221\n",
            "Epoch: 360. Loss: 0.6156916802808712\n",
            "Epoch: 370. Loss: 0.6156649962736817\n",
            "Epoch: 380. Loss: 0.6156409561273569\n",
            "Epoch: 390. Loss: 0.6156192946115157\n",
            "Epoch: 400. Loss: 0.6155997736255346\n",
            "Epoch: 410. Loss: 0.615582179338068\n",
            "Epoch: 420. Loss: 0.6155663196425419\n",
            "Epoch: 430. Loss: 0.615552021891246\n",
            "Epoch: 440. Loss: 0.6155391308754927\n",
            "Epoch: 450. Loss: 0.6155275070234687\n",
            "Epoch: 460. Loss: 0.6155170247909628\n",
            "Epoch: 470. Loss: 0.6155075712232135\n",
            "Epoch: 480. Loss: 0.6154990446687664\n",
            "Epoch: 490. Loss: 0.6154913536285199\n",
            "tensor(0.4910, dtype=torch.float64)\n",
            "2022-09-04 00:00:00\n",
            "Epoch: 0. Loss: 3.1973400784884345\n",
            "Epoch: 10. Loss: 1.043274516896615\n",
            "Epoch: 20. Loss: 0.6977671583516442\n",
            "Epoch: 30. Loss: 0.662211685782886\n",
            "Epoch: 40. Loss: 0.6448359323280312\n",
            "Epoch: 50. Loss: 0.6350888318524548\n",
            "Epoch: 60. Loss: 0.6294387593128612\n",
            "Epoch: 70. Loss: 0.6260081814887469\n",
            "Epoch: 80. Loss: 0.6238095225171117\n",
            "Epoch: 90. Loss: 0.6223173433774136\n",
            "Epoch: 100. Loss: 0.6212458095940478\n",
            "Epoch: 110. Loss: 0.6204354539741882\n",
            "Epoch: 120. Loss: 0.6197949299594816\n",
            "Epoch: 130. Loss: 0.6192704206138545\n",
            "Epoch: 140. Loss: 0.6188292179771614\n",
            "Epoch: 150. Loss: 0.6184507301531612\n",
            "Epoch: 160. Loss: 0.6181214668201179\n",
            "Epoch: 170. Loss: 0.6178321967550807\n",
            "Epoch: 180. Loss: 0.6175763110654633\n",
            "Epoch: 190. Loss: 0.6173488655875266\n",
            "Epoch: 200. Loss: 0.6171460109401284\n",
            "Epoch: 210. Loss: 0.6169646466091671\n",
            "Epoch: 220. Loss: 0.6168022061100259\n",
            "Epoch: 230. Loss: 0.6166565198517467\n",
            "Epoch: 240. Loss: 0.6165257247448679\n",
            "Epoch: 250. Loss: 0.6164082024211229\n",
            "Epoch: 260. Loss: 0.6163025353368761\n",
            "Epoch: 270. Loss: 0.6162074743407362\n",
            "Epoch: 280. Loss: 0.6161219138129024\n",
            "Epoch: 290. Loss: 0.616044871977998\n",
            "Epoch: 300. Loss: 0.6159754748844332\n",
            "Epoch: 310. Loss: 0.6159129430804487\n",
            "Epoch: 320. Loss: 0.6158565803446986\n",
            "Epoch: 330. Loss: 0.6158057640322689\n",
            "Epoch: 340. Loss: 0.6157599367252399\n",
            "Epoch: 350. Loss: 0.6157185989597642\n",
            "Epoch: 360. Loss: 0.6156813028566949\n",
            "Epoch: 370. Loss: 0.6156476465205165\n",
            "Epoch: 380. Loss: 0.6156172690980767\n",
            "Epoch: 390. Loss: 0.6155898464082062\n",
            "Epoch: 400. Loss: 0.6155650870681433\n",
            "Epoch: 410. Loss: 0.6155427290542299\n",
            "Epoch: 420. Loss: 0.6155225366435635\n",
            "Epoch: 430. Loss: 0.6155042976908002\n",
            "Epoch: 440. Loss: 0.6154878212005201\n",
            "Epoch: 450. Loss: 0.6154729351607753\n",
            "Epoch: 460. Loss: 0.6154594846078555\n",
            "Epoch: 470. Loss: 0.6154473298960657\n",
            "Epoch: 480. Loss: 0.6154363451495404\n",
            "Epoch: 490. Loss: 0.6154264168759032\n",
            "tensor(0.4596, dtype=torch.float64)\n",
            "2022-09-11 00:00:00\n",
            "Epoch: 0. Loss: 3.1926645811325716\n",
            "Epoch: 10. Loss: 0.9152272655286199\n",
            "Epoch: 20. Loss: 0.6765824175878606\n",
            "Epoch: 30. Loss: 0.6508518570516131\n",
            "Epoch: 40. Loss: 0.6421728638952684\n",
            "Epoch: 50. Loss: 0.6379200868421909\n",
            "Epoch: 60. Loss: 0.6351794165491267\n",
            "Epoch: 70. Loss: 0.6331166805320224\n",
            "Epoch: 80. Loss: 0.6314477300186593\n",
            "Epoch: 90. Loss: 0.6300506302241354\n",
            "Epoch: 100. Loss: 0.6288595400003418\n",
            "Epoch: 110. Loss: 0.6278324364189658\n",
            "Epoch: 120. Loss: 0.6269396618149641\n",
            "Epoch: 130. Loss: 0.6261590109398514\n",
            "Epoch: 140. Loss: 0.625473217624457\n",
            "Epoch: 150. Loss: 0.6248684937710851\n",
            "Epoch: 160. Loss: 0.6243336066578848\n",
            "Epoch: 170. Loss: 0.623859262641961\n",
            "Epoch: 180. Loss: 0.6234376777534315\n",
            "Epoch: 190. Loss: 0.623062267968477\n",
            "Epoch: 200. Loss: 0.6227274191776028\n",
            "Epoch: 210. Loss: 0.6224283120726545\n",
            "Epoch: 220. Loss: 0.6221607860572343\n",
            "Epoch: 230. Loss: 0.621921231648216\n",
            "Epoch: 240. Loss: 0.6217065041733322\n",
            "Epoch: 250. Loss: 0.6215138537086973\n",
            "Epoch: 260. Loss: 0.621340867611773\n",
            "Epoch: 270. Loss: 0.6211854229638134\n",
            "Epoch: 280. Loss: 0.6210456469041673\n",
            "Epoch: 290. Loss: 0.6209198833161073\n",
            "Epoch: 300. Loss: 0.6208066646718903\n",
            "Epoch: 310. Loss: 0.6207046881031769\n",
            "Epoch: 320. Loss: 0.6206127949577718\n",
            "Epoch: 330. Loss: 0.6205299532524672\n",
            "Epoch: 340. Loss: 0.6204552425467689\n",
            "Epoch: 350. Loss: 0.6203878408519723\n",
            "Epoch: 360. Loss: 0.6203270132606747\n",
            "Epoch: 370. Loss: 0.6202721020378062\n",
            "Epoch: 380. Loss: 0.6202225179590167\n",
            "Epoch: 390. Loss: 0.6201777327182607\n",
            "Epoch: 400. Loss: 0.6201372722555588\n",
            "Epoch: 410. Loss: 0.6201007108796659\n",
            "Epoch: 420. Loss: 0.6200676660798062\n",
            "Epoch: 430. Loss: 0.6200377939366676\n",
            "Epoch: 440. Loss: 0.6200107850561063\n",
            "Epoch: 450. Loss: 0.6199863609600469\n",
            "Epoch: 460. Loss: 0.6199642708783084\n",
            "Epoch: 470. Loss: 0.6199442888928315\n",
            "Epoch: 480. Loss: 0.6199262113923398\n",
            "Epoch: 490. Loss: 0.6199098548010133\n",
            "tensor(0.5991, dtype=torch.float64)\n",
            "2022-09-18 00:00:00\n",
            "Epoch: 0. Loss: 2.499812931938956\n",
            "Epoch: 10. Loss: 1.3498511474975792\n",
            "Epoch: 20. Loss: 0.8776073226426403\n",
            "Epoch: 30. Loss: 0.7725309492830619\n",
            "Epoch: 40. Loss: 0.7096292187354225\n",
            "Epoch: 50. Loss: 0.6701696797825131\n",
            "Epoch: 60. Loss: 0.6466309543106885\n",
            "Epoch: 70. Loss: 0.6329707731683204\n",
            "Epoch: 80. Loss: 0.6251223330461398\n",
            "Epoch: 90. Loss: 0.6206139594991744\n",
            "Epoch: 100. Loss: 0.6180116039600801\n",
            "Epoch: 110. Loss: 0.6164979741604273\n",
            "Epoch: 120. Loss: 0.615609078855097\n",
            "Epoch: 130. Loss: 0.6150808279490668\n",
            "Epoch: 140. Loss: 0.6147621359566439\n",
            "Epoch: 150. Loss: 0.6145660614620672\n",
            "Epoch: 160. Loss: 0.6144422874379074\n",
            "Epoch: 170. Loss: 0.6143615364605277\n",
            "Epoch: 180. Loss: 0.6143066862713191\n",
            "Epoch: 190. Loss: 0.6142676720068275\n",
            "Epoch: 200. Loss: 0.6142385440749859\n",
            "Epoch: 210. Loss: 0.6142157616628224\n",
            "Epoch: 220. Loss: 0.6141971988230311\n",
            "Epoch: 230. Loss: 0.6141815636039824\n",
            "Epoch: 240. Loss: 0.6141680576037195\n",
            "Epoch: 250. Loss: 0.6141561759429252\n",
            "Epoch: 260. Loss: 0.6141455894707419\n",
            "Epoch: 270. Loss: 0.6141360752325205\n",
            "Epoch: 280. Loss: 0.6141274753124807\n",
            "Epoch: 290. Loss: 0.6141196723845918\n",
            "Epoch: 300. Loss: 0.614112575116157\n",
            "Epoch: 310. Loss: 0.6141061093905125\n",
            "Epoch: 320. Loss: 0.6141002129731045\n",
            "Epoch: 330. Loss: 0.614094832220394\n",
            "Epoch: 340. Loss: 0.6140899200052066\n",
            "Epoch: 350. Loss: 0.6140854343704345\n",
            "Epoch: 360. Loss: 0.614081337622442\n",
            "Epoch: 370. Loss: 0.6140775956931545\n",
            "Epoch: 380. Loss: 0.6140741776692301\n",
            "Epoch: 390. Loss: 0.6140710554277005\n",
            "Epoch: 400. Loss: 0.6140682033416944\n",
            "Epoch: 410. Loss: 0.6140655980341895\n",
            "Epoch: 420. Loss: 0.6140632181662343\n",
            "Epoch: 430. Loss: 0.6140610442511414\n",
            "Epoch: 440. Loss: 0.6140590584891654\n",
            "Epoch: 450. Loss: 0.6140572446190049\n",
            "Epoch: 460. Loss: 0.6140555877835683\n",
            "Epoch: 470. Loss: 0.6140540744081302\n",
            "Epoch: 480. Loss: 0.6140526920894411\n",
            "Epoch: 490. Loss: 0.6140514294946283\n",
            "tensor(0.5198, dtype=torch.float64)\n",
            "2022-09-25 00:00:00\n",
            "Epoch: 0. Loss: 1.8372059666972593\n",
            "Epoch: 10. Loss: 0.7429951299761198\n",
            "Epoch: 20. Loss: 0.6653428419965179\n",
            "Epoch: 30. Loss: 0.6442835345763532\n",
            "Epoch: 40. Loss: 0.6380663852679447\n",
            "Epoch: 50. Loss: 0.6354569305385142\n",
            "Epoch: 60. Loss: 0.633805545874518\n",
            "Epoch: 70. Loss: 0.6324771484180415\n",
            "Epoch: 80. Loss: 0.6313070157717917\n",
            "Epoch: 90. Loss: 0.6302459269347148\n",
            "Epoch: 100. Loss: 0.6292747545726965\n",
            "Epoch: 110. Loss: 0.6283830108856218\n",
            "Epoch: 120. Loss: 0.6275631823544967\n",
            "Epoch: 130. Loss: 0.6268090977683571\n",
            "Epoch: 140. Loss: 0.6261153788197592\n",
            "Epoch: 150. Loss: 0.6254772098516364\n",
            "Epoch: 160. Loss: 0.624890218083722\n",
            "Epoch: 170. Loss: 0.6243504007567502\n",
            "Epoch: 180. Loss: 0.6238540761243663\n",
            "Epoch: 190. Loss: 0.6233978480429243\n",
            "Epoch: 200. Loss: 0.6229785788203972\n",
            "Epoch: 210. Loss: 0.622593367280995\n",
            "Epoch: 220. Loss: 0.622239530238153\n",
            "Epoch: 230. Loss: 0.6219145862852968\n",
            "Epoch: 240. Loss: 0.6216162412422702\n",
            "Epoch: 250. Loss: 0.6213423748537944\n",
            "Epoch: 260. Loss: 0.621091028492087\n",
            "Epoch: 270. Loss: 0.6208603937090625\n",
            "Epoch: 280. Loss: 0.6206488015388927\n",
            "Epoch: 290. Loss: 0.6204547124841192\n",
            "Epoch: 300. Loss: 0.6202767071371984\n",
            "Epoch: 310. Loss: 0.6201134773998938\n",
            "Epoch: 320. Loss: 0.619963818268761\n",
            "Epoch: 330. Loss: 0.6198266201580863\n",
            "Epoch: 340. Loss: 0.619700861733316\n",
            "Epoch: 350. Loss: 0.6195856032289324\n",
            "Epoch: 360. Loss: 0.6194799802253196\n",
            "Epoch: 370. Loss: 0.6193831978596482\n",
            "Epoch: 380. Loss: 0.6192945254463055\n",
            "Epoch: 390. Loss: 0.619213291482964\n",
            "Epoch: 400. Loss: 0.6191388790190456\n",
            "Epoch: 410. Loss: 0.6190707213640804\n",
            "Epoch: 420. Loss: 0.6190082981142856\n",
            "Epoch: 430. Loss: 0.6189511314765762\n",
            "Epoch: 440. Loss: 0.6188987828701509\n",
            "Epoch: 450. Loss: 0.6188508497867556\n",
            "Epoch: 460. Loss: 0.6188069628916992\n",
            "Epoch: 470. Loss: 0.6187667833486745\n",
            "Epoch: 480. Loss: 0.6187300003524024\n",
            "Epoch: 490. Loss: 0.6186963288540615\n",
            "tensor(0.5433, dtype=torch.float64)\n",
            "2022-10-02 00:00:00\n",
            "Epoch: 0. Loss: 4.000611912237468\n",
            "Epoch: 10. Loss: 1.1753657203576162\n",
            "Epoch: 20. Loss: 0.6968965127881209\n",
            "Epoch: 30. Loss: 0.6532942790915063\n",
            "Epoch: 40. Loss: 0.6370191169374964\n",
            "Epoch: 50. Loss: 0.6292873455993562\n",
            "Epoch: 60. Loss: 0.6252604886282093\n",
            "Epoch: 70. Loss: 0.6230693172047921\n",
            "Epoch: 80. Loss: 0.6218485182251522\n",
            "Epoch: 90. Loss: 0.6211569367263652\n",
            "Epoch: 100. Loss: 0.620759051073017\n",
            "Epoch: 110. Loss: 0.6205261092678\n",
            "Epoch: 120. Loss: 0.620386718202965\n",
            "Epoch: 130. Loss: 0.6203008948136831\n",
            "Epoch: 140. Loss: 0.6202460722662978\n",
            "Epoch: 150. Loss: 0.6202094285659706\n",
            "Epoch: 160. Loss: 0.6201836325938417\n",
            "Epoch: 170. Loss: 0.6201644647335698\n",
            "Epoch: 180. Loss: 0.6201494770277681\n",
            "Epoch: 190. Loss: 0.6201372346629381\n",
            "Epoch: 200. Loss: 0.62012688470519\n",
            "Epoch: 210. Loss: 0.6201179100240807\n",
            "Epoch: 220. Loss: 0.6201099884487786\n",
            "Epoch: 230. Loss: 0.6201029119207854\n",
            "Epoch: 240. Loss: 0.620096539945113\n",
            "Epoch: 250. Loss: 0.6200907726934902\n",
            "Epoch: 260. Loss: 0.6200855353904396\n",
            "Epoch: 270. Loss: 0.6200807691900841\n",
            "Epoch: 280. Loss: 0.6200764257950556\n",
            "Epoch: 290. Loss: 0.6200724642386709\n",
            "Epoch: 300. Loss: 0.6200688489222538\n",
            "Epoch: 310. Loss: 0.6200655483845349\n",
            "Epoch: 320. Loss: 0.620062534501363\n",
            "Epoch: 330. Loss: 0.6200597819412752\n",
            "Epoch: 340. Loss: 0.6200572677757734\n",
            "Epoch: 350. Loss: 0.6200549711854085\n",
            "Epoch: 360. Loss: 0.6200528732271595\n",
            "Epoch: 370. Loss: 0.6200509566426831\n",
            "Epoch: 380. Loss: 0.6200492056951795\n",
            "Epoch: 390. Loss: 0.6200476060273634\n",
            "Epoch: 400. Loss: 0.6200461445358098\n",
            "Epoch: 410. Loss: 0.6200448092585698\n",
            "Epoch: 420. Loss: 0.6200435892739385\n",
            "Epoch: 430. Loss: 0.6200424746088372\n",
            "Epoch: 440. Loss: 0.6200414561556471\n",
            "Epoch: 450. Loss: 0.6200405255965701\n",
            "Epoch: 460. Loss: 0.6200396753347448\n",
            "Epoch: 470. Loss: 0.6200388984314648\n",
            "Epoch: 480. Loss: 0.6200381885489288\n",
            "Epoch: 490. Loss: 0.6200375398980129\n",
            "tensor(0.6457, dtype=torch.float64)\n",
            "2022-10-09 00:00:00\n",
            "Epoch: 0. Loss: 4.136490985198562\n",
            "Epoch: 10. Loss: 1.3345773178490103\n",
            "Epoch: 20. Loss: 0.727344934576046\n",
            "Epoch: 30. Loss: 0.6779983818118124\n",
            "Epoch: 40. Loss: 0.6628060891279878\n",
            "Epoch: 50. Loss: 0.6552696292670831\n",
            "Epoch: 60. Loss: 0.6505102284224917\n",
            "Epoch: 70. Loss: 0.6470506874080236\n",
            "Epoch: 80. Loss: 0.644340309981881\n",
            "Epoch: 90. Loss: 0.6421262882090091\n",
            "Epoch: 100. Loss: 0.6402713482206116\n",
            "Epoch: 110. Loss: 0.6386916219100358\n",
            "Epoch: 120. Loss: 0.6373313285406165\n",
            "Epoch: 130. Loss: 0.6361508403785611\n",
            "Epoch: 140. Loss: 0.6351204989467152\n",
            "Epoch: 150. Loss: 0.6342172045904129\n",
            "Epoch: 160. Loss: 0.6334224338350448\n",
            "Epoch: 170. Loss: 0.6327210219797903\n",
            "Epoch: 180. Loss: 0.6321003708192451\n",
            "Epoch: 190. Loss: 0.6315499027976069\n",
            "Epoch: 200. Loss: 0.6310606656038037\n",
            "Epoch: 210. Loss: 0.6306250340588654\n",
            "Epoch: 220. Loss: 0.630236478602344\n",
            "Epoch: 230. Loss: 0.6298893816867553\n",
            "Epoch: 240. Loss: 0.6295788900087371\n",
            "Epoch: 250. Loss: 0.6293007943233423\n",
            "Epoch: 260. Loss: 0.6290514309154221\n",
            "Epoch: 270. Loss: 0.6288276003094249\n",
            "Epoch: 280. Loss: 0.6286264998327032\n",
            "Epoch: 290. Loss: 0.6284456673912234\n",
            "Epoch: 300. Loss: 0.6282829343714476\n",
            "Epoch: 310. Loss: 0.6281363860066373\n",
            "Epoch: 320. Loss: 0.6280043278759958\n",
            "Epoch: 330. Loss: 0.6278852574646424\n",
            "Epoch: 340. Loss: 0.6277778399179245\n",
            "Epoch: 350. Loss: 0.627680887287036\n",
            "Epoch: 360. Loss: 0.6275933406934265\n",
            "Epoch: 370. Loss: 0.6275142549439939\n",
            "Epoch: 380. Loss: 0.6274427852129764\n",
            "Epoch: 390. Loss: 0.6273781754740775\n",
            "Epoch: 400. Loss: 0.6273197484209654\n",
            "Epoch: 410. Loss: 0.6272668966585785\n",
            "Epoch: 420. Loss: 0.6272190749836855\n",
            "Epoch: 430. Loss: 0.6271757936025598\n",
            "Epoch: 440. Loss: 0.627136612157742\n",
            "Epoch: 450. Loss: 0.6271011344556944\n",
            "Epoch: 460. Loss: 0.6270690038035632\n",
            "Epoch: 470. Loss: 0.6270398988768416\n",
            "Epoch: 480. Loss: 0.627013530051088\n",
            "Epoch: 490. Loss: 0.626989636140316\n",
            "tensor(0.4478, dtype=torch.float64)\n",
            "2022-10-16 00:00:00\n",
            "Epoch: 0. Loss: 1.3732169524315767\n",
            "Epoch: 10. Loss: 0.7430663232341265\n",
            "Epoch: 20. Loss: 0.6692041310545243\n",
            "Epoch: 30. Loss: 0.6468210953572131\n",
            "Epoch: 40. Loss: 0.6388967229293161\n",
            "Epoch: 50. Loss: 0.6357253537752432\n",
            "Epoch: 60. Loss: 0.6342615617741049\n",
            "Epoch: 70. Loss: 0.6335228748769239\n",
            "Epoch: 80. Loss: 0.6331321909933662\n",
            "Epoch: 90. Loss: 0.6329195125669015\n",
            "Epoch: 100. Loss: 0.6328007293949381\n",
            "Epoch: 110. Loss: 0.6327323280239076\n",
            "Epoch: 120. Loss: 0.6326913152241003\n",
            "Epoch: 130. Loss: 0.6326654017285909\n",
            "Epoch: 140. Loss: 0.6326479683889841\n",
            "Epoch: 150. Loss: 0.6326354251850456\n",
            "Epoch: 160. Loss: 0.6326258091955489\n",
            "Epoch: 170. Loss: 0.6326180352034132\n",
            "Epoch: 180. Loss: 0.6326114933663334\n",
            "Epoch: 190. Loss: 0.632605832531277\n",
            "Epoch: 200. Loss: 0.6326008432331209\n",
            "Epoch: 210. Loss: 0.6325963943654481\n",
            "Epoch: 220. Loss: 0.632592398807707\n",
            "Epoch: 230. Loss: 0.6325887946995123\n",
            "Epoch: 240. Loss: 0.6325855351824932\n",
            "Epoch: 250. Loss: 0.6325825827316546\n",
            "Epoch: 260. Loss: 0.6325799059794697\n",
            "Epoch: 270. Loss: 0.6325774778980272\n",
            "Epoch: 280. Loss: 0.6325752747246831\n",
            "Epoch: 290. Loss: 0.6325732752979957\n",
            "Epoch: 300. Loss: 0.6325714606229742\n",
            "Epoch: 310. Loss: 0.632569813567099\n",
            "Epoch: 320. Loss: 0.6325683186332216\n",
            "Epoch: 330. Loss: 0.6325669617796573\n",
            "Epoch: 340. Loss: 0.6325657302709248\n",
            "Epoch: 350. Loss: 0.6325646125497337\n",
            "Epoch: 360. Loss: 0.6325635981247262\n",
            "Epoch: 370. Loss: 0.632562677470625\n",
            "Epoch: 380. Loss: 0.63256184193863\n",
            "Epoch: 390. Loss: 0.6325610836755864\n",
            "Epoch: 400. Loss: 0.6325603955508322\n",
            "Epoch: 410. Loss: 0.6325597710898729\n",
            "Epoch: 420. Loss: 0.6325592044141856\n",
            "Epoch: 430. Loss: 0.63255869018655\n",
            "Epoch: 440. Loss: 0.6325582235613871\n",
            "Epoch: 450. Loss: 0.6325578001396377\n",
            "Epoch: 460. Loss: 0.6325574159277638\n",
            "Epoch: 470. Loss: 0.6325570673004997\n",
            "Epoch: 480. Loss: 0.6325567509670049\n",
            "Epoch: 490. Loss: 0.6325564639401156\n",
            "tensor(0.6709, dtype=torch.float64)\n",
            "2022-10-23 00:00:00\n",
            "Epoch: 0. Loss: 2.5817979023612034\n",
            "Epoch: 10. Loss: 0.8075455647244145\n",
            "Epoch: 20. Loss: 0.6839219666573049\n",
            "Epoch: 30. Loss: 0.6629816930867976\n",
            "Epoch: 40. Loss: 0.655986703564284\n",
            "Epoch: 50. Loss: 0.6532229114292947\n",
            "Epoch: 60. Loss: 0.6516108447629558\n",
            "Epoch: 70. Loss: 0.6503495412547763\n",
            "Epoch: 80. Loss: 0.6492455537966151\n",
            "Epoch: 90. Loss: 0.648248133580015\n",
            "Epoch: 100. Loss: 0.6473391872681945\n",
            "Epoch: 110. Loss: 0.646508734519588\n",
            "Epoch: 120. Loss: 0.6457493638629422\n",
            "Epoch: 130. Loss: 0.6450548398583174\n",
            "Epoch: 140. Loss: 0.644419662421164\n",
            "Epoch: 150. Loss: 0.643838878902616\n",
            "Epoch: 160. Loss: 0.6433079821853672\n",
            "Epoch: 170. Loss: 0.6428228465959643\n",
            "Epoch: 180. Loss: 0.6423796834728271\n",
            "Epoch: 190. Loss: 0.6419750078692587\n",
            "Epoch: 200. Loss: 0.6416056118963746\n",
            "Epoch: 210. Loss: 0.6412685422194825\n",
            "Epoch: 220. Loss: 0.640961080308502\n",
            "Epoch: 230. Loss: 0.6406807246479485\n",
            "Epoch: 240. Loss: 0.6404251744504551\n",
            "Epoch: 250. Loss: 0.640192314606511\n",
            "Epoch: 260. Loss: 0.6399802017074621\n",
            "Epoch: 270. Loss: 0.6397870510359095\n",
            "Epoch: 280. Loss: 0.6396112244484722\n",
            "Epoch: 290. Loss: 0.639451219092287\n",
            "Epoch: 300. Loss: 0.6393056569052834\n",
            "Epoch: 310. Loss: 0.6391732748548902\n",
            "Epoch: 320. Loss: 0.6390529158724471\n",
            "Epoch: 330. Loss: 0.6389435204423021\n",
            "Epoch: 340. Loss: 0.6388441188059555\n",
            "Epoch: 350. Loss: 0.6387538237429162\n",
            "Epoch: 360. Loss: 0.6386718238913301\n",
            "Epoch: 370. Loss: 0.6385973775729056\n",
            "Epoch: 380. Loss: 0.6385298070882502\n",
            "Epoch: 390. Loss: 0.6384684934503684\n",
            "Epoch: 400. Loss: 0.6384128715257721\n",
            "Epoch: 410. Loss: 0.6383624255543489\n",
            "Epoch: 420. Loss: 0.6383166850208355\n",
            "Epoch: 430. Loss: 0.6382752208523962\n",
            "Epoch: 440. Loss: 0.6382376419184219\n",
            "Epoch: 450. Loss: 0.6382035918102121\n",
            "Epoch: 460. Loss: 0.6381727458796864\n",
            "Epoch: 470. Loss: 0.6381448085176762\n",
            "Epoch: 480. Loss: 0.6381195106536824\n",
            "Epoch: 490. Loss: 0.6380966074602397\n",
            "tensor(0.4417, dtype=torch.float64)\n",
            "2022-10-30 00:00:00\n",
            "Epoch: 0. Loss: 4.086543463813472\n",
            "Epoch: 10. Loss: 1.3793951404056908\n",
            "Epoch: 20. Loss: 0.8016846820756462\n",
            "Epoch: 30. Loss: 0.7452208665537815\n",
            "Epoch: 40. Loss: 0.7116767527938578\n",
            "Epoch: 50. Loss: 0.688740865994561\n",
            "Epoch: 60. Loss: 0.67395398973192\n",
            "Epoch: 70. Loss: 0.6648055596482912\n",
            "Epoch: 80. Loss: 0.6591766277054273\n",
            "Epoch: 90. Loss: 0.6556021457996858\n",
            "Epoch: 100. Loss: 0.6531973507659711\n",
            "Epoch: 110. Loss: 0.6514679381401671\n",
            "Epoch: 120. Loss: 0.6501469698710681\n",
            "Epoch: 130. Loss: 0.6490902149418574\n",
            "Epoch: 140. Loss: 0.6482173710864604\n",
            "Epoch: 150. Loss: 0.6474812163646904\n",
            "Epoch: 160. Loss: 0.646851940381525\n",
            "Epoch: 170. Loss: 0.6463092629439461\n",
            "Epoch: 180. Loss: 0.6458384345204219\n",
            "Epoch: 190. Loss: 0.6454281518792335\n",
            "Epoch: 200. Loss: 0.6450694226648077\n",
            "Epoch: 210. Loss: 0.644754908706197\n",
            "Epoch: 220. Loss: 0.6444785187983598\n",
            "Epoch: 230. Loss: 0.6442351377639396\n",
            "Epoch: 240. Loss: 0.6440204345652074\n",
            "Epoch: 250. Loss: 0.6438307194672558\n",
            "Epoch: 260. Loss: 0.6436628337425435\n",
            "Epoch: 270. Loss: 0.6435140622750862\n",
            "Epoch: 280. Loss: 0.6433820630566528\n",
            "Epoch: 290. Loss: 0.6432648095875774\n",
            "Epoch: 300. Loss: 0.6431605433852475\n",
            "Epoch: 310. Loss: 0.6430677345497036\n",
            "Epoch: 320. Loss: 0.6429850488324733\n",
            "Epoch: 330. Loss: 0.6429113200028221\n",
            "Epoch: 340. Loss: 0.6428455265598046\n",
            "Epoch: 350. Loss: 0.6427867720299879\n",
            "Epoch: 360. Loss: 0.6427342682382329\n",
            "Epoch: 370. Loss: 0.64268732105441\n",
            "Epoch: 380. Loss: 0.6426453182103528\n",
            "Epoch: 390. Loss: 0.6426077188543976\n",
            "Epoch: 400. Loss: 0.6425740445695513\n",
            "Epoch: 410. Loss: 0.6425438716287857\n",
            "Epoch: 420. Loss: 0.6425168242994738\n",
            "Epoch: 430. Loss: 0.6424925690403916\n",
            "Epoch: 440. Loss: 0.6424708094604105\n",
            "Epoch: 450. Loss: 0.6424512819291057\n",
            "Epoch: 460. Loss: 0.6424337517469191\n",
            "Epoch: 470. Loss: 0.6424180097968831\n",
            "Epoch: 480. Loss: 0.6424038696118731\n",
            "Epoch: 490. Loss: 0.6423911648012799\n",
            "tensor(0.5634, dtype=torch.float64)\n",
            "2022-11-06 00:00:00\n",
            "Epoch: 0. Loss: 2.789312898147073\n",
            "Epoch: 10. Loss: 1.5209875720886146\n",
            "Epoch: 20. Loss: 1.0625901041978119\n",
            "Epoch: 30. Loss: 0.7843903849784801\n",
            "Epoch: 40. Loss: 0.6855665909497429\n",
            "Epoch: 50. Loss: 0.6619270287914224\n",
            "Epoch: 60. Loss: 0.6551208459271601\n",
            "Epoch: 70. Loss: 0.6524934500485208\n",
            "Epoch: 80. Loss: 0.6513072096341924\n",
            "Epoch: 90. Loss: 0.6507358015317933\n",
            "Epoch: 100. Loss: 0.6504530402763834\n",
            "Epoch: 110. Loss: 0.6503112896611909\n",
            "Epoch: 120. Loss: 0.6502396688620704\n",
            "Epoch: 130. Loss: 0.6502032547086779\n",
            "Epoch: 140. Loss: 0.6501846182451942\n",
            "Epoch: 150. Loss: 0.6501749972137387\n",
            "Epoch: 160. Loss: 0.6501699655764045\n",
            "Epoch: 170. Loss: 0.6501672801093352\n",
            "Epoch: 180. Loss: 0.6501658008750948\n",
            "Epoch: 190. Loss: 0.650164947179873\n",
            "Epoch: 200. Loss: 0.6501644224038512\n",
            "Epoch: 210. Loss: 0.6501640744703238\n",
            "Epoch: 220. Loss: 0.6501638249643839\n",
            "Epoch: 230. Loss: 0.6501636330766035\n",
            "Epoch: 240. Loss: 0.6501634772418311\n",
            "Epoch: 250. Loss: 0.6501633457796844\n",
            "Epoch: 260. Loss: 0.6501632321182558\n",
            "Epoch: 270. Loss: 0.6501631323529549\n",
            "Epoch: 280. Loss: 0.6501630439958348\n",
            "Epoch: 290. Loss: 0.6501629653322692\n",
            "Epoch: 300. Loss: 0.6501628950877852\n",
            "Epoch: 310. Loss: 0.6501628322535205\n",
            "Epoch: 320. Loss: 0.6501627759930203\n",
            "Epoch: 330. Loss: 0.6501627255909299\n",
            "Epoch: 340. Loss: 0.6501626804234271\n",
            "Epoch: 350. Loss: 0.6501626399400878\n",
            "Epoch: 360. Loss: 0.6501626036518914\n",
            "Epoch: 370. Loss: 0.6501625711226378\n",
            "Epoch: 380. Loss: 0.6501625419623553\n",
            "Epoch: 390. Loss: 0.6501625158219521\n",
            "Epoch: 400. Loss: 0.6501624923887043\n",
            "Epoch: 410. Loss: 0.6501624713823551\n",
            "Epoch: 420. Loss: 0.6501624525516896\n",
            "Epoch: 430. Loss: 0.6501624356714992\n",
            "Epoch: 440. Loss: 0.6501624205398783\n",
            "Epoch: 450. Loss: 0.6501624069758084\n",
            "Epoch: 460. Loss: 0.6501623948169971\n",
            "Epoch: 470. Loss: 0.6501623839179416\n",
            "Epoch: 480. Loss: 0.6501623741481919\n",
            "Epoch: 490. Loss: 0.6501623653907967\n",
            "tensor(0.5755, dtype=torch.float64)\n",
            "2022-11-13 00:00:00\n",
            "Epoch: 0. Loss: 3.287635157244301\n",
            "Epoch: 10. Loss: 1.8419445658215041\n",
            "Epoch: 20. Loss: 1.2149414708767763\n",
            "Epoch: 30. Loss: 0.9072650715638582\n",
            "Epoch: 40. Loss: 0.7573104549180171\n",
            "Epoch: 50. Loss: 0.6980591138837835\n",
            "Epoch: 60. Loss: 0.6747306099438496\n",
            "Epoch: 70. Loss: 0.6649957735757591\n",
            "Epoch: 80. Loss: 0.660574179834128\n",
            "Epoch: 90. Loss: 0.6583223705069217\n",
            "Epoch: 100. Loss: 0.6570108247704963\n",
            "Epoch: 110. Loss: 0.6561407298847711\n",
            "Epoch: 120. Loss: 0.6555006571669286\n",
            "Epoch: 130. Loss: 0.6549958941642338\n",
            "Epoch: 140. Loss: 0.6545807982434978\n",
            "Epoch: 150. Loss: 0.6542311872652722\n",
            "Epoch: 160. Loss: 0.6539327429462609\n",
            "Epoch: 170. Loss: 0.6536759936930802\n",
            "Epoch: 180. Loss: 0.6534540681477498\n",
            "Epoch: 190. Loss: 0.6532616429475665\n",
            "Epoch: 200. Loss: 0.6530944180270963\n",
            "Epoch: 210. Loss: 0.6529488321456445\n",
            "Epoch: 220. Loss: 0.6528218925190266\n",
            "Epoch: 230. Loss: 0.6527110620281618\n",
            "Epoch: 240. Loss: 0.6526141779550528\n",
            "Epoch: 250. Loss: 0.6525293897416845\n",
            "Epoch: 260. Loss: 0.6524551093973892\n",
            "Epoch: 270. Loss: 0.6523899710283856\n",
            "Epoch: 280. Loss: 0.6523327973414664\n",
            "Epoch: 290. Loss: 0.6522825716829702\n",
            "Epoch: 300. Loss: 0.6522384145708209\n",
            "Epoch: 310. Loss: 0.6521995639219533\n",
            "Epoch: 320. Loss: 0.6521653583429864\n",
            "Epoch: 330. Loss: 0.6521352229728661\n",
            "Epoch: 340. Loss: 0.6521086574590489\n",
            "Epoch: 350. Loss: 0.6520852257224671\n",
            "Epoch: 360. Loss: 0.6520645472259805\n",
            "Epoch: 370. Loss: 0.6520462895095313\n",
            "Epoch: 380. Loss: 0.6520301617949843\n",
            "Epoch: 390. Loss: 0.6520159094963607\n",
            "Epoch: 400. Loss: 0.6520033094981511\n",
            "Epoch: 410. Loss: 0.6519921660866883\n",
            "Epoch: 420. Loss: 0.651982307438012\n",
            "Epoch: 430. Loss: 0.651973582580958\n",
            "Epoch: 440. Loss: 0.6519658587669289\n",
            "Epoch: 450. Loss: 0.6519590191883862\n",
            "Epoch: 460. Loss: 0.6519529609969569\n",
            "Epoch: 470. Loss: 0.6519475935794385\n",
            "Epoch: 480. Loss: 0.6519428370561918\n",
            "Epoch: 490. Loss: 0.6519386209716332\n",
            "tensor(0.5459, dtype=torch.float64)\n",
            "2022-11-20 00:00:00\n",
            "Epoch: 0. Loss: 2.4929329506645668\n",
            "Epoch: 10. Loss: 0.9501241046147808\n",
            "Epoch: 20. Loss: 0.7005022518811522\n",
            "Epoch: 30. Loss: 0.6695302765988109\n",
            "Epoch: 40. Loss: 0.6570235801065669\n",
            "Epoch: 50. Loss: 0.6513588276299377\n",
            "Epoch: 60. Loss: 0.6486670764033474\n",
            "Epoch: 70. Loss: 0.6473330220223109\n",
            "Epoch: 80. Loss: 0.6466473814530659\n",
            "Epoch: 90. Loss: 0.6462825256679671\n",
            "Epoch: 100. Loss: 0.646080837653819\n",
            "Epoch: 110. Loss: 0.6459641404903401\n",
            "Epoch: 120. Loss: 0.6458927547747827\n",
            "Epoch: 130. Loss: 0.6458461688085205\n",
            "Epoch: 140. Loss: 0.6458136088375773\n",
            "Epoch: 150. Loss: 0.6457893254303648\n",
            "Epoch: 160. Loss: 0.6457701940440848\n",
            "Epoch: 170. Loss: 0.6457544766729779\n",
            "Epoch: 180. Loss: 0.6457411758447775\n",
            "Epoch: 190. Loss: 0.6457296946555459\n",
            "Epoch: 200. Loss: 0.6457196564598745\n",
            "Epoch: 210. Loss: 0.6457108084891149\n",
            "Epoch: 220. Loss: 0.645702969868057\n",
            "Epoch: 230. Loss: 0.6456960032511151\n",
            "Epoch: 240. Loss: 0.6456897990946073\n",
            "Epoch: 250. Loss: 0.6456842667325976\n",
            "Epoch: 260. Loss: 0.6456793291462398\n",
            "Epoch: 270. Loss: 0.6456749197614321\n",
            "Epoch: 280. Loss: 0.645670980379068\n",
            "Epoch: 290. Loss: 0.6456674597532067\n",
            "Epoch: 300. Loss: 0.6456643125527365\n",
            "Epoch: 310. Loss: 0.6456614985605181\n",
            "Epoch: 320. Loss: 0.6456589820279278\n",
            "Epoch: 330. Loss: 0.6456567311374535\n",
            "Epoch: 340. Loss: 0.6456547175450262\n",
            "Epoch: 350. Loss: 0.6456529159843287\n",
            "Epoch: 360. Loss: 0.6456513039213105\n",
            "Epoch: 370. Loss: 0.6456498612506119\n",
            "Epoch: 380. Loss: 0.6456485700277138\n",
            "Epoch: 390. Loss: 0.6456474142319636\n",
            "Epoch: 400. Loss: 0.6456463795565304\n",
            "Epoch: 410. Loss: 0.645645453221991\n",
            "Epoch: 420. Loss: 0.6456446238107234\n",
            "Epoch: 430. Loss: 0.6456438811196814\n",
            "Epoch: 440. Loss: 0.6456432160294269\n",
            "Epoch: 450. Loss: 0.6456426203875654\n",
            "Epoch: 460. Loss: 0.6456420869049532\n",
            "Epoch: 470. Loss: 0.6456416090632395\n",
            "Epoch: 480. Loss: 0.6456411810324737\n",
            "Epoch: 490. Loss: 0.6456407975976574\n",
            "tensor(0.6437, dtype=torch.float64)\n",
            "2022-11-27 00:00:00\n",
            "Epoch: 0. Loss: 4.10161114196068\n",
            "Epoch: 10. Loss: 1.0806643305710038\n",
            "Epoch: 20. Loss: 0.7006967288194288\n",
            "Epoch: 30. Loss: 0.6830238546963595\n",
            "Epoch: 40. Loss: 0.6769981736818391\n",
            "Epoch: 50. Loss: 0.6734909590356505\n",
            "Epoch: 60. Loss: 0.6707516932592419\n",
            "Epoch: 70. Loss: 0.6683521607734384\n",
            "Epoch: 80. Loss: 0.6661773893376469\n",
            "Epoch: 90. Loss: 0.6641856817860339\n",
            "Epoch: 100. Loss: 0.6623547137605836\n",
            "Epoch: 110. Loss: 0.6606688818039576\n",
            "Epoch: 120. Loss: 0.6591157680162024\n",
            "Epoch: 130. Loss: 0.6576848309771203\n",
            "Epoch: 140. Loss: 0.6563667795762528\n",
            "Epoch: 150. Loss: 0.6551532268636877\n",
            "Epoch: 160. Loss: 0.6540364859086121\n",
            "Epoch: 170. Loss: 0.653009445181535\n",
            "Epoch: 180. Loss: 0.652065489951078\n",
            "Epoch: 190. Loss: 0.6511984504300904\n",
            "Epoch: 200. Loss: 0.6504025653690597\n",
            "Epoch: 210. Loss: 0.6496724544683061\n",
            "Epoch: 220. Loss: 0.6490030957612823\n",
            "Epoch: 230. Loss: 0.6483898057761788\n",
            "Epoch: 240. Loss: 0.6478282212617116\n",
            "Epoch: 250. Loss: 0.6473142818352973\n",
            "Epoch: 260. Loss: 0.6468442132407604\n",
            "Epoch: 270. Loss: 0.6464145110867058\n",
            "Epoch: 280. Loss: 0.6460219250350562\n",
            "Epoch: 290. Loss: 0.6456634434577062\n",
            "Epoch: 300. Loss: 0.6453362785991187\n",
            "Epoch: 310. Loss: 0.6450378522867201\n",
            "Epoch: 320. Loss: 0.6447657822266597\n",
            "Epoch: 330. Loss: 0.6445178689142915\n",
            "Epoch: 340. Loss: 0.6442920831791477\n",
            "Epoch: 350. Loss: 0.6440865543746246\n",
            "Epoch: 360. Loss: 0.6438995592138387\n",
            "Epoch: 370. Loss: 0.6437295112455137\n",
            "Epoch: 380. Loss: 0.6435749509574358\n",
            "Epoch: 390. Loss: 0.643434536489967\n",
            "Epoch: 400. Loss: 0.6433070349382596\n",
            "Epoch: 410. Loss: 0.64319131421903\n",
            "Epoch: 420. Loss: 0.6430863354759019\n",
            "Epoch: 430. Loss: 0.6429911459962585\n",
            "Epoch: 440. Loss: 0.6429048726121288\n",
            "Epoch: 450. Loss: 0.6428267155577151\n",
            "Epoch: 460. Loss: 0.6427559427566709\n",
            "Epoch: 470. Loss: 0.6426918845130084\n",
            "Epoch: 480. Loss: 0.642633928580516\n",
            "Epoch: 490. Loss: 0.6425815155866833\n",
            "tensor(0.5530, dtype=torch.float64)\n",
            "2022-12-04 00:00:00\n",
            "Epoch: 0. Loss: 2.8691954037434\n",
            "Epoch: 10. Loss: 0.7673806129825617\n",
            "Epoch: 20. Loss: 0.6891569224887313\n",
            "Epoch: 30. Loss: 0.6717180636939141\n",
            "Epoch: 40. Loss: 0.6606040928159457\n",
            "Epoch: 50. Loss: 0.6530735090255168\n",
            "Epoch: 60. Loss: 0.6479057147348086\n",
            "Epoch: 70. Loss: 0.6443371750203524\n",
            "Epoch: 80. Loss: 0.6418443741307522\n",
            "Epoch: 90. Loss: 0.6400668624150183\n",
            "Epoch: 100. Loss: 0.6387617301921\n",
            "Epoch: 110. Loss: 0.6377690705245382\n",
            "Epoch: 120. Loss: 0.6369855420874824\n",
            "Epoch: 130. Loss: 0.6363451369067715\n",
            "Epoch: 140. Loss: 0.6358058760396198\n",
            "Epoch: 150. Loss: 0.6353409639088367\n",
            "Epoch: 160. Loss: 0.63493307964935\n",
            "Epoch: 170. Loss: 0.634570773465234\n",
            "Epoch: 180. Loss: 0.6342462283698304\n",
            "Epoch: 190. Loss: 0.6339538859346806\n",
            "Epoch: 200. Loss: 0.6336896088912412\n",
            "Epoch: 210. Loss: 0.6334501728187281\n",
            "Epoch: 220. Loss: 0.633232957558577\n",
            "Epoch: 230. Loss: 0.6330357589913647\n",
            "Epoch: 240. Loss: 0.6328566730211381\n",
            "Epoch: 250. Loss: 0.6326940227908783\n",
            "Epoch: 260. Loss: 0.6325463118004877\n",
            "Epoch: 270. Loss: 0.6324121926093397\n",
            "Epoch: 280. Loss: 0.6322904449962491\n",
            "Epoch: 290. Loss: 0.6321799599418917\n",
            "Epoch: 300. Loss: 0.6320797272750025\n",
            "Epoch: 310. Loss: 0.631988825695899\n",
            "Epoch: 320. Loss: 0.6319064144053806\n",
            "Epoch: 330. Loss: 0.6318317258704919\n",
            "Epoch: 340. Loss: 0.6317640594377782\n",
            "Epoch: 350. Loss: 0.6317027756107907\n",
            "Epoch: 360. Loss: 0.6316472908717702\n",
            "Epoch: 370. Loss: 0.6315970729654571\n",
            "Epoch: 380. Loss: 0.6315516365861132\n",
            "Epoch: 390. Loss: 0.6315105394232539\n",
            "Epoch: 400. Loss: 0.6314733785307953\n",
            "Epoch: 410. Loss: 0.6314397869904231\n",
            "Epoch: 420. Loss: 0.6314094308442132\n",
            "Epoch: 430. Loss: 0.6313820062745964\n",
            "Epoch: 440. Loss: 0.6313572370120977\n",
            "Epoch: 450. Loss: 0.6313348719531366\n",
            "Epoch: 460. Loss: 0.6313146829717238\n",
            "Epoch: 470. Loss: 0.6312964629102015\n",
            "Epoch: 480. Loss: 0.6312800237353374\n",
            "Epoch: 490. Loss: 0.6312651948471081\n",
            "tensor(0.7180, dtype=torch.float64)\n",
            "2022-12-11 00:00:00\n",
            "Epoch: 0. Loss: 1.9491726404262515\n",
            "Epoch: 10. Loss: 0.8925815213418761\n",
            "Epoch: 20. Loss: 0.6627109207680199\n",
            "Epoch: 30. Loss: 0.6497756006894201\n",
            "Epoch: 40. Loss: 0.647453937952062\n",
            "Epoch: 50. Loss: 0.6467053541174947\n",
            "Epoch: 60. Loss: 0.6463357149251011\n",
            "Epoch: 70. Loss: 0.6461016123410629\n",
            "Epoch: 80. Loss: 0.6459329651419934\n",
            "Epoch: 90. Loss: 0.645801591149793\n",
            "Epoch: 100. Loss: 0.6456937586257057\n",
            "Epoch: 110. Loss: 0.6456021490209298\n",
            "Epoch: 120. Loss: 0.6455226253654318\n",
            "Epoch: 130. Loss: 0.6454526983610203\n",
            "Epoch: 140. Loss: 0.6453907539637821\n",
            "Epoch: 150. Loss: 0.6453356571413033\n",
            "Epoch: 160. Loss: 0.6452865468482976\n",
            "Epoch: 170. Loss: 0.645242728852535\n",
            "Epoch: 180. Loss: 0.6452036187099928\n",
            "Epoch: 190. Loss: 0.6451687104939006\n",
            "Epoch: 200. Loss: 0.6451375588162162\n",
            "Epoch: 210. Loss: 0.6451097677812895\n",
            "Epoch: 220. Loss: 0.645084983623904\n",
            "Epoch: 230. Loss: 0.645062889369011\n",
            "Epoch: 240. Loss: 0.645043200657064\n",
            "Epoch: 250. Loss: 0.6450256622893574\n",
            "Epoch: 260. Loss: 0.64501004525697\n",
            "Epoch: 270. Loss: 0.6449961441238564\n",
            "Epoch: 280. Loss: 0.6449837746896167\n",
            "Epoch: 290. Loss: 0.6449727718860422\n",
            "Epoch: 300. Loss: 0.644962987876633\n",
            "Epoch: 310. Loss: 0.6449542903364884\n",
            "Epoch: 320. Loss: 0.6449465608946502\n",
            "Epoch: 330. Loss: 0.6449396937238056\n",
            "Epoch: 340. Loss: 0.6449335942641387\n",
            "Epoch: 350. Loss: 0.6449281780694636\n",
            "Epoch: 360. Loss: 0.6449233697648515\n",
            "Epoch: 370. Loss: 0.6449191021058589\n",
            "Epoch: 380. Loss: 0.6449153151302593\n",
            "Epoch: 390. Loss: 0.6449119553939088\n",
            "Epoch: 400. Loss: 0.6449089752830374\n",
            "Epoch: 410. Loss: 0.6449063323958781\n",
            "Epoch: 420. Loss: 0.6449039889871315\n",
            "Epoch: 430. Loss: 0.6449019114692933\n",
            "Epoch: 440. Loss: 0.6449000699653916\n",
            "Epoch: 450. Loss: 0.6448984379081358\n",
            "Epoch: 460. Loss: 0.6448969916809322\n",
            "Epoch: 470. Loss: 0.644895710296614\n",
            "Epoch: 480. Loss: 0.644894575110119\n",
            "Epoch: 490. Loss: 0.6448935695616902\n",
            "tensor(0.7663, dtype=torch.float64)\n",
            "2022-12-18 00:00:00\n",
            "Epoch: 0. Loss: 2.6528431190019703\n",
            "Epoch: 10. Loss: 1.2105005021597548\n",
            "Epoch: 20. Loss: 0.8307561764992966\n",
            "Epoch: 30. Loss: 0.7494792370358615\n",
            "Epoch: 40. Loss: 0.7080966112518056\n",
            "Epoch: 50. Loss: 0.6853507981828856\n",
            "Epoch: 60. Loss: 0.6728986744397587\n",
            "Epoch: 70. Loss: 0.6661776933329312\n",
            "Epoch: 80. Loss: 0.6625107489767772\n",
            "Epoch: 90. Loss: 0.6604054310527355\n",
            "Epoch: 100. Loss: 0.6590848990512957\n",
            "Epoch: 110. Loss: 0.6581646406224059\n",
            "Epoch: 120. Loss: 0.6574595570563837\n",
            "Epoch: 130. Loss: 0.6568811253826069\n",
            "Epoch: 140. Loss: 0.6563862972265334\n",
            "Epoch: 150. Loss: 0.655953145327019\n",
            "Epoch: 160. Loss: 0.6555695404306909\n",
            "Epoch: 170. Loss: 0.6552279609861096\n",
            "Epoch: 180. Loss: 0.6549231303016421\n",
            "Epoch: 190. Loss: 0.6546509409057476\n",
            "Epoch: 200. Loss: 0.6544079604714355\n",
            "Epoch: 210. Loss: 0.6541911994865739\n",
            "Epoch: 220. Loss: 0.6539979967137244\n",
            "Epoch: 230. Loss: 0.6538259579195409\n",
            "Epoch: 240. Loss: 0.6536729190210747\n",
            "Epoch: 250. Loss: 0.6535369207484913\n",
            "Epoch: 260. Loss: 0.6534161890411858\n",
            "Epoch: 270. Loss: 0.6533091185663725\n",
            "Epoch: 280. Loss: 0.6532142581633245\n",
            "Epoch: 290. Loss: 0.6531302976481095\n",
            "Epoch: 300. Loss: 0.6530560556972459\n",
            "Epoch: 310. Loss: 0.6529904686572428\n",
            "Epoch: 320. Loss: 0.6529325801863339\n",
            "Epoch: 330. Loss: 0.6528815316629523\n",
            "Epoch: 340. Loss: 0.6528365533096279\n",
            "Epoch: 350. Loss: 0.6527969559885567\n",
            "Epoch: 360. Loss: 0.6527621236295054\n",
            "Epoch: 370. Loss: 0.6527315062535235\n",
            "Epoch: 380. Loss: 0.6527046135578833\n",
            "Epoch: 390. Loss: 0.6526810090290964\n",
            "Epoch: 400. Loss: 0.6526603045520171\n",
            "Epoch: 410. Loss: 0.6526421554840105\n",
            "Epoch: 420. Loss: 0.6526262561640697\n",
            "Epoch: 430. Loss: 0.6526123358276337\n",
            "Epoch: 440. Loss: 0.6526001548987603\n",
            "Epoch: 450. Loss: 0.6525895016322484\n",
            "Epoch: 460. Loss: 0.6525801890793075\n",
            "Epoch: 470. Loss: 0.6525720523514541\n",
            "Epoch: 480. Loss: 0.6525649461584471\n",
            "Epoch: 490. Loss: 0.6525587425972826\n",
            "tensor(0.5122, dtype=torch.float64)\n",
            "2022-12-25 00:00:00\n",
            "Epoch: 0. Loss: 5.314197394380467\n",
            "Epoch: 10. Loss: 1.6625373797397038\n",
            "Epoch: 20. Loss: 0.7378456533645544\n",
            "Epoch: 30. Loss: 0.6859084419697551\n",
            "Epoch: 40. Loss: 0.6692121520922092\n",
            "Epoch: 50. Loss: 0.6620956108204196\n",
            "Epoch: 60. Loss: 0.6589707816131806\n",
            "Epoch: 70. Loss: 0.6576054062353185\n",
            "Epoch: 80. Loss: 0.6570162368306841\n",
            "Epoch: 90. Loss: 0.6567645314356207\n",
            "Epoch: 100. Loss: 0.6566574154953944\n",
            "Epoch: 110. Loss: 0.6566116127792534\n",
            "Epoch: 120. Loss: 0.6565916686442725\n",
            "Epoch: 130. Loss: 0.6565826295554227\n",
            "Epoch: 140. Loss: 0.6565782230024839\n",
            "Epoch: 150. Loss: 0.656575822942523\n",
            "Epoch: 160. Loss: 0.6565743275558061\n",
            "Epoch: 170. Loss: 0.656573270600198\n",
            "Epoch: 180. Loss: 0.6565724508566713\n",
            "Epoch: 190. Loss: 0.6565717779783022\n",
            "Epoch: 200. Loss: 0.6565712084170844\n",
            "Epoch: 210. Loss: 0.6565707187667763\n",
            "Epoch: 220. Loss: 0.6565702946309079\n",
            "Epoch: 230. Loss: 0.6565699259324671\n",
            "Epoch: 240. Loss: 0.6565696049000358\n",
            "Epoch: 250. Loss: 0.6565693251702576\n",
            "Epoch: 260. Loss: 0.6565690813599622\n",
            "Epoch: 270. Loss: 0.6565688688394927\n",
            "Epoch: 280. Loss: 0.6565686835953621\n",
            "Epoch: 290. Loss: 0.6565685221352354\n",
            "Epoch: 300. Loss: 0.6565683814151464\n",
            "Epoch: 310. Loss: 0.6565682587800674\n",
            "Epoch: 320. Loss: 0.6565681519136513\n",
            "Epoch: 330. Loss: 0.6565680587949663\n",
            "Epoch: 340. Loss: 0.6565679776609376\n",
            "Epoch: 350. Loss: 0.6565679069736101\n",
            "Epoch: 360. Loss: 0.6565678453915658\n",
            "Epoch: 370. Loss: 0.6565677917449529\n",
            "Epoch: 380. Loss: 0.6565677450136651\n",
            "Epoch: 390. Loss: 0.6565677043082762\n",
            "Epoch: 400. Loss: 0.6565676688533832\n",
            "Epoch: 410. Loss: 0.6565676379730577\n",
            "Epoch: 420. Loss: 0.656567611078141\n",
            "Epoch: 430. Loss: 0.6565675876551517\n",
            "Epoch: 440. Loss: 0.6565675672566017\n",
            "Epoch: 450. Loss: 0.6565675494925455\n",
            "Epoch: 460. Loss: 0.6565675340232061\n",
            "Epoch: 470. Loss: 0.6565675205525399\n",
            "Epoch: 480. Loss: 0.6565675088226249\n",
            "Epoch: 490. Loss: 0.6565674986087648\n",
            "tensor(0.5899, dtype=torch.float64)\n",
            "2023-01-01 00:00:00\n",
            "Epoch: 0. Loss: 3.4985779936329235\n",
            "Epoch: 10. Loss: 1.579112116823269\n",
            "Epoch: 20. Loss: 0.7686295765082707\n",
            "Epoch: 30. Loss: 0.6917994127577081\n",
            "Epoch: 40. Loss: 0.6764747415713468\n",
            "Epoch: 50. Loss: 0.6689736252153632\n",
            "Epoch: 60. Loss: 0.6646603425522694\n",
            "Epoch: 70. Loss: 0.6618913475889412\n",
            "Epoch: 80. Loss: 0.6599693193305652\n",
            "Epoch: 90. Loss: 0.65856383319282\n",
            "Epoch: 100. Loss: 0.6575004974435239\n",
            "Epoch: 110. Loss: 0.6566775731679897\n",
            "Epoch: 120. Loss: 0.6560304478128881\n",
            "Epoch: 130. Loss: 0.6555153722347342\n",
            "Epoch: 140. Loss: 0.6551013753141819\n",
            "Epoch: 150. Loss: 0.6547658595313247\n",
            "Epoch: 160. Loss: 0.6544919846385492\n",
            "Epoch: 170. Loss: 0.6542670006808462\n",
            "Epoch: 180. Loss: 0.6540811307165647\n",
            "Epoch: 190. Loss: 0.6539267954946513\n",
            "Epoch: 200. Loss: 0.6537980623435709\n",
            "Epoch: 210. Loss: 0.6536902465031602\n",
            "Epoch: 220. Loss: 0.6535996187248683\n",
            "Epoch: 230. Loss: 0.6535231882963343\n",
            "Epoch: 240. Loss: 0.6534585403491998\n",
            "Epoch: 250. Loss: 0.6534037126915747\n",
            "Epoch: 260. Loss: 0.6533571017173845\n",
            "Epoch: 270. Loss: 0.6533173899111462\n",
            "Epoch: 280. Loss: 0.6532834895366001\n",
            "Epoch: 290. Loss: 0.6532544985583795\n",
            "Epoch: 300. Loss: 0.6532296658869577\n",
            "Epoch: 310. Loss: 0.6532083637857085\n",
            "Epoch: 320. Loss: 0.653190065821804\n",
            "Epoch: 330. Loss: 0.6531743291395861\n",
            "Epoch: 340. Loss: 0.6531607801275409\n",
            "Epoch: 350. Loss: 0.6531491027672254\n",
            "Epoch: 360. Loss: 0.6531390291150179\n",
            "Epoch: 370. Loss: 0.6531303314900665\n",
            "Epoch: 380. Loss: 0.6531228160347963\n",
            "Epoch: 390. Loss: 0.6531163173854172\n",
            "Epoch: 400. Loss: 0.6531106942445625\n",
            "Epoch: 410. Loss: 0.6531058256905463\n",
            "Epoch: 420. Loss: 0.6531016080907339\n",
            "Epoch: 430. Loss: 0.6530979525123951\n",
            "Epoch: 440. Loss: 0.6530947825448091\n",
            "Epoch: 450. Loss: 0.6530920324625674\n",
            "Epoch: 460. Loss: 0.6530896456729037\n",
            "Epoch: 470. Loss: 0.6530875734002148\n",
            "Epoch: 480. Loss: 0.6530857735692315\n",
            "Epoch: 490. Loss: 0.6530842098550328\n",
            "tensor(0.6334, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "parameters = pd.DataFrame(columns=['a','b','prob'])\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_ml_dataset_for_date(date)\n",
        "  a,b = train_and_get_a_b(dataset[:-1])  \n",
        "  with torch.no_grad():\n",
        "    y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "    print(y_test)\n",
        "    parameters.loc[date] = [a,b,y_test.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWaPoTs-NqAF",
        "outputId": "5a681f2d-03e7-4dc0-ebd0-80bc35ebbbc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "ks = np.arange(0, 1, 0.05)\n",
        "backtest_returns = pd.DataFrame(columns = ks)\n",
        "\n",
        "for date in daterange:  \n",
        "  print(date)\n",
        "  prob = parameters.loc[date]['prob']\n",
        "  rets = []\n",
        "  for k in ks:\n",
        "    weight = calculate_ml_portfolio_weights(prob, k)\n",
        "    rets.append(get_backtest_return(date, weight))\n",
        "  backtest_returns.loc[date] = rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QJznmoa50iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2ef9bc-4547-4af4-b276-f42c025d9e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00    0.001456\n",
            "0.05    0.001456\n",
            "0.10    0.001456\n",
            "0.15    0.001456\n",
            "0.20    0.001456\n",
            "0.25    0.001313\n",
            "0.30    0.001310\n",
            "0.35    0.001310\n",
            "0.40    0.001449\n",
            "0.45    0.001412\n",
            "0.50    0.001171\n",
            "0.55    0.000878\n",
            "0.60    0.000853\n",
            "0.65    0.000776\n",
            "0.70    0.000631\n",
            "0.75    0.001024\n",
            "0.80    0.001051\n",
            "0.85    0.000569\n",
            "0.90    0.000621\n",
            "0.95    0.000470\n",
            "dtype: float64\n",
            "0.00    0.000522\n",
            "0.05    0.000522\n",
            "0.10    0.000522\n",
            "0.15    0.000522\n",
            "0.20    0.000522\n",
            "0.25    0.000507\n",
            "0.30    0.000505\n",
            "0.35    0.000505\n",
            "0.40    0.000497\n",
            "0.45    0.000489\n",
            "0.50    0.000466\n",
            "0.55    0.000430\n",
            "0.60    0.000379\n",
            "0.65    0.000344\n",
            "0.70    0.000287\n",
            "0.75    0.000222\n",
            "0.80    0.000183\n",
            "0.85    0.000148\n",
            "0.90    0.000112\n",
            "0.95    0.000081\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "backtest_mean = backtest_returns.mean()\n",
        "backtest_var = backtest_returns.var()\n",
        "print(backtest_mean)\n",
        "print(backtest_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Uy0n-yp8SPt5",
        "outputId": "37f74f71-e411-46a0-d9c9-31f1909457c2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NoPoints = len(backtest_mean)\n",
        "\n",
        "colours = \"red\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for ML Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter( np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aPJVsE3U1u"
      },
      "source": [
        "### MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_mv_dataset_for_date(date(2023,1,1))\n",
        "r, cov = get_sample_return_and_covariance(dataset)"
      ],
      "metadata": {
        "id": "HQdOY59TvGDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a4N3uUyzyz",
        "outputId": "d2091c54-e9c8-4f33-ebd0-d6bb56599c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r)\n",
        "print(cov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfgBvPuDzNXt",
        "outputId": "a5c099d7-813c-4434-fb60-9ceab245b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l_Close   -0.149595\n",
            "h_Close   -0.148826\n",
            "dtype: float64\n",
            "          l_Close   h_Close\n",
            "l_Close  0.010103  0.004556\n",
            "h_Close  0.004556  0.057944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_markovitz_weights(r, cov, m):\n",
        "  r = r.to_numpy()\n",
        "  cov = cov.to_numpy()\n",
        "  cov_inv = np.linalg.inv(cov)\n",
        "  ones = [1,1]\n",
        "  a = np.matmul(np.matmul(r, cov_inv), ones)\n",
        "  b = np.matmul(np.matmul(r, cov_inv), r)\n",
        "  c = np.matmul(np.matmul(ones, cov_inv), ones)\n",
        "  # print(r, cov, cov_inv,a,b,c)\n",
        "  numerator = b * np.matmul(cov_inv, ones) - a * np.matmul(cov_inv, r)  + m * (c * np.matmul(cov_inv, r) - a * np.matmul(cov_inv, ones))\n",
        "  denominator = b*c-pow(a,2)\n",
        "  x =  numerator / denominator\n",
        "  # print(numerator,denominator,x)\n",
        "  #/ (b*c-a^2) \n",
        "  return x"
      ],
      "metadata": {
        "id": "f5jaNAq8t8NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = calculate_markovitz_weights(r , cov , 0.01)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zcZVqWVvdki",
        "outputId": "53161a89-68f5-4b01-c6e0-76f0b228fa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-206.6925489,  207.6925489])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_weight_for_constraint(weight):\n",
        "  if weight < 0:\n",
        "    return 0\n",
        "  if weight > 1:\n",
        "    return 1\n",
        "  return weight"
      ],
      "metadata": {
        "id": "-mrSWBmGFGFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef55af4-56b7-4908-cb57-f5e0c796bcdd",
        "id": "r4OTRAPogrNe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:   0.000000\n"
          ]
        }
      ],
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef27242-a41c-4143-9c79-05a255f84b64",
        "id": "KX2KDSHGgrNe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n"
          ]
        }
      ],
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = np.arange(0,1.5, 0.1)\n",
        "ratios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x9YHqcv5NDA",
        "outputId": "6d0dcb08-d4b1-48e7-ffb6-35d7a331434e"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
              "       1.3, 1.4])"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XevciqKG3aJ0",
        "outputId": "effded6b-38f6-4051-a091-5c6a7c4dd572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# mv_backtest_weights = pd.DataFrame(columns = ratios)\n",
        "mv_backtest_returns = pd.DataFrame(columns = ratios)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  weights = []\n",
        "  rets = []\n",
        "\n",
        "  result1 = MaximizeReturns(r, 2)\n",
        "  maxReturnWeights = result1.x\n",
        "  maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "\n",
        "  result2 = MinimizeRisk(cov, 2)\n",
        "  minRiskWeights = result2.x\n",
        "  minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "\n",
        "  for ratio in ratios:\n",
        "    weights = maxReturnWeights * ratio + minRiskWeights * (1-ratio)\n",
        "    low_risk_weight = weights[0]\n",
        "    high_risk_weight = weights[1]\n",
        "    ret = get_mv_backtest_return(date, low_risk_weight, high_risk_weight)\n",
        "    # weights.append(high_risk_weight)\n",
        "    rets.append(ret)\n",
        "  # mv_backtest_weights.loc[date] = weights\n",
        "  mv_backtest_returns.loc[date] = rets\n",
        "  # print(weights)\n",
        "  # print(rets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_returns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S5MJbCKQ4wot",
        "outputId": "5a0260b0-67d9-4d2f-878d-6bc513d6554d"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0.0       0.1       0.2       0.3       0.4       0.5  \\\n",
              "2003-09-21  0.007450  0.003885  0.000320 -0.003244 -0.006809 -0.010373   \n",
              "2003-09-28 -0.003550 -0.000114  0.003321  0.006757  0.010193  0.013629   \n",
              "2003-10-05  0.002961  0.003718  0.004475  0.005232  0.005990  0.006747   \n",
              "2003-10-12 -0.009141 -0.008657 -0.008172 -0.007688 -0.007204 -0.006719   \n",
              "2003-10-19  0.009441  0.007664  0.005887  0.004110  0.002333  0.000556   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.004699 -0.004229 -0.003760 -0.003290 -0.002820 -0.002350   \n",
              "2022-12-11  0.000178  0.000160  0.000142  0.000125  0.000107  0.000089   \n",
              "2022-12-18 -0.012158 -0.010942 -0.009726 -0.008510 -0.007295 -0.006079   \n",
              "2022-12-25 -0.004228 -0.003805 -0.003382 -0.002960 -0.002537 -0.002114   \n",
              "2023-01-01  0.014649  0.013184  0.011720  0.010255  0.008790  0.007325   \n",
              "\n",
              "                 0.6       0.7       0.8       0.9       1.0       1.1  \\\n",
              "2003-09-21 -0.013938 -0.017503 -0.021067 -0.024632 -0.028196 -0.031761   \n",
              "2003-09-28  0.017064  0.020500  0.023936  0.027372  0.030808  0.034243   \n",
              "2003-10-05  0.007504  0.008262  0.009019  0.009776  0.010533  0.011291   \n",
              "2003-10-12 -0.006235 -0.005751 -0.005266 -0.004782 -0.004298 -0.003813   \n",
              "2003-10-19 -0.001221 -0.002998 -0.004775 -0.006552 -0.008329 -0.010106   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.001880 -0.001410 -0.000940 -0.000470 -0.000000  0.000470   \n",
              "2022-12-11  0.000071  0.000053  0.000036  0.000018  0.000000 -0.000018   \n",
              "2022-12-18 -0.004863 -0.003647 -0.002432 -0.001216 -0.000000  0.001216   \n",
              "2022-12-25 -0.001691 -0.001268 -0.000846 -0.000423 -0.000000  0.000423   \n",
              "2023-01-01  0.005860  0.004395  0.002930  0.001465  0.000000 -0.001465   \n",
              "\n",
              "                 1.2       1.3       1.4  \n",
              "2003-09-21 -0.035326 -0.038890 -0.042455  \n",
              "2003-09-28  0.037679  0.041115  0.044551  \n",
              "2003-10-05  0.012048  0.012805  0.013563  \n",
              "2003-10-12 -0.003329 -0.002845 -0.002360  \n",
              "2003-10-19 -0.011883 -0.013660 -0.015437  \n",
              "...              ...       ...       ...  \n",
              "2022-12-04  0.000940  0.001410  0.001880  \n",
              "2022-12-11 -0.000036 -0.000053 -0.000071  \n",
              "2022-12-18  0.002432  0.003647  0.004863  \n",
              "2022-12-25  0.000846  0.001268  0.001691  \n",
              "2023-01-01 -0.002930 -0.004395 -0.005860  \n",
              "\n",
              "[1007 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.1</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.3</th>\n",
              "      <th>1.4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2003-09-21</th>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.003885</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.006809</td>\n",
              "      <td>-0.010373</td>\n",
              "      <td>-0.013938</td>\n",
              "      <td>-0.017503</td>\n",
              "      <td>-0.021067</td>\n",
              "      <td>-0.024632</td>\n",
              "      <td>-0.028196</td>\n",
              "      <td>-0.031761</td>\n",
              "      <td>-0.035326</td>\n",
              "      <td>-0.038890</td>\n",
              "      <td>-0.042455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-09-28</th>\n",
              "      <td>-0.003550</td>\n",
              "      <td>-0.000114</td>\n",
              "      <td>0.003321</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.010193</td>\n",
              "      <td>0.013629</td>\n",
              "      <td>0.017064</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.023936</td>\n",
              "      <td>0.027372</td>\n",
              "      <td>0.030808</td>\n",
              "      <td>0.034243</td>\n",
              "      <td>0.037679</td>\n",
              "      <td>0.041115</td>\n",
              "      <td>0.044551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-05</th>\n",
              "      <td>0.002961</td>\n",
              "      <td>0.003718</td>\n",
              "      <td>0.004475</td>\n",
              "      <td>0.005232</td>\n",
              "      <td>0.005990</td>\n",
              "      <td>0.006747</td>\n",
              "      <td>0.007504</td>\n",
              "      <td>0.008262</td>\n",
              "      <td>0.009019</td>\n",
              "      <td>0.009776</td>\n",
              "      <td>0.010533</td>\n",
              "      <td>0.011291</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>0.012805</td>\n",
              "      <td>0.013563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-12</th>\n",
              "      <td>-0.009141</td>\n",
              "      <td>-0.008657</td>\n",
              "      <td>-0.008172</td>\n",
              "      <td>-0.007688</td>\n",
              "      <td>-0.007204</td>\n",
              "      <td>-0.006719</td>\n",
              "      <td>-0.006235</td>\n",
              "      <td>-0.005751</td>\n",
              "      <td>-0.005266</td>\n",
              "      <td>-0.004782</td>\n",
              "      <td>-0.004298</td>\n",
              "      <td>-0.003813</td>\n",
              "      <td>-0.003329</td>\n",
              "      <td>-0.002845</td>\n",
              "      <td>-0.002360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-19</th>\n",
              "      <td>0.009441</td>\n",
              "      <td>0.007664</td>\n",
              "      <td>0.005887</td>\n",
              "      <td>0.004110</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>-0.002998</td>\n",
              "      <td>-0.004775</td>\n",
              "      <td>-0.006552</td>\n",
              "      <td>-0.008329</td>\n",
              "      <td>-0.010106</td>\n",
              "      <td>-0.011883</td>\n",
              "      <td>-0.013660</td>\n",
              "      <td>-0.015437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-04</th>\n",
              "      <td>-0.004699</td>\n",
              "      <td>-0.004229</td>\n",
              "      <td>-0.003760</td>\n",
              "      <td>-0.003290</td>\n",
              "      <td>-0.002820</td>\n",
              "      <td>-0.002350</td>\n",
              "      <td>-0.001880</td>\n",
              "      <td>-0.001410</td>\n",
              "      <td>-0.000940</td>\n",
              "      <td>-0.000470</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000470</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.001410</td>\n",
              "      <td>0.001880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-11</th>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>-0.000036</td>\n",
              "      <td>-0.000053</td>\n",
              "      <td>-0.000071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-18</th>\n",
              "      <td>-0.012158</td>\n",
              "      <td>-0.010942</td>\n",
              "      <td>-0.009726</td>\n",
              "      <td>-0.008510</td>\n",
              "      <td>-0.007295</td>\n",
              "      <td>-0.006079</td>\n",
              "      <td>-0.004863</td>\n",
              "      <td>-0.003647</td>\n",
              "      <td>-0.002432</td>\n",
              "      <td>-0.001216</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.004863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-25</th>\n",
              "      <td>-0.004228</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>-0.003382</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.002537</td>\n",
              "      <td>-0.002114</td>\n",
              "      <td>-0.001691</td>\n",
              "      <td>-0.001268</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.000423</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.001691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-01</th>\n",
              "      <td>0.014649</td>\n",
              "      <td>0.013184</td>\n",
              "      <td>0.011720</td>\n",
              "      <td>0.010255</td>\n",
              "      <td>0.008790</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.001465</td>\n",
              "      <td>-0.002930</td>\n",
              "      <td>-0.004395</td>\n",
              "      <td>-0.005860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1007 rows  15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_mean = mv_backtest_returns.mean()\n",
        "mv_backtest_var = mv_backtest_returns.var()\n",
        "print(mv_backtest_mean)\n",
        "print(np.sqrt(mv_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdE0BXHf4Rur",
        "outputId": "f3de2dc3-cbce-4608-c2dc-c033cbc73c1e"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    0.000548\n",
            "0.1    0.000555\n",
            "0.2    0.000562\n",
            "0.3    0.000569\n",
            "0.4    0.000575\n",
            "0.5    0.000582\n",
            "0.6    0.000589\n",
            "0.7    0.000596\n",
            "0.8    0.000603\n",
            "0.9    0.000609\n",
            "1.0    0.000616\n",
            "1.1    0.000623\n",
            "1.2    0.000630\n",
            "1.3    0.000637\n",
            "1.4    0.000643\n",
            "dtype: float64\n",
            "0.0    0.007145\n",
            "0.1    0.007141\n",
            "0.2    0.007447\n",
            "0.3    0.008027\n",
            "0.4    0.008827\n",
            "0.5    0.009793\n",
            "0.6    0.010882\n",
            "0.7    0.012059\n",
            "0.8    0.013302\n",
            "0.9    0.014594\n",
            "1.0    0.015923\n",
            "1.1    0.017280\n",
            "1.2    0.018659\n",
            "1.3    0.020056\n",
            "1.4    0.021467\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fG9H0VuB4H_i",
        "outputId": "3f94ecdf-fa3d-47f7-e5bd-f4070b00af10"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Portfolio"
      ],
      "metadata": {
        "id": "JoA9UX-AIaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thetas = np.arange(0, 1.05, 0.05)\n",
        "thetas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC0UiR1DIdtE",
        "outputId": "05efdea8-7096-434f-c2ac-1f1cb1065bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_returns = pd.DataFrame(columns = thetas)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  rets=[]\n",
        "  for theta in thetas:\n",
        "    ret = get_mv_backtest_return(date, 1-theta, theta)\n",
        "    rets.append(ret)\n",
        "  naive_backtest_returns.loc[date] = rets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYsRgLjIZmr",
        "outputId": "752aeb7e-9973-4684-e5f8-05549f86777a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_mean = naive_backtest_returns.mean()\n",
        "naive_backtest_var = naive_backtest_returns.var()\n",
        "print(naive_backtest_mean)\n",
        "print(np.sqrt(naive_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e4a98-facd-4559-890a-4b5cdd1a2305",
        "id": "OK8b3Re5JK4v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00    0.000407\n",
            "0.05    0.000459\n",
            "0.10    0.000512\n",
            "0.15    0.000564\n",
            "0.20    0.000617\n",
            "0.25    0.000669\n",
            "0.30    0.000722\n",
            "0.35    0.000774\n",
            "0.40    0.000827\n",
            "0.45    0.000879\n",
            "0.50    0.000932\n",
            "0.55    0.000984\n",
            "0.60    0.001037\n",
            "0.65    0.001089\n",
            "0.70    0.001142\n",
            "0.75    0.001194\n",
            "0.80    0.001246\n",
            "0.85    0.001299\n",
            "0.90    0.001351\n",
            "0.95    0.001404\n",
            "1.00    0.001456\n",
            "dtype: float64\n",
            "0.00    0.008582\n",
            "0.05    0.007926\n",
            "0.10    0.007449\n",
            "0.15    0.007187\n",
            "0.20    0.007164\n",
            "0.25    0.007381\n",
            "0.30    0.007819\n",
            "0.35    0.008444\n",
            "0.40    0.009218\n",
            "0.45    0.010106\n",
            "0.50    0.011081\n",
            "0.55    0.012122\n",
            "0.60    0.013213\n",
            "0.65    0.014344\n",
            "0.70    0.015505\n",
            "0.75    0.016690\n",
            "0.80    0.017894\n",
            "0.85    0.019114\n",
            "0.90    0.020347\n",
            "0.95    0.021590\n",
            "1.00    0.022842\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "08cc11d4-c4ae-4d95-ac10-7fb508b0737b",
        "id": "QP0dekjMJK4v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Graph"
      ],
      "metadata": {
        "id": "yyBQMceuJ_-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = 21\n",
        "\n",
        "area = np.pi*3\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ml_var = np.sqrt(backtest_var * (trading_days_in_year /5))\n",
        "ml_mean = backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "mv_var = np.sqrt(mv_backtest_var * (trading_days_in_year /5))\n",
        "mv_mean = mv_backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "naive_var = np.sqrt(naive_backtest_var * (trading_days_in_year /5))\n",
        "naive_mean = naive_backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "fit = np.polyfit(ml_var, ml_mean, deg=4) \n",
        "p = np.poly1d(fit) \n",
        "ax1.plot(ml_var,p(ml_var),\"r--\") \n",
        "\n",
        "# fit = np.polyfit(mv_var, mv_mean, deg=4) \n",
        "# p = np.poly1d(fit) \n",
        "# ax1.plot(mv_var,p(mv_var),\"g--\") \n",
        "\n",
        "# fit = np.polyfit(naive_var, naive_mean, deg=6) \n",
        "# p = np.poly1d(fit) \n",
        "# ax1.plot(naive_var,p(naive_var),\"b--\") \n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=\"red\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "x2aGNhpuKEan",
        "outputId": "3799e9f3-4200-403e-ddab-982ef4941e53"
      },
      "execution_count": 362,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59JkxM_-c9uk"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBobZ4qo53Lo"
      },
      "outputs": [],
      "source": [
        "# model = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "def train_epoch(dataloader):\n",
        "    train_loss,train_correct=0.0,0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "        loss = loss_fn(y_output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return train_loss\n",
        "  \n",
        "def valid_epoch(dataloader):\n",
        "\n",
        "    valid_loss, val_correct = 0.0, 0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "        loss = loss_fn(y_output, y)\n",
        "\n",
        "        valid_loss+=loss.item() * x.size(0)\n",
        "\n",
        "    return valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DeuyMHGu_Lmy",
        "outputId": "11c663c7-9cc6-41d6-d789-6e05591addaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c07c40cb1bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3768fb6a26b4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ],
      "source": [
        "history = {'train_loss': [], 'test_loss': []}\n",
        " \n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss=train_epoch(train_loader)\n",
        "        test_loss=valid_epoch(test_loader)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1,n_epochs,train_loss,test_loss))\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsd-ud7DWRC5"
      },
      "outputs": [],
      "source": [
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "YBYaqWwGoDBM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx3K4DmgFpd7"
      },
      "source": [
        "## MV Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1A4Jk4uWHDj"
      },
      "source": [
        "### Build data for high and low risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e5kg5IleWKbF",
        "outputId": "5c460d6a-b245-405b-ad81-0d12ba019502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            high        low\n",
              "25     89.540001  85.199997\n",
              "26     88.779999  85.540001\n",
              "27     90.000000  84.879997\n",
              "28     90.660004  84.760002\n",
              "29     91.699997  85.059998\n",
              "...          ...        ...\n",
              "5142  382.429993  95.779999\n",
              "5143  380.820007  96.529999\n",
              "5144  383.760010  97.269997\n",
              "5145  379.380005  97.129997\n",
              "5146  388.079987  98.379997\n",
              "\n",
              "[5122 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>89.540001</td>\n",
              "      <td>85.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>88.779999</td>\n",
              "      <td>85.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>84.879997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>90.660004</td>\n",
              "      <td>84.760002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>91.699997</td>\n",
              "      <td>85.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>382.429993</td>\n",
              "      <td>95.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>380.820007</td>\n",
              "      <td>96.529999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>383.760010</td>\n",
              "      <td>97.269997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>379.380005</td>\n",
              "      <td>97.129997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>388.079987</td>\n",
              "      <td>98.379997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ],
      "source": [
        "mv_data = pd.DataFrame(data={'high': high_risk['Close'], 'low':low_risk['Close']})\n",
        "mv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BOYoifDBaqP"
      },
      "source": [
        "### Optimization using linear programming\n",
        "\n",
        "(Reference: https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_t1dGnAtHYV"
      },
      "outputs": [],
      "source": [
        "TERMINATION = 10**-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6r-NvbtYDDn"
      },
      "outputs": [],
      "source": [
        "def print_min_variance_portfolio(mean_returns, cov_returns):\n",
        "    number_of_assets = len(mean_returns)\n",
        "    result = MinimizeRisk(cov_returns, number_of_assets)\n",
        "\n",
        "    print()\n",
        "    minRiskWeights = result.x\n",
        "    minRiskExpPortfolioReturn = np.matmul(mean_returns.T, minRiskWeights)\n",
        "    print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)\n",
        "    minRisk = np.matmul(np.matmul(minRiskWeights, cov_returns), minRiskWeights.T) \n",
        "    print(\"Variance of Minimum Risk Portfolio : %7.6f\" % minRisk)\n",
        "    print(\"S.D. of Minimum Risk Portfolio : %7.6f\" % np.sqrt(minRisk))\n",
        "    threshold = 1e-3\n",
        "    print(\"Weights (showing only those > %.6f): \" % threshold)\n",
        "    for i in range(0, number_of_assets):\n",
        "        if result.x[i] > threshold:\n",
        "            print(f\"{mean_returns.index[i]}\\t{result.x[i]:.6f}\")\n",
        "    print('Assets Considered:')\n",
        "    print(mean_returns.index.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNuu3KurcJDL"
      },
      "outputs": [],
      "source": [
        "#function obtains Minimal risk and Maximum return portfolios\n",
        "\n",
        "#dependencies\n",
        "import numpy as np\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Xe_zRSHcbxxb",
        "outputId": "69bff57b-a2f7-49ef-8742-3abec15813e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Close   h_Close\n",
              "l_Close  0.010103  0.004556\n",
              "h_Close  0.004556  0.057944"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ee3c5d9-72ca-4342-9514-909e4599f61d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Close</th>\n",
              "      <th>h_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>l_Close</th>\n",
              "      <td>0.010103</td>\n",
              "      <td>0.004556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h_Close</th>\n",
              "      <td>0.004556</td>\n",
              "      <td>0.057944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee3c5d9-72ca-4342-9514-909e4599f61d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ee3c5d9-72ca-4342-9514-909e4599f61d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ee3c5d9-72ca-4342-9514-909e4599f61d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkZ69QycGDx",
        "outputId": "2c9d586a-9ff2-4635-f89c-d2c5a9a6851b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n",
            "Variance of Minimum Risk Portfolio : 0.009581\n",
            "S.D. of Minimum Risk Portfolio : 0.097884\n",
            "Weights (showing only those > 0.001000): \n",
            "l_Close\t0.905878\n",
            "h_Close\t0.094122\n",
            "Assets Considered:\n",
            "['l_Close' 'h_Close']\n"
          ]
        }
      ],
      "source": [
        "print_min_variance_portfolio(r, cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvkOfW5-GXpS",
        "outputId": "bef55af4-56b7-4908-cb57-f5e0c796bcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:   0.000000\n"
          ]
        }
      ],
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnMjflTbGaO7",
        "outputId": "eef27242-a41c-4143-9c79-05a255f84b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n"
          ]
        }
      ],
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minRiskWeights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrq0nFRpb8Ml",
        "outputId": "e9c58889-be3d-4384-e454-e1104ea1bc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9058782, 0.0941218])"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kw9InlwDh3v",
        "outputId": "73eed3e5-06c2-415f-af53-6899dc67fce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the  efficient set: (15, 2)\n",
            "Optimal weights of the efficient set portfolios: \n",
            " [[ 9.03663741e-01  9.63362594e-02]\n",
            " [-6.99435915e-06  9.98652333e-01]\n",
            " [-1.45120188e-05  9.97203837e-01]\n",
            " [-2.20296783e-05  9.95755341e-01]\n",
            " [-2.95473998e-05  9.94306844e-01]\n",
            " [-3.70649972e-05  9.92858348e-01]\n",
            " [-4.45826568e-05  9.91409852e-01]\n",
            " [-5.21003162e-05  9.89961356e-01]\n",
            " [-5.96181202e-05  9.88512860e-01]\n",
            " [-6.71356356e-05  9.87064364e-01]\n",
            " [-7.46531138e-05  9.85615867e-01]\n",
            " [-8.21709547e-05  9.84167371e-01]\n",
            " [-8.96888312e-05  9.82718876e-01]\n",
            " [-9.72062735e-05  9.81270379e-01]\n",
            " [-1.04724187e-04  9.79821883e-01]]\n",
            "Annualized Risk and Return of the efficient set portfolios: \n",
            " [[ 0.09788576 -0.14952253]\n",
            " [ 0.24039177 -0.13952253]\n",
            " [ 0.24004295 -0.12952253]\n",
            " [ 0.23969413 -0.11952253]\n",
            " [ 0.23934531 -0.10952253]\n",
            " [ 0.23899649 -0.09952253]\n",
            " [ 0.23864767 -0.08952253]\n",
            " [ 0.23829885 -0.07952253]\n",
            " [ 0.23795003 -0.06952253]\n",
            " [ 0.23760121 -0.05952253]\n",
            " [ 0.2372524  -0.04952253]\n",
            " [ 0.23690358 -0.03952253]\n",
            " [ 0.23655476 -0.02952253]\n",
            " [ 0.23620594 -0.01952253]\n",
            " [ 0.23585712 -0.00952253]]\n"
          ]
        }
      ],
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.01\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "#initialize optimal weight set and risk-return point set\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "#repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "while (low < high):\n",
        "    \n",
        "    result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "    \n",
        "#gather optimal weight set    \n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "#obtain annualized risk for the efficient set portfolios \n",
        "#for trading days = 251\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint) \n",
        "\n",
        "#obtain expected portfolio annualized return for the \n",
        "#efficient set portfolios, for trading days = 251\n",
        "retPoint = np.array(expPortfolioReturnPoint) \n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #compute efficient set for the maximum return and minimum risk portfolios\n",
        "# increment = 0.000001\n",
        "# low = minRiskExpPortfolioReturn\n",
        "# high = maxExpPortfolioReturn\n",
        "\n",
        "# #initialize optimal weight set and risk-return point set\n",
        "# xOptimal =[]\n",
        "# minRiskPoint = []\n",
        "# expPortfolioReturnPoint =[]\n",
        "\n",
        "# #repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "# while (low < high):\n",
        "    \n",
        "#     result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "#     xOptimal.append(result3.x)\n",
        "#     expPortfolioReturnPoint.append(low)\n",
        "#     low = low+increment\n",
        "    \n",
        "# #gather optimal weight set    \n",
        "# xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "# #obtain annualized risk for the efficient set portfolios \n",
        "# #for trading days = 251\n",
        "# minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "#                                      np.transpose(xOptimalArray)))\n",
        "# riskPoint =   np.sqrt(minRiskPoint*trading_days_in_year) \n",
        "\n",
        "# #obtain expected portfolio annualized return for the \n",
        "# #efficient set portfolios, for trading days = 251\n",
        "# retPoint = trading_days_in_year*np.array(expPortfolioReturnPoint) \n",
        "\n",
        "# #display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "# print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "#                                                 np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "id": "CWVcn0qldNvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2_0opIvqHAG1",
        "outputId": "79863e7e-d703-440b-e800-4b69d1be1eaa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Graph Efficient Frontier\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMoyxpN5dY_z"
      },
      "source": [
        "## Naive Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGhdT3AWHGa-"
      },
      "outputs": [],
      "source": [
        "naive_risks = []\n",
        "naive_returns = []\n",
        "\n",
        "for x in np.arange(0, 1, 0.01):\n",
        "  weights = [x, 1-x]\n",
        "  risk = np.matmul((np.matmul(weights,cov)),np.transpose(weights)) * trading_days_in_year\n",
        "  naive_risks.append(np.sqrt(risk))\n",
        "\n",
        "  #obtain expected portfolio annualized return for the \n",
        "  #efficient set portfolios, for trading days = 251\n",
        "  ret = trading_days_in_year*(np.matmul(weights,r))\n",
        "  naive_returns.append(ret)\n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[naive_risks, naive_returns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wJgflp2eJ2c"
      },
      "outputs": [],
      "source": [
        "NoPoints = len(naive_risks)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(naive_risks, naive_returns, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-x_ZCjwg57n"
      },
      "source": [
        "## Combined Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpqNZRCtgYQK"
      },
      "outputs": [],
      "source": [
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(riskPoint, retPoint, s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(naive_risks, naive_returns, s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sTlOQOIhTCZ"
      },
      "outputs": [],
      "source": [
        "cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5N-KuYQxAmQ"
      },
      "outputs": [],
      "source": [
        "print(high_risk[\"Close\"].var())\n",
        "print(high_risk[\"Close\"].var() * trading_days_in_year)\n",
        "print(high_risk[\"Close\"].pct_change().var())\n",
        "print(high_risk[\"Close\"].pct_change().var() * trading_days_in_year)\n",
        "print(np.sqrt(high_risk[\"Close\"].pct_change().var() * trading_days_in_year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU2640mM0RnU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPIaNU4mklVCHZoSWKeIMXD"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}