{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4PiESSn5Wx4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from scipy import optimize \n",
        "from scipy import stats\n",
        "from scipy.optimize import linprog\n",
        "import numpy as np\n",
        "from os import path\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import date\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26v-Cnl1lg6t"
      },
      "outputs": [],
      "source": [
        "MA_DAYS = 25\n",
        "trading_days_in_year = 252"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRi8JtX9gAb0"
      },
      "source": [
        "# Import raw data from yahoo finance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puHUCbHEMIoP",
        "outputId": "9b030a8b-aff3-4bd3-fd70-55c4a613acdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_files_path_prefix = \"/content/drive/MyDrive\"\n",
        "data_files_path = \"ML-Portfolio-Data\"\n",
        "data_files_path = path.join(data_files_path_prefix, data_files_path)\n",
        "\n",
        "high_risk_file = 'SPY.csv'\n",
        "low_risk_file = 'IEF.csv'\n",
        "high_risk = pd.read_csv(path.join(data_files_path, high_risk_file))\n",
        "low_risk = pd.read_csv(path.join(data_files_path, low_risk_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmNxB-dXPdjh"
      },
      "outputs": [],
      "source": [
        "# Read files from the same directory\n",
        "#high_risk = pd.read_csv('SPY.csv')\n",
        "#low_risk = pd.read_csv('IEF.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEp0KCBSE3uX",
        "outputId": "c4ab18db-248a-4678-ba64-697b3eee1f68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5147, 7)\n",
            "(5147, 7)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)\n",
        "print(low_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ffmGB06pT8_q",
        "outputId": "6b5b4b36-5764-4e01-bb4e-bcc4bd9f7b4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close    Volume\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939  47532200\n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453  44669900\n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054  66571900\n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895  51772900\n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496  47191300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae2eb106-edb5-4bfa-981b-7fa2a1b00c27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 290
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DY4FPgNCEssV",
        "outputId": "e64d50dd-d52f-477e-98ab-c82d49d61ee3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300\n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600\n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400\n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300\n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d597fd2-2830-4196-88f7-940c75a27333\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d597fd2-2830-4196-88f7-940c75a27333')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d597fd2-2830-4196-88f7-940c75a27333 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d597fd2-2830-4196-88f7-940c75a27333');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 291
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnPRd0TkrMsN"
      },
      "source": [
        "# Build Dataset for ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvSntSIA4qiC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EZ0sQ3rTgn4"
      },
      "source": [
        "## Enrich data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NraBWrzef4BA"
      },
      "source": [
        "### Calculate daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e03XXEgf1r4"
      },
      "outputs": [],
      "source": [
        "def add_daily_return(market_data):\n",
        "    market_data[\"Daily Return\"]  = market_data['Close'] - market_data['Open']\n",
        "\n",
        "add_daily_return(high_risk)\n",
        "add_daily_return(low_risk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dqBMvFWo4oQ"
      },
      "source": [
        "### Calculate moving average (MA) of daily returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9EW2Fzjo9ly"
      },
      "outputs": [],
      "source": [
        "def add_moving_average(market_data, ma_days):\n",
        "    temp_vars = []\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data[temp_var] = market_data[\"Daily Return\"].shift(i)\n",
        "        temp_vars.append(temp_var)\n",
        "\n",
        "    market_data[\"MA\"] = market_data[temp_vars].mean(axis=1)\n",
        "\n",
        "    for i in range(0,ma_days):\n",
        "        temp_var = \"M_{0}\".format(i)\n",
        "        market_data.drop(temp_var, axis = 1, inplace = True)\n",
        "\n",
        "add_moving_average(high_risk, MA_DAYS)\n",
        "add_moving_average(low_risk, MA_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xp5iRKB4FeRZ",
        "outputId": "fab62ef6-69a0-44b8-9a88-7539e26ddcbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date        Open        High         Low       Close   Adj Close  \\\n",
              "5142  2022-12-30  380.640015  382.579987  378.429993  382.429993  382.429993   \n",
              "5143  2023-01-03  384.369995  386.429993  377.829987  380.820007  380.820007   \n",
              "5144  2023-01-04  383.179993  385.880005  380.000000  383.760010  383.760010   \n",
              "5145  2023-01-05  381.720001  381.839996  378.760010  379.380005  379.380005   \n",
              "5146  2023-01-06  382.609985  389.250000  379.410004  388.079987  388.079987   \n",
              "\n",
              "         Volume  Daily Return        MA  \n",
              "5142   83975100      1.789978 -0.368799  \n",
              "5143   74850700     -3.549988 -0.530798  \n",
              "5144   85934100      0.580017 -0.380398  \n",
              "5145   76970500     -2.339996 -0.441199  \n",
              "5146  104041300      5.470002 -0.709999  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76fc994d-cc76-4254-811d-9980b55f3c7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>380.640015</td>\n",
              "      <td>382.579987</td>\n",
              "      <td>378.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>382.429993</td>\n",
              "      <td>83975100</td>\n",
              "      <td>1.789978</td>\n",
              "      <td>-0.368799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>384.369995</td>\n",
              "      <td>386.429993</td>\n",
              "      <td>377.829987</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>380.820007</td>\n",
              "      <td>74850700</td>\n",
              "      <td>-3.549988</td>\n",
              "      <td>-0.530798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>383.179993</td>\n",
              "      <td>385.880005</td>\n",
              "      <td>380.000000</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>383.760010</td>\n",
              "      <td>85934100</td>\n",
              "      <td>0.580017</td>\n",
              "      <td>-0.380398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>381.720001</td>\n",
              "      <td>381.839996</td>\n",
              "      <td>378.760010</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>379.380005</td>\n",
              "      <td>76970500</td>\n",
              "      <td>-2.339996</td>\n",
              "      <td>-0.441199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>382.609985</td>\n",
              "      <td>389.250000</td>\n",
              "      <td>379.410004</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>388.079987</td>\n",
              "      <td>104041300</td>\n",
              "      <td>5.470002</td>\n",
              "      <td>-0.709999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76fc994d-cc76-4254-811d-9980b55f3c7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76fc994d-cc76-4254-811d-9980b55f3c7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76fc994d-cc76-4254-811d-9980b55f3c7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ],
      "source": [
        "high_risk.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rtkml8ylGG47",
        "outputId": "430db8fc-9fe4-4b1c-a68a-d12228a2cabe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date       Open       High        Low      Close  Adj Close  \\\n",
              "5142  2022-12-30  95.860001  96.269997  95.620003  95.779999  95.779999   \n",
              "5143  2023-01-03  96.910004  97.000000  96.339996  96.529999  96.529999   \n",
              "5144  2023-01-04  97.339996  97.419998  96.989998  97.269997  97.269997   \n",
              "5145  2023-01-05  96.699997  97.220001  96.570000  97.129997  97.129997   \n",
              "5146  2023-01-06  97.169998  98.430000  97.080002  98.379997  98.379997   \n",
              "\n",
              "       Volume  Daily Return        MA  \n",
              "5142  5039800     -0.080002  0.050399  \n",
              "5143  6808300     -0.380005  0.025599  \n",
              "5144  7800100     -0.069999  0.025599  \n",
              "5145  3177900      0.430000  0.043600  \n",
              "5146  6807700      1.209999  0.050399  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f17aae12-720c-45cf-a8e3-b58228d1b59e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.860001</td>\n",
              "      <td>96.269997</td>\n",
              "      <td>95.620003</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>5039800</td>\n",
              "      <td>-0.080002</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.910004</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>96.339996</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>6808300</td>\n",
              "      <td>-0.380005</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.339996</td>\n",
              "      <td>97.419998</td>\n",
              "      <td>96.989998</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>7800100</td>\n",
              "      <td>-0.069999</td>\n",
              "      <td>0.025599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>96.699997</td>\n",
              "      <td>97.220001</td>\n",
              "      <td>96.570000</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>3177900</td>\n",
              "      <td>0.430000</td>\n",
              "      <td>0.043600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>97.169998</td>\n",
              "      <td>98.430000</td>\n",
              "      <td>97.080002</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>6807700</td>\n",
              "      <td>1.209999</td>\n",
              "      <td>0.050399</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f17aae12-720c-45cf-a8e3-b58228d1b59e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f17aae12-720c-45cf-a8e3-b58228d1b59e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f17aae12-720c-45cf-a8e3-b58228d1b59e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ],
      "source": [
        "low_risk.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6a-Fc3EZNxB"
      },
      "source": [
        "### Calculate ROE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42UscmnQZMpE"
      },
      "outputs": [],
      "source": [
        "def add_roe(market_data):    \n",
        "    market_data[\"Next Close\"] = market_data[\"Close\"].shift(-1)\n",
        "    market_data[\"ROE\"] = (market_data[\"Next Close\"] - market_data[\"Close\"]) / market_data['Close']\n",
        "\n",
        "add_roe(high_risk)\n",
        "add_roe(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5kEAXakgkCs"
      },
      "outputs": [],
      "source": [
        "def add_roe_binary(market_data, tau=-0.005):    \n",
        "    market_data[\"ROE Binary\"] = np.where(market_data[\"ROE\"].values < tau, 0, 1)\n",
        "\n",
        "add_roe_binary(high_risk)\n",
        "add_roe_binary(low_risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKK4t3UVfl_6",
        "outputId": "5dee819f-f1d9-4358-97c0-5ad4314a930a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  \\\n",
              "0  2002-07-30  89.320000  91.400002  88.720001  90.940002  61.380939   \n",
              "1  2002-07-31  90.489998  91.550003  89.250000  91.160004  61.529453   \n",
              "2  2002-08-01  90.879997  91.349998  88.330002  88.779999  59.923054   \n",
              "3  2002-08-02  88.500000  88.910004  85.620003  86.790001  58.579895   \n",
              "4  2002-08-05  86.489998  86.930000  83.550003  83.769997  56.541496   \n",
              "\n",
              "     Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0  47532200      1.620002  1.620002   91.160004  0.002419           1  \n",
              "1  44669900      0.670006  1.145004   88.779999 -0.026108           0  \n",
              "2  66571900     -2.099998  0.063337   86.790001 -0.022415           0  \n",
              "3  51772900     -1.709999 -0.379997   83.769997 -0.034797           0  \n",
              "4  47191300     -2.720001 -0.847998   86.589996  0.033664           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-978518de-7f05-4cc8-856c-c619ab4021b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>89.320000</td>\n",
              "      <td>91.400002</td>\n",
              "      <td>88.720001</td>\n",
              "      <td>90.940002</td>\n",
              "      <td>61.380939</td>\n",
              "      <td>47532200</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>1.620002</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>0.002419</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>90.489998</td>\n",
              "      <td>91.550003</td>\n",
              "      <td>89.250000</td>\n",
              "      <td>91.160004</td>\n",
              "      <td>61.529453</td>\n",
              "      <td>44669900</td>\n",
              "      <td>0.670006</td>\n",
              "      <td>1.145004</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.026108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>90.879997</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.330002</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>66571900</td>\n",
              "      <td>-2.099998</td>\n",
              "      <td>0.063337</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>-0.022415</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>88.500000</td>\n",
              "      <td>88.910004</td>\n",
              "      <td>85.620003</td>\n",
              "      <td>86.790001</td>\n",
              "      <td>58.579895</td>\n",
              "      <td>51772900</td>\n",
              "      <td>-1.709999</td>\n",
              "      <td>-0.379997</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>-0.034797</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>86.489998</td>\n",
              "      <td>86.930000</td>\n",
              "      <td>83.550003</td>\n",
              "      <td>83.769997</td>\n",
              "      <td>56.541496</td>\n",
              "      <td>47191300</td>\n",
              "      <td>-2.720001</td>\n",
              "      <td>-0.847998</td>\n",
              "      <td>86.589996</td>\n",
              "      <td>0.033664</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-978518de-7f05-4cc8-856c-c619ab4021b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-978518de-7f05-4cc8-856c-c619ab4021b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-978518de-7f05-4cc8-856c-c619ab4021b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uurD8aCKfmH3",
        "outputId": "a2ad0cca-e97e-41c9-f8f2-a6090714f114"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Open       High        Low      Close  Adj Close  Volume  \\\n",
              "0  2002-07-30  81.940002  82.120003  81.699997  81.769997  45.672558   41300   \n",
              "1  2002-07-31  82.050003  82.580002  82.050003  82.519997  46.091442   32600   \n",
              "2  2002-08-01  82.540001  82.900002  82.519997  82.860001  46.281376   71400   \n",
              "3  2002-08-02  83.019997  83.699997  82.900002  83.500000  46.638828  120300   \n",
              "4  2002-08-05  83.680000  83.919998  83.529999  83.919998  46.873459  159300   \n",
              "\n",
              "   Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "0     -0.170005 -0.170005   82.519997  0.009172           1  \n",
              "1      0.469994  0.149994   82.860001  0.004120           1  \n",
              "2      0.320000  0.206663   83.500000  0.007724           1  \n",
              "3      0.480003  0.274998   83.919998  0.005030           1  \n",
              "4      0.239998  0.267998   83.239998 -0.008103           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2002-07-30</td>\n",
              "      <td>81.940002</td>\n",
              "      <td>82.120003</td>\n",
              "      <td>81.699997</td>\n",
              "      <td>81.769997</td>\n",
              "      <td>45.672558</td>\n",
              "      <td>41300</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>-0.170005</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2002-07-31</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.580002</td>\n",
              "      <td>82.050003</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>46.091442</td>\n",
              "      <td>32600</td>\n",
              "      <td>0.469994</td>\n",
              "      <td>0.149994</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>0.004120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002-08-01</td>\n",
              "      <td>82.540001</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>82.519997</td>\n",
              "      <td>82.860001</td>\n",
              "      <td>46.281376</td>\n",
              "      <td>71400</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>0.206663</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>0.007724</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002-08-02</td>\n",
              "      <td>83.019997</td>\n",
              "      <td>83.699997</td>\n",
              "      <td>82.900002</td>\n",
              "      <td>83.500000</td>\n",
              "      <td>46.638828</td>\n",
              "      <td>120300</td>\n",
              "      <td>0.480003</td>\n",
              "      <td>0.274998</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>0.005030</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2002-08-05</td>\n",
              "      <td>83.680000</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>83.529999</td>\n",
              "      <td>83.919998</td>\n",
              "      <td>46.873459</td>\n",
              "      <td>159300</td>\n",
              "      <td>0.239998</td>\n",
              "      <td>0.267998</td>\n",
              "      <td>83.239998</td>\n",
              "      <td>-0.008103</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-71c276af-ab2a-4d7f-ad21-a6d32fbc185a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L1SeZ_ggNPL"
      },
      "source": [
        "## Build feature space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKS0pN_Ola5g"
      },
      "outputs": [],
      "source": [
        "def remove_for_ma(market_data, ma_days):\n",
        "  return market_data[ma_days:]\n",
        "\n",
        "high_risk = remove_for_ma(high_risk, MA_DAYS)\n",
        "low_risk = remove_for_ma(low_risk, MA_DAYS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnHuHNjPmrQO",
        "outputId": "edf5a6f6-554a-49e5-9027-313f0644fdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5122, 12)\n"
          ]
        }
      ],
      "source": [
        "print(high_risk.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9hQrj2LMVvF5",
        "outputId": "7990b60d-f780-4731-842f-0a7eb69865d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  51099500      0.930000  0.088801   88.779999 -0.008488           0  \n",
              "26  67250900      0.290001  0.073600   90.000000  0.013742           1  \n",
              "27  38622200      0.250000  0.167600   90.660004  0.007333           1  \n",
              "28  33998400      1.560006  0.298400   91.699997  0.011471           1  \n",
              "29  41416600      0.559998  0.429600   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>51099500</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.088801</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>67250900</td>\n",
              "      <td>0.290001</td>\n",
              "      <td>0.073600</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>38622200</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.167600</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>33998400</td>\n",
              "      <td>1.560006</td>\n",
              "      <td>0.298400</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>41416600</td>\n",
              "      <td>0.559998</td>\n",
              "      <td>0.429600</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ac1f5d-d5b5-4bb2-bc33-d16c9c8fb475');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "low_risk.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p3olOzMyWVDI",
        "outputId": "fbef2ff8-6118-4cd5-efe6-23407b6473dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69d00051-9937-4bdf-973d-48b7591486b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69d00051-9937-4bdf-973d-48b7591486b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-69d00051-9937-4bdf-973d-48b7591486b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-69d00051-9937-4bdf-973d-48b7591486b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L7qIEJvdIvp"
      },
      "outputs": [],
      "source": [
        "def standardize_columns(market_data, columns):\n",
        "  for column in columns:\n",
        "    market_data.loc[:,column] = market_data[column]/market_data[column].std()\n",
        "\n",
        "standardize_columns(high_risk, ['Volume', 'Daily Return', 'MA'])\n",
        "standardize_columns(low_risk, ['Volume', 'Daily Return', 'MA'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tqgwASZBIDOa",
        "outputId": "95b569b3-eb6f-4a68-c497-de0ad0cb7f38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  88.610001  90.250000  88.059998  89.540001  60.436001   \n",
              "26  2002-09-05  88.489998  89.430000  87.500000  88.779999  59.923054   \n",
              "27  2002-09-06  89.750000  90.570000  89.339996  90.000000  60.746498   \n",
              "28  2002-09-09  89.099998  91.349998  88.800003  90.660004  61.191929   \n",
              "29  2002-09-10  91.139999  91.779999  90.559998  91.699997  61.893936   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.550024      0.479605  0.276737   88.779999 -0.008488           0  \n",
              "26  0.723874      0.149555  0.229367   90.000000  0.013742           1  \n",
              "27  0.415721      0.128926  0.522307   90.660004  0.007333           1  \n",
              "28  0.365951      0.804501  0.929931   91.699997  0.011471           1  \n",
              "29  0.445799      0.288793  1.338801   91.129997 -0.006216           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>88.610001</td>\n",
              "      <td>90.250000</td>\n",
              "      <td>88.059998</td>\n",
              "      <td>89.540001</td>\n",
              "      <td>60.436001</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>-0.008488</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>88.489998</td>\n",
              "      <td>89.430000</td>\n",
              "      <td>87.500000</td>\n",
              "      <td>88.779999</td>\n",
              "      <td>59.923054</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.013742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>89.750000</td>\n",
              "      <td>90.570000</td>\n",
              "      <td>89.339996</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>60.746498</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>89.099998</td>\n",
              "      <td>91.349998</td>\n",
              "      <td>88.800003</td>\n",
              "      <td>90.660004</td>\n",
              "      <td>61.191929</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>0.011471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>91.139999</td>\n",
              "      <td>91.779999</td>\n",
              "      <td>90.559998</td>\n",
              "      <td>91.699997</td>\n",
              "      <td>61.893936</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>91.129997</td>\n",
              "      <td>-0.006216</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-150f4b99-ee71-4f97-8385-3c46e0a6bc2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 306
        }
      ],
      "source": [
        "high_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q-55dkiIJIal",
        "outputId": "2ea8db78-0839-4dbc-d3b4-4cf4c800620e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Date       Open       High        Low      Close  Adj Close  \\\n",
              "25  2002-09-04  85.160004  85.449997  85.080002  85.199997  47.752071   \n",
              "26  2002-09-05  85.599998  85.650002  85.190002  85.540001  47.942638   \n",
              "27  2002-09-06  85.089996  85.250000  84.839996  84.879997  47.572742   \n",
              "28  2002-09-09  84.940002  85.150002  84.750000  84.760002  47.505463   \n",
              "29  2002-09-10  84.709999  85.209999  84.660004  85.059998  47.673588   \n",
              "\n",
              "      Volume  Daily Return        MA  Next Close       ROE  ROE Binary  \n",
              "25  0.023505      0.135391  0.912126   85.540001  0.003991           1  \n",
              "26  0.017606     -0.203112  0.564337   84.879997 -0.007716           0  \n",
              "27  0.009791     -0.710926  0.216542   84.760002 -0.001414           1  \n",
              "28  0.027002     -0.609368 -0.216563   85.059998  0.003539           1  \n",
              "29  0.006507      1.184878 -0.144378   84.750000 -0.003644           1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acaf1370-1b86-4c17-83e0-01426df1f30b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Daily Return</th>\n",
              "      <th>MA</th>\n",
              "      <th>Next Close</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.160004</td>\n",
              "      <td>85.449997</td>\n",
              "      <td>85.080002</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>47.752071</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>0.003991</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.599998</td>\n",
              "      <td>85.650002</td>\n",
              "      <td>85.190002</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>47.942638</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>-0.007716</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>85.089996</td>\n",
              "      <td>85.250000</td>\n",
              "      <td>84.839996</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>47.572742</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>-0.001414</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.940002</td>\n",
              "      <td>85.150002</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>47.505463</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>0.003539</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>84.709999</td>\n",
              "      <td>85.209999</td>\n",
              "      <td>84.660004</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>47.673588</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>84.750000</td>\n",
              "      <td>-0.003644</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acaf1370-1b86-4c17-83e0-01426df1f30b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acaf1370-1b86-4c17-83e0-01426df1f30b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ],
      "source": [
        "low_risk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "49t7Zc8bKsUQ",
        "outputId": "93af6037-374b-48ef-dc35-1f3e3495a80f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date  l_Daily Return      l_MA  l_Volume  h_Daily Return  \\\n",
              "25    2002-09-04        0.135391  0.912126  0.023505        0.479605   \n",
              "26    2002-09-05       -0.203112  0.564337  0.017606        0.149555   \n",
              "27    2002-09-06       -0.710926  0.216542  0.009791        0.128926   \n",
              "28    2002-09-09       -0.609368 -0.216563  0.027002        0.804501   \n",
              "29    2002-09-10        1.184878 -0.144378  0.006507        0.288793   \n",
              "...          ...             ...       ...       ...             ...   \n",
              "5142  2022-12-30       -0.270837  0.826825  1.532486        0.923099   \n",
              "5143  2023-01-03       -1.286460  0.419968  2.070246       -1.830743   \n",
              "5144  2023-01-04       -0.236973  0.419968  2.371829        0.299117   \n",
              "5145  2023-01-05        1.455712  0.715269  0.966325       -1.206745   \n",
              "5146  2023-01-06        4.096301  0.826824  2.070063        2.820901   \n",
              "\n",
              "          h_MA  h_Volume  h_ROE Binary  \n",
              "25    0.276737  0.550024             0  \n",
              "26    0.229367  0.723874             1  \n",
              "27    0.522307  0.415721             1  \n",
              "28    0.929931  0.365951             1  \n",
              "29    1.338801  0.445799             0  \n",
              "...        ...       ...           ...  \n",
              "5142 -1.149319  0.903889             1  \n",
              "5143 -1.654172  0.805676             1  \n",
              "5144 -1.185467  0.924976             0  \n",
              "5145 -1.374945  0.828493             1  \n",
              "5146 -2.212630  1.119878             1  \n",
              "\n",
              "[5122 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Daily Return</th>\n",
              "      <th>l_MA</th>\n",
              "      <th>l_Volume</th>\n",
              "      <th>h_Daily Return</th>\n",
              "      <th>h_MA</th>\n",
              "      <th>h_Volume</th>\n",
              "      <th>h_ROE Binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>0.135391</td>\n",
              "      <td>0.912126</td>\n",
              "      <td>0.023505</td>\n",
              "      <td>0.479605</td>\n",
              "      <td>0.276737</td>\n",
              "      <td>0.550024</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>-0.203112</td>\n",
              "      <td>0.564337</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>0.149555</td>\n",
              "      <td>0.229367</td>\n",
              "      <td>0.723874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>-0.710926</td>\n",
              "      <td>0.216542</td>\n",
              "      <td>0.009791</td>\n",
              "      <td>0.128926</td>\n",
              "      <td>0.522307</td>\n",
              "      <td>0.415721</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>-0.609368</td>\n",
              "      <td>-0.216563</td>\n",
              "      <td>0.027002</td>\n",
              "      <td>0.804501</td>\n",
              "      <td>0.929931</td>\n",
              "      <td>0.365951</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>1.184878</td>\n",
              "      <td>-0.144378</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.288793</td>\n",
              "      <td>1.338801</td>\n",
              "      <td>0.445799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>-0.270837</td>\n",
              "      <td>0.826825</td>\n",
              "      <td>1.532486</td>\n",
              "      <td>0.923099</td>\n",
              "      <td>-1.149319</td>\n",
              "      <td>0.903889</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>-1.286460</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.070246</td>\n",
              "      <td>-1.830743</td>\n",
              "      <td>-1.654172</td>\n",
              "      <td>0.805676</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>-0.236973</td>\n",
              "      <td>0.419968</td>\n",
              "      <td>2.371829</td>\n",
              "      <td>0.299117</td>\n",
              "      <td>-1.185467</td>\n",
              "      <td>0.924976</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>1.455712</td>\n",
              "      <td>0.715269</td>\n",
              "      <td>0.966325</td>\n",
              "      <td>-1.206745</td>\n",
              "      <td>-1.374945</td>\n",
              "      <td>0.828493</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>4.096301</td>\n",
              "      <td>0.826824</td>\n",
              "      <td>2.070063</td>\n",
              "      <td>2.820901</td>\n",
              "      <td>-2.212630</td>\n",
              "      <td>1.119878</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-511b69a3-c41a-4a9e-99e5-b8ee36dccfa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ],
      "source": [
        "ml_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']]\n",
        "ml_master_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zmM8pF0Nxl4"
      },
      "source": [
        "## Build graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {
        "id": "qjzCkZxbRPke"
      },
      "outputs": [],
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 350\n",
        "torch.manual_seed(42)\n",
        "lambda1 = 1e-3 #0.5\n",
        "lambda2 = 1e-3 #0.5\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjgtH2co3IPg"
      },
      "outputs": [],
      "source": [
        "folds=10\n",
        "splits=KFold(n_splits=folds,shuffle=True,random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUEtsz9ZRRFN"
      },
      "outputs": [],
      "source": [
        "#no cross-validation\n",
        "\n",
        "def train_and_get_a_b(dataset):\n",
        "\n",
        "  a = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "  b = torch.randn((6), requires_grad=True, dtype=torch.double)\n",
        "\n",
        "  optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "  X_tensor = torch.from_numpy(dataset[:,:-1])\n",
        "  Y_tensor = torch.from_numpy(dataset[:,-1])\n",
        "    \n",
        "  for epoch in range(n_epochs):\n",
        "    \n",
        "      yhat = torch.exp(torch.matmul(X_tensor, a)) / (torch.exp (torch.matmul(X_tensor, a)) + torch.exp(torch.matmul(X_tensor, b)))\n",
        "\n",
        "      loss = loss_fn(yhat, Y_tensor)\n",
        "      loss.backward()   \n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "  return a,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R2xXpWs2tus"
      },
      "source": [
        "# Build Dataset for MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "aqbtJ5LC2E7x",
        "outputId": "162f1b1e-5b87-4c52-a484-5d1c52738e11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Date    l_Close     h_Close\n",
              "25    2002-09-04  85.199997   89.540001\n",
              "26    2002-09-05  85.540001   88.779999\n",
              "27    2002-09-06  84.879997   90.000000\n",
              "28    2002-09-09  84.760002   90.660004\n",
              "29    2002-09-10  85.059998   91.699997\n",
              "...          ...        ...         ...\n",
              "5142  2022-12-30  95.779999  382.429993\n",
              "5143  2023-01-03  96.529999  380.820007\n",
              "5144  2023-01-04  97.269997  383.760010\n",
              "5145  2023-01-05  97.129997  379.380005\n",
              "5146  2023-01-06  98.379997  388.079987\n",
              "\n",
              "[5122 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2a34618-c657-430e-ac98-7c7dca5fc38d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Date</th>\n",
              "      <th>l_Close</th>\n",
              "      <th>h_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2002-09-04</td>\n",
              "      <td>85.199997</td>\n",
              "      <td>89.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2002-09-05</td>\n",
              "      <td>85.540001</td>\n",
              "      <td>88.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2002-09-06</td>\n",
              "      <td>84.879997</td>\n",
              "      <td>90.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2002-09-09</td>\n",
              "      <td>84.760002</td>\n",
              "      <td>90.660004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2002-09-10</td>\n",
              "      <td>85.059998</td>\n",
              "      <td>91.699997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>2022-12-30</td>\n",
              "      <td>95.779999</td>\n",
              "      <td>382.429993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>96.529999</td>\n",
              "      <td>380.820007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>2023-01-04</td>\n",
              "      <td>97.269997</td>\n",
              "      <td>383.760010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>2023-01-05</td>\n",
              "      <td>97.129997</td>\n",
              "      <td>379.380005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>2023-01-06</td>\n",
              "      <td>98.379997</td>\n",
              "      <td>388.079987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2a34618-c657-430e-ac98-7c7dca5fc38d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2a34618-c657-430e-ac98-7c7dca5fc38d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ],
      "source": [
        "mv_master_dataset = pd.concat([low_risk.add_prefix('l_'), high_risk.add_prefix('h_')], join='outer', axis=1)[['l_Date','l_Close','h_Close']]\n",
        "mv_master_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekt1011K23kV"
      },
      "outputs": [],
      "source": [
        "def get_mv_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(mv_master_dataset['l_Date']) > startdate) & (pd.to_datetime(mv_master_dataset['l_Date']) <= enddate)\n",
        "  subset = mv_master_dataset.loc[mask]\n",
        "  dataset = subset[['l_Close','h_Close']]\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ay84qKK3kSO"
      },
      "outputs": [],
      "source": [
        "def get_annual_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change()\n",
        "    annual_return = daily_return.mean() * trading_days_in_year\n",
        "    daily_covariance = daily_return.cov()\n",
        "    annual_covariance = daily_covariance * trading_days_in_year\n",
        "    return annual_return, annual_covariance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBzfeFvH32g4"
      },
      "outputs": [],
      "source": [
        "def get_sample_return_and_covariance(data):\n",
        "    daily_return = data.pct_change().mean()\n",
        "    daily_covariance = data.pct_change().cov()\n",
        "    return daily_return * len(data), daily_covariance * len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65SYaxYzFVOi"
      },
      "outputs": [],
      "source": [
        "#function obtains maximal return portfolio using linear programming\n",
        "\n",
        "def MaximizeReturns(MeanReturns, PortfolioSize):\n",
        "   \n",
        "    c = (np.multiply(-1, MeanReturns))\n",
        "    A = np.ones([PortfolioSize,1]).T\n",
        "    b=[1] \n",
        "    res = linprog(c, A_ub = A, b_ub = b, bounds = (0,1), method = 'simplex') \n",
        "    \n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESkZdqjLb_MH"
      },
      "outputs": [],
      "source": [
        "#function obtains minimal risk portfolio \n",
        "\n",
        "def MinimizeRisk(CovarReturns, PortfolioSize):\n",
        "    \n",
        "    def  f(x, CovarReturns):\n",
        "        func = np.matmul(np.matmul(x, CovarReturns), x.T) \n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        A=np.ones(x.shape)\n",
        "        b=1\n",
        "        constraintVal = np.matmul(A,x.T)-b \n",
        "        return constraintVal\n",
        "    \n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq})\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, x0 = xinit, args = (CovarReturns),  bounds = bnds, \\\n",
        "                             constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw2-EUMt4Otu"
      },
      "outputs": [],
      "source": [
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WvoS-8a6YvW"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_data(date):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "    \n",
        "  low_risk_mask = (pd.to_datetime(low_risk['Date']) > startdate) & (pd.to_datetime(low_risk['Date']) <= enddate)\n",
        "  high_risk_mask = (pd.to_datetime(high_risk['Date']) > startdate) & (pd.to_datetime(high_risk['Date']) <= enddate)\n",
        "  low_risk_backtest_data = low_risk.loc[low_risk_mask]\n",
        "  high_risk_backtest_data = high_risk.loc[high_risk_mask]\n",
        "\n",
        "  return low_risk_backtest_data, high_risk_backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGK6T6AW7Yg4"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwpNskex6YvX"
      },
      "outputs": [],
      "source": [
        "def calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, low_risk_weight, high_risk_weight):\n",
        "  low_return = calculate_backtest_return(low_risk_backtest_data)\n",
        "  high_return = calculate_backtest_return(high_risk_backtest_data)\n",
        "  # print(low_return)\n",
        "  # print(high_return)\n",
        "  return low_return * low_risk_weight + high_return * high_risk_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otburto36YvX"
      },
      "outputs": [],
      "source": [
        "def get_mv_backtest_return(date, low_risk_weight, high_risk_weight):\n",
        "  low_risk_backtest_data, high_risk_backtest_data = get_mv_backtest_data(date)\n",
        "  return calculate_mv_backtest_return(low_risk_backtest_data, high_risk_backtest_data, low_risk_weight, high_risk_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYyH6QC07N4X"
      },
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bbj-yDR504Fv"
      },
      "outputs": [],
      "source": [
        "first_date = date(2003,9,21)\n",
        "last_date = date(2023,1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4v4UTD431hJ4"
      },
      "outputs": [],
      "source": [
        "delta_50weeks = timedelta(weeks=50)\n",
        "delta_1week = timedelta(weeks=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKt0kekQ21Ts",
        "outputId": "6685a6b0-c03b-4b12-ca35-af29e1059a87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2003-09-21', '2003-09-28', '2003-10-05', '2003-10-12',\n",
              "               '2003-10-19', '2003-10-26', '2003-11-02', '2003-11-09',\n",
              "               '2003-11-16', '2003-11-23',\n",
              "               ...\n",
              "               '2022-10-30', '2022-11-06', '2022-11-13', '2022-11-20',\n",
              "               '2022-11-27', '2022-12-04', '2022-12-11', '2022-12-18',\n",
              "               '2022-12-25', '2023-01-01'],\n",
              "              dtype='datetime64[ns]', length=1007, freq='W-SUN')"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ],
      "source": [
        "daterange = pd.date_range(first_date, last_date, freq='1W')\n",
        "daterange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV3MvASZ7kOM"
      },
      "outputs": [],
      "source": [
        "def get_ml_dataset_for_date(date):\n",
        "  startdate = pd.to_datetime(date) - delta_50weeks\n",
        "  enddate = pd.to_datetime(date)\n",
        "  mask = (pd.to_datetime(ml_master_dataset['l_Date']) > startdate) & (pd.to_datetime(ml_master_dataset['l_Date']) <= enddate)\n",
        "  subset = ml_master_dataset.loc[mask]\n",
        "  # print(subset)\n",
        "  dataset = subset[['l_Daily Return','l_MA','l_Volume','h_Daily Return','h_MA','h_Volume','h_ROE Binary']].to_numpy()\n",
        "  # print(dataset)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Po5CtXBzyxS"
      },
      "source": [
        "### First date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fra6gOlGT1-v",
        "outputId": "cc4717b7-0df2-47ab-876b-91feddf8ee9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.10155789,  1.89647755,  0.02441736, ..., -0.97480731,\n",
              "         0.57250387,  1.        ],\n",
              "       [ 0.40625526,  1.88335059,  0.04092873, ..., -0.59959326,\n",
              "         0.8560541 ,  0.        ],\n",
              "       [ 0.16925525,  1.88991473,  0.02873525, ..., -0.83893149,\n",
              "         0.86063301,  1.        ],\n",
              "       ...,\n",
              "       [ 0.20311239,  0.702162  ,  0.02435655, ...,  0.53227856,\n",
              "         0.40786757,  1.        ],\n",
              "       [ 1.11718079,  1.03027115,  0.05385199, ...,  0.41510118,\n",
              "         0.3432117 ,  1.        ],\n",
              "       [-0.06772444,  1.33868853,  0.04019894, ...,  0.66191837,\n",
              "         0.32553542,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "dataset = get_ml_dataset_for_date(first_date)\n",
        "dataset[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmWm27_faerS",
        "outputId": "4c142090-c425-46a0-f3e4-e1d54b752aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0. Loss: 1.2250968985965647\n",
            "Epoch: 10. Loss: 1.0422664556524388\n",
            "Epoch: 20. Loss: 0.9103199651473237\n",
            "Epoch: 30. Loss: 0.8211627365206585\n",
            "Epoch: 40. Loss: 0.7621501754153689\n",
            "Epoch: 50. Loss: 0.7225548587061368\n",
            "Epoch: 60. Loss: 0.6954737927837602\n",
            "Epoch: 70. Loss: 0.6767014150071979\n",
            "Epoch: 80. Loss: 0.6635699476207669\n",
            "Epoch: 90. Loss: 0.6543132706623938\n",
            "Epoch: 100. Loss: 0.6477360885029361\n",
            "Epoch: 110. Loss: 0.6430221585728905\n",
            "Epoch: 120. Loss: 0.6396116532648428\n",
            "Epoch: 130. Loss: 0.6371191459597229\n",
            "Epoch: 140. Loss: 0.635278073957452\n",
            "Epoch: 150. Loss: 0.6339030752274836\n",
            "Epoch: 160. Loss: 0.6328644511700781\n",
            "Epoch: 170. Loss: 0.6320708338895114\n",
            "Epoch: 180. Loss: 0.6314573915018703\n",
            "Epoch: 190. Loss: 0.6309777707686528\n",
            "Epoch: 200. Loss: 0.6305985665087154\n",
            "Epoch: 210. Loss: 0.6302955051416969\n",
            "Epoch: 220. Loss: 0.6300507962110538\n",
            "Epoch: 230. Loss: 0.6298512837528443\n",
            "Epoch: 240. Loss: 0.6296871483410416\n",
            "Epoch: 250. Loss: 0.6295509903413822\n",
            "Epoch: 260. Loss: 0.6294371785102312\n",
            "Epoch: 270. Loss: 0.6293413842983838\n",
            "Epoch: 280. Loss: 0.6292602468248716\n",
            "Epoch: 290. Loss: 0.6291911302889445\n",
            "Epoch: 300. Loss: 0.6291319471250912\n",
            "Epoch: 310. Loss: 0.6290810281684981\n",
            "Epoch: 320. Loss: 0.6290370266219606\n",
            "Epoch: 330. Loss: 0.6289988464656815\n",
            "Epoch: 340. Loss: 0.6289655886479608\n",
            "Epoch: 350. Loss: 0.6289365102917657\n",
            "Epoch: 360. Loss: 0.6289109934924184\n",
            "Epoch: 370. Loss: 0.628888521232558\n",
            "Epoch: 380. Loss: 0.6288686586180415\n",
            "Epoch: 390. Loss: 0.6288510381231767\n",
            "Epoch: 400. Loss: 0.628835347881967\n",
            "Epoch: 410. Loss: 0.6288213223134048\n",
            "Epoch: 420. Loss: 0.6288087345510793\n",
            "Epoch: 430. Loss: 0.628797390280147\n",
            "Epoch: 440. Loss: 0.6287871226819385\n",
            "Epoch: 450. Loss: 0.6287777882581012\n",
            "Epoch: 460. Loss: 0.6287692633592182\n",
            "Epoch: 470. Loss: 0.628761441282425\n",
            "Epoch: 480. Loss: 0.628754229832236\n",
            "Epoch: 490. Loss: 0.6287475492612717\n"
          ]
        }
      ],
      "source": [
        "a,b = train_and_get_a_b(dataset[:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMsYhNrSeoDv",
        "outputId": "61e19e31-8e53-4c5d-f6cb-78d1d19b50d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6920, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "  y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "  print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsH_YCVPyOer"
      },
      "outputs": [],
      "source": [
        "def calculate_ml_portfolio_weights(x, k):\n",
        "  return 0 if x < k else 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqJY6MNe079u",
        "outputId": "ccb5fecb-b23d-42e8-fbe7-48a0511ccc95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "weight = calculate_ml_portfolio_weights(y_test.numpy(), 0.5)\n",
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkX6whwN4KX0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_data(date, weight):\n",
        "  startdate = pd.to_datetime(date)\n",
        "  enddate = pd.to_datetime(date) + delta_1week\n",
        "\n",
        "  investment = low_risk if weight == 0 else high_risk\n",
        "    \n",
        "  backtest_mask = (pd.to_datetime(investment['Date']) > startdate) & (pd.to_datetime(investment['Date']) <= enddate)\n",
        "  backtest_data = investment.loc[backtest_mask]\n",
        "\n",
        "  return backtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7grWmruL4LNu"
      },
      "outputs": [],
      "source": [
        "def calculate_backtest_return(backtest_data):\n",
        "  first_open = backtest_data.iloc[0]['Open']\n",
        "  last_close = backtest_data.iloc[-1]['Close']\n",
        "  return (last_close - first_open)/first_open"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGPtDN524CA0"
      },
      "outputs": [],
      "source": [
        "def get_backtest_return(date, weight):\n",
        "  backtest_data = get_backtest_data(date, weight)\n",
        "  return calculate_backtest_return(backtest_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWzbQZb01qHF",
        "outputId": "ab3858d6-c15f-4a08-9339-785658d211c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102.849998"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ],
      "source": [
        "backtest_data = get_backtest_data(first_date, weight)\n",
        "backtest_data.iloc[-1]['Close']\n",
        "backtest_data.iloc[0]['Open']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxw0Vpct44Bq",
        "outputId": "870a2d9c-6aaa-48e1-8ddf-107f586989d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.028196412799152443"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ],
      "source": [
        "get_backtest_return(first_date, weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5v5C2j_0IQw"
      },
      "source": [
        "## Back test for all range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgECBqg00_LI"
      },
      "source": [
        "### ML Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8zIjtzG4xOv",
        "outputId": "fc6f57e5-909b-4bb9-b2ef-db2a2e0d96a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 310. Loss: 0.6136204273991065\n",
            "Epoch: 320. Loss: 0.6136013296178443\n",
            "Epoch: 330. Loss: 0.6135851861977251\n",
            "Epoch: 340. Loss: 0.6135715441278842\n",
            "tensor(0.6905, dtype=torch.float64)\n",
            "2020-06-07 00:00:00\n",
            "Epoch: 0. Loss: 2.358002773478689\n",
            "Epoch: 10. Loss: 1.817617876813826\n",
            "Epoch: 20. Loss: 1.3741913418256335\n",
            "Epoch: 30. Loss: 1.0432007001293422\n",
            "Epoch: 40. Loss: 0.8470154683871246\n",
            "Epoch: 50. Loss: 0.7413323857695766\n",
            "Epoch: 60. Loss: 0.6804685251582273\n",
            "Epoch: 70. Loss: 0.6467306595647399\n",
            "Epoch: 80. Loss: 0.6294039854942947\n",
            "Epoch: 90. Loss: 0.6213532991246847\n",
            "Epoch: 100. Loss: 0.617730418274301\n",
            "Epoch: 110. Loss: 0.6159086536486179\n",
            "Epoch: 120. Loss: 0.614794464790639\n",
            "Epoch: 130. Loss: 0.6139885293756996\n",
            "Epoch: 140. Loss: 0.6133468092134353\n",
            "Epoch: 150. Loss: 0.6128129763235444\n",
            "Epoch: 160. Loss: 0.61236095769948\n",
            "Epoch: 170. Loss: 0.6119757195950082\n",
            "Epoch: 180. Loss: 0.6116467635630298\n",
            "Epoch: 190. Loss: 0.611365839722769\n",
            "Epoch: 200. Loss: 0.6111260816696468\n",
            "Epoch: 210. Loss: 0.6109216340413707\n",
            "Epoch: 220. Loss: 0.610747458264262\n",
            "Epoch: 230. Loss: 0.6105992075584081\n",
            "Epoch: 240. Loss: 0.6104731324605226\n",
            "Epoch: 250. Loss: 0.6103660026055426\n",
            "Epoch: 260. Loss: 0.6102750392199366\n",
            "Epoch: 270. Loss: 0.6101978559302615\n",
            "Epoch: 280. Loss: 0.6101324066438308\n",
            "Epoch: 290. Loss: 0.6100769396868381\n",
            "Epoch: 300. Loss: 0.6100299575515749\n",
            "Epoch: 310. Loss: 0.6099901816786104\n",
            "Epoch: 320. Loss: 0.6099565217442441\n",
            "Epoch: 330. Loss: 0.6099280489602618\n",
            "Epoch: 340. Loss: 0.6099039729290416\n",
            "tensor(0.8557, dtype=torch.float64)\n",
            "2020-06-14 00:00:00\n",
            "Epoch: 0. Loss: 1.4388300525906985\n",
            "Epoch: 10. Loss: 1.2509979441003343\n",
            "Epoch: 20. Loss: 1.091630394746532\n",
            "Epoch: 30. Loss: 0.9580297199822284\n",
            "Epoch: 40. Loss: 0.8489565876090094\n",
            "Epoch: 50. Loss: 0.7634561178970933\n",
            "Epoch: 60. Loss: 0.7010996732689724\n",
            "Epoch: 70. Loss: 0.6604094292540758\n",
            "Epoch: 80. Loss: 0.6374188594479452\n",
            "Epoch: 90. Loss: 0.6262967590090056\n",
            "Epoch: 100. Loss: 0.621503999031075\n",
            "Epoch: 110. Loss: 0.6195234984325092\n",
            "Epoch: 120. Loss: 0.6186867016380172\n",
            "Epoch: 130. Loss: 0.6183064645615076\n",
            "Epoch: 140. Loss: 0.6181122416829408\n",
            "Epoch: 150. Loss: 0.617997792758065\n",
            "Epoch: 160. Loss: 0.6179206930493137\n",
            "Epoch: 170. Loss: 0.6178634140047349\n",
            "Epoch: 180. Loss: 0.6178182669101392\n",
            "Epoch: 190. Loss: 0.617781538915927\n",
            "Epoch: 200. Loss: 0.6177511863370728\n",
            "Epoch: 210. Loss: 0.6177259141708497\n",
            "Epoch: 220. Loss: 0.6177047999941448\n",
            "Epoch: 230. Loss: 0.617687133690905\n",
            "Epoch: 240. Loss: 0.6176723439945568\n",
            "Epoch: 250. Loss: 0.6176599608476316\n",
            "Epoch: 260. Loss: 0.6176495932390133\n",
            "Epoch: 270. Loss: 0.6176409142852868\n",
            "Epoch: 280. Loss: 0.6176336501304566\n",
            "Epoch: 290. Loss: 0.6176275711642759\n",
            "Epoch: 300. Loss: 0.6176224848429824\n",
            "Epoch: 310. Loss: 0.6176182297246168\n",
            "Epoch: 320. Loss: 0.6176146704765595\n",
            "Epoch: 330. Loss: 0.6176116936836966\n",
            "Epoch: 340. Loss: 0.6176092043249217\n",
            "tensor(0.7427, dtype=torch.float64)\n",
            "2020-06-21 00:00:00\n",
            "Epoch: 0. Loss: 0.8967799510406685\n",
            "Epoch: 10. Loss: 0.781783715955925\n",
            "Epoch: 20. Loss: 0.7146672622715314\n",
            "Epoch: 30. Loss: 0.6749626240160397\n",
            "Epoch: 40. Loss: 0.6528350435532483\n",
            "Epoch: 50. Loss: 0.6409210667800465\n",
            "Epoch: 60. Loss: 0.634368092964554\n",
            "Epoch: 70. Loss: 0.6304272820561204\n",
            "Epoch: 80. Loss: 0.6277571636684198\n",
            "Epoch: 90. Loss: 0.6257563194501684\n",
            "Epoch: 100. Loss: 0.6241589674379665\n",
            "Epoch: 110. Loss: 0.6228411158653095\n",
            "Epoch: 120. Loss: 0.6217375564541241\n",
            "Epoch: 130. Loss: 0.6208081094268916\n",
            "Epoch: 140. Loss: 0.6200241479923893\n",
            "Epoch: 150. Loss: 0.6193631820126172\n",
            "Epoch: 160. Loss: 0.6188065944576369\n",
            "Epoch: 170. Loss: 0.6183386069026585\n",
            "Epoch: 180. Loss: 0.6179457288349299\n",
            "Epoch: 190. Loss: 0.6176164040356713\n",
            "Epoch: 200. Loss: 0.6173407441983496\n",
            "Epoch: 210. Loss: 0.6171103077790665\n",
            "Epoch: 220. Loss: 0.6169179078812879\n",
            "Epoch: 230. Loss: 0.616757442646493\n",
            "Epoch: 240. Loss: 0.6166237451322499\n",
            "Epoch: 250. Loss: 0.6165124508520567\n",
            "Epoch: 260. Loss: 0.6164198815040788\n",
            "Epoch: 270. Loss: 0.6163429434922019\n",
            "Epoch: 280. Loss: 0.616279039852301\n",
            "Epoch: 290. Loss: 0.6162259942118095\n",
            "Epoch: 300. Loss: 0.616181985451356\n",
            "Epoch: 310. Loss: 0.6161454918036849\n",
            "Epoch: 320. Loss: 0.6161152432111542\n",
            "Epoch: 330. Loss: 0.6160901808615157\n",
            "Epoch: 340. Loss: 0.616069422925826\n",
            "tensor(0.7277, dtype=torch.float64)\n",
            "2020-06-28 00:00:00\n",
            "Epoch: 0. Loss: 2.453042114609569\n",
            "Epoch: 10. Loss: 1.8008236638715405\n",
            "Epoch: 20. Loss: 1.3164490312949153\n",
            "Epoch: 30. Loss: 0.9386921179741284\n",
            "Epoch: 40. Loss: 0.7112233682982562\n",
            "Epoch: 50. Loss: 0.6485846171480996\n",
            "Epoch: 60. Loss: 0.6297586426000991\n",
            "Epoch: 70. Loss: 0.6226363256904152\n",
            "Epoch: 80. Loss: 0.6201044667787984\n",
            "Epoch: 90. Loss: 0.6192275961594251\n",
            "Epoch: 100. Loss: 0.6188947413336024\n",
            "Epoch: 110. Loss: 0.6187408757080164\n",
            "Epoch: 120. Loss: 0.6186514573900493\n",
            "Epoch: 130. Loss: 0.6185897516805496\n",
            "Epoch: 140. Loss: 0.6185429814357967\n",
            "Epoch: 150. Loss: 0.6185059763403501\n",
            "Epoch: 160. Loss: 0.6184761574979876\n",
            "Epoch: 170. Loss: 0.6184519458802118\n",
            "Epoch: 180. Loss: 0.6184322255635247\n",
            "Epoch: 190. Loss: 0.6184161435805049\n",
            "Epoch: 200. Loss: 0.6184030230886404\n",
            "Epoch: 210. Loss: 0.618392317885209\n",
            "Epoch: 220. Loss: 0.6183835839354254\n",
            "Epoch: 230. Loss: 0.6183764591350014\n",
            "Epoch: 240. Loss: 0.6183706478323462\n",
            "Epoch: 250. Loss: 0.6183659085431863\n",
            "Epoch: 260. Loss: 0.6183620440263917\n",
            "Epoch: 270. Loss: 0.6183588932033613\n",
            "Epoch: 280. Loss: 0.6183563245562412\n",
            "Epoch: 290. Loss: 0.6183542307275289\n",
            "Epoch: 300. Loss: 0.6183525241011288\n",
            "Epoch: 310. Loss: 0.6183511331869698\n",
            "Epoch: 320. Loss: 0.6183499996639679\n",
            "Epoch: 330. Loss: 0.618349075962334\n",
            "Epoch: 340. Loss: 0.6183483232875835\n",
            "tensor(0.7234, dtype=torch.float64)\n",
            "2020-07-05 00:00:00\n",
            "Epoch: 0. Loss: 1.585141726493322\n",
            "Epoch: 10. Loss: 1.2824178222918357\n",
            "Epoch: 20. Loss: 1.0350713638715705\n",
            "Epoch: 30. Loss: 0.8611482687001105\n",
            "Epoch: 40. Loss: 0.7458513939902822\n",
            "Epoch: 50. Loss: 0.6780141864850253\n",
            "Epoch: 60. Loss: 0.641163789676013\n",
            "Epoch: 70. Loss: 0.6234827668712605\n",
            "Epoch: 80. Loss: 0.6164577108026518\n",
            "Epoch: 90. Loss: 0.6140002025078438\n",
            "Epoch: 100. Loss: 0.6131103484612406\n",
            "Epoch: 110. Loss: 0.612715486312923\n",
            "Epoch: 120. Loss: 0.6124872156693307\n",
            "Epoch: 130. Loss: 0.6123276699178949\n",
            "Epoch: 140. Loss: 0.6122055461145541\n",
            "Epoch: 150. Loss: 0.6121087758674864\n",
            "Epoch: 160. Loss: 0.6120312088351683\n",
            "Epoch: 170. Loss: 0.6119688350393775\n",
            "Epoch: 180. Loss: 0.6119186584969292\n",
            "Epoch: 190. Loss: 0.6118783136066954\n",
            "Epoch: 200. Loss: 0.6118458973203712\n",
            "Epoch: 210. Loss: 0.6118198708201767\n",
            "Epoch: 220. Loss: 0.6117989891108448\n",
            "Epoch: 230. Loss: 0.6117822457915086\n",
            "Epoch: 240. Loss: 0.611768828335682\n",
            "Epoch: 250. Loss: 0.6117580815667457\n",
            "Epoch: 260. Loss: 0.6117494778044967\n",
            "Epoch: 270. Loss: 0.6117425925044871\n",
            "Epoch: 280. Loss: 0.611737084423735\n",
            "Epoch: 290. Loss: 0.6117326795076151\n",
            "Epoch: 300. Loss: 0.611729157826539\n",
            "Epoch: 310. Loss: 0.6117263430045917\n",
            "Epoch: 320. Loss: 0.6117240936786877\n",
            "Epoch: 330. Loss: 0.6117222966081808\n",
            "Epoch: 340. Loss: 0.6117208611230869\n",
            "tensor(0.6751, dtype=torch.float64)\n",
            "2020-07-12 00:00:00\n",
            "Epoch: 0. Loss: 1.8429459131613026\n",
            "Epoch: 10. Loss: 0.7146993981916414\n",
            "Epoch: 20. Loss: 0.6243188309673751\n",
            "Epoch: 30. Loss: 0.6166355805864321\n",
            "Epoch: 40. Loss: 0.6147199955109349\n",
            "Epoch: 50. Loss: 0.6140279236771935\n",
            "Epoch: 60. Loss: 0.6137562896548862\n",
            "Epoch: 70. Loss: 0.6136479587768543\n",
            "Epoch: 80. Loss: 0.6136045931143935\n",
            "Epoch: 90. Loss: 0.6135871592513988\n",
            "Epoch: 100. Loss: 0.6135800854147959\n",
            "Epoch: 110. Loss: 0.6135771612990839\n",
            "Epoch: 120. Loss: 0.613575910013522\n",
            "Epoch: 130. Loss: 0.6135753419931365\n",
            "Epoch: 140. Loss: 0.6135750601281739\n",
            "Epoch: 150. Loss: 0.613574903585174\n",
            "Epoch: 160. Loss: 0.6135748060520018\n",
            "Epoch: 170. Loss: 0.6135747392731327\n",
            "Epoch: 180. Loss: 0.6135746905095263\n",
            "Epoch: 190. Loss: 0.6135746535005405\n",
            "Epoch: 200. Loss: 0.6135746248078365\n",
            "Epoch: 210. Loss: 0.6135746023112427\n",
            "Epoch: 220. Loss: 0.6135745845703511\n",
            "Epoch: 230. Loss: 0.6135745705385535\n",
            "Epoch: 240. Loss: 0.6135745594238142\n",
            "Epoch: 250. Loss: 0.6135745506130466\n",
            "Epoch: 260. Loss: 0.6135745436259702\n",
            "Epoch: 270. Loss: 0.6135745380840112\n",
            "Epoch: 280. Loss: 0.6135745336878238\n",
            "Epoch: 290. Loss: 0.6135745302003298\n",
            "Epoch: 300. Loss: 0.6135745274336145\n",
            "Epoch: 310. Loss: 0.613574525238669\n",
            "Epoch: 320. Loss: 0.6135745234973095\n",
            "Epoch: 330. Loss: 0.6135745221157902\n",
            "Epoch: 340. Loss: 0.6135745210197453\n",
            "tensor(0.5498, dtype=torch.float64)\n",
            "2020-07-19 00:00:00\n",
            "Epoch: 0. Loss: 1.443534690183964\n",
            "Epoch: 10. Loss: 0.9351169113126303\n",
            "Epoch: 20. Loss: 0.7647175431680221\n",
            "Epoch: 30. Loss: 0.692385740551756\n",
            "Epoch: 40. Loss: 0.6502848702846468\n",
            "Epoch: 50. Loss: 0.6273424126555476\n",
            "Epoch: 60. Loss: 0.6155631393859943\n",
            "Epoch: 70. Loss: 0.6092427205386053\n",
            "Epoch: 80. Loss: 0.6054227914205773\n",
            "Epoch: 90. Loss: 0.6028317262131951\n",
            "Epoch: 100. Loss: 0.6009393708069738\n",
            "Epoch: 110. Loss: 0.5995015088354834\n",
            "Epoch: 120. Loss: 0.5983863121132112\n",
            "Epoch: 130. Loss: 0.5975115929643384\n",
            "Epoch: 140. Loss: 0.5968208155468413\n",
            "Epoch: 150. Loss: 0.5962727757227526\n",
            "Epoch: 160. Loss: 0.5958364622283371\n",
            "Epoch: 170. Loss: 0.5954881087273106\n",
            "Epoch: 180. Loss: 0.5952093026187988\n",
            "Epoch: 190. Loss: 0.5949856769087524\n",
            "Epoch: 200. Loss: 0.5948059628335809\n",
            "Epoch: 210. Loss: 0.5946612849390182\n",
            "Epoch: 220. Loss: 0.5945446280006306\n",
            "Epoch: 230. Loss: 0.5944504297171315\n",
            "Epoch: 240. Loss: 0.5943742672556228\n",
            "Epoch: 250. Loss: 0.5943126146835594\n",
            "Epoch: 260. Loss: 0.5942626543842667\n",
            "Epoch: 270. Loss: 0.5942221298380811\n",
            "Epoch: 280. Loss: 0.5941892302620787\n",
            "Epoch: 290. Loss: 0.5941624998968345\n",
            "Epoch: 300. Loss: 0.5941407664400963\n",
            "Epoch: 310. Loss: 0.5941230844125965\n",
            "Epoch: 320. Loss: 0.5941086902119714\n",
            "Epoch: 330. Loss: 0.5940969663475041\n",
            "Epoch: 340. Loss: 0.59408741291007\n",
            "tensor(0.6371, dtype=torch.float64)\n",
            "2020-07-26 00:00:00\n",
            "Epoch: 0. Loss: 1.4459193941747779\n",
            "Epoch: 10. Loss: 0.9372787927546852\n",
            "Epoch: 20. Loss: 0.75234466786091\n",
            "Epoch: 30. Loss: 0.6700385846018511\n",
            "Epoch: 40. Loss: 0.6305067993162673\n",
            "Epoch: 50. Loss: 0.6112172496578647\n",
            "Epoch: 60. Loss: 0.6020561445569699\n",
            "Epoch: 70. Loss: 0.5979351016659358\n",
            "Epoch: 80. Loss: 0.5961565357419059\n",
            "Epoch: 90. Loss: 0.5954039933834723\n",
            "Epoch: 100. Loss: 0.5950851153672106\n",
            "Epoch: 110. Loss: 0.5949467008569005\n",
            "Epoch: 120. Loss: 0.5948834108203283\n",
            "Epoch: 130. Loss: 0.5948519032663994\n",
            "Epoch: 140. Loss: 0.5948343414528627\n",
            "Epoch: 150. Loss: 0.594823305050293\n",
            "Epoch: 160. Loss: 0.5948156294598045\n",
            "Epoch: 170. Loss: 0.594809901654392\n",
            "Epoch: 180. Loss: 0.5948054416430931\n",
            "Epoch: 190. Loss: 0.5948018860557077\n",
            "Epoch: 200. Loss: 0.5947990159810922\n",
            "Epoch: 210. Loss: 0.5947966842586813\n",
            "Epoch: 220. Loss: 0.5947947835726015\n",
            "Epoch: 230. Loss: 0.5947932315253118\n",
            "Epoch: 240. Loss: 0.5947919629635408\n",
            "Epoch: 250. Loss: 0.5947909255468693\n",
            "Epoch: 260. Loss: 0.5947900768770561\n",
            "Epoch: 270. Loss: 0.5947893824599537\n",
            "Epoch: 280. Loss: 0.5947888141672256\n",
            "Epoch: 290. Loss: 0.5947883490325123\n",
            "Epoch: 300. Loss: 0.5947879682903564\n",
            "Epoch: 310. Loss: 0.5947876566007458\n",
            "Epoch: 320. Loss: 0.5947874014198943\n",
            "Epoch: 330. Loss: 0.5947871924881414\n",
            "Epoch: 340. Loss: 0.5947870214124689\n",
            "tensor(0.6805, dtype=torch.float64)\n",
            "2020-08-02 00:00:00\n",
            "Epoch: 0. Loss: 1.248976490421301\n",
            "Epoch: 10. Loss: 0.9407325835078207\n",
            "Epoch: 20. Loss: 0.7925947197967258\n",
            "Epoch: 30. Loss: 0.7199168526625853\n",
            "Epoch: 40. Loss: 0.6797572695146636\n",
            "Epoch: 50. Loss: 0.6547725169392247\n",
            "Epoch: 60. Loss: 0.6386502367168092\n",
            "Epoch: 70. Loss: 0.6282663866774013\n",
            "Epoch: 80. Loss: 0.6214728574840496\n",
            "Epoch: 90. Loss: 0.6167633948414325\n",
            "Epoch: 100. Loss: 0.6132364476270034\n",
            "Epoch: 110. Loss: 0.6104200585100134\n",
            "Epoch: 120. Loss: 0.6080803699204743\n",
            "Epoch: 130. Loss: 0.6060980233082405\n",
            "Epoch: 140. Loss: 0.6044050881660158\n",
            "Epoch: 150. Loss: 0.6029565608709208\n",
            "Epoch: 160. Loss: 0.6017183077466998\n",
            "Epoch: 170. Loss: 0.6006621166408731\n",
            "Epoch: 180. Loss: 0.5997636544054378\n",
            "Epoch: 190. Loss: 0.5990015711165513\n",
            "Epoch: 200. Loss: 0.5983570464359665\n",
            "Epoch: 210. Loss: 0.597813504385822\n",
            "Epoch: 220. Loss: 0.597356392974604\n",
            "Epoch: 230. Loss: 0.5969729907635444\n",
            "Epoch: 240. Loss: 0.5966522273123737\n",
            "Epoch: 250. Loss: 0.5963845136464455\n",
            "Epoch: 260. Loss: 0.5961615821597633\n",
            "Epoch: 270. Loss: 0.5959763364049695\n",
            "Epoch: 280. Loss: 0.5958227114139513\n",
            "Epoch: 290. Loss: 0.5956955450678467\n",
            "Epoch: 300. Loss: 0.5955904607984562\n",
            "Epoch: 310. Loss: 0.595503761641019\n",
            "Epoch: 320. Loss: 0.5954323354116521\n",
            "Epoch: 330. Loss: 0.5953735705718946\n",
            "Epoch: 340. Loss: 0.5953252821772085\n",
            "tensor(0.7514, dtype=torch.float64)\n",
            "2020-08-09 00:00:00\n",
            "Epoch: 0. Loss: 2.547135772838615\n",
            "Epoch: 10. Loss: 1.2488583762214374\n",
            "Epoch: 20. Loss: 0.8864270271773046\n",
            "Epoch: 30. Loss: 0.7584364935824358\n",
            "Epoch: 40. Loss: 0.6985290819297145\n",
            "Epoch: 50. Loss: 0.6661256878509675\n",
            "Epoch: 60. Loss: 0.6469638486446303\n",
            "Epoch: 70. Loss: 0.6350807531143924\n",
            "Epoch: 80. Loss: 0.6271112232962267\n",
            "Epoch: 90. Loss: 0.6212272996201714\n",
            "Epoch: 100. Loss: 0.6165250462523398\n",
            "Epoch: 110. Loss: 0.6125773201787449\n",
            "Epoch: 120. Loss: 0.609178535985354\n",
            "Epoch: 130. Loss: 0.6062206760481759\n",
            "Epoch: 140. Loss: 0.6036380248550547\n",
            "Epoch: 150. Loss: 0.601383626420418\n",
            "Epoch: 160. Loss: 0.5994195271188164\n",
            "Epoch: 170. Loss: 0.5977128130602132\n",
            "Epoch: 180. Loss: 0.5962340196763384\n",
            "Epoch: 190. Loss: 0.5949564818836104\n",
            "Epoch: 200. Loss: 0.5938560388870487\n",
            "Epoch: 210. Loss: 0.5929108608629284\n",
            "Epoch: 220. Loss: 0.5921013096218124\n",
            "Epoch: 230. Loss: 0.5914098032800855\n",
            "Epoch: 240. Loss: 0.5908206771662816\n",
            "Epoch: 250. Loss: 0.5903200410290191\n",
            "Epoch: 260. Loss: 0.5898956348953651\n",
            "Epoch: 270. Loss: 0.5895366862020706\n",
            "Epoch: 280. Loss: 0.5892337704697209\n",
            "Epoch: 290. Loss: 0.5889786773139895\n",
            "Epoch: 300. Loss: 0.5887642831462034\n",
            "Epoch: 310. Loss: 0.5885844315388319\n",
            "Epoch: 320. Loss: 0.5884338219135158\n",
            "Epoch: 330. Loss: 0.5883079069372485\n",
            "Epoch: 340. Loss: 0.5882027987774376\n",
            "tensor(0.6550, dtype=torch.float64)\n",
            "2020-08-16 00:00:00\n",
            "Epoch: 0. Loss: 1.2934273148823998\n",
            "Epoch: 10. Loss: 0.8973284213141969\n",
            "Epoch: 20. Loss: 0.7780987044122696\n",
            "Epoch: 30. Loss: 0.7163792363447269\n",
            "Epoch: 40. Loss: 0.676840633326241\n",
            "Epoch: 50. Loss: 0.6511665731924265\n",
            "Epoch: 60. Loss: 0.634192665803831\n",
            "Epoch: 70. Loss: 0.6224923761891681\n",
            "Epoch: 80. Loss: 0.6140802416925566\n",
            "Epoch: 90. Loss: 0.6078370493729462\n",
            "Epoch: 100. Loss: 0.603107102733762\n",
            "Epoch: 110. Loss: 0.5994781473464095\n",
            "Epoch: 120. Loss: 0.5966716540095861\n",
            "Epoch: 130. Loss: 0.5944890004023314\n",
            "Epoch: 140. Loss: 0.5927837712942593\n",
            "Epoch: 150. Loss: 0.5914460654734862\n",
            "Epoch: 160. Loss: 0.5903925901156567\n",
            "Epoch: 170. Loss: 0.5895598556634755\n",
            "Epoch: 180. Loss: 0.588899259866573\n",
            "Epoch: 190. Loss: 0.5883734495306917\n",
            "Epoch: 200. Loss: 0.5879536008009348\n",
            "Epoch: 210. Loss: 0.587617378094026\n",
            "Epoch: 220. Loss: 0.5873473991743752\n",
            "Epoch: 230. Loss: 0.5871300784868317\n",
            "Epoch: 240. Loss: 0.5869547531839748\n",
            "Epoch: 250. Loss: 0.5868130204936141\n",
            "Epoch: 260. Loss: 0.5866982332923372\n",
            "Epoch: 270. Loss: 0.5866051143987004\n",
            "Epoch: 280. Loss: 0.5865294602570716\n",
            "Epoch: 290. Loss: 0.5864679122048655\n",
            "Epoch: 300. Loss: 0.5864177790699644\n",
            "Epoch: 310. Loss: 0.586376898943162\n",
            "Epoch: 320. Loss: 0.5863435309973521\n",
            "Epoch: 330. Loss: 0.5863162704663184\n",
            "Epoch: 340. Loss: 0.5862939815611323\n",
            "tensor(0.6578, dtype=torch.float64)\n",
            "2020-08-23 00:00:00\n",
            "Epoch: 0. Loss: 3.4325211055773734\n",
            "Epoch: 10. Loss: 1.3070343969960616\n",
            "Epoch: 20. Loss: 0.6857052182271831\n",
            "Epoch: 30. Loss: 0.610778052991948\n",
            "Epoch: 40. Loss: 0.5947288441906119\n",
            "Epoch: 50. Loss: 0.5903889888068475\n",
            "Epoch: 60. Loss: 0.5889013214335875\n",
            "Epoch: 70. Loss: 0.5883170644949829\n",
            "Epoch: 80. Loss: 0.5880570844250869\n",
            "Epoch: 90. Loss: 0.5879226964518429\n",
            "Epoch: 100. Loss: 0.5878411198686689\n",
            "Epoch: 110. Loss: 0.5877844884811085\n",
            "Epoch: 120. Loss: 0.58774156034427\n",
            "Epoch: 130. Loss: 0.587707409732939\n",
            "Epoch: 140. Loss: 0.5876795887330764\n",
            "Epoch: 150. Loss: 0.5876566756710537\n",
            "Epoch: 160. Loss: 0.5876377157047561\n",
            "Epoch: 170. Loss: 0.5876219979183241\n",
            "Epoch: 180. Loss: 0.5876089607122922\n",
            "Epoch: 190. Loss: 0.5875981470640887\n",
            "Epoch: 200. Loss: 0.5875891799437631\n",
            "Epoch: 210. Loss: 0.5875817465061283\n",
            "Epoch: 220. Loss: 0.5875755866045204\n",
            "Epoch: 230. Loss: 0.5875704838000837\n",
            "Epoch: 240. Loss: 0.5875662580499944\n",
            "Epoch: 250. Loss: 0.5875627596556973\n",
            "Epoch: 260. Loss: 0.5875598642174263\n",
            "Epoch: 270. Loss: 0.5875574684171154\n",
            "Epoch: 280. Loss: 0.5875554864922782\n",
            "Epoch: 290. Loss: 0.5875538472890894\n",
            "Epoch: 300. Loss: 0.5875524918015699\n",
            "Epoch: 310. Loss: 0.5875513711185947\n",
            "Epoch: 320. Loss: 0.5875504447127162\n",
            "Epoch: 330. Loss: 0.5875496790151344\n",
            "Epoch: 340. Loss: 0.5875490462299219\n",
            "tensor(0.6738, dtype=torch.float64)\n",
            "2020-08-30 00:00:00\n",
            "Epoch: 0. Loss: 1.239986729429578\n",
            "Epoch: 10. Loss: 0.9488155260984493\n",
            "Epoch: 20. Loss: 0.8024807124658905\n",
            "Epoch: 30. Loss: 0.7135089467905952\n",
            "Epoch: 40. Loss: 0.6576464110195342\n",
            "Epoch: 50. Loss: 0.6254618869258706\n",
            "Epoch: 60. Loss: 0.6089909787087933\n",
            "Epoch: 70. Loss: 0.6012073059802825\n",
            "Epoch: 80. Loss: 0.5974763663056362\n",
            "Epoch: 90. Loss: 0.5954663662725801\n",
            "Epoch: 100. Loss: 0.5941872173801928\n",
            "Epoch: 110. Loss: 0.5932498190371317\n",
            "Epoch: 120. Loss: 0.5925020627201628\n",
            "Epoch: 130. Loss: 0.5918805442024198\n",
            "Epoch: 140. Loss: 0.5913548561260242\n",
            "Epoch: 150. Loss: 0.5909073104045538\n",
            "Epoch: 160. Loss: 0.590525593385159\n",
            "Epoch: 170. Loss: 0.590200060065129\n",
            "Epoch: 180. Loss: 0.5899226877904382\n",
            "Epoch: 190. Loss: 0.5896866279083249\n",
            "Epoch: 200. Loss: 0.5894859773435613\n",
            "Epoch: 210. Loss: 0.5893156350103657\n",
            "Epoch: 220. Loss: 0.5891711944647317\n",
            "Epoch: 230. Loss: 0.5890488550768446\n",
            "Epoch: 240. Loss: 0.5889453450422608\n",
            "Epoch: 250. Loss: 0.5888578534935118\n",
            "Epoch: 260. Loss: 0.5887839703760059\n",
            "Epoch: 270. Loss: 0.5887216332484364\n",
            "Epoch: 280. Loss: 0.5886690803460501\n",
            "Epoch: 290. Loss: 0.5886248093158452\n",
            "Epoch: 300. Loss: 0.5885875410706284\n",
            "Epoch: 310. Loss: 0.5885561882393838\n",
            "Epoch: 320. Loss: 0.5885298277224279\n",
            "Epoch: 330. Loss: 0.5885076768930311\n",
            "Epoch: 340. Loss: 0.5884890730221995\n",
            "tensor(0.7010, dtype=torch.float64)\n",
            "2020-09-06 00:00:00\n",
            "Epoch: 0. Loss: 1.2887466566824552\n",
            "Epoch: 10. Loss: 1.011527314885678\n",
            "Epoch: 20. Loss: 0.8289601399867842\n",
            "Epoch: 30. Loss: 0.7222161049299265\n",
            "Epoch: 40. Loss: 0.6699998541018124\n",
            "Epoch: 50. Loss: 0.6468401583989405\n",
            "Epoch: 60. Loss: 0.635748839010878\n",
            "Epoch: 70. Loss: 0.6292009288702191\n",
            "Epoch: 80. Loss: 0.6244802207149521\n",
            "Epoch: 90. Loss: 0.6206556982604647\n",
            "Epoch: 100. Loss: 0.617388698358416\n",
            "Epoch: 110. Loss: 0.6145374267751441\n",
            "Epoch: 120. Loss: 0.6120296907892842\n",
            "Epoch: 130. Loss: 0.6098200594618556\n",
            "Epoch: 140. Loss: 0.6078744691656695\n",
            "Epoch: 150. Loss: 0.6061644104059914\n",
            "Epoch: 160. Loss: 0.6046646745742174\n",
            "Epoch: 170. Loss: 0.6033524643386944\n",
            "Epoch: 180. Loss: 0.6022070241869713\n",
            "Epoch: 190. Loss: 0.6012094613313471\n",
            "Epoch: 200. Loss: 0.6003426295368715\n",
            "Epoch: 210. Loss: 0.5995910288226206\n",
            "Epoch: 220. Loss: 0.5989407055560081\n",
            "Epoch: 230. Loss: 0.5983791494443815\n",
            "Epoch: 240. Loss: 0.5978951881307983\n",
            "Epoch: 250. Loss: 0.5974788812768335\n",
            "Epoch: 260. Loss: 0.5971214160685049\n",
            "Epoch: 270. Loss: 0.5968150057662294\n",
            "Epoch: 280. Loss: 0.5965527925278188\n",
            "Epoch: 290. Loss: 0.5963287553703898\n",
            "Epoch: 300. Loss: 0.5961376238335648\n",
            "Epoch: 310. Loss: 0.5959747976644829\n",
            "Epoch: 320. Loss: 0.5958362726569205\n",
            "Epoch: 330. Loss: 0.5957185726321451\n",
            "Epoch: 340. Loss: 0.5956186874388035\n",
            "tensor(0.7389, dtype=torch.float64)\n",
            "2020-09-13 00:00:00\n",
            "Epoch: 0. Loss: 3.687262980617296\n",
            "Epoch: 10. Loss: 1.76164098226733\n",
            "Epoch: 20. Loss: 0.8661581612462148\n",
            "Epoch: 30. Loss: 0.6645671689347618\n",
            "Epoch: 40. Loss: 0.6356028745434057\n",
            "Epoch: 50. Loss: 0.6236379301328581\n",
            "Epoch: 60. Loss: 0.6167466447257449\n",
            "Epoch: 70. Loss: 0.6121924840560332\n",
            "Epoch: 80. Loss: 0.6089205317393739\n",
            "Epoch: 90. Loss: 0.6064482259629926\n",
            "Epoch: 100. Loss: 0.6045239723405246\n",
            "Epoch: 110. Loss: 0.6029998043170763\n",
            "Epoch: 120. Loss: 0.6017791396117489\n",
            "Epoch: 130. Loss: 0.6007939617900004\n",
            "Epoch: 140. Loss: 0.5999940270858451\n",
            "Epoch: 150. Loss: 0.5993411706498283\n",
            "Epoch: 160. Loss: 0.5988059225698736\n",
            "Epoch: 170. Loss: 0.5983652846880172\n",
            "Epoch: 180. Loss: 0.5980011680935374\n",
            "Epoch: 190. Loss: 0.5976992510926108\n",
            "Epoch: 200. Loss: 0.5974481264641583\n",
            "Epoch: 210. Loss: 0.5972386569489903\n",
            "Epoch: 220. Loss: 0.5970634842283498\n",
            "Epoch: 230. Loss: 0.5969166524537748\n",
            "Epoch: 240. Loss: 0.5967933179007578\n",
            "Epoch: 250. Loss: 0.5966895237324346\n",
            "Epoch: 260. Loss: 0.5966020242398815\n",
            "Epoch: 270. Loss: 0.5965281468780188\n",
            "Epoch: 280. Loss: 0.5964656833344623\n",
            "Epoch: 290. Loss: 0.5964128030294158\n",
            "Epoch: 300. Loss: 0.5963679840485908\n",
            "Epoch: 310. Loss: 0.5963299577053168\n",
            "Epoch: 320. Loss: 0.5962976638205597\n",
            "Epoch: 330. Loss: 0.596270214479664\n",
            "Epoch: 340. Loss: 0.5962468645302713\n",
            "tensor(0.5940, dtype=torch.float64)\n",
            "2020-09-20 00:00:00\n",
            "Epoch: 0. Loss: 2.3726011317148736\n",
            "Epoch: 10. Loss: 1.1478249011362218\n",
            "Epoch: 20. Loss: 0.737803389843153\n",
            "Epoch: 30. Loss: 0.6725980089422827\n",
            "Epoch: 40. Loss: 0.655557741505235\n",
            "Epoch: 50. Loss: 0.6472688372470071\n",
            "Epoch: 60. Loss: 0.6415945517475095\n",
            "Epoch: 70. Loss: 0.6369506342439128\n",
            "Epoch: 80. Loss: 0.6328615682185812\n",
            "Epoch: 90. Loss: 0.6291637723883717\n",
            "Epoch: 100. Loss: 0.625789351466111\n",
            "Epoch: 110. Loss: 0.6227025477073163\n",
            "Epoch: 120. Loss: 0.6198793639978502\n",
            "Epoch: 130. Loss: 0.6173005048759971\n",
            "Epoch: 140. Loss: 0.614948785571505\n",
            "Epoch: 150. Loss: 0.6128081530352268\n",
            "Epoch: 160. Loss: 0.6108633245127847\n",
            "Epoch: 170. Loss: 0.6090996721711183\n",
            "Epoch: 180. Loss: 0.6075032055862164\n",
            "Epoch: 190. Loss: 0.6060605896494689\n",
            "Epoch: 200. Loss: 0.6047591707046623\n",
            "Epoch: 210. Loss: 0.6035869991446131\n",
            "Epoch: 220. Loss: 0.6025328437768981\n",
            "Epoch: 230. Loss: 0.6015861966250926\n",
            "Epoch: 240. Loss: 0.6007372684371799\n",
            "Epoch: 250. Loss: 0.5999769759168071\n",
            "Epoch: 260. Loss: 0.5992969219970671\n",
            "Epoch: 270. Loss: 0.5986893705486036\n",
            "Epoch: 280. Loss: 0.5981472168618718\n",
            "Epoch: 290. Loss: 0.5976639551262077\n",
            "Epoch: 300. Loss: 0.5972336439799929\n",
            "Epoch: 310. Loss: 0.5968508710471617\n",
            "Epoch: 320. Loss: 0.5965107172183025\n",
            "Epoch: 330. Loss: 0.5962087212873891\n",
            "Epoch: 340. Loss: 0.5959408454221808\n",
            "tensor(0.6092, dtype=torch.float64)\n",
            "2020-09-27 00:00:00\n",
            "Epoch: 0. Loss: 2.475043345037162\n",
            "Epoch: 10. Loss: 1.1337067490254926\n",
            "Epoch: 20. Loss: 0.7547178310676264\n",
            "Epoch: 30. Loss: 0.6590259097655362\n",
            "Epoch: 40. Loss: 0.6218747159867519\n",
            "Epoch: 50. Loss: 0.6068937547351752\n",
            "Epoch: 60. Loss: 0.6008621661728689\n",
            "Epoch: 70. Loss: 0.5983792370583212\n",
            "Epoch: 80. Loss: 0.5973333205065098\n",
            "Epoch: 90. Loss: 0.5968744154727504\n",
            "Epoch: 100. Loss: 0.5966557701835572\n",
            "Epoch: 110. Loss: 0.596537044055334\n",
            "Epoch: 120. Loss: 0.5964619593616534\n",
            "Epoch: 130. Loss: 0.5964078799189154\n",
            "Epoch: 140. Loss: 0.5963654583681498\n",
            "Epoch: 150. Loss: 0.596330583012504\n",
            "Epoch: 160. Loss: 0.5963012322011064\n",
            "Epoch: 170. Loss: 0.5962762510278596\n",
            "Epoch: 180. Loss: 0.5962548726430631\n",
            "Epoch: 190. Loss: 0.5962365267095382\n",
            "Epoch: 200. Loss: 0.5962207589027506\n",
            "Epoch: 210. Loss: 0.5962071939238444\n",
            "Epoch: 220. Loss: 0.5961955160949233\n",
            "Epoch: 230. Loss: 0.596185457498604\n",
            "Epoch: 240. Loss: 0.5961767896997652\n",
            "Epoch: 250. Loss: 0.5961693174226987\n",
            "Epoch: 260. Loss: 0.5961628734659797\n",
            "Epoch: 270. Loss: 0.5961573145006714\n",
            "Epoch: 280. Loss: 0.5961525175500125\n",
            "Epoch: 290. Loss: 0.5961483770184205\n",
            "Epoch: 300. Loss: 0.5961448021736281\n",
            "Epoch: 310. Loss: 0.5961417150071812\n",
            "Epoch: 320. Loss: 0.5961390484129921\n",
            "Epoch: 330. Loss: 0.5961367446343474\n",
            "Epoch: 340. Loss: 0.5961347539381279\n",
            "tensor(0.4649, dtype=torch.float64)\n",
            "2020-10-04 00:00:00\n",
            "Epoch: 0. Loss: 2.670082597889688\n",
            "Epoch: 10. Loss: 1.4579429544222051\n",
            "Epoch: 20. Loss: 0.927912243607329\n",
            "Epoch: 30. Loss: 0.7411218727761422\n",
            "Epoch: 40. Loss: 0.6710360679157487\n",
            "Epoch: 50. Loss: 0.638340739872692\n",
            "Epoch: 60. Loss: 0.6228698117446605\n",
            "Epoch: 70. Loss: 0.6155151182979381\n",
            "Epoch: 80. Loss: 0.611682618666335\n",
            "Epoch: 90. Loss: 0.6093516498544339\n",
            "Epoch: 100. Loss: 0.6077305628864627\n",
            "Epoch: 110. Loss: 0.6065106277305936\n",
            "Epoch: 120. Loss: 0.6055565955615575\n",
            "Epoch: 130. Loss: 0.6047967145121673\n",
            "Epoch: 140. Loss: 0.6041855668626305\n",
            "Epoch: 150. Loss: 0.6036910114624638\n",
            "Epoch: 160. Loss: 0.6032889654598201\n",
            "Epoch: 170. Loss: 0.6029608759492634\n",
            "Epoch: 180. Loss: 0.6026922410248197\n",
            "Epoch: 190. Loss: 0.6024716239140664\n",
            "Epoch: 200. Loss: 0.6022899464555811\n",
            "Epoch: 210. Loss: 0.6021399638864607\n",
            "Epoch: 220. Loss: 0.6020158669233361\n",
            "Epoch: 230. Loss: 0.601912976913713\n",
            "Epoch: 240. Loss: 0.6018275104759642\n",
            "Epoch: 250. Loss: 0.601756396642606\n",
            "Epoch: 260. Loss: 0.6016971339911436\n",
            "Epoch: 270. Loss: 0.60164767842423\n",
            "Epoch: 280. Loss: 0.6016063545757073\n",
            "Epoch: 290. Loss: 0.6015717855275013\n",
            "Epoch: 300. Loss: 0.6015428367930731\n",
            "Epoch: 310. Loss: 0.6015185714738178\n",
            "Epoch: 320. Loss: 0.6014982142095991\n",
            "Epoch: 330. Loss: 0.6014811220847123\n",
            "Epoch: 340. Loss: 0.6014667610606755\n",
            "tensor(0.5393, dtype=torch.float64)\n",
            "2020-10-11 00:00:00\n",
            "Epoch: 0. Loss: 2.347846657917899\n",
            "Epoch: 10. Loss: 1.7876549025316275\n",
            "Epoch: 20. Loss: 1.3881716319183768\n",
            "Epoch: 30. Loss: 1.1136036832543397\n",
            "Epoch: 40. Loss: 0.9197981017018539\n",
            "Epoch: 50. Loss: 0.7922145295072394\n",
            "Epoch: 60. Loss: 0.718386379381897\n",
            "Epoch: 70. Loss: 0.6791054405721989\n",
            "Epoch: 80. Loss: 0.6576670536371422\n",
            "Epoch: 90. Loss: 0.6444699234282666\n",
            "Epoch: 100. Loss: 0.6352187312464234\n",
            "Epoch: 110. Loss: 0.6281964023513124\n",
            "Epoch: 120. Loss: 0.6226866341239314\n",
            "Epoch: 130. Loss: 0.6183206250746395\n",
            "Epoch: 140. Loss: 0.6148543347216501\n",
            "Epoch: 150. Loss: 0.6121013480791219\n",
            "Epoch: 160. Loss: 0.6099128361773313\n",
            "Epoch: 170. Loss: 0.608169693944555\n",
            "Epoch: 180. Loss: 0.6067773967873639\n",
            "Epoch: 190. Loss: 0.6056615542799745\n",
            "Epoch: 200. Loss: 0.6047639493751967\n",
            "Epoch: 210. Loss: 0.6040391399567276\n",
            "Epoch: 220. Loss: 0.6034516570487132\n",
            "Epoch: 230. Loss: 0.6029737639818832\n",
            "Epoch: 240. Loss: 0.6025837009861822\n",
            "Epoch: 250. Loss: 0.6022643278922032\n",
            "Epoch: 260. Loss: 0.6020020822534274\n",
            "Epoch: 270. Loss: 0.6017861819921605\n",
            "Epoch: 280. Loss: 0.6016080151472394\n",
            "Epoch: 290. Loss: 0.6014606717905894\n",
            "Epoch: 300. Loss: 0.6013385836803313\n",
            "Epoch: 310. Loss: 0.6012372455838442\n",
            "Epoch: 320. Loss: 0.6011529986603367\n",
            "Epoch: 330. Loss: 0.6010828611816161\n",
            "Epoch: 340. Loss: 0.6010243955326527\n",
            "tensor(0.5494, dtype=torch.float64)\n",
            "2020-10-18 00:00:00\n",
            "Epoch: 0. Loss: 1.265281531239551\n",
            "Epoch: 10. Loss: 1.0115360403063385\n",
            "Epoch: 20. Loss: 0.838689576738918\n",
            "Epoch: 30. Loss: 0.7212402547477768\n",
            "Epoch: 40. Loss: 0.65591695237751\n",
            "Epoch: 50. Loss: 0.6269274426918167\n",
            "Epoch: 60. Loss: 0.6156168302099928\n",
            "Epoch: 70. Loss: 0.6114026541499832\n",
            "Epoch: 80. Loss: 0.6098632052643916\n",
            "Epoch: 90. Loss: 0.6092937157423743\n",
            "Epoch: 100. Loss: 0.6090671906651512\n",
            "Epoch: 110. Loss: 0.6089628049446796\n",
            "Epoch: 120. Loss: 0.6089042917488021\n",
            "Epoch: 130. Loss: 0.6088650860188862\n",
            "Epoch: 140. Loss: 0.6088355671425341\n",
            "Epoch: 150. Loss: 0.6088119541741148\n",
            "Epoch: 160. Loss: 0.6087925372268809\n",
            "Epoch: 170. Loss: 0.6087763829073616\n",
            "Epoch: 180. Loss: 0.6087628800536488\n",
            "Epoch: 190. Loss: 0.6087515744011143\n",
            "Epoch: 200. Loss: 0.6087421041945983\n",
            "Epoch: 210. Loss: 0.6087341719144022\n",
            "Epoch: 220. Loss: 0.6087275294811596\n",
            "Epoch: 230. Loss: 0.6087219689149761\n",
            "Epoch: 240. Loss: 0.6087173155308941\n",
            "Epoch: 250. Loss: 0.6087134225557718\n",
            "Epoch: 260. Loss: 0.6087101666976815\n",
            "Epoch: 270. Loss: 0.6087074444369942\n",
            "Epoch: 280. Loss: 0.6087051689012791\n",
            "Epoch: 290. Loss: 0.6087032672267593\n",
            "Epoch: 300. Loss: 0.6087016783301766\n",
            "Epoch: 310. Loss: 0.6087003510282863\n",
            "Epoch: 320. Loss: 0.6086992424520388\n",
            "Epoch: 330. Loss: 0.6086983167104562\n",
            "Epoch: 340. Loss: 0.6086975437658607\n",
            "tensor(0.6211, dtype=torch.float64)\n",
            "2020-10-25 00:00:00\n",
            "Epoch: 0. Loss: 2.996143912427898\n",
            "Epoch: 10. Loss: 2.4481653970457944\n",
            "Epoch: 20. Loss: 1.9759126816608645\n",
            "Epoch: 30. Loss: 1.6548697764689313\n",
            "Epoch: 40. Loss: 1.404062705683251\n",
            "Epoch: 50. Loss: 1.187018797859716\n",
            "Epoch: 60. Loss: 1.0045271863008927\n",
            "Epoch: 70. Loss: 0.8608371933026285\n",
            "Epoch: 80. Loss: 0.7585220415537225\n",
            "Epoch: 90. Loss: 0.6924380761340287\n",
            "Epoch: 100. Loss: 0.6533075141963903\n",
            "Epoch: 110. Loss: 0.6320090554881426\n",
            "Epoch: 120. Loss: 0.6213593589781865\n",
            "Epoch: 130. Loss: 0.6164403412719018\n",
            "Epoch: 140. Loss: 0.6142301838825742\n",
            "Epoch: 150. Loss: 0.6131739238634187\n",
            "Epoch: 160. Loss: 0.612595364394798\n",
            "Epoch: 170. Loss: 0.6122264437868721\n",
            "Epoch: 180. Loss: 0.6119625356290197\n",
            "Epoch: 190. Loss: 0.6117605425332461\n",
            "Epoch: 200. Loss: 0.6116004719807862\n",
            "Epoch: 210. Loss: 0.6114714345785469\n",
            "Epoch: 220. Loss: 0.6113665110999352\n",
            "Epoch: 230. Loss: 0.611280790450383\n",
            "Epoch: 240. Loss: 0.6112105534004093\n",
            "Epoch: 250. Loss: 0.6111528854999442\n",
            "Epoch: 260. Loss: 0.6111054624231802\n",
            "Epoch: 270. Loss: 0.6110664128529886\n",
            "Epoch: 280. Loss: 0.611034221732272\n",
            "Epoch: 290. Loss: 0.6110076578533543\n",
            "Epoch: 300. Loss: 0.6109857178907787\n",
            "Epoch: 310. Loss: 0.6109675823789767\n",
            "Epoch: 320. Loss: 0.6109525807328974\n",
            "Epoch: 330. Loss: 0.610940163273138\n",
            "Epoch: 340. Loss: 0.6109298787487015\n",
            "tensor(0.6793, dtype=torch.float64)\n",
            "2020-11-01 00:00:00\n",
            "Epoch: 0. Loss: 0.8807200552517468\n",
            "Epoch: 10. Loss: 0.7546141481633374\n",
            "Epoch: 20. Loss: 0.6859124095141101\n",
            "Epoch: 30. Loss: 0.6523916763623913\n",
            "Epoch: 40. Loss: 0.6350155666937193\n",
            "Epoch: 50. Loss: 0.6261694272470856\n",
            "Epoch: 60. Loss: 0.6218167962767313\n",
            "Epoch: 70. Loss: 0.6196188220198181\n",
            "Epoch: 80. Loss: 0.6183999716457064\n",
            "Epoch: 90. Loss: 0.6176359226481867\n",
            "Epoch: 100. Loss: 0.6171045703675688\n",
            "Epoch: 110. Loss: 0.6167096188538471\n",
            "Epoch: 120. Loss: 0.6164051803368219\n",
            "Epoch: 130. Loss: 0.6161660870364903\n",
            "Epoch: 140. Loss: 0.6159764753501309\n",
            "Epoch: 150. Loss: 0.6158252770265505\n",
            "Epoch: 160. Loss: 0.6157042890937955\n",
            "Epoch: 170. Loss: 0.6156072327330763\n",
            "Epoch: 180. Loss: 0.6155292198456119\n",
            "Epoch: 190. Loss: 0.6154664091826306\n",
            "Epoch: 200. Loss: 0.6154157647044555\n",
            "Epoch: 210. Loss: 0.6153748771414285\n",
            "Epoch: 220. Loss: 0.6153418286394211\n",
            "Epoch: 230. Loss: 0.6153150885527678\n",
            "Epoch: 240. Loss: 0.6152934324994381\n",
            "Epoch: 250. Loss: 0.6152758791059157\n",
            "Epoch: 260. Loss: 0.615261640349424\n",
            "Epoch: 270. Loss: 0.6152500824269095\n",
            "Epoch: 280. Loss: 0.615240694817433\n",
            "Epoch: 290. Loss: 0.61523306575004\n",
            "Epoch: 300. Loss: 0.6152268626986436\n",
            "Epoch: 310. Loss: 0.6152218168357997\n",
            "Epoch: 320. Loss: 0.6152177106140795\n",
            "Epoch: 330. Loss: 0.6152143678255103\n",
            "Epoch: 340. Loss: 0.6152116456297053\n",
            "tensor(0.5831, dtype=torch.float64)\n",
            "2020-11-08 00:00:00\n",
            "Epoch: 0. Loss: 1.678297718406967\n",
            "Epoch: 10. Loss: 1.2640957708126341\n",
            "Epoch: 20. Loss: 1.0365748417616953\n",
            "Epoch: 30. Loss: 0.8866525458694535\n",
            "Epoch: 40. Loss: 0.778101079896126\n",
            "Epoch: 50. Loss: 0.7031094533692775\n",
            "Epoch: 60. Loss: 0.6594331550681531\n",
            "Epoch: 70. Loss: 0.6390121619871323\n",
            "Epoch: 80. Loss: 0.6304473442214842\n",
            "Epoch: 90. Loss: 0.6265112478246865\n",
            "Epoch: 100. Loss: 0.6242916261925057\n",
            "Epoch: 110. Loss: 0.6227799731991271\n",
            "Epoch: 120. Loss: 0.6216214331317651\n",
            "Epoch: 130. Loss: 0.6206798631761022\n",
            "Epoch: 140. Loss: 0.6198949706680743\n",
            "Epoch: 150. Loss: 0.6192343179076374\n",
            "Epoch: 160. Loss: 0.6186766565216046\n",
            "Epoch: 170. Loss: 0.6182059429624384\n",
            "Epoch: 180. Loss: 0.6178090891027863\n",
            "Epoch: 190. Loss: 0.6174750424812052\n",
            "Epoch: 200. Loss: 0.617194348012855\n",
            "Epoch: 210. Loss: 0.6169588896276796\n",
            "Epoch: 220. Loss: 0.6167617044857568\n",
            "Epoch: 230. Loss: 0.6165968315594007\n",
            "Epoch: 240. Loss: 0.6164591808446463\n",
            "Epoch: 250. Loss: 0.6163444180067589\n",
            "Epoch: 260. Loss: 0.6162488621742582\n",
            "Epoch: 270. Loss: 0.6161693955490891\n",
            "Epoch: 280. Loss: 0.6161033837955482\n",
            "Epoch: 290. Loss: 0.6160486062586727\n",
            "Epoch: 300. Loss: 0.6160031950964516\n",
            "Epoch: 310. Loss: 0.6159655824381828\n",
            "Epoch: 320. Loss: 0.6159344547170209\n",
            "Epoch: 330. Loss: 0.615908713370063\n",
            "Epoch: 340. Loss: 0.6158874411525048\n",
            "tensor(0.7012, dtype=torch.float64)\n",
            "2020-11-15 00:00:00\n",
            "Epoch: 0. Loss: 1.461977877930106\n",
            "Epoch: 10. Loss: 0.9111414823351701\n",
            "Epoch: 20. Loss: 0.7153465792433978\n",
            "Epoch: 30. Loss: 0.6639287431035756\n",
            "Epoch: 40. Loss: 0.6506968373974011\n",
            "Epoch: 50. Loss: 0.6441745111398351\n",
            "Epoch: 60. Loss: 0.6394952337954146\n",
            "Epoch: 70. Loss: 0.6356581029043756\n",
            "Epoch: 80. Loss: 0.6323827274106164\n",
            "Epoch: 90. Loss: 0.6295570283091556\n",
            "Epoch: 100. Loss: 0.6271154868222842\n",
            "Epoch: 110. Loss: 0.6250087454655356\n",
            "Epoch: 120. Loss: 0.6231950947543899\n",
            "Epoch: 130. Loss: 0.6216377907051215\n",
            "Epoch: 140. Loss: 0.6203040763602017\n",
            "Epoch: 150. Loss: 0.6191647287075094\n",
            "Epoch: 160. Loss: 0.6181937648352395\n",
            "Epoch: 170. Loss: 0.6173681901054514\n",
            "Epoch: 180. Loss: 0.6166677537212851\n",
            "Epoch: 190. Loss: 0.6160747051770081\n",
            "Epoch: 200. Loss: 0.6155735539794946\n",
            "Epoch: 210. Loss: 0.6151508369745297\n",
            "Epoch: 220. Loss: 0.6147948971601122\n",
            "Epoch: 230. Loss: 0.6144956767611797\n",
            "Epoch: 240. Loss: 0.6142445262200137\n",
            "Epoch: 250. Loss: 0.614034029831154\n",
            "Epoch: 260. Loss: 0.6138578480546838\n",
            "Epoch: 270. Loss: 0.6137105760515714\n",
            "Epoch: 280. Loss: 0.6135876176575965\n",
            "Epoch: 290. Loss: 0.6134850738081218\n",
            "Epoch: 300. Loss: 0.6133996443115025\n",
            "Epoch: 310. Loss: 0.6133285418190321\n",
            "Epoch: 320. Loss: 0.6132694168352918\n",
            "Epoch: 330. Loss: 0.6132202926409661\n",
            "Epoch: 340. Loss: 0.6131795090505489\n",
            "tensor(0.5742, dtype=torch.float64)\n",
            "2020-11-22 00:00:00\n",
            "Epoch: 0. Loss: 1.8597332606821952\n",
            "Epoch: 10. Loss: 0.8884914524873943\n",
            "Epoch: 20. Loss: 0.6893482973711457\n",
            "Epoch: 30. Loss: 0.6621116627418221\n",
            "Epoch: 40. Loss: 0.6492009513210517\n",
            "Epoch: 50. Loss: 0.6407565442175697\n",
            "Epoch: 60. Loss: 0.6347611770094954\n",
            "Epoch: 70. Loss: 0.6303284681446448\n",
            "Epoch: 80. Loss: 0.6269737685847044\n",
            "Epoch: 90. Loss: 0.6244005542615861\n",
            "Epoch: 100. Loss: 0.6224107763254247\n",
            "Epoch: 110. Loss: 0.620863721332702\n",
            "Epoch: 120. Loss: 0.619655722904854\n",
            "Epoch: 130. Loss: 0.6187089424182216\n",
            "Epoch: 140. Loss: 0.6179643458607657\n",
            "Epoch: 150. Loss: 0.6173768864260567\n",
            "Epoch: 160. Loss: 0.6169120287432014\n",
            "Epoch: 170. Loss: 0.6165431823738329\n",
            "Epoch: 180. Loss: 0.6162497880290697\n",
            "Epoch: 190. Loss: 0.616015883727404\n",
            "Epoch: 200. Loss: 0.6158290268282596\n",
            "Epoch: 210. Loss: 0.615679480727542\n",
            "Epoch: 220. Loss: 0.6155595987629446\n",
            "Epoch: 230. Loss: 0.6154633554347066\n",
            "Epoch: 240. Loss: 0.6153859880435607\n",
            "Epoch: 250. Loss: 0.6153237214337212\n",
            "Epoch: 260. Loss: 0.615273555577538\n",
            "Epoch: 270. Loss: 0.6152331009152165\n",
            "Epoch: 280. Loss: 0.6152004501680434\n",
            "Epoch: 290. Loss: 0.6151740781473886\n",
            "Epoch: 300. Loss: 0.6151527631555586\n",
            "Epoch: 310. Loss: 0.6151355251155155\n",
            "Epoch: 320. Loss: 0.615121576717324\n",
            "Epoch: 330. Loss: 0.6151102847333496\n",
            "Epoch: 340. Loss: 0.615101139306663\n",
            "tensor(0.8009, dtype=torch.float64)\n",
            "2020-11-29 00:00:00\n",
            "Epoch: 0. Loss: 1.6045979687899008\n",
            "Epoch: 10. Loss: 0.8791029915227239\n",
            "Epoch: 20. Loss: 0.6928283615164985\n",
            "Epoch: 30. Loss: 0.6450775196574073\n",
            "Epoch: 40. Loss: 0.6330871103411551\n",
            "Epoch: 50. Loss: 0.6288080173502654\n",
            "Epoch: 60. Loss: 0.6264067967116129\n",
            "Epoch: 70. Loss: 0.6246470382010966\n",
            "Epoch: 80. Loss: 0.6232269990512314\n",
            "Epoch: 90. Loss: 0.6220501944575366\n",
            "Epoch: 100. Loss: 0.6210697809913126\n",
            "Epoch: 110. Loss: 0.6202534786691744\n",
            "Epoch: 120. Loss: 0.6195752485995991\n",
            "Epoch: 130. Loss: 0.619013082118136\n",
            "Epoch: 140. Loss: 0.6185482067161284\n",
            "Epoch: 150. Loss: 0.6181646312422707\n",
            "Epoch: 160. Loss: 0.6178487860321777\n",
            "Epoch: 170. Loss: 0.6175892049171383\n",
            "Epoch: 180. Loss: 0.6173762386787653\n",
            "Epoch: 190. Loss: 0.6172017980499217\n",
            "Epoch: 200. Loss: 0.6170591253941071\n",
            "Epoch: 210. Loss: 0.616942593803467\n",
            "Epoch: 220. Loss: 0.6168475318688811\n",
            "Epoch: 230. Loss: 0.6167700720410141\n",
            "Epoch: 240. Loss: 0.6167070203296345\n",
            "Epoch: 250. Loss: 0.6166557450467816\n",
            "Epoch: 260. Loss: 0.6166140823519494\n",
            "Epoch: 270. Loss: 0.6165802564743035\n",
            "Epoch: 280. Loss: 0.616552812644249\n",
            "Epoch: 290. Loss: 0.6165305609460882\n",
            "Epoch: 300. Loss: 0.6165125294913811\n",
            "Epoch: 310. Loss: 0.6164979254991454\n",
            "Epoch: 320. Loss: 0.6164861030474521\n",
            "Epoch: 330. Loss: 0.6164765364270476\n",
            "Epoch: 340. Loss: 0.6164687981789227\n",
            "tensor(0.5744, dtype=torch.float64)\n",
            "2020-12-06 00:00:00\n",
            "Epoch: 0. Loss: 2.0938663200995213\n",
            "Epoch: 10. Loss: 1.3105413074008956\n",
            "Epoch: 20. Loss: 1.0039256193029658\n",
            "Epoch: 30. Loss: 0.8555349830001268\n",
            "Epoch: 40. Loss: 0.7696556896591323\n",
            "Epoch: 50. Loss: 0.7145350257767685\n",
            "Epoch: 60. Loss: 0.6789257254071283\n",
            "Epoch: 70. Loss: 0.6574548227233724\n",
            "Epoch: 80. Loss: 0.6449590589537119\n",
            "Epoch: 90. Loss: 0.6373396762643042\n",
            "Epoch: 100. Loss: 0.6322804519502326\n",
            "Epoch: 110. Loss: 0.6286777236305322\n",
            "Epoch: 120. Loss: 0.6260001507754712\n",
            "Epoch: 130. Loss: 0.6239631365281068\n",
            "Epoch: 140. Loss: 0.6223936461906168\n",
            "Epoch: 150. Loss: 0.6211753592216492\n",
            "Epoch: 160. Loss: 0.6202250085012625\n",
            "Epoch: 170. Loss: 0.6194808936978687\n",
            "Epoch: 180. Loss: 0.6188964494782536\n",
            "Epoch: 190. Loss: 0.6184361684925842\n",
            "Epoch: 200. Loss: 0.6180727948671146\n",
            "Epoch: 210. Loss: 0.6177853016860116\n",
            "Epoch: 220. Loss: 0.6175573986996145\n",
            "Epoch: 230. Loss: 0.6173764173786674\n",
            "Epoch: 240. Loss: 0.6172324714662595\n",
            "Epoch: 250. Loss: 0.6171178213031363\n",
            "Epoch: 260. Loss: 0.617026390038271\n",
            "Epoch: 270. Loss: 0.61695339369851\n",
            "Epoch: 280. Loss: 0.61689505704818\n",
            "Epoch: 290. Loss: 0.6168483944092119\n",
            "Epoch: 300. Loss: 0.6168110399089737\n",
            "Epoch: 310. Loss: 0.6167811155154078\n",
            "Epoch: 320. Loss: 0.6167571280919334\n",
            "Epoch: 330. Loss: 0.6167378888349245\n",
            "Epoch: 340. Loss: 0.6167224500442021\n",
            "tensor(0.6000, dtype=torch.float64)\n",
            "2020-12-13 00:00:00\n",
            "Epoch: 0. Loss: 1.3700763802371894\n",
            "Epoch: 10. Loss: 0.8509532842651073\n",
            "Epoch: 20. Loss: 0.6707693606432076\n",
            "Epoch: 30. Loss: 0.6349426171331445\n",
            "Epoch: 40. Loss: 0.6223155235838653\n",
            "Epoch: 50. Loss: 0.6178037176742518\n",
            "Epoch: 60. Loss: 0.61620227320358\n",
            "Epoch: 70. Loss: 0.6155959917896512\n",
            "Epoch: 80. Loss: 0.6153391392751888\n",
            "Epoch: 90. Loss: 0.6152122565561866\n",
            "Epoch: 100. Loss: 0.6151380682887736\n",
            "Epoch: 110. Loss: 0.6150881291868452\n",
            "Epoch: 120. Loss: 0.6150512897420399\n",
            "Epoch: 130. Loss: 0.6150227273890781\n",
            "Epoch: 140. Loss: 0.615000038520622\n",
            "Epoch: 150. Loss: 0.614981814131062\n",
            "Epoch: 160. Loss: 0.6149671047847064\n",
            "Epoch: 170. Loss: 0.6149552090641732\n",
            "Epoch: 180. Loss: 0.6149455820570244\n",
            "Epoch: 190. Loss: 0.6149377899576891\n",
            "Epoch: 200. Loss: 0.6149314835774512\n",
            "Epoch: 210. Loss: 0.6149263805219423\n",
            "Epoch: 220. Loss: 0.614922252006136\n",
            "Epoch: 230. Loss: 0.6149189125816305\n",
            "Epoch: 240. Loss: 0.6149162119312404\n",
            "Epoch: 250. Loss: 0.6149140282425528\n",
            "Epoch: 260. Loss: 0.6149122628328946\n",
            "Epoch: 270. Loss: 0.6149108357828874\n",
            "Epoch: 280. Loss: 0.6149096823885181\n",
            "Epoch: 290. Loss: 0.6149087502791075\n",
            "Epoch: 300. Loss: 0.6149079970772899\n",
            "Epoch: 310. Loss: 0.6149073885000413\n",
            "Epoch: 320. Loss: 0.6149068968184012\n",
            "Epoch: 330. Loss: 0.6149064996087108\n",
            "Epoch: 340. Loss: 0.6149061787406319\n",
            "tensor(0.6501, dtype=torch.float64)\n",
            "2020-12-20 00:00:00\n",
            "Epoch: 0. Loss: 2.0799914351767836\n",
            "Epoch: 10. Loss: 1.3003011992164704\n",
            "Epoch: 20. Loss: 0.9407396424448946\n",
            "Epoch: 30. Loss: 0.7596583400810932\n",
            "Epoch: 40. Loss: 0.6731334146865966\n",
            "Epoch: 50. Loss: 0.6393023411717347\n",
            "Epoch: 60. Loss: 0.6274026018219936\n",
            "Epoch: 70. Loss: 0.6226121457081404\n",
            "Epoch: 80. Loss: 0.6200896985834528\n",
            "Epoch: 90. Loss: 0.6184372315823885\n",
            "Epoch: 100. Loss: 0.6172268055444626\n",
            "Epoch: 110. Loss: 0.6162982897481039\n",
            "Epoch: 120. Loss: 0.6155724810733331\n",
            "Epoch: 130. Loss: 0.6150001689673175\n",
            "Epoch: 140. Loss: 0.6145466910026648\n",
            "Epoch: 150. Loss: 0.6141861989045229\n",
            "Epoch: 160. Loss: 0.6138989141883247\n",
            "Epoch: 170. Loss: 0.6136695050728448\n",
            "Epoch: 180. Loss: 0.613485995445944\n",
            "Epoch: 190. Loss: 0.6133389813941529\n",
            "Epoch: 200. Loss: 0.6132210493356274\n",
            "Epoch: 210. Loss: 0.6131263358007337\n",
            "Epoch: 220. Loss: 0.6130501905491155\n",
            "Epoch: 230. Loss: 0.6129889167185358\n",
            "Epoch: 240. Loss: 0.6129395691826872\n",
            "Epoch: 250. Loss: 0.6128997973126494\n",
            "Epoch: 260. Loss: 0.6128677218550889\n",
            "Epoch: 270. Loss: 0.6128418381765962\n",
            "Epoch: 280. Loss: 0.612820939985276\n",
            "Epoch: 290. Loss: 0.6128040590246768\n",
            "Epoch: 300. Loss: 0.612790417273938\n",
            "Epoch: 310. Loss: 0.6127793889737972\n",
            "Epoch: 320. Loss: 0.6127704703964018\n",
            "Epoch: 330. Loss: 0.6127632557350624\n",
            "Epoch: 340. Loss: 0.6127574178428055\n",
            "tensor(0.6418, dtype=torch.float64)\n",
            "2020-12-27 00:00:00\n",
            "Epoch: 0. Loss: 1.5386694271273225\n",
            "Epoch: 10. Loss: 0.8982157707537447\n",
            "Epoch: 20. Loss: 0.6765677430977209\n",
            "Epoch: 30. Loss: 0.6312537001728066\n",
            "Epoch: 40. Loss: 0.6192481686553404\n",
            "Epoch: 50. Loss: 0.6155194612348208\n",
            "Epoch: 60. Loss: 0.6142361175371424\n",
            "Epoch: 70. Loss: 0.6137439109672143\n",
            "Epoch: 80. Loss: 0.6135295862405179\n",
            "Epoch: 90. Loss: 0.6134208963040023\n",
            "Epoch: 100. Loss: 0.6133563163615234\n",
            "Epoch: 110. Loss: 0.6133126056027409\n",
            "Epoch: 120. Loss: 0.6132803735175435\n",
            "Epoch: 130. Loss: 0.6132554403650439\n",
            "Epoch: 140. Loss: 0.6132356811670358\n",
            "Epoch: 150. Loss: 0.6132198410249248\n",
            "Epoch: 160. Loss: 0.6132070759255248\n",
            "Epoch: 170. Loss: 0.6131967656029121\n",
            "Epoch: 180. Loss: 0.6131884306263927\n",
            "Epoch: 190. Loss: 0.6131816907936619\n",
            "Epoch: 200. Loss: 0.6131762409091911\n",
            "Epoch: 210. Loss: 0.6131718346523126\n",
            "Epoch: 220. Loss: 0.6131682727714433\n",
            "Epoch: 230. Loss: 0.6131653939621551\n",
            "Epoch: 240. Loss: 0.6131630676220055\n",
            "Epoch: 250. Loss: 0.6131611880214465\n",
            "Epoch: 260. Loss: 0.6131596695877768\n",
            "Epoch: 270. Loss: 0.613158443081354\n",
            "Epoch: 280. Loss: 0.6131574524933623\n",
            "Epoch: 290. Loss: 0.6131566525291339\n",
            "Epoch: 300. Loss: 0.6131560065671832\n",
            "Epoch: 310. Loss: 0.6131554850047367\n",
            "Epoch: 320. Loss: 0.6131550639171556\n",
            "Epoch: 330. Loss: 0.6131547239721544\n",
            "Epoch: 340. Loss: 0.6131544495507283\n",
            "tensor(0.5806, dtype=torch.float64)\n",
            "2021-01-03 00:00:00\n",
            "Epoch: 0. Loss: 2.846780855675352\n",
            "Epoch: 10. Loss: 1.2761879462063646\n",
            "Epoch: 20. Loss: 0.8343640095314018\n",
            "Epoch: 30. Loss: 0.7355454339310974\n",
            "Epoch: 40. Loss: 0.6831384758878618\n",
            "Epoch: 50. Loss: 0.6517160970300736\n",
            "Epoch: 60. Loss: 0.6353672157493241\n",
            "Epoch: 70. Loss: 0.6274612767747461\n",
            "Epoch: 80. Loss: 0.623370009924118\n",
            "Epoch: 90. Loss: 0.6209389226060359\n",
            "Epoch: 100. Loss: 0.6193074717882929\n",
            "Epoch: 110. Loss: 0.6181241036213021\n",
            "Epoch: 120. Loss: 0.6172281908219113\n",
            "Epoch: 130. Loss: 0.6165346143873986\n",
            "Epoch: 140. Loss: 0.6159913661852726\n",
            "Epoch: 150. Loss: 0.6155630924441345\n",
            "Epoch: 160. Loss: 0.6152241143006213\n",
            "Epoch: 170. Loss: 0.6149550792722637\n",
            "Epoch: 180. Loss: 0.6147411109157368\n",
            "Epoch: 190. Loss: 0.6145706479350999\n",
            "Epoch: 200. Loss: 0.6144346465620437\n",
            "Epoch: 210. Loss: 0.6143260014158477\n",
            "Epoch: 220. Loss: 0.6142391118231098\n",
            "Epoch: 230. Loss: 0.6141695514695988\n",
            "Epoch: 240. Loss: 0.6141138142338162\n",
            "Epoch: 250. Loss: 0.6140691173574206\n",
            "Epoch: 260. Loss: 0.614033248289752\n",
            "Epoch: 270. Loss: 0.6140044450561518\n",
            "Epoch: 280. Loss: 0.6139813025026333\n",
            "Epoch: 290. Loss: 0.6139626986038689\n",
            "Epoch: 300. Loss: 0.6139477363877014\n",
            "Epoch: 310. Loss: 0.6139356980571371\n",
            "Epoch: 320. Loss: 0.6139260086693421\n",
            "Epoch: 330. Loss: 0.6139182073242913\n",
            "Epoch: 340. Loss: 0.6139119242697899\n",
            "tensor(0.6334, dtype=torch.float64)\n",
            "2021-01-10 00:00:00\n",
            "Epoch: 0. Loss: 2.0138972966332487\n",
            "Epoch: 10. Loss: 1.3085768527926789\n",
            "Epoch: 20. Loss: 0.8934970461755748\n",
            "Epoch: 30. Loss: 0.7088852550491186\n",
            "Epoch: 40. Loss: 0.6453310316404017\n",
            "Epoch: 50. Loss: 0.6217532182099427\n",
            "Epoch: 60. Loss: 0.6128621614602613\n",
            "Epoch: 70. Loss: 0.6094089171313498\n",
            "Epoch: 80. Loss: 0.6079119779507584\n",
            "Epoch: 90. Loss: 0.6071482100688532\n",
            "Epoch: 100. Loss: 0.6066886926407578\n",
            "Epoch: 110. Loss: 0.6063744420098032\n",
            "Epoch: 120. Loss: 0.6061414066966897\n",
            "Epoch: 130. Loss: 0.6059606983890293\n",
            "Epoch: 140. Loss: 0.605817308743644\n",
            "Epoch: 150. Loss: 0.6057022077699759\n",
            "Epoch: 160. Loss: 0.6056092679321745\n",
            "Epoch: 170. Loss: 0.6055339852962416\n",
            "Epoch: 180. Loss: 0.6054728937756968\n",
            "Epoch: 190. Loss: 0.6054232601273463\n",
            "Epoch: 200. Loss: 0.6053829016170935\n",
            "Epoch: 210. Loss: 0.6053500635137543\n",
            "Epoch: 220. Loss: 0.6053233299373701\n",
            "Epoch: 230. Loss: 0.6053015558544024\n",
            "Epoch: 240. Loss: 0.6052838138591979\n",
            "Epoch: 250. Loss: 0.6052693519569717\n",
            "Epoch: 260. Loss: 0.6052575598257016\n",
            "Epoch: 270. Loss: 0.6052479417381523\n",
            "Epoch: 280. Loss: 0.6052400947695643\n",
            "Epoch: 290. Loss: 0.6052336912249231\n",
            "Epoch: 300. Loss: 0.6052284644471061\n",
            "Epoch: 310. Loss: 0.6052241973408077\n",
            "Epoch: 320. Loss: 0.6052207130822412\n",
            "Epoch: 330. Loss: 0.6052178675908915\n",
            "Epoch: 340. Loss: 0.6052155434237115\n",
            "tensor(0.7724, dtype=torch.float64)\n",
            "2021-01-17 00:00:00\n",
            "Epoch: 0. Loss: 1.2872076677975364\n",
            "Epoch: 10. Loss: 0.913114832675425\n",
            "Epoch: 20. Loss: 0.8006372800547443\n",
            "Epoch: 30. Loss: 0.7643507522457326\n",
            "Epoch: 40. Loss: 0.741162755484983\n",
            "Epoch: 50. Loss: 0.7228998720599512\n",
            "Epoch: 60. Loss: 0.7076704715480018\n",
            "Epoch: 70. Loss: 0.6945663352764282\n",
            "Epoch: 80. Loss: 0.6830959685068354\n",
            "Epoch: 90. Loss: 0.6729838956338123\n",
            "Epoch: 100. Loss: 0.6640610220735537\n",
            "Epoch: 110. Loss: 0.6562079033121867\n",
            "Epoch: 120. Loss: 0.649327125300138\n",
            "Epoch: 130. Loss: 0.643330659994228\n",
            "Epoch: 140. Loss: 0.6381347050407326\n",
            "Epoch: 150. Loss: 0.6336581664751845\n",
            "Epoch: 160. Loss: 0.6298228067244971\n",
            "Epoch: 170. Loss: 0.6265540285060766\n",
            "Epoch: 180. Loss: 0.6237817635935006\n",
            "Epoch: 190. Loss: 0.6214412091471337\n",
            "Epoch: 200. Loss: 0.6194733093381868\n",
            "Epoch: 210. Loss: 0.6178249671505398\n",
            "Epoch: 220. Loss: 0.6164490169271291\n",
            "Epoch: 230. Loss: 0.6153040079978949\n",
            "Epoch: 240. Loss: 0.6143538538228999\n",
            "Epoch: 250. Loss: 0.6135673965276474\n",
            "Epoch: 260. Loss: 0.612917928190061\n",
            "Epoch: 270. Loss: 0.6123827006817676\n",
            "Epoch: 280. Loss: 0.6119424468997752\n",
            "Epoch: 290. Loss: 0.6115809286054076\n",
            "Epoch: 300. Loss: 0.6112845200366243\n",
            "Epoch: 310. Loss: 0.6110418319054638\n",
            "Epoch: 320. Loss: 0.6108433771274879\n",
            "Epoch: 330. Loss: 0.6106812774072162\n",
            "Epoch: 340. Loss: 0.6105490083840321\n",
            "tensor(0.7556, dtype=torch.float64)\n",
            "2021-01-24 00:00:00\n",
            "Epoch: 0. Loss: 1.2392152815404027\n",
            "Epoch: 10. Loss: 0.9115431074670397\n",
            "Epoch: 20. Loss: 0.7249337446398597\n",
            "Epoch: 30. Loss: 0.6580232345551347\n",
            "Epoch: 40. Loss: 0.6378424238563128\n",
            "Epoch: 50. Loss: 0.6295866581534618\n",
            "Epoch: 60. Loss: 0.6249181380958679\n",
            "Epoch: 70. Loss: 0.6217262898334048\n",
            "Epoch: 80. Loss: 0.6193093339327279\n",
            "Epoch: 90. Loss: 0.6173828559533499\n",
            "Epoch: 100. Loss: 0.6158098870544034\n",
            "Epoch: 110. Loss: 0.6145121416087267\n",
            "Epoch: 120. Loss: 0.6134374755931288\n",
            "Epoch: 130. Loss: 0.612547051160422\n",
            "Epoch: 140. Loss: 0.6118099359679451\n",
            "Epoch: 150. Loss: 0.6112006378151686\n",
            "Epoch: 160. Loss: 0.6106978342279947\n",
            "Epoch: 170. Loss: 0.6102836045648092\n",
            "Epoch: 180. Loss: 0.6099428865661352\n",
            "Epoch: 190. Loss: 0.6096630459198832\n",
            "Epoch: 200. Loss: 0.6094335142505152\n",
            "Epoch: 210. Loss: 0.6092454771755892\n",
            "Epoch: 220. Loss: 0.6090916039484148\n",
            "Epoch: 230. Loss: 0.6089658136819185\n",
            "Epoch: 240. Loss: 0.6088630742667647\n",
            "Epoch: 250. Loss: 0.6087792304438828\n",
            "Epoch: 260. Loss: 0.6087108576541913\n",
            "Epoch: 270. Loss: 0.608655138456602\n",
            "Epoch: 280. Loss: 0.6086097585214166\n",
            "Epoch: 290. Loss: 0.6085728194628497\n",
            "Epoch: 300. Loss: 0.6085427660528284\n",
            "Epoch: 310. Loss: 0.6085183256407014\n",
            "Epoch: 320. Loss: 0.60849845787689\n",
            "Epoch: 330. Loss: 0.6084823130943178\n",
            "Epoch: 340. Loss: 0.6084691979348297\n",
            "tensor(0.7089, dtype=torch.float64)\n",
            "2021-01-31 00:00:00\n",
            "Epoch: 0. Loss: 1.6151519066063595\n",
            "Epoch: 10. Loss: 0.7440348950505912\n",
            "Epoch: 20. Loss: 0.6241506155010668\n",
            "Epoch: 30. Loss: 0.6152451684012965\n",
            "Epoch: 40. Loss: 0.612814955709453\n",
            "Epoch: 50. Loss: 0.6119108838335608\n",
            "Epoch: 60. Loss: 0.6115230629192989\n",
            "Epoch: 70. Loss: 0.6113292029241236\n",
            "Epoch: 80. Loss: 0.6112155921467046\n",
            "Epoch: 90. Loss: 0.6111395166686665\n",
            "Epoch: 100. Loss: 0.6110837833112246\n",
            "Epoch: 110. Loss: 0.6110407923417748\n",
            "Epoch: 120. Loss: 0.6110067326869972\n",
            "Epoch: 130. Loss: 0.6109793949981662\n",
            "Epoch: 140. Loss: 0.6109573185587291\n",
            "Epoch: 150. Loss: 0.6109394422730413\n",
            "Epoch: 160. Loss: 0.6109249508307505\n",
            "Epoch: 170. Loss: 0.6109131989101064\n",
            "Epoch: 180. Loss: 0.6109036682547939\n",
            "Epoch: 190. Loss: 0.6108959398400639\n",
            "Epoch: 200. Loss: 0.6108896738793154\n",
            "Epoch: 210. Loss: 0.6108845945298369\n",
            "Epoch: 220. Loss: 0.6108804777929371\n",
            "Epoch: 230. Loss: 0.6108771417827794\n",
            "Epoch: 240. Loss: 0.6108744388415829\n",
            "Epoch: 250. Loss: 0.6108722491310431\n",
            "Epoch: 260. Loss: 0.6108704754180855\n",
            "Epoch: 270. Loss: 0.6108690388318018\n",
            "Epoch: 280. Loss: 0.6108678754115657\n",
            "Epoch: 290. Loss: 0.6108669332999473\n",
            "Epoch: 300. Loss: 0.6108661704609928\n",
            "Epoch: 310. Loss: 0.6108655528263541\n",
            "Epoch: 320. Loss: 0.6108650527896545\n",
            "Epoch: 330. Loss: 0.610864647984134\n",
            "Epoch: 340. Loss: 0.6108643202906118\n",
            "tensor(0.8288, dtype=torch.float64)\n",
            "2021-02-07 00:00:00\n",
            "Epoch: 0. Loss: 4.093960362077378\n",
            "Epoch: 10. Loss: 1.4310453435405455\n",
            "Epoch: 20. Loss: 0.7105464679286912\n",
            "Epoch: 30. Loss: 0.6256908594011228\n",
            "Epoch: 40. Loss: 0.6121314956370304\n",
            "Epoch: 50. Loss: 0.6086157254989788\n",
            "Epoch: 60. Loss: 0.6070275957388821\n",
            "Epoch: 70. Loss: 0.6060046036119718\n",
            "Epoch: 80. Loss: 0.60524136757802\n",
            "Epoch: 90. Loss: 0.6046423898739685\n",
            "Epoch: 100. Loss: 0.6041642357900286\n",
            "Epoch: 110. Loss: 0.6037801263301478\n",
            "Epoch: 120. Loss: 0.6034706842899552\n",
            "Epoch: 130. Loss: 0.6032209687099989\n",
            "Epoch: 140. Loss: 0.6030191924166641\n",
            "Epoch: 150. Loss: 0.6028559748926147\n",
            "Epoch: 160. Loss: 0.602723820567744\n",
            "Epoch: 170. Loss: 0.6026167250195817\n",
            "Epoch: 180. Loss: 0.602529868982305\n",
            "Epoch: 190. Loss: 0.6024593779210575\n",
            "Epoch: 200. Loss: 0.6024021321286611\n",
            "Epoch: 210. Loss: 0.6023556162247268\n",
            "Epoch: 220. Loss: 0.6023177995591915\n",
            "Epoch: 230. Loss: 0.602287040944325\n",
            "Epoch: 240. Loss: 0.6022620125968623\n",
            "Epoch: 250. Loss: 0.6022416392911214\n",
            "Epoch: 260. Loss: 0.6022250495881246\n",
            "Epoch: 270. Loss: 0.6022115366755266\n",
            "Epoch: 280. Loss: 0.6022005268739923\n",
            "Epoch: 290. Loss: 0.6021915542720845\n",
            "Epoch: 300. Loss: 0.6021842402698658\n",
            "Epoch: 310. Loss: 0.602178277061297\n",
            "Epoch: 320. Loss: 0.6021734142823763\n",
            "Epoch: 330. Loss: 0.6021694482075229\n",
            "Epoch: 340. Loss: 0.6021662129999658\n",
            "tensor(0.6560, dtype=torch.float64)\n",
            "2021-02-14 00:00:00\n",
            "Epoch: 0. Loss: 1.5269153006428466\n",
            "Epoch: 10. Loss: 0.9986798774302771\n",
            "Epoch: 20. Loss: 0.742385717047111\n",
            "Epoch: 30. Loss: 0.6442544717588008\n",
            "Epoch: 40. Loss: 0.6192511606511769\n",
            "Epoch: 50. Loss: 0.6096578746650336\n",
            "Epoch: 60. Loss: 0.6046973772648783\n",
            "Epoch: 70. Loss: 0.6015493517399227\n",
            "Epoch: 80. Loss: 0.5992271753902771\n",
            "Epoch: 90. Loss: 0.5973655311556194\n",
            "Epoch: 100. Loss: 0.5958143515917147\n",
            "Epoch: 110. Loss: 0.5945004129855708\n",
            "Epoch: 120. Loss: 0.5933800597449754\n",
            "Epoch: 130. Loss: 0.592422575676052\n",
            "Epoch: 140. Loss: 0.5916039739115037\n",
            "Epoch: 150. Loss: 0.5909044521021827\n",
            "Epoch: 160. Loss: 0.5903072116435377\n",
            "Epoch: 170. Loss: 0.5897978228474388\n",
            "Epoch: 180. Loss: 0.5893638274669153\n",
            "Epoch: 190. Loss: 0.5889944543582386\n",
            "Epoch: 200. Loss: 0.5886803952506929\n",
            "Epoch: 210. Loss: 0.5884136168642078\n",
            "Epoch: 220. Loss: 0.5881871982402891\n",
            "Epoch: 230. Loss: 0.5879951877437951\n",
            "Epoch: 240. Loss: 0.5878324766840266\n",
            "Epoch: 250. Loss: 0.5876946876016833\n",
            "Epoch: 260. Loss: 0.5875780757450388\n",
            "Epoch: 270. Loss: 0.5874794424682418\n",
            "Epoch: 280. Loss: 0.5873960593881228\n",
            "Epoch: 290. Loss: 0.5873256022043387\n",
            "Epoch: 300. Loss: 0.5872660931499815\n",
            "Epoch: 310. Loss: 0.5872158511057678\n",
            "Epoch: 320. Loss: 0.5871734484821219\n",
            "Epoch: 330. Loss: 0.587137674048325\n",
            "Epoch: 340. Loss: 0.5871075009639675\n",
            "tensor(0.8090, dtype=torch.float64)\n",
            "2021-02-21 00:00:00\n",
            "Epoch: 0. Loss: 2.6533289247957783\n",
            "Epoch: 10. Loss: 1.1936560809535353\n",
            "Epoch: 20. Loss: 0.7547291444903313\n",
            "Epoch: 30. Loss: 0.6240043257178525\n",
            "Epoch: 40. Loss: 0.5874244112789886\n",
            "Epoch: 50. Loss: 0.5761875864134481\n",
            "Epoch: 60. Loss: 0.5716304096154949\n",
            "Epoch: 70. Loss: 0.5691719780342689\n",
            "Epoch: 80. Loss: 0.5675177256457609\n",
            "Epoch: 90. Loss: 0.5662460895442362\n",
            "Epoch: 100. Loss: 0.5652009587890682\n",
            "Epoch: 110. Loss: 0.564315323470367\n",
            "Epoch: 120. Loss: 0.563554752849926\n",
            "Epoch: 130. Loss: 0.5628979305285882\n",
            "Epoch: 140. Loss: 0.562329519024629\n",
            "Epoch: 150. Loss: 0.5618373678628511\n",
            "Epoch: 160. Loss: 0.5614113320065723\n",
            "Epoch: 170. Loss: 0.561042717637365\n",
            "Epoch: 180. Loss: 0.5607239851438724\n",
            "Epoch: 190. Loss: 0.5604485638702515\n",
            "Epoch: 200. Loss: 0.5602107192433401\n",
            "Epoch: 210. Loss: 0.5600054472156155\n",
            "Epoch: 220. Loss: 0.5598283851050074\n",
            "Epoch: 230. Loss: 0.5596757338772872\n",
            "Epoch: 240. Loss: 0.5595441894598017\n",
            "Epoch: 250. Loss: 0.5594308817587754\n",
            "Epoch: 260. Loss: 0.5593333205104066\n",
            "Epoch: 270. Loss: 0.5592493472897997\n",
            "Epoch: 280. Loss: 0.5591770930884715\n",
            "Epoch: 290. Loss: 0.5591149409180293\n",
            "Epoch: 300. Loss: 0.559061492932247\n",
            "Epoch: 310. Loss: 0.55901554159249\n",
            "Epoch: 320. Loss: 0.5589760444352281\n",
            "Epoch: 330. Loss: 0.5589421020354031\n",
            "Epoch: 340. Loss: 0.5589129387948742\n",
            "tensor(0.7742, dtype=torch.float64)\n",
            "2021-02-28 00:00:00\n",
            "Epoch: 0. Loss: 2.7127012003950295\n",
            "Epoch: 10. Loss: 1.877959227072589\n",
            "Epoch: 20. Loss: 1.293347139619717\n",
            "Epoch: 30. Loss: 0.9889944460015803\n",
            "Epoch: 40. Loss: 0.8432435586308351\n",
            "Epoch: 50. Loss: 0.7691590359472772\n",
            "Epoch: 60. Loss: 0.7285103513038591\n",
            "Epoch: 70. Loss: 0.7023872230589727\n",
            "Epoch: 80. Loss: 0.6828772496343425\n",
            "Epoch: 90. Loss: 0.666913223721437\n",
            "Epoch: 100. Loss: 0.6533261862847001\n",
            "Epoch: 110. Loss: 0.6416338059526275\n",
            "Epoch: 120. Loss: 0.631584963551281\n",
            "Epoch: 130. Loss: 0.6229984069968029\n",
            "Epoch: 140. Loss: 0.6157114620966065\n",
            "Epoch: 150. Loss: 0.6095676579681995\n",
            "Epoch: 160. Loss: 0.604416814555297\n",
            "Epoch: 170. Loss: 0.600118132145886\n",
            "Epoch: 180. Loss: 0.5965430736303136\n",
            "Epoch: 190. Loss: 0.59357711990198\n",
            "Epoch: 200. Loss: 0.5911203312746299\n",
            "Epoch: 210. Loss: 0.5890869529158856\n",
            "Epoch: 220. Loss: 0.587404377906187\n",
            "Epoch: 230. Loss: 0.5860117559978117\n",
            "Epoch: 240. Loss: 0.5848584714775567\n",
            "Epoch: 250. Loss: 0.5839026424502906\n",
            "Epoch: 260. Loss: 0.5831097323556437\n",
            "Epoch: 270. Loss: 0.5824513182856879\n",
            "Epoch: 280. Loss: 0.5819040295463829\n",
            "Epoch: 290. Loss: 0.5814486511258999\n",
            "Epoch: 300. Loss: 0.581069376871067\n",
            "Epoch: 310. Loss: 0.5807531931559015\n",
            "Epoch: 320. Loss: 0.5804893732977416\n",
            "Epoch: 330. Loss: 0.5802690643104765\n",
            "Epoch: 340. Loss: 0.5800849497486957\n",
            "tensor(0.9833, dtype=torch.float64)\n",
            "2021-03-07 00:00:00\n",
            "Epoch: 0. Loss: 1.0389608386909432\n",
            "Epoch: 10. Loss: 0.8161166504772336\n",
            "Epoch: 20. Loss: 0.6710105454361041\n",
            "Epoch: 30. Loss: 0.6086802844533702\n",
            "Epoch: 40. Loss: 0.5914439131398254\n",
            "Epoch: 50. Loss: 0.5863389458545604\n",
            "Epoch: 60. Loss: 0.5839218326274529\n",
            "Epoch: 70. Loss: 0.5824208520015586\n",
            "Epoch: 80. Loss: 0.5813974830078268\n",
            "Epoch: 90. Loss: 0.5806743515760725\n",
            "Epoch: 100. Loss: 0.5801542144470891\n",
            "Epoch: 110. Loss: 0.579775782639398\n",
            "Epoch: 120. Loss: 0.5794979298561608\n",
            "Epoch: 130. Loss: 0.5792922275911507\n",
            "Epoch: 140. Loss: 0.57913871439394\n",
            "Epoch: 150. Loss: 0.5790232357442723\n",
            "Epoch: 160. Loss: 0.5789356793446624\n",
            "Epoch: 170. Loss: 0.5788687725633147\n",
            "Epoch: 180. Loss: 0.5788172512185129\n",
            "Epoch: 190. Loss: 0.5787772800576312\n",
            "Epoch: 200. Loss: 0.5787460461815438\n",
            "Epoch: 210. Loss: 0.5787214722878455\n",
            "Epoch: 220. Loss: 0.5787020134168308\n",
            "Epoch: 230. Loss: 0.5786865121769246\n",
            "Epoch: 240. Loss: 0.5786740951093556\n",
            "Epoch: 250. Loss: 0.5786640981198035\n",
            "Epoch: 260. Loss: 0.5786560125368221\n",
            "Epoch: 270. Loss: 0.5786494458725059\n",
            "Epoch: 280. Loss: 0.5786440931103801\n",
            "Epoch: 290. Loss: 0.5786397155668799\n",
            "Epoch: 300. Loss: 0.578636125228586\n",
            "Epoch: 310. Loss: 0.5786331730691892\n",
            "Epoch: 320. Loss: 0.5786307402748558\n",
            "Epoch: 330. Loss: 0.5786287316074262\n",
            "Epoch: 340. Loss: 0.5786270703486623\n",
            "tensor(0.9005, dtype=torch.float64)\n",
            "2021-03-14 00:00:00\n",
            "Epoch: 0. Loss: 1.6610513283333181\n",
            "Epoch: 10. Loss: 1.3506024357101523\n",
            "Epoch: 20. Loss: 1.0741510788002873\n",
            "Epoch: 30. Loss: 0.8566481910446796\n",
            "Epoch: 40. Loss: 0.7141836248987528\n",
            "Epoch: 50. Loss: 0.6434461777193454\n",
            "Epoch: 60. Loss: 0.6153397331590502\n",
            "Epoch: 70. Loss: 0.6038019952975697\n",
            "Epoch: 80. Loss: 0.5977043437746619\n",
            "Epoch: 90. Loss: 0.5936202421329616\n",
            "Epoch: 100. Loss: 0.5905220805506847\n",
            "Epoch: 110. Loss: 0.58803969431229\n",
            "Epoch: 120. Loss: 0.5859995924409257\n",
            "Epoch: 130. Loss: 0.5843002512614397\n",
            "Epoch: 140. Loss: 0.5828731571639698\n",
            "Epoch: 150. Loss: 0.5816681242050241\n",
            "Epoch: 160. Loss: 0.5806466258495875\n",
            "Epoch: 170. Loss: 0.579778230196304\n",
            "Epoch: 180. Loss: 0.5790384363762505\n",
            "Epoch: 190. Loss: 0.5784072404518242\n",
            "Epoch: 200. Loss: 0.5778681294766559\n",
            "Epoch: 210. Loss: 0.5774073499445198\n",
            "Epoch: 220. Loss: 0.5770133624953624\n",
            "Epoch: 230. Loss: 0.5766764276519487\n",
            "Epoch: 240. Loss: 0.5763882858669487\n",
            "Epoch: 250. Loss: 0.5761419065779217\n",
            "Epoch: 260. Loss: 0.5759312884691901\n",
            "Epoch: 270. Loss: 0.5757512982562848\n",
            "Epoch: 280. Loss: 0.5755975388701166\n",
            "Epoch: 290. Loss: 0.5754662404225735\n",
            "Epoch: 300. Loss: 0.5753541691058042\n",
            "Epoch: 310. Loss: 0.5752585504332272\n",
            "Epoch: 320. Loss: 0.5751770041240231\n",
            "Epoch: 330. Loss: 0.5751074885719085\n",
            "Epoch: 340. Loss: 0.5750482532992133\n",
            "tensor(0.7129, dtype=torch.float64)\n",
            "2021-03-21 00:00:00\n",
            "Epoch: 0. Loss: 1.1598548915880917\n",
            "Epoch: 10. Loss: 1.02430698668616\n",
            "Epoch: 20. Loss: 0.9197462014681569\n",
            "Epoch: 30. Loss: 0.8415442586442622\n",
            "Epoch: 40. Loss: 0.7816969289355014\n",
            "Epoch: 50. Loss: 0.7347704617701285\n",
            "Epoch: 60. Loss: 0.6976701917996379\n",
            "Epoch: 70. Loss: 0.6685077802636684\n",
            "Epoch: 80. Loss: 0.6458839950967457\n",
            "Epoch: 90. Loss: 0.6285967815294522\n",
            "Epoch: 100. Loss: 0.61556835760792\n",
            "Epoch: 110. Loss: 0.6058529586840459\n",
            "Epoch: 120. Loss: 0.5986563417286436\n",
            "Epoch: 130. Loss: 0.5933408412379286\n",
            "Epoch: 140. Loss: 0.5894133831529889\n",
            "Epoch: 150. Loss: 0.586503213208881\n",
            "Epoch: 160. Loss: 0.5843367647340031\n",
            "Epoch: 170. Loss: 0.5827144607616349\n",
            "Epoch: 180. Loss: 0.5814915158268719\n",
            "Epoch: 190. Loss: 0.5805630450555166\n",
            "Epoch: 200. Loss: 0.5798529585288079\n",
            "Epoch: 210. Loss: 0.5793058690191163\n",
            "Epoch: 220. Loss: 0.578881271088398\n",
            "Epoch: 230. Loss: 0.5785493797231317\n",
            "Epoch: 240. Loss: 0.5782881606486813\n",
            "Epoch: 250. Loss: 0.5780812089004507\n",
            "Epoch: 260. Loss: 0.5779162291731677\n",
            "Epoch: 270. Loss: 0.5777839430965764\n",
            "Epoch: 280. Loss: 0.5776773000180647\n",
            "Epoch: 290. Loss: 0.5775909042568415\n",
            "Epoch: 300. Loss: 0.5775205973583417\n",
            "Epoch: 310. Loss: 0.5774631518056608\n",
            "Epoch: 320. Loss: 0.5774160452314465\n",
            "Epoch: 330. Loss: 0.5773772930346002\n",
            "Epoch: 340. Loss: 0.5773453235666532\n",
            "tensor(0.8427, dtype=torch.float64)\n",
            "2021-03-28 00:00:00\n",
            "Epoch: 0. Loss: 1.0216470356334388\n",
            "Epoch: 10. Loss: 0.9358603969778921\n",
            "Epoch: 20. Loss: 0.8851440233335359\n",
            "Epoch: 30. Loss: 0.8451185938570146\n",
            "Epoch: 40. Loss: 0.8110687761508775\n",
            "Epoch: 50. Loss: 0.7812093626691694\n",
            "Epoch: 60. Loss: 0.7546515135537973\n",
            "Epoch: 70. Loss: 0.730912620098204\n",
            "Epoch: 80. Loss: 0.7097095974624651\n",
            "Epoch: 90. Loss: 0.6908522550974172\n",
            "Epoch: 100. Loss: 0.674186980902601\n",
            "Epoch: 110. Loss: 0.6595685405212106\n",
            "Epoch: 120. Loss: 0.6468477773758794\n",
            "Epoch: 130. Loss: 0.635868064170107\n",
            "Epoch: 140. Loss: 0.6264663851514911\n",
            "Epoch: 150. Loss: 0.6184767141450027\n",
            "Epoch: 160. Loss: 0.6117343057685914\n",
            "Epoch: 170. Loss: 0.6060800058830009\n",
            "Epoch: 180. Loss: 0.6013639859908991\n",
            "Epoch: 190. Loss: 0.5974485496497886\n",
            "Epoch: 200. Loss: 0.5942098770008343\n",
            "Epoch: 210. Loss: 0.5915387510824945\n",
            "Epoch: 220. Loss: 0.5893404287218155\n",
            "Epoch: 230. Loss: 0.5875338757473322\n",
            "Epoch: 240. Loss: 0.586050591599286\n",
            "Epoch: 250. Loss: 0.5848332199670426\n",
            "Epoch: 260. Loss: 0.5838340977562338\n",
            "Epoch: 270. Loss: 0.5830138480627177\n",
            "Epoch: 280. Loss: 0.5823400819658501\n",
            "Epoch: 290. Loss: 0.5817862422149225\n",
            "Epoch: 300. Loss: 0.5813305995297215\n",
            "Epoch: 310. Loss: 0.5809553979204949\n",
            "Epoch: 320. Loss: 0.5806461372578624\n",
            "Epoch: 330. Loss: 0.5803909774500627\n",
            "Epoch: 340. Loss: 0.5801802474975021\n",
            "tensor(0.8215, dtype=torch.float64)\n",
            "2021-04-04 00:00:00\n",
            "Epoch: 0. Loss: 1.7290231813131398\n",
            "Epoch: 10. Loss: 0.9702371139379645\n",
            "Epoch: 20. Loss: 0.8396439351977745\n",
            "Epoch: 30. Loss: 0.8019608087834158\n",
            "Epoch: 40. Loss: 0.7761045990645628\n",
            "Epoch: 50. Loss: 0.7531335617073712\n",
            "Epoch: 60. Loss: 0.7320756837061873\n",
            "Epoch: 70. Loss: 0.7127468909925286\n",
            "Epoch: 80. Loss: 0.6950683267588345\n",
            "Epoch: 90. Loss: 0.6789862528325908\n",
            "Epoch: 100. Loss: 0.6644516561729508\n",
            "Epoch: 110. Loss: 0.6514103871972826\n",
            "Epoch: 120. Loss: 0.6397982652778642\n",
            "Epoch: 130. Loss: 0.629539355916067\n",
            "Epoch: 140. Loss: 0.6205463332976887\n",
            "Epoch: 150. Loss: 0.6127222745350562\n",
            "Epoch: 160. Loss: 0.6059634460360216\n",
            "Epoch: 170. Loss: 0.6001626677446085\n",
            "Epoch: 180. Loss: 0.5952128096309494\n",
            "Epoch: 190. Loss: 0.5910100011491498\n",
            "Epoch: 200. Loss: 0.5874562442918854\n",
            "Epoch: 210. Loss: 0.5844612738648124\n",
            "Epoch: 220. Loss: 0.5819436522328412\n",
            "Epoch: 230. Loss: 0.5798311881216506\n",
            "Epoch: 240. Loss: 0.5780608227062297\n",
            "Epoch: 250. Loss: 0.5765781393593612\n",
            "Epoch: 260. Loss: 0.5753366399752776\n",
            "Epoch: 270. Loss: 0.5742969040014737\n",
            "Epoch: 280. Loss: 0.5734257160194607\n",
            "Epoch: 290. Loss: 0.5726952198175917\n",
            "Epoch: 300. Loss: 0.5720821341231719\n",
            "Epoch: 310. Loss: 0.5715670481292526\n",
            "Epoch: 320. Loss: 0.5711338031367534\n",
            "Epoch: 330. Loss: 0.5707689590346335\n",
            "Epoch: 340. Loss: 0.5704613398880765\n",
            "tensor(0.8429, dtype=torch.float64)\n",
            "2021-04-11 00:00:00\n",
            "Epoch: 0. Loss: 0.883881892343089\n",
            "Epoch: 10. Loss: 0.6908745483382714\n",
            "Epoch: 20. Loss: 0.6511126739465808\n",
            "Epoch: 30. Loss: 0.6300454544951201\n",
            "Epoch: 40. Loss: 0.614840999783541\n",
            "Epoch: 50. Loss: 0.603283806232184\n",
            "Epoch: 60. Loss: 0.5944670628417271\n",
            "Epoch: 70. Loss: 0.5877538847148908\n",
            "Epoch: 80. Loss: 0.5826400406277435\n",
            "Epoch: 90. Loss: 0.5787278762366237\n",
            "Epoch: 100. Loss: 0.5757113821534977\n",
            "Epoch: 110. Loss: 0.573360400609775\n",
            "Epoch: 120. Loss: 0.5715047398115369\n",
            "Epoch: 130. Loss: 0.5700199122615959\n",
            "Epoch: 140. Loss: 0.5688153537162673\n",
            "Epoch: 150. Loss: 0.5678252240624774\n",
            "Epoch: 160. Loss: 0.5670014924026299\n",
            "Epoch: 170. Loss: 0.5663088715906652\n",
            "Epoch: 180. Loss: 0.5657211715107633\n",
            "Epoch: 190. Loss: 0.56521870342425\n",
            "Epoch: 200. Loss: 0.5647864451625121\n",
            "Epoch: 210. Loss: 0.5644127485794802\n",
            "Epoch: 220. Loss: 0.5640884295004661\n",
            "Epoch: 230. Loss: 0.5638061256982241\n",
            "Epoch: 240. Loss: 0.5635598419714104\n",
            "Epoch: 250. Loss: 0.5633446256285084\n",
            "Epoch: 260. Loss: 0.5631563328903305\n",
            "Epoch: 270. Loss: 0.5629914588125394\n",
            "Epoch: 280. Loss: 0.5628470117559943\n",
            "Epoch: 290. Loss: 0.5627204192764317\n",
            "Epoch: 300. Loss: 0.5626094563439484\n",
            "Epoch: 310. Loss: 0.5625121895884656\n",
            "Epoch: 320. Loss: 0.5624269331864835\n",
            "Epoch: 330. Loss: 0.5623522133260631\n",
            "Epoch: 340. Loss: 0.5622867390974396\n",
            "tensor(0.8268, dtype=torch.float64)\n",
            "2021-04-18 00:00:00\n",
            "Epoch: 0. Loss: 1.3395785352962046\n",
            "Epoch: 10. Loss: 1.071751929785153\n",
            "Epoch: 20. Loss: 0.8908775918544659\n",
            "Epoch: 30. Loss: 0.7828474557280252\n",
            "Epoch: 40. Loss: 0.7243728595940965\n",
            "Epoch: 50. Loss: 0.6910909774535916\n",
            "Epoch: 60. Loss: 0.6680181615865866\n",
            "Epoch: 70. Loss: 0.6495025091626663\n",
            "Epoch: 80. Loss: 0.6338878106839564\n",
            "Epoch: 90. Loss: 0.6206091735185831\n",
            "Epoch: 100. Loss: 0.6093489823874807\n",
            "Epoch: 110. Loss: 0.5998455021072767\n",
            "Epoch: 120. Loss: 0.5918573842467232\n",
            "Epoch: 130. Loss: 0.5851615777557282\n",
            "Epoch: 140. Loss: 0.5795565575357909\n",
            "Epoch: 150. Loss: 0.5748646605844049\n",
            "Epoch: 160. Loss: 0.5709325585580521\n",
            "Epoch: 170. Loss: 0.5676301826439581\n",
            "Epoch: 180. Loss: 0.56484866122824\n",
            "Epoch: 190. Loss: 0.562497772990582\n",
            "Epoch: 200. Loss: 0.5605032826622359\n",
            "Epoch: 210. Loss: 0.5588043929640253\n",
            "Epoch: 220. Loss: 0.5573514404790783\n",
            "Epoch: 230. Loss: 0.55610388944372\n",
            "Epoch: 240. Loss: 0.5550286309031086\n",
            "Epoch: 250. Loss: 0.5540985682957564\n",
            "Epoch: 260. Loss: 0.5532914577360195\n",
            "Epoch: 270. Loss: 0.5525889669433888\n",
            "Epoch: 280. Loss: 0.5519759173216241\n",
            "Epoch: 290. Loss: 0.5514396767591824\n",
            "Epoch: 300. Loss: 0.5509696748492955\n",
            "Epoch: 310. Loss: 0.5505570165703095\n",
            "Epoch: 320. Loss: 0.550194174573863\n",
            "Epoch: 330. Loss: 0.5498747438892029\n",
            "Epoch: 340. Loss: 0.5495932459948862\n",
            "tensor(0.8790, dtype=torch.float64)\n",
            "2021-04-25 00:00:00\n",
            "Epoch: 0. Loss: 1.257513335796087\n",
            "Epoch: 10. Loss: 0.9343316579011874\n",
            "Epoch: 20. Loss: 0.7242414090047632\n",
            "Epoch: 30. Loss: 0.6141692683120349\n",
            "Epoch: 40. Loss: 0.5753316543806641\n",
            "Epoch: 50. Loss: 0.5650179396452734\n",
            "Epoch: 60. Loss: 0.5615837202494592\n",
            "Epoch: 70. Loss: 0.5598362624430855\n",
            "Epoch: 80. Loss: 0.5586772125093985\n",
            "Epoch: 90. Loss: 0.5578106474485731\n",
            "Epoch: 100. Loss: 0.5571300773029239\n",
            "Epoch: 110. Loss: 0.5565846856151746\n",
            "Epoch: 120. Loss: 0.5561436631962109\n",
            "Epoch: 130. Loss: 0.5557852813589804\n",
            "Epoch: 140. Loss: 0.5554930370263289\n",
            "Epoch: 150. Loss: 0.5552539948005565\n",
            "Epoch: 160. Loss: 0.5550578850363901\n",
            "Epoch: 170. Loss: 0.5548965097779887\n",
            "Epoch: 180. Loss: 0.5547633063770043\n",
            "Epoch: 190. Loss: 0.5546530108478585\n",
            "Epoch: 200. Loss: 0.5545613931350295\n",
            "Epoch: 210. Loss: 0.5544850474912335\n",
            "Epoch: 220. Loss: 0.5544212261071237\n",
            "Epoch: 230. Loss: 0.5543677069596323\n",
            "Epoch: 240. Loss: 0.5543226887917526\n",
            "Epoch: 250. Loss: 0.5542847076098562\n",
            "Epoch: 260. Loss: 0.5542525702426234\n",
            "Epoch: 270. Loss: 0.5542253014262247\n",
            "Epoch: 280. Loss: 0.554202101613476\n",
            "Epoch: 290. Loss: 0.5541823132877487\n",
            "Epoch: 300. Loss: 0.5541653940252369\n",
            "Epoch: 310. Loss: 0.5541508949159628\n",
            "Epoch: 320. Loss: 0.5541384432441198\n",
            "Epoch: 330. Loss: 0.5541277285578095\n",
            "Epoch: 340. Loss: 0.5541184914394951\n",
            "tensor(0.7910, dtype=torch.float64)\n",
            "2021-05-02 00:00:00\n",
            "Epoch: 0. Loss: 0.9130520853828304\n",
            "Epoch: 10. Loss: 0.8299329561985981\n",
            "Epoch: 20. Loss: 0.7653232659218702\n",
            "Epoch: 30. Loss: 0.7168118284374052\n",
            "Epoch: 40. Loss: 0.6813019818754043\n",
            "Epoch: 50. Loss: 0.6551948937354946\n",
            "Epoch: 60. Loss: 0.6353837166422781\n",
            "Epoch: 70. Loss: 0.6198087354587858\n",
            "Epoch: 80. Loss: 0.6072708865723673\n",
            "Epoch: 90. Loss: 0.5970663985784801\n",
            "Epoch: 100. Loss: 0.5887385879300808\n",
            "Epoch: 110. Loss: 0.5819527717804462\n",
            "Epoch: 120. Loss: 0.57644121418566\n",
            "Epoch: 130. Loss: 0.571980390361178\n",
            "Epoch: 140. Loss: 0.5683813910247243\n",
            "Epoch: 150. Loss: 0.5654850250876352\n",
            "Epoch: 160. Loss: 0.563158311671139\n",
            "Epoch: 170. Loss: 0.5612912710693504\n",
            "Epoch: 180. Loss: 0.5597937894455711\n",
            "Epoch: 190. Loss: 0.5585926115290455\n",
            "Epoch: 200. Loss: 0.5576285634003607\n",
            "Epoch: 210. Loss: 0.556854078811923\n",
            "Epoch: 220. Loss: 0.5562310602638857\n",
            "Epoch: 230. Loss: 0.5557290718647702\n",
            "Epoch: 240. Loss: 0.555323839292005\n",
            "Epoch: 250. Loss: 0.5549960211921362\n",
            "Epoch: 260. Loss: 0.5547302129041841\n",
            "Epoch: 270. Loss: 0.5545141445178001\n",
            "Epoch: 280. Loss: 0.5543380388213967\n",
            "Epoch: 290. Loss: 0.5541940992311141\n",
            "Epoch: 300. Loss: 0.5540761024713667\n",
            "Epoch: 310. Loss: 0.5539790751478946\n",
            "Epoch: 320. Loss: 0.5538990372096744\n",
            "Epoch: 330. Loss: 0.5538327985775865\n",
            "Epoch: 340. Loss: 0.5537777979448697\n",
            "tensor(0.8377, dtype=torch.float64)\n",
            "2021-05-09 00:00:00\n",
            "Epoch: 0. Loss: 0.9883697612188272\n",
            "Epoch: 10. Loss: 0.8092336555348912\n",
            "Epoch: 20. Loss: 0.6882737195832966\n",
            "Epoch: 30. Loss: 0.6273111347513027\n",
            "Epoch: 40. Loss: 0.605120710955463\n",
            "Epoch: 50. Loss: 0.5965826046483241\n",
            "Epoch: 60. Loss: 0.5912861914928668\n",
            "Epoch: 70. Loss: 0.5869319370022422\n",
            "Epoch: 80. Loss: 0.5830948115528789\n",
            "Epoch: 90. Loss: 0.5796637101162173\n",
            "Epoch: 100. Loss: 0.5765820873157248\n",
            "Epoch: 110. Loss: 0.5738078474305535\n",
            "Epoch: 120. Loss: 0.5713060708522877\n",
            "Epoch: 130. Loss: 0.569046948138378\n",
            "Epoch: 140. Loss: 0.5670047437986703\n",
            "Epoch: 150. Loss: 0.5651570778693887\n",
            "Epoch: 160. Loss: 0.5634843699349711\n",
            "Epoch: 170. Loss: 0.561969393946077\n",
            "Epoch: 180. Loss: 0.5605969170249788\n",
            "Epoch: 190. Loss: 0.5593534042332861\n",
            "Epoch: 200. Loss: 0.5582267758956583\n",
            "Epoch: 210. Loss: 0.5572062071454397\n",
            "Epoch: 220. Loss: 0.5562819616036256\n",
            "Epoch: 230. Loss: 0.5554452527975803\n",
            "Epoch: 240. Loss: 0.5546881282210683\n",
            "Epoch: 250. Loss: 0.5540033719345056\n",
            "Epoch: 260. Loss: 0.5533844223790141\n",
            "Epoch: 270. Loss: 0.5528253026865271\n",
            "Epoch: 280. Loss: 0.5523205612531633\n",
            "Epoch: 290. Loss: 0.5518652207356504\n",
            "Epoch: 300. Loss: 0.5514547339532967\n",
            "Epoch: 310. Loss: 0.5510849454468688\n",
            "Epoch: 320. Loss: 0.5507520576718353\n",
            "Epoch: 330. Loss: 0.5504526009944157\n",
            "Epoch: 340. Loss: 0.5501834068200717\n",
            "tensor(0.8160, dtype=torch.float64)\n",
            "2021-05-16 00:00:00\n",
            "Epoch: 0. Loss: 1.5391859295359354\n",
            "Epoch: 10. Loss: 0.9351433887245663\n",
            "Epoch: 20. Loss: 0.7462863319352525\n",
            "Epoch: 30. Loss: 0.6716223823648843\n",
            "Epoch: 40. Loss: 0.634869670510853\n",
            "Epoch: 50. Loss: 0.6132040745661826\n",
            "Epoch: 60. Loss: 0.598468568655606\n",
            "Epoch: 70. Loss: 0.5878759421450287\n",
            "Epoch: 80. Loss: 0.5802069995207443\n",
            "Epoch: 90. Loss: 0.5746842289581691\n",
            "Epoch: 100. Loss: 0.5707282122281697\n",
            "Epoch: 110. Loss: 0.5679012972258991\n",
            "Epoch: 120. Loss: 0.5658793967347089\n",
            "Epoch: 130. Loss: 0.5644274781756392\n",
            "Epoch: 140. Loss: 0.563377804212715\n",
            "Epoch: 150. Loss: 0.5626119773313493\n",
            "Epoch: 160. Loss: 0.5620469933622126\n",
            "Epoch: 170. Loss: 0.5616248564354887\n",
            "Epoch: 180. Loss: 0.5613050655264178\n",
            "Epoch: 190. Loss: 0.5610592840399403\n",
            "Epoch: 200. Loss: 0.5608676076209739\n",
            "Epoch: 210. Loss: 0.5607159732958207\n",
            "Epoch: 220. Loss: 0.5605943702234624\n",
            "Epoch: 230. Loss: 0.560495607262964\n",
            "Epoch: 240. Loss: 0.5604144645646014\n",
            "Epoch: 250. Loss: 0.5603471088796856\n",
            "Epoch: 260. Loss: 0.5602906895870207\n",
            "Epoch: 270. Loss: 0.5602430585046666\n",
            "Epoch: 280. Loss: 0.5602025745734522\n",
            "Epoch: 290. Loss: 0.5601679668588693\n",
            "Epoch: 300. Loss: 0.5601382377568276\n",
            "Epoch: 310. Loss: 0.560112594034234\n",
            "Epoch: 320. Loss: 0.5600903972420441\n",
            "Epoch: 330. Loss: 0.5600711276945792\n",
            "Epoch: 340. Loss: 0.5600543580164443\n",
            "tensor(0.7892, dtype=torch.float64)\n",
            "2021-05-23 00:00:00\n",
            "Epoch: 0. Loss: 2.128427899430386\n",
            "Epoch: 10. Loss: 0.9613565929676463\n",
            "Epoch: 20. Loss: 0.770882594243599\n",
            "Epoch: 30. Loss: 0.7123187520693908\n",
            "Epoch: 40. Loss: 0.6758688108856191\n",
            "Epoch: 50. Loss: 0.649096527954236\n",
            "Epoch: 60. Loss: 0.6284532905501287\n",
            "Epoch: 70. Loss: 0.6124140760506273\n",
            "Epoch: 80. Loss: 0.6000545637827034\n",
            "Epoch: 90. Loss: 0.5906497776342728\n",
            "Epoch: 100. Loss: 0.5835810695341209\n",
            "Epoch: 110. Loss: 0.5783213937174133\n",
            "Epoch: 120. Loss: 0.5744339404468826\n",
            "Epoch: 130. Loss: 0.5715688513457094\n",
            "Epoch: 140. Loss: 0.5694551584522742\n",
            "Epoch: 150. Loss: 0.567888948776398\n",
            "Epoch: 160. Loss: 0.5667201125790852\n",
            "Epoch: 170. Loss: 0.5658397982314628\n",
            "Epoch: 180. Loss: 0.5651697688857754\n",
            "Epoch: 190. Loss: 0.5646540029313107\n",
            "Epoch: 200. Loss: 0.5642523735880761\n",
            "Epoch: 210. Loss: 0.5639360382714054\n",
            "Epoch: 220. Loss: 0.5636841408700021\n",
            "Epoch: 230. Loss: 0.5634814809215607\n",
            "Epoch: 240. Loss: 0.5633168765384442\n",
            "Epoch: 250. Loss: 0.5631820171369283\n",
            "Epoch: 260. Loss: 0.5630706587123214\n",
            "Epoch: 270. Loss: 0.5629780575172249\n",
            "Epoch: 280. Loss: 0.5629005694246884\n",
            "Epoch: 290. Loss: 0.5628353645747962\n",
            "Epoch: 300. Loss: 0.5627802224973113\n",
            "Epoch: 310. Loss: 0.562733383691438\n",
            "Epoch: 320. Loss: 0.5626934410649188\n",
            "Epoch: 330. Loss: 0.5626592597259894\n",
            "Epoch: 340. Loss: 0.5626299171135585\n",
            "tensor(0.7086, dtype=torch.float64)\n",
            "2021-05-30 00:00:00\n",
            "Epoch: 0. Loss: 1.653745809299261\n",
            "Epoch: 10. Loss: 1.4412775425410937\n",
            "Epoch: 20. Loss: 1.246586781769393\n",
            "Epoch: 30. Loss: 1.0759884445074013\n",
            "Epoch: 40. Loss: 0.9363521506773544\n",
            "Epoch: 50. Loss: 0.8312677152911779\n",
            "Epoch: 60. Loss: 0.7585915823362979\n",
            "Epoch: 70. Loss: 0.7109944239561976\n",
            "Epoch: 80. Loss: 0.6795680158576121\n",
            "Epoch: 90. Loss: 0.6574326546567408\n",
            "Epoch: 100. Loss: 0.6405990842044612\n",
            "Epoch: 110. Loss: 0.6270704731380913\n",
            "Epoch: 120. Loss: 0.6158667500976805\n",
            "Epoch: 130. Loss: 0.6064592918107691\n",
            "Epoch: 140. Loss: 0.598512193827832\n",
            "Epoch: 150. Loss: 0.5917774445592014\n",
            "Epoch: 160. Loss: 0.5860553144077488\n",
            "Epoch: 170. Loss: 0.5811794853778276\n",
            "Epoch: 180. Loss: 0.5770106143141971\n",
            "Epoch: 190. Loss: 0.5734324215882441\n",
            "Epoch: 200. Loss: 0.5703484550174458\n",
            "Epoch: 210. Loss: 0.5676791029757329\n",
            "Epoch: 220. Loss: 0.5653588471469793\n",
            "Epoch: 230. Loss: 0.5633338158709722\n",
            "Epoch: 240. Loss: 0.5615596736999717\n",
            "Epoch: 250. Loss: 0.5599998462581282\n",
            "Epoch: 260. Loss: 0.5586240542329354\n",
            "Epoch: 270. Loss: 0.5574071179567924\n",
            "Epoch: 280. Loss: 0.5563279908419791\n",
            "Epoch: 290. Loss: 0.5553689820069921\n",
            "Epoch: 300. Loss: 0.5545151329669099\n",
            "Epoch: 310. Loss: 0.5537537185513873\n",
            "Epoch: 320. Loss: 0.5530738473560082\n",
            "Epoch: 330. Loss: 0.552466141618466\n",
            "Epoch: 340. Loss: 0.5519224803118392\n",
            "tensor(0.7073, dtype=torch.float64)\n",
            "2021-06-06 00:00:00\n",
            "Epoch: 0. Loss: 1.7491150306009746\n",
            "Epoch: 10. Loss: 0.7043299776140276\n",
            "Epoch: 20. Loss: 0.6104287776483902\n",
            "Epoch: 30. Loss: 0.5891264935391709\n",
            "Epoch: 40. Loss: 0.5788861847438497\n",
            "Epoch: 50. Loss: 0.5720866910143715\n",
            "Epoch: 60. Loss: 0.5669657581068426\n",
            "Epoch: 70. Loss: 0.5629598192778621\n",
            "Epoch: 80. Loss: 0.5597942351281862\n",
            "Epoch: 90. Loss: 0.5572852066188342\n",
            "Epoch: 100. Loss: 0.5552934859968962\n",
            "Epoch: 110. Loss: 0.5537100293323375\n",
            "Epoch: 120. Loss: 0.5524488997016822\n",
            "Epoch: 130. Loss: 0.5514423691914644\n",
            "Epoch: 140. Loss: 0.5506371107627989\n",
            "Epoch: 150. Loss: 0.5499911617785559\n",
            "Epoch: 160. Loss: 0.5494715040112461\n",
            "Epoch: 170. Loss: 0.5490521454059542\n",
            "Epoch: 180. Loss: 0.5487126073138388\n",
            "Epoch: 190. Loss: 0.5484367359479623\n",
            "Epoch: 200. Loss: 0.5482117708154426\n",
            "Epoch: 210. Loss: 0.5480276155280599\n",
            "Epoch: 220. Loss: 0.5478762673104768\n",
            "Epoch: 230. Loss: 0.547751370621958\n",
            "Epoch: 240. Loss: 0.5476478677029796\n",
            "Epoch: 250. Loss: 0.5475617247704486\n",
            "Epoch: 260. Loss: 0.5474897172587602\n",
            "Epoch: 270. Loss: 0.5474292611706056\n",
            "Epoch: 280. Loss: 0.5473782804644791\n",
            "Epoch: 290. Loss: 0.5473351026348307\n",
            "Epoch: 300. Loss: 0.5472983763735072\n",
            "Epoch: 310. Loss: 0.5472670065472073\n",
            "Epoch: 320. Loss: 0.5472401027714668\n",
            "Epoch: 330. Loss: 0.547216938674638\n",
            "Epoch: 340. Loss: 0.5471969195778068\n",
            "tensor(0.8212, dtype=torch.float64)\n",
            "2021-06-13 00:00:00\n",
            "Epoch: 0. Loss: 1.0661533536698813\n",
            "Epoch: 10. Loss: 0.9345177677343924\n",
            "Epoch: 20. Loss: 0.8473896802020706\n",
            "Epoch: 30. Loss: 0.7857384491006832\n",
            "Epoch: 40. Loss: 0.7378935125765637\n",
            "Epoch: 50. Loss: 0.6987512533421185\n",
            "Epoch: 60. Loss: 0.666319331668283\n",
            "Epoch: 70. Loss: 0.6396745482506919\n",
            "Epoch: 80. Loss: 0.6181558485641253\n",
            "Epoch: 90. Loss: 0.6011128527707769\n",
            "Epoch: 100. Loss: 0.587863186054929\n",
            "Epoch: 110. Loss: 0.577722324776207\n",
            "Epoch: 120. Loss: 0.5700486422951492\n",
            "Epoch: 130. Loss: 0.5642785728237706\n",
            "Epoch: 140. Loss: 0.5599439781371692\n",
            "Epoch: 150. Loss: 0.5566733080770898\n",
            "Epoch: 160. Loss: 0.554182061299752\n",
            "Epoch: 170. Loss: 0.5522582524098232\n",
            "Epoch: 180. Loss: 0.5507470503174925\n",
            "Epoch: 190. Loss: 0.5495369283223782\n",
            "Epoch: 200. Loss: 0.5485482622246295\n",
            "Epoch: 210. Loss: 0.5477244696040012\n",
            "Epoch: 220. Loss: 0.5470253827844697\n",
            "Epoch: 230. Loss: 0.5464224198680668\n",
            "Epoch: 240. Loss: 0.5458951284198436\n",
            "Epoch: 250. Loss: 0.5454287419669988\n",
            "Epoch: 260. Loss: 0.5450124671016171\n",
            "Epoch: 270. Loss: 0.5446382896056066\n",
            "Epoch: 280. Loss: 0.5443001454438132\n",
            "Epoch: 290. Loss: 0.5439933464080323\n",
            "Epoch: 300. Loss: 0.5437141826011571\n",
            "Epoch: 310. Loss: 0.543459647301591\n",
            "Epoch: 320. Loss: 0.5432272463172729\n",
            "Epoch: 330. Loss: 0.5430148655751033\n",
            "Epoch: 340. Loss: 0.5428206788067489\n",
            "tensor(0.6111, dtype=torch.float64)\n",
            "2021-06-20 00:00:00\n",
            "Epoch: 0. Loss: 2.0631647987859307\n",
            "Epoch: 10. Loss: 0.8518043691425626\n",
            "Epoch: 20. Loss: 0.6695271452329058\n",
            "Epoch: 30. Loss: 0.6294604219953135\n",
            "Epoch: 40. Loss: 0.6098034310606946\n",
            "Epoch: 50. Loss: 0.5971522588868023\n",
            "Epoch: 60. Loss: 0.5878870247118506\n",
            "Epoch: 70. Loss: 0.5807477659563007\n",
            "Epoch: 80. Loss: 0.575165430005927\n",
            "Epoch: 90. Loss: 0.5707894829595527\n",
            "Epoch: 100. Loss: 0.5673615819435229\n",
            "Epoch: 110. Loss: 0.5646794559214315\n",
            "Epoch: 120. Loss: 0.5625827557795865\n",
            "Epoch: 130. Loss: 0.5609445444460748\n",
            "Epoch: 140. Loss: 0.5596647594401417\n",
            "Epoch: 150. Loss: 0.5586648394477886\n",
            "Epoch: 160. Loss: 0.5578832957966411\n",
            "Epoch: 170. Loss: 0.5572721069178499\n",
            "Epoch: 180. Loss: 0.5567938207471096\n",
            "Epoch: 190. Loss: 0.5564192507040718\n",
            "Epoch: 200. Loss: 0.5561256582501413\n",
            "Epoch: 210. Loss: 0.5558953274796891\n",
            "Epoch: 220. Loss: 0.5557144516096336\n",
            "Epoch: 230. Loss: 0.555572265390927\n",
            "Epoch: 240. Loss: 0.5554603702093864\n",
            "Epoch: 250. Loss: 0.5553722095256549\n",
            "Epoch: 260. Loss: 0.5553026612888611\n",
            "Epoch: 270. Loss: 0.5552477212123179\n",
            "Epoch: 280. Loss: 0.5552042565676247\n",
            "Epoch: 290. Loss: 0.5551698146928661\n",
            "Epoch: 300. Loss: 0.5551424739580013\n",
            "Epoch: 310. Loss: 0.5551207276898876\n",
            "Epoch: 320. Loss: 0.5551033936993862\n",
            "Epoch: 330. Loss: 0.5550895437098134\n",
            "Epoch: 340. Loss: 0.5550784482676075\n",
            "tensor(0.9094, dtype=torch.float64)\n",
            "2021-06-27 00:00:00\n",
            "Epoch: 0. Loss: 0.8507484389646056\n",
            "Epoch: 10. Loss: 0.7235881089448953\n",
            "Epoch: 20. Loss: 0.6520401437388965\n",
            "Epoch: 30. Loss: 0.6148789766566721\n",
            "Epoch: 40. Loss: 0.5946424108655866\n",
            "Epoch: 50. Loss: 0.5821230249676183\n",
            "Epoch: 60. Loss: 0.5735296930100856\n",
            "Epoch: 70. Loss: 0.5673308243751681\n",
            "Epoch: 80. Loss: 0.5627760126966997\n",
            "Epoch: 90. Loss: 0.5594023442329563\n",
            "Epoch: 100. Loss: 0.5568859924529568\n",
            "Epoch: 110. Loss: 0.5549916381744252\n",
            "Epoch: 120. Loss: 0.5535479048080295\n",
            "Epoch: 130. Loss: 0.5524308767558823\n",
            "Epoch: 140. Loss: 0.5515516123845353\n",
            "Epoch: 150. Loss: 0.5508465909590573\n",
            "Epoch: 160. Loss: 0.5502705468246077\n",
            "Epoch: 170. Loss: 0.5497912082894665\n",
            "Epoch: 180. Loss: 0.5493854999468093\n",
            "Epoch: 190. Loss: 0.5490368345182094\n",
            "Epoch: 200. Loss: 0.5487331975347718\n",
            "Epoch: 210. Loss: 0.5484657999194502\n",
            "Epoch: 220. Loss: 0.5482281330276715\n",
            "Epoch: 230. Loss: 0.5480153068907074\n",
            "Epoch: 240. Loss: 0.5478235868441705\n",
            "Epoch: 250. Loss: 0.5476500687507139\n",
            "Epoch: 260. Loss: 0.5474924509126541\n",
            "Epoch: 270. Loss: 0.5473488734145688\n",
            "Epoch: 280. Loss: 0.5472178045102105\n",
            "Epoch: 290. Loss: 0.5470979598672702\n",
            "Epoch: 300. Loss: 0.5469882448011502\n",
            "Epoch: 310. Loss: 0.5468877126307589\n",
            "Epoch: 320. Loss: 0.5467955343745092\n",
            "Epoch: 330. Loss: 0.5467109764527406\n",
            "Epoch: 340. Loss: 0.5466333840685857\n",
            "tensor(0.6534, dtype=torch.float64)\n",
            "2021-07-04 00:00:00\n",
            "Epoch: 0. Loss: 0.6858174854232683\n",
            "Epoch: 10. Loss: 0.588914889647497\n",
            "Epoch: 20. Loss: 0.5758685646017382\n",
            "Epoch: 30. Loss: 0.5714833982991074\n",
            "Epoch: 40. Loss: 0.5689214922110669\n",
            "Epoch: 50. Loss: 0.5669369236005776\n",
            "Epoch: 60. Loss: 0.5652412446544252\n",
            "Epoch: 70. Loss: 0.5637434257159393\n",
            "Epoch: 80. Loss: 0.5623997289721552\n",
            "Epoch: 90. Loss: 0.5611819243852214\n",
            "Epoch: 100. Loss: 0.5600694479568162\n",
            "Epoch: 110. Loss: 0.5590466876683222\n",
            "Epoch: 120. Loss: 0.558101573710683\n",
            "Epoch: 130. Loss: 0.5572246471021689\n",
            "Epoch: 140. Loss: 0.5564083901992269\n",
            "Epoch: 150. Loss: 0.5556467349584547\n",
            "Epoch: 160. Loss: 0.5549347004554283\n",
            "Epoch: 170. Loss: 0.55426812582373\n",
            "Epoch: 180. Loss: 0.5536434736653795\n",
            "Epoch: 190. Loss: 0.5530576853668939\n",
            "Epoch: 200. Loss: 0.5525080745371994\n",
            "Epoch: 210. Loss: 0.5519922483780593\n",
            "Epoch: 220. Loss: 0.5515080494854141\n",
            "Epoch: 230. Loss: 0.5510535125775234\n",
            "Epoch: 240. Loss: 0.5506268321225208\n",
            "Epoch: 250. Loss: 0.5502263379250111\n",
            "Epoch: 260. Loss: 0.5498504765286666\n",
            "Epoch: 270. Loss: 0.5494977968749644\n",
            "Epoch: 280. Loss: 0.549166939083747\n",
            "Epoch: 290. Loss: 0.5488566255311991\n",
            "Epoch: 300. Loss: 0.5485656536261689\n",
            "Epoch: 310. Loss: 0.5482928898494079\n",
            "Epoch: 320. Loss: 0.548037264738992\n",
            "Epoch: 330. Loss: 0.5477977685912567\n",
            "Epoch: 340. Loss: 0.547573447708912\n",
            "tensor(0.7993, dtype=torch.float64)\n",
            "2021-07-11 00:00:00\n",
            "Epoch: 0. Loss: 1.2003578048221004\n",
            "Epoch: 10. Loss: 0.9375634033850098\n",
            "Epoch: 20. Loss: 0.7980791455030217\n",
            "Epoch: 30. Loss: 0.7020941380176765\n",
            "Epoch: 40. Loss: 0.6417147740937575\n",
            "Epoch: 50. Loss: 0.6098292992249734\n",
            "Epoch: 60. Loss: 0.5936971241539646\n",
            "Epoch: 70. Loss: 0.584145002267221\n",
            "Epoch: 80. Loss: 0.5773766230187831\n",
            "Epoch: 90. Loss: 0.5720881567400042\n",
            "Epoch: 100. Loss: 0.5677869335557096\n",
            "Epoch: 110. Loss: 0.5642331756047475\n",
            "Epoch: 120. Loss: 0.5612760015897623\n",
            "Epoch: 130. Loss: 0.558804198086666\n",
            "Epoch: 140. Loss: 0.5567298938633007\n",
            "Epoch: 150. Loss: 0.5549819386280549\n",
            "Epoch: 160. Loss: 0.5535023266645529\n",
            "Epoch: 170. Loss: 0.5522437269873149\n",
            "Epoch: 180. Loss: 0.5511675447502024\n",
            "Epoch: 190. Loss: 0.5502423301426866\n",
            "Epoch: 200. Loss: 0.5494424608247226\n",
            "Epoch: 210. Loss: 0.5487470539937093\n",
            "Epoch: 220. Loss: 0.5481390730846404\n",
            "Epoch: 230. Loss: 0.5476045982441985\n",
            "Epoch: 240. Loss: 0.5471322331856956\n",
            "Epoch: 250. Loss: 0.546712624542088\n",
            "Epoch: 260. Loss: 0.5463380733084438\n",
            "Epoch: 270. Loss: 0.5460022212253076\n",
            "Epoch: 280. Loss: 0.5456997978811429\n",
            "Epoch: 290. Loss: 0.5454264168555217\n",
            "Epoch: 300. Loss: 0.5451784113839725\n",
            "Epoch: 310. Loss: 0.5449527018275561\n",
            "Epoch: 320. Loss: 0.5447466887158796\n",
            "Epoch: 330. Loss: 0.5445581663458733\n",
            "Epoch: 340. Loss: 0.5443852529035065\n",
            "tensor(0.7767, dtype=torch.float64)\n",
            "2021-07-18 00:00:00\n",
            "Epoch: 0. Loss: 1.8694656627201494\n",
            "Epoch: 10. Loss: 0.6163132999172108\n",
            "Epoch: 20. Loss: 0.5796824546333085\n",
            "Epoch: 30. Loss: 0.5724373570619851\n",
            "Epoch: 40. Loss: 0.5687313115845961\n",
            "Epoch: 50. Loss: 0.56618902885112\n",
            "Epoch: 60. Loss: 0.5642038429554278\n",
            "Epoch: 70. Loss: 0.5625534076348486\n",
            "Epoch: 80. Loss: 0.561137733806939\n",
            "Epoch: 90. Loss: 0.5599015885276241\n",
            "Epoch: 100. Loss: 0.558808924504024\n",
            "Epoch: 110. Loss: 0.5578337343485763\n",
            "Epoch: 120. Loss: 0.5569562848211924\n",
            "Epoch: 130. Loss: 0.5561612293336828\n",
            "Epoch: 140. Loss: 0.5554364652820821\n",
            "Epoch: 150. Loss: 0.5547723498093722\n",
            "Epoch: 160. Loss: 0.554161126439059\n",
            "Epoch: 170. Loss: 0.553596494510146\n",
            "Epoch: 180. Loss: 0.553073282520098\n",
            "Epoch: 190. Loss: 0.5525871993263912\n",
            "Epoch: 200. Loss: 0.5521346442610952\n",
            "Epoch: 210. Loss: 0.551712561924324\n",
            "Epoch: 220. Loss: 0.5513183308616042\n",
            "Epoch: 230. Loss: 0.5509496779336138\n",
            "Epoch: 240. Loss: 0.5506046121746022\n",
            "Epoch: 250. Loss: 0.5502813734513423\n",
            "Epoch: 260. Loss: 0.5499783923849512\n",
            "Epoch: 270. Loss: 0.5496942588674933\n",
            "Epoch: 280. Loss: 0.5494276971602736\n",
            "Epoch: 290. Loss: 0.549177546052951\n",
            "Epoch: 300. Loss: 0.5489427429320535\n",
            "Epoch: 310. Loss: 0.5487223108847298\n",
            "Epoch: 320. Loss: 0.5485153481718038\n",
            "Epoch: 330. Loss: 0.5483210195608222\n",
            "Epoch: 340. Loss: 0.548138549127894\n",
            "tensor(0.7086, dtype=torch.float64)\n",
            "2021-07-25 00:00:00\n",
            "Epoch: 0. Loss: 1.0842625344763506\n",
            "Epoch: 10. Loss: 0.8766351153496951\n",
            "Epoch: 20. Loss: 0.7374851987910274\n",
            "Epoch: 30. Loss: 0.6549651186822365\n",
            "Epoch: 40. Loss: 0.6105575628207648\n",
            "Epoch: 50. Loss: 0.588025123640055\n",
            "Epoch: 60. Loss: 0.575810251040033\n",
            "Epoch: 70. Loss: 0.5682896294306784\n",
            "Epoch: 80. Loss: 0.5631885283214241\n",
            "Epoch: 90. Loss: 0.5595524497098281\n",
            "Epoch: 100. Loss: 0.5569048463295856\n",
            "Epoch: 110. Loss: 0.5549584606068658\n",
            "Epoch: 120. Loss: 0.5535180987322387\n",
            "Epoch: 130. Loss: 0.5524440809830693\n",
            "Epoch: 140. Loss: 0.5516349861472877\n",
            "Epoch: 150. Loss: 0.5510172140433693\n",
            "Epoch: 160. Loss: 0.5505376346538036\n",
            "Epoch: 170. Loss: 0.5501581161633443\n",
            "Epoch: 180. Loss: 0.5498514217463746\n",
            "Epoch: 190. Loss: 0.5495981605855941\n",
            "Epoch: 200. Loss: 0.5493845504314666\n",
            "Epoch: 210. Loss: 0.549200794673015\n",
            "Epoch: 220. Loss: 0.5490399164621301\n",
            "Epoch: 230. Loss: 0.5488969275877109\n",
            "Epoch: 240. Loss: 0.5487682395279542\n",
            "Epoch: 250. Loss: 0.548651248039283\n",
            "Epoch: 260. Loss: 0.5485440411782833\n",
            "Epoch: 270. Loss: 0.5484451946173582\n",
            "Epoch: 280. Loss: 0.5483536284218709\n",
            "Epoch: 290. Loss: 0.5482685069513594\n",
            "Epoch: 300. Loss: 0.5481891689370549\n",
            "Epoch: 310. Loss: 0.5481150786314796\n",
            "Epoch: 320. Loss: 0.5480457916493962\n",
            "Epoch: 330. Loss: 0.5479809310397287\n",
            "Epoch: 340. Loss: 0.5479201704768955\n",
            "tensor(0.8443, dtype=torch.float64)\n",
            "2021-08-01 00:00:00\n",
            "Epoch: 0. Loss: 1.762004607163544\n",
            "Epoch: 10. Loss: 1.0018325238858212\n",
            "Epoch: 20. Loss: 0.7989941749592726\n",
            "Epoch: 30. Loss: 0.6994068056671013\n",
            "Epoch: 40. Loss: 0.6435590789563519\n",
            "Epoch: 50. Loss: 0.6152093960261557\n",
            "Epoch: 60. Loss: 0.599934809947211\n",
            "Epoch: 70. Loss: 0.5898223501590556\n",
            "Epoch: 80. Loss: 0.5820593918527005\n",
            "Epoch: 90. Loss: 0.5757160682128547\n",
            "Epoch: 100. Loss: 0.5704208488012805\n",
            "Epoch: 110. Loss: 0.5659697232563071\n",
            "Epoch: 120. Loss: 0.5622188865264784\n",
            "Epoch: 130. Loss: 0.5590546671271006\n",
            "Epoch: 140. Loss: 0.5563836972804855\n",
            "Epoch: 150. Loss: 0.5541283780154039\n",
            "Epoch: 160. Loss: 0.5522239064965947\n",
            "Epoch: 170. Loss: 0.5506159739092791\n",
            "Epoch: 180. Loss: 0.5492589085373283\n",
            "Epoch: 190. Loss: 0.5481141759119644\n",
            "Epoch: 200. Loss: 0.5471491718058373\n",
            "Epoch: 210. Loss: 0.5463362505660944\n",
            "Epoch: 220. Loss: 0.5456519386736768\n",
            "Epoch: 230. Loss: 0.5450762923599954\n",
            "Epoch: 240. Loss: 0.5445923670441493\n",
            "Epoch: 250. Loss: 0.5441857741685091\n",
            "Epoch: 260. Loss: 0.543844307286431\n",
            "Epoch: 270. Loss: 0.5435576240105434\n",
            "Epoch: 280. Loss: 0.5433169738875004\n",
            "Epoch: 290. Loss: 0.5431149647095662\n",
            "Epoch: 300. Loss: 0.5429453614736542\n",
            "Epoch: 310. Loss: 0.5428029133766296\n",
            "Epoch: 320. Loss: 0.5426832050609216\n",
            "Epoch: 330. Loss: 0.5425825289179642\n",
            "Epoch: 340. Loss: 0.5424977757014443\n",
            "tensor(0.8198, dtype=torch.float64)\n",
            "2021-08-08 00:00:00\n",
            "Epoch: 0. Loss: 1.2461508607344978\n",
            "Epoch: 10. Loss: 1.1504087975036759\n",
            "Epoch: 20. Loss: 1.0707475762135568\n",
            "Epoch: 30. Loss: 1.0033101569287137\n",
            "Epoch: 40. Loss: 0.9451510248341111\n",
            "Epoch: 50. Loss: 0.8937476723814607\n",
            "Epoch: 60. Loss: 0.847377462571842\n",
            "Epoch: 70. Loss: 0.8051309714930978\n",
            "Epoch: 80. Loss: 0.766636095749253\n",
            "Epoch: 90. Loss: 0.7317921794167407\n",
            "Epoch: 100. Loss: 0.7005984414755185\n",
            "Epoch: 110. Loss: 0.6730573608899408\n",
            "Epoch: 120. Loss: 0.6491233761716051\n",
            "Epoch: 130. Loss: 0.6286784885520338\n",
            "Epoch: 140. Loss: 0.6115256986305748\n",
            "Epoch: 150. Loss: 0.5973953886640435\n",
            "Epoch: 160. Loss: 0.5859607346390813\n",
            "Epoch: 170. Loss: 0.5768586261044337\n",
            "Epoch: 180. Loss: 0.5697133960447703\n",
            "Epoch: 190. Loss: 0.5641608522258739\n",
            "Epoch: 200. Loss: 0.5598691403449181\n",
            "Epoch: 210. Loss: 0.55655273899661\n",
            "Epoch: 220. Loss: 0.5539779038528095\n",
            "Epoch: 230. Loss: 0.5519607789683815\n",
            "Epoch: 240. Loss: 0.5503610289256715\n",
            "Epoch: 250. Loss: 0.5490737751701074\n",
            "Epoch: 260. Loss: 0.5480216987768147\n",
            "Epoch: 270. Loss: 0.547148224522614\n",
            "Epoch: 280. Loss: 0.5464120568244725\n",
            "Epoch: 290. Loss: 0.5457829982101\n",
            "Epoch: 300. Loss: 0.5452388448738115\n",
            "Epoch: 310. Loss: 0.5447631277404085\n",
            "Epoch: 320. Loss: 0.5443434903427069\n",
            "Epoch: 330. Loss: 0.5439705336454318\n",
            "Epoch: 340. Loss: 0.54363699719921\n",
            "tensor(0.7497, dtype=torch.float64)\n",
            "2021-08-15 00:00:00\n",
            "Epoch: 0. Loss: 2.0243658913918927\n",
            "Epoch: 10. Loss: 1.45486724884983\n",
            "Epoch: 20. Loss: 1.1750855190878826\n",
            "Epoch: 30. Loss: 1.006481424010903\n",
            "Epoch: 40. Loss: 0.8827979975137569\n",
            "Epoch: 50. Loss: 0.7944614389346523\n",
            "Epoch: 60. Loss: 0.7381559501804289\n",
            "Epoch: 70. Loss: 0.7041983951462176\n",
            "Epoch: 80. Loss: 0.6822451035090497\n",
            "Epoch: 90. Loss: 0.6660542042404634\n",
            "Epoch: 100. Loss: 0.6527216742333185\n",
            "Epoch: 110. Loss: 0.6410290360158607\n",
            "Epoch: 120. Loss: 0.6304803032207261\n",
            "Epoch: 130. Loss: 0.6208678780893045\n",
            "Epoch: 140. Loss: 0.6120938971297872\n",
            "Epoch: 150. Loss: 0.6040998954423558\n",
            "Epoch: 160. Loss: 0.5968400586605281\n",
            "Epoch: 170. Loss: 0.5902715401716121\n",
            "Epoch: 180. Loss: 0.5843513366815752\n",
            "Epoch: 190. Loss: 0.5790356378408533\n",
            "Epoch: 200. Loss: 0.5742800777145742\n",
            "Epoch: 210. Loss: 0.5700402823661729\n",
            "Epoch: 220. Loss: 0.5662724761736928\n",
            "Epoch: 230. Loss: 0.5629340503961806\n",
            "Epoch: 240. Loss: 0.5599840532537617\n",
            "Epoch: 250. Loss: 0.557383584945537\n",
            "Epoch: 260. Loss: 0.5550960932788006\n",
            "Epoch: 270. Loss: 0.5530875729098543\n",
            "Epoch: 280. Loss: 0.5513266759872285\n",
            "Epoch: 290. Loss: 0.549784745054872\n",
            "Epoch: 300. Loss: 0.5484357807553334\n",
            "Epoch: 310. Loss: 0.5472563574100697\n",
            "Epoch: 320. Loss: 0.5462254991864837\n",
            "Epoch: 330. Loss: 0.5453245285390306\n",
            "Epoch: 340. Loss: 0.5445368971748062\n",
            "tensor(0.8756, dtype=torch.float64)\n",
            "2021-08-22 00:00:00\n",
            "Epoch: 0. Loss: 3.9854103903263907\n",
            "Epoch: 10. Loss: 0.9404118726073312\n",
            "Epoch: 20. Loss: 0.7012381298133988\n",
            "Epoch: 30. Loss: 0.6602682007718499\n",
            "Epoch: 40. Loss: 0.6384321229544038\n",
            "Epoch: 50. Loss: 0.6225492913298797\n",
            "Epoch: 60. Loss: 0.609902056975713\n",
            "Epoch: 70. Loss: 0.5994954458067666\n",
            "Epoch: 80. Loss: 0.5908244105479139\n",
            "Epoch: 90. Loss: 0.5835620739288622\n",
            "Epoch: 100. Loss: 0.577461145298871\n",
            "Epoch: 110. Loss: 0.5723205939618013\n",
            "Epoch: 120. Loss: 0.5679732485865259\n",
            "Epoch: 130. Loss: 0.5642798898711561\n",
            "Epoch: 140. Loss: 0.5611252357003953\n",
            "Epoch: 150. Loss: 0.5584144935919265\n",
            "Epoch: 160. Loss: 0.5560701970104073\n",
            "Epoch: 170. Loss: 0.5540293270158023\n",
            "Epoch: 180. Loss: 0.5522407634524679\n",
            "Epoch: 190. Loss: 0.5506630880637535\n",
            "Epoch: 200. Loss: 0.5492627330998621\n",
            "Epoch: 210. Loss: 0.548012448515639\n",
            "Epoch: 220. Loss: 0.5468900501298927\n",
            "Epoch: 230. Loss: 0.5458774077531345\n",
            "Epoch: 240. Loss: 0.5449596335411121\n",
            "Epoch: 250. Loss: 0.544124434552018\n",
            "Epoch: 260. Loss: 0.5433615982385388\n",
            "Epoch: 270. Loss: 0.5426625845234992\n",
            "Epoch: 280. Loss: 0.5420202027165897\n",
            "Epoch: 290. Loss: 0.541428355609014\n",
            "Epoch: 300. Loss: 0.5408818365629401\n",
            "Epoch: 310. Loss: 0.5403761683067938\n",
            "Epoch: 320. Loss: 0.539907474510567\n",
            "Epoch: 330. Loss: 0.5394723771186172\n",
            "Epoch: 340. Loss: 0.539067913934617\n",
            "tensor(0.7824, dtype=torch.float64)\n",
            "2021-08-29 00:00:00\n",
            "Epoch: 0. Loss: 6.371211872075299\n",
            "Epoch: 10. Loss: 1.4150129757701295\n",
            "Epoch: 20. Loss: 0.6306762722495143\n",
            "Epoch: 30. Loss: 0.5930292662092105\n",
            "Epoch: 40. Loss: 0.5766582337690531\n",
            "Epoch: 50. Loss: 0.5657172387825842\n",
            "Epoch: 60. Loss: 0.5578650165640702\n",
            "Epoch: 70. Loss: 0.5520356138794806\n",
            "Epoch: 80. Loss: 0.5476255514329561\n",
            "Epoch: 90. Loss: 0.5442545162279826\n",
            "Epoch: 100. Loss: 0.5416606226346965\n",
            "Epoch: 110. Loss: 0.5396531900584149\n",
            "Epoch: 120. Loss: 0.5380896509988011\n",
            "Epoch: 130. Loss: 0.5368624396630948\n",
            "Epoch: 140. Loss: 0.5358903255094162\n",
            "Epoch: 150. Loss: 0.5351120909841565\n",
            "Epoch: 160. Loss: 0.5344817146944392\n",
            "Epoch: 170. Loss: 0.5339646609379106\n",
            "Epoch: 180. Loss: 0.5335350301150387\n",
            "Epoch: 190. Loss: 0.5331733867901614\n",
            "Epoch: 200. Loss: 0.5328651175723141\n",
            "Epoch: 210. Loss: 0.5325991983653664\n",
            "Epoch: 220. Loss: 0.5323672742123898\n",
            "Epoch: 230. Loss: 0.5321629754273228\n",
            "Epoch: 240. Loss: 0.5319814108753542\n",
            "Epoch: 250. Loss: 0.5318187932175956\n",
            "Epoch: 260. Loss: 0.5316721619850422\n",
            "Epoch: 270. Loss: 0.5315391789199925\n",
            "Epoch: 280. Loss: 0.5314179765722332\n",
            "Epoch: 290. Loss: 0.531307046081177\n",
            "Epoch: 300. Loss: 0.531205153773511\n",
            "Epoch: 310. Loss: 0.5311112789534089\n",
            "Epoch: 320. Loss: 0.531024567292602\n",
            "Epoch: 330. Loss: 0.5309442957218103\n",
            "Epoch: 340. Loss: 0.5308698458213922\n",
            "tensor(0.8635, dtype=torch.float64)\n",
            "2021-09-05 00:00:00\n",
            "Epoch: 0. Loss: 2.6637604000682558\n",
            "Epoch: 10. Loss: 0.7284331609668966\n",
            "Epoch: 20. Loss: 0.623727699638225\n",
            "Epoch: 30. Loss: 0.5928559126623988\n",
            "Epoch: 40. Loss: 0.5748742882103354\n",
            "Epoch: 50. Loss: 0.5632189347006773\n",
            "Epoch: 60. Loss: 0.5549368215498814\n",
            "Epoch: 70. Loss: 0.5485746675026931\n",
            "Epoch: 80. Loss: 0.5434432367125283\n",
            "Epoch: 90. Loss: 0.5391970754704529\n",
            "Epoch: 100. Loss: 0.535639303782564\n",
            "Epoch: 110. Loss: 0.532640148380009\n",
            "Epoch: 120. Loss: 0.5301038423401851\n",
            "Epoch: 130. Loss: 0.5279547658964885\n",
            "Epoch: 140. Loss: 0.5261311223082229\n",
            "Epoch: 150. Loss: 0.5245816124363141\n",
            "Epoch: 160. Loss: 0.5232633653954729\n",
            "Epoch: 170. Loss: 0.5221404533603392\n",
            "Epoch: 180. Loss: 0.5211827268950203\n",
            "Epoch: 190. Loss: 0.5203648617955744\n",
            "Epoch: 200. Loss: 0.5196655662887744\n",
            "Epoch: 210. Loss: 0.5190669189593734\n",
            "Epoch: 220. Loss: 0.5185538161548585\n",
            "Epoch: 230. Loss: 0.5181135115158809\n",
            "Epoch: 240. Loss: 0.5177352327759445\n",
            "Epoch: 250. Loss: 0.5174098630406924\n",
            "Epoch: 260. Loss: 0.5171296756364826\n",
            "Epoch: 270. Loss: 0.5168881133300511\n",
            "Epoch: 280. Loss: 0.5166796042432389\n",
            "Epoch: 290. Loss: 0.5164994081052275\n",
            "Epoch: 300. Loss: 0.5163434876026946\n",
            "Epoch: 310. Loss: 0.5162084005214318\n",
            "Epoch: 320. Loss: 0.5160912091434122\n",
            "Epoch: 330. Loss: 0.5159894039949289\n",
            "Epoch: 340. Loss: 0.5159008395571947\n",
            "tensor(0.7796, dtype=torch.float64)\n",
            "2021-09-12 00:00:00\n",
            "Epoch: 0. Loss: 0.9548346053645171\n",
            "Epoch: 10. Loss: 0.7990283533357709\n",
            "Epoch: 20. Loss: 0.7055750313574715\n",
            "Epoch: 30. Loss: 0.6388190276979552\n",
            "Epoch: 40. Loss: 0.5950488470108544\n",
            "Epoch: 50. Loss: 0.5696299537910835\n",
            "Epoch: 60. Loss: 0.5560921712765476\n",
            "Epoch: 70. Loss: 0.5489538640409862\n",
            "Epoch: 80. Loss: 0.5449075564126953\n",
            "Epoch: 90. Loss: 0.5423148465497545\n",
            "Epoch: 100. Loss: 0.5404228025575368\n",
            "Epoch: 110. Loss: 0.5388885367634092\n",
            "Epoch: 120. Loss: 0.537553650119905\n",
            "Epoch: 130. Loss: 0.53634330790616\n",
            "Epoch: 140. Loss: 0.5352211017458343\n",
            "Epoch: 150. Loss: 0.5341685597850048\n",
            "Epoch: 160. Loss: 0.533175691163969\n",
            "Epoch: 170. Loss: 0.5322365623691905\n",
            "Epoch: 180. Loss: 0.5313472071702848\n",
            "Epoch: 190. Loss: 0.5305046329170611\n",
            "Epoch: 200. Loss: 0.5297063465251995\n",
            "Epoch: 210. Loss: 0.5289501281161036\n",
            "Epoch: 220. Loss: 0.5282339229638274\n",
            "Epoch: 230. Loss: 0.5275557899624379\n",
            "Epoch: 240. Loss: 0.52691387703426\n",
            "Epoch: 250. Loss: 0.5263064093102163\n",
            "Epoch: 260. Loss: 0.5257316832993055\n",
            "Epoch: 270. Loss: 0.5251880638053841\n",
            "Epoch: 280. Loss: 0.5246739820470726\n",
            "Epoch: 290. Loss: 0.5241879342504698\n",
            "Epoch: 300. Loss: 0.5237284803747327\n",
            "Epoch: 310. Loss: 0.5232942428180266\n",
            "Epoch: 320. Loss: 0.5228839050414302\n",
            "Epoch: 330. Loss: 0.5224962100916033\n",
            "Epoch: 340. Loss: 0.5221299590235648\n",
            "tensor(0.8265, dtype=torch.float64)\n",
            "2021-09-19 00:00:00\n",
            "Epoch: 0. Loss: 1.2791015772055259\n",
            "Epoch: 10. Loss: 0.7123250401660215\n",
            "Epoch: 20. Loss: 0.612649022338697\n",
            "Epoch: 30. Loss: 0.5769739746799167\n",
            "Epoch: 40. Loss: 0.5625577209269764\n",
            "Epoch: 50. Loss: 0.5560888846093263\n",
            "Epoch: 60. Loss: 0.5525215141657679\n",
            "Epoch: 70. Loss: 0.5500491434514548\n",
            "Epoch: 80. Loss: 0.5480452263835514\n",
            "Epoch: 90. Loss: 0.5462844471552528\n",
            "Epoch: 100. Loss: 0.5446784625417856\n",
            "Epoch: 110. Loss: 0.5431878789161839\n",
            "Epoch: 120. Loss: 0.5417921085903418\n",
            "Epoch: 130. Loss: 0.5404785394401913\n",
            "Epoch: 140. Loss: 0.5392383877366985\n",
            "Epoch: 150. Loss: 0.5380649732327696\n",
            "Epoch: 160. Loss: 0.5369529231484709\n",
            "Epoch: 170. Loss: 0.5358977583673588\n",
            "Epoch: 180. Loss: 0.5348956514296205\n",
            "Epoch: 190. Loss: 0.533943270332488\n",
            "Epoch: 200. Loss: 0.5330376702831672\n",
            "Epoch: 210. Loss: 0.5321762151416609\n",
            "Epoch: 220. Loss: 0.5313565187731538\n",
            "Epoch: 230. Loss: 0.5305764004982563\n",
            "Epoch: 240. Loss: 0.5298338508689864\n",
            "Epoch: 250. Loss: 0.5291270051590247\n",
            "Epoch: 260. Loss: 0.5284541226828481\n",
            "Epoch: 270. Loss: 0.527813570547907\n",
            "Epoch: 280. Loss: 0.5272038107916434\n",
            "Epoch: 290. Loss: 0.5266233901099966\n",
            "Epoch: 300. Loss: 0.5260709315744848\n",
            "Epoch: 310. Loss: 0.5255451278786172\n",
            "Epoch: 320. Loss: 0.5250447357634745\n",
            "Epoch: 330. Loss: 0.5245685713552354\n",
            "Epoch: 340. Loss: 0.524115506210651\n",
            "tensor(0.7325, dtype=torch.float64)\n",
            "2021-09-26 00:00:00\n",
            "Epoch: 0. Loss: 0.7056280956061981\n",
            "Epoch: 10. Loss: 0.6093508939750719\n",
            "Epoch: 20. Loss: 0.5806197359814685\n",
            "Epoch: 30. Loss: 0.5663799902572527\n",
            "Epoch: 40. Loss: 0.556146262886839\n",
            "Epoch: 50. Loss: 0.5482122908819241\n",
            "Epoch: 60. Loss: 0.5419757099791427\n",
            "Epoch: 70. Loss: 0.5370667424215171\n",
            "Epoch: 80. Loss: 0.5332091864366797\n",
            "Epoch: 90. Loss: 0.5301821167471898\n",
            "Epoch: 100. Loss: 0.5278061487101019\n",
            "Epoch: 110. Loss: 0.5259365555888039\n",
            "Epoch: 120. Loss: 0.5244580657947002\n",
            "Epoch: 130. Loss: 0.5232800882983029\n",
            "Epoch: 140. Loss: 0.5223322678467209\n",
            "Epoch: 150. Loss: 0.5215605003308618\n",
            "Epoch: 160. Loss: 0.5209235052661143\n",
            "Epoch: 170. Loss: 0.5203899772004328\n",
            "Epoch: 180. Loss: 0.5199362811305538\n",
            "Epoch: 190. Loss: 0.5195446264182436\n",
            "Epoch: 200. Loss: 0.519201643009263\n",
            "Epoch: 210. Loss: 0.518897285233375\n",
            "Epoch: 220. Loss: 0.5186239961664524\n",
            "Epoch: 230. Loss: 0.5183760756371117\n",
            "Epoch: 240. Loss: 0.5181492052670794\n",
            "Epoch: 250. Loss: 0.5179400933416075\n",
            "Epoch: 260. Loss: 0.517746210367282\n",
            "Epoch: 270. Loss: 0.5175655928095739\n",
            "Epoch: 280. Loss: 0.5173966978151524\n",
            "Epoch: 290. Loss: 0.5172382958943675\n",
            "Epoch: 300. Loss: 0.5170893917651165\n",
            "Epoch: 310. Loss: 0.5169491660265716\n",
            "Epoch: 320. Loss: 0.5168169322018772\n",
            "Epoch: 330. Loss: 0.5166921050973542\n",
            "Epoch: 340. Loss: 0.516574177480255\n",
            "tensor(0.8564, dtype=torch.float64)\n",
            "2021-10-03 00:00:00\n",
            "Epoch: 0. Loss: 1.190043599956372\n",
            "Epoch: 10. Loss: 0.9568361296806867\n",
            "Epoch: 20. Loss: 0.8335057669558297\n",
            "Epoch: 30. Loss: 0.7404929823169643\n",
            "Epoch: 40. Loss: 0.6699596750308406\n",
            "Epoch: 50. Loss: 0.6216275603476066\n",
            "Epoch: 60. Loss: 0.5920124861731785\n",
            "Epoch: 70. Loss: 0.574793399902004\n",
            "Epoch: 80. Loss: 0.5644263858447974\n",
            "Epoch: 90. Loss: 0.5576077316395597\n",
            "Epoch: 100. Loss: 0.5526753499483928\n",
            "Epoch: 110. Loss: 0.5488200717335465\n",
            "Epoch: 120. Loss: 0.5456353703775533\n",
            "Epoch: 130. Loss: 0.5429049492950598\n",
            "Epoch: 140. Loss: 0.5405055018012536\n",
            "Epoch: 150. Loss: 0.5383613433599674\n",
            "Epoch: 160. Loss: 0.5364225617759073\n",
            "Epoch: 170. Loss: 0.5346540976295862\n",
            "Epoch: 180. Loss: 0.5330300430413417\n",
            "Epoch: 190. Loss: 0.5315305038434078\n",
            "Epoch: 200. Loss: 0.5301397646012439\n",
            "Epoch: 210. Loss: 0.5288451450517054\n",
            "Epoch: 220. Loss: 0.5276362435865241\n",
            "Epoch: 230. Loss: 0.5265044109285235\n",
            "Epoch: 240. Loss: 0.5254423694028318\n",
            "Epoch: 250. Loss: 0.5244439295681225\n",
            "Epoch: 260. Loss: 0.523503774977815\n",
            "Epoch: 270. Loss: 0.5226172962756267\n",
            "Epoch: 280. Loss: 0.5217804619012086\n",
            "Epoch: 290. Loss: 0.5209897164357765\n",
            "Epoch: 300. Loss: 0.520241900073762\n",
            "Epoch: 310. Loss: 0.5195341843905374\n",
            "Epoch: 320. Loss: 0.5188640207727003\n",
            "Epoch: 330. Loss: 0.5182290987492945\n",
            "Epoch: 340. Loss: 0.5176273121088687\n",
            "tensor(0.9708, dtype=torch.float64)\n",
            "2021-10-10 00:00:00\n",
            "Epoch: 0. Loss: 3.904247698836649\n",
            "Epoch: 10. Loss: 0.657544453401785\n",
            "Epoch: 20. Loss: 0.594540009937104\n",
            "Epoch: 30. Loss: 0.5801859120094428\n",
            "Epoch: 40. Loss: 0.5691425305712905\n",
            "Epoch: 50. Loss: 0.5600089815324687\n",
            "Epoch: 60. Loss: 0.5524051120773377\n",
            "Epoch: 70. Loss: 0.5460624707713054\n",
            "Epoch: 80. Loss: 0.5407651037087926\n",
            "Epoch: 90. Loss: 0.5363348297762396\n",
            "Epoch: 100. Loss: 0.5326237967543641\n",
            "Epoch: 110. Loss: 0.5295093709142377\n",
            "Epoch: 120. Loss: 0.5268900303169971\n",
            "Epoch: 130. Loss: 0.5246818770409462\n",
            "Epoch: 140. Loss: 0.5228156521866149\n",
            "Epoch: 150. Loss: 0.5212342010471244\n",
            "Epoch: 160. Loss: 0.5198903434281045\n",
            "Epoch: 170. Loss: 0.5187451012368067\n",
            "Epoch: 180. Loss: 0.5177662340830824\n",
            "Epoch: 190. Loss: 0.516927035489198\n",
            "Epoch: 200. Loss: 0.5162053465005078\n",
            "Epoch: 210. Loss: 0.5155827488278951\n",
            "Epoch: 220. Loss: 0.5150439052350574\n",
            "Epoch: 230. Loss: 0.5145760201655017\n",
            "Epoch: 240. Loss: 0.5141683983161115\n",
            "Epoch: 250. Loss: 0.5138120829139877\n",
            "Epoch: 260. Loss: 0.5134995588500163\n",
            "Epoch: 270. Loss: 0.5132245086257899\n",
            "Epoch: 280. Loss: 0.5129816113593751\n",
            "Epoch: 290. Loss: 0.5127663769517187\n",
            "Epoch: 300. Loss: 0.5125750090149535\n",
            "Epoch: 310. Loss: 0.5124042913726009\n",
            "Epoch: 320. Loss: 0.5122514939154563\n",
            "Epoch: 330. Loss: 0.5121142943817195\n",
            "Epoch: 340. Loss: 0.5119907132630971\n",
            "tensor(0.6729, dtype=torch.float64)\n",
            "2021-10-17 00:00:00\n",
            "Epoch: 0. Loss: 3.7073105748825124\n",
            "Epoch: 10. Loss: 1.3169033233781164\n",
            "Epoch: 20. Loss: 0.8616192518803931\n",
            "Epoch: 30. Loss: 0.7179173909525676\n",
            "Epoch: 40. Loss: 0.6503943659366451\n",
            "Epoch: 50. Loss: 0.62026929011281\n",
            "Epoch: 60. Loss: 0.6062379508420901\n",
            "Epoch: 70. Loss: 0.5978761810629315\n",
            "Epoch: 80. Loss: 0.5914988724843926\n",
            "Epoch: 90. Loss: 0.5860055142052047\n",
            "Epoch: 100. Loss: 0.5810617163996847\n",
            "Epoch: 110. Loss: 0.5765426107744038\n",
            "Epoch: 120. Loss: 0.572383013576675\n",
            "Epoch: 130. Loss: 0.5685380024624497\n",
            "Epoch: 140. Loss: 0.5649720375476327\n",
            "Epoch: 150. Loss: 0.5616554782279892\n",
            "Epoch: 160. Loss: 0.5585631082914155\n",
            "Epoch: 170. Loss: 0.5556732792811319\n",
            "Epoch: 180. Loss: 0.5529672967472383\n",
            "Epoch: 190. Loss: 0.5504289366585873\n",
            "Epoch: 200. Loss: 0.5480440504410268\n",
            "Epoch: 210. Loss: 0.5458002382499835\n",
            "Epoch: 220. Loss: 0.5436865774788259\n",
            "Epoch: 230. Loss: 0.5416933968071083\n",
            "Epoch: 240. Loss: 0.5398120880179729\n",
            "Epoch: 250. Loss: 0.5380349491803834\n",
            "Epoch: 260. Loss: 0.5363550538694966\n",
            "Epoch: 270. Loss: 0.5347661419872575\n",
            "Epoch: 280. Loss: 0.5332625284897726\n",
            "Epoch: 290. Loss: 0.5318390269532757\n",
            "Epoch: 300. Loss: 0.5304908854347241\n",
            "Epoch: 310. Loss: 0.5292137325210357\n",
            "Epoch: 320. Loss: 0.5280035318256983\n",
            "Epoch: 330. Loss: 0.5268565434942527\n",
            "Epoch: 340. Loss: 0.525769291530866\n",
            "tensor(0.8032, dtype=torch.float64)\n",
            "2021-10-24 00:00:00\n",
            "Epoch: 0. Loss: 0.6352865729016194\n",
            "Epoch: 10. Loss: 0.5966123443895243\n",
            "Epoch: 20. Loss: 0.5840962277129459\n",
            "Epoch: 30. Loss: 0.5754658247283956\n",
            "Epoch: 40. Loss: 0.5684306066313574\n",
            "Epoch: 50. Loss: 0.5623658255612313\n",
            "Epoch: 60. Loss: 0.5570301835404506\n",
            "Epoch: 70. Loss: 0.5523001288658294\n",
            "Epoch: 80. Loss: 0.5480930679443664\n",
            "Epoch: 90. Loss: 0.5443441932290722\n",
            "Epoch: 100. Loss: 0.5409990253960608\n",
            "Epoch: 110. Loss: 0.5380105589893095\n",
            "Epoch: 120. Loss: 0.5353378171897635\n",
            "Epoch: 130. Loss: 0.532944901065104\n",
            "Epoch: 140. Loss: 0.5308002627652452\n",
            "Epoch: 150. Loss: 0.5288761135229598\n",
            "Epoch: 160. Loss: 0.5271479295342855\n",
            "Epoch: 170. Loss: 0.5255940350525247\n",
            "Epoch: 180. Loss: 0.5241952481860648\n",
            "Epoch: 190. Loss: 0.5229345780923041\n",
            "Epoch: 200. Loss: 0.5217969644733921\n",
            "Epoch: 210. Loss: 0.520769052037281\n",
            "Epoch: 220. Loss: 0.5198389940349837\n",
            "Epoch: 230. Loss: 0.5189962801707376\n",
            "Epoch: 240. Loss: 0.5182315851369265\n",
            "Epoch: 250. Loss: 0.5175366347809286\n",
            "Epoch: 260. Loss: 0.516904087498909\n",
            "Epoch: 270. Loss: 0.5163274289035314\n",
            "Epoch: 280. Loss: 0.5158008781574986\n",
            "Epoch: 290. Loss: 0.5153193046275832\n",
            "Epoch: 300. Loss: 0.514878153714829\n",
            "Epoch: 310. Loss: 0.5144733808721124\n",
            "Epoch: 320. Loss: 0.5141013929426765\n",
            "Epoch: 330. Loss: 0.5137589960518828\n",
            "Epoch: 340. Loss: 0.5134433493659682\n",
            "tensor(0.8733, dtype=torch.float64)\n",
            "2021-10-31 00:00:00\n",
            "Epoch: 0. Loss: 4.34307640967145\n",
            "Epoch: 10. Loss: 1.1125655760475595\n",
            "Epoch: 20. Loss: 0.8069617675425097\n",
            "Epoch: 30. Loss: 0.7368993888183016\n",
            "Epoch: 40. Loss: 0.6970058734847713\n",
            "Epoch: 50. Loss: 0.6703236740147293\n",
            "Epoch: 60. Loss: 0.6515977758265631\n",
            "Epoch: 70. Loss: 0.6376659013380414\n",
            "Epoch: 80. Loss: 0.6266245946253932\n",
            "Epoch: 90. Loss: 0.6174009033582823\n",
            "Epoch: 100. Loss: 0.6094042462895071\n",
            "Epoch: 110. Loss: 0.6023040135224671\n",
            "Epoch: 120. Loss: 0.5959056610757091\n",
            "Epoch: 130. Loss: 0.5900858687666211\n",
            "Epoch: 140. Loss: 0.5847595299533254\n",
            "Epoch: 150. Loss: 0.5798631013427976\n",
            "Epoch: 160. Loss: 0.5753461603486582\n",
            "Epoch: 170. Loss: 0.5711670232086262\n",
            "Epoch: 180. Loss: 0.5672903581927424\n",
            "Epoch: 190. Loss: 0.5636857810051769\n",
            "Epoch: 200. Loss: 0.5603269424203877\n",
            "Epoch: 210. Loss: 0.5571908737785546\n",
            "Epoch: 220. Loss: 0.5542574788244423\n",
            "Epoch: 230. Loss: 0.5515091183901434\n",
            "Epoch: 240. Loss: 0.5489302613125482\n",
            "Epoch: 250. Loss: 0.5465071872263942\n",
            "Epoch: 260. Loss: 0.5442277324030677\n",
            "Epoch: 270. Loss: 0.5420810723409801\n",
            "Epoch: 280. Loss: 0.5400575360642658\n",
            "Epoch: 290. Loss: 0.5381484478112426\n",
            "Epoch: 300. Loss: 0.5363459923125531\n",
            "Epoch: 310. Loss: 0.5346431002969043\n",
            "Epoch: 320. Loss: 0.5330333512623544\n",
            "Epoch: 330. Loss: 0.5315108909235877\n",
            "Epoch: 340. Loss: 0.5300703610899694\n",
            "tensor(0.9363, dtype=torch.float64)\n",
            "2021-11-07 00:00:00\n",
            "Epoch: 0. Loss: 1.4266193722726188\n",
            "Epoch: 10. Loss: 0.8762070893582963\n",
            "Epoch: 20. Loss: 0.7674113596226985\n",
            "Epoch: 30. Loss: 0.7134165894922762\n",
            "Epoch: 40. Loss: 0.6767379313644056\n",
            "Epoch: 50. Loss: 0.6501833227864451\n",
            "Epoch: 60. Loss: 0.6300352857603796\n",
            "Epoch: 70. Loss: 0.6138343320399479\n",
            "Epoch: 80. Loss: 0.6001385776463302\n",
            "Epoch: 90. Loss: 0.5881873627134876\n",
            "Epoch: 100. Loss: 0.5775844381723669\n",
            "Epoch: 110. Loss: 0.5681050162256509\n",
            "Epoch: 120. Loss: 0.5596016712807318\n",
            "Epoch: 130. Loss: 0.5519633815300611\n",
            "Epoch: 140. Loss: 0.5450985653386133\n",
            "Epoch: 150. Loss: 0.5389280228644865\n",
            "Epoch: 160. Loss: 0.5333817796719867\n",
            "Epoch: 170. Loss: 0.528397442480685\n",
            "Epoch: 180. Loss: 0.5239191525870773\n",
            "Epoch: 190. Loss: 0.5198967955564332\n",
            "Epoch: 200. Loss: 0.516285341973413\n",
            "Epoch: 210. Loss: 0.5130442738590208\n",
            "Epoch: 220. Loss: 0.5101370798508528\n",
            "Epoch: 230. Loss: 0.5075308115591778\n",
            "Epoch: 240. Loss: 0.5051956958407035\n",
            "Epoch: 250. Loss: 0.5031047977660617\n",
            "Epoch: 260. Loss: 0.5012337286082434\n",
            "Epoch: 270. Loss: 0.4995603929037435\n",
            "Epoch: 280. Loss: 0.49806476870923755\n",
            "Epoch: 290. Loss: 0.496728715567489\n",
            "Epoch: 300. Loss: 0.4955358053091501\n",
            "Epoch: 310. Loss: 0.4944711715440119\n",
            "Epoch: 320. Loss: 0.49352137444437383\n",
            "Epoch: 330. Loss: 0.49267427812844455\n",
            "Epoch: 340. Loss: 0.49191893857266983\n",
            "tensor(0.9381, dtype=torch.float64)\n",
            "2021-11-14 00:00:00\n",
            "Epoch: 0. Loss: 5.5740981593617995\n",
            "Epoch: 10. Loss: 1.2193632454270664\n",
            "Epoch: 20. Loss: 0.7699423047103955\n",
            "Epoch: 30. Loss: 0.6872400041944621\n",
            "Epoch: 40. Loss: 0.6394207023497146\n",
            "Epoch: 50. Loss: 0.6067691649084985\n",
            "Epoch: 60. Loss: 0.5843688509989039\n",
            "Epoch: 70. Loss: 0.5691420714875243\n",
            "Epoch: 80. Loss: 0.558695155388701\n",
            "Epoch: 90. Loss: 0.551279857253164\n",
            "Epoch: 100. Loss: 0.5457320859195529\n",
            "Epoch: 110. Loss: 0.5413329287390762\n",
            "Epoch: 120. Loss: 0.5376600417657053\n",
            "Epoch: 130. Loss: 0.5344711482494343\n",
            "Epoch: 140. Loss: 0.5316270332068574\n",
            "Epoch: 150. Loss: 0.529045582417988\n",
            "Epoch: 160. Loss: 0.526675989340832\n",
            "Epoch: 170. Loss: 0.5244847797845202\n",
            "Epoch: 180. Loss: 0.5224483571825826\n",
            "Epoch: 190. Loss: 0.5205490219984462\n",
            "Epoch: 200. Loss: 0.5187728093684167\n",
            "Epoch: 210. Loss: 0.5171082746062079\n",
            "Epoch: 220. Loss: 0.5155457775265396\n",
            "Epoch: 230. Loss: 0.5140770355311274\n",
            "Epoch: 240. Loss: 0.5126948271150663\n",
            "Epoch: 250. Loss: 0.5113927839391916\n",
            "Epoch: 260. Loss: 0.510165238181949\n",
            "Epoch: 270. Loss: 0.5090071064779811\n",
            "Epoch: 280. Loss: 0.507913799367769\n",
            "Epoch: 290. Loss: 0.506881149297712\n",
            "Epoch: 300. Loss: 0.505905352540279\n",
            "Epoch: 310. Loss: 0.5049829217999806\n",
            "Epoch: 320. Loss: 0.5041106471582618\n",
            "Epoch: 330. Loss: 0.5032855636061558\n",
            "Epoch: 340. Loss: 0.502504923831945\n",
            "tensor(0.8971, dtype=torch.float64)\n",
            "2021-11-21 00:00:00\n",
            "Epoch: 0. Loss: 3.616320049017957\n",
            "Epoch: 10. Loss: 0.9842223771468078\n",
            "Epoch: 20. Loss: 0.7450472762667611\n",
            "Epoch: 30. Loss: 0.6498018637501348\n",
            "Epoch: 40. Loss: 0.5835085965131188\n",
            "Epoch: 50. Loss: 0.5415800708966306\n",
            "Epoch: 60. Loss: 0.5182120512830725\n",
            "Epoch: 70. Loss: 0.5061330209751603\n",
            "Epoch: 80. Loss: 0.49986230311735785\n",
            "Epoch: 90. Loss: 0.49637745405124556\n",
            "Epoch: 100. Loss: 0.49424754823697264\n",
            "Epoch: 110. Loss: 0.4928212935186694\n",
            "Epoch: 120. Loss: 0.49179379096307635\n",
            "Epoch: 130. Loss: 0.4910130246607038\n",
            "Epoch: 140. Loss: 0.49039716039579967\n",
            "Epoch: 150. Loss: 0.4898985951996179\n",
            "Epoch: 160. Loss: 0.48948758990429686\n",
            "Epoch: 170. Loss: 0.4891443700507267\n",
            "Epoch: 180. Loss: 0.4888550759226092\n",
            "Epoch: 190. Loss: 0.4886095623866098\n",
            "Epoch: 200. Loss: 0.4884001378393255\n",
            "Epoch: 210. Loss: 0.4882208049401467\n",
            "Epoch: 220. Loss: 0.48806678235319917\n",
            "Epoch: 230. Loss: 0.48793419081114703\n",
            "Epoch: 240. Loss: 0.48781983918536\n",
            "Epoch: 250. Loss: 0.48772107371220735\n",
            "Epoch: 260. Loss: 0.48763566848687745\n",
            "Epoch: 270. Loss: 0.4875617437804104\n",
            "Epoch: 280. Loss: 0.4874977036628841\n",
            "Epoch: 290. Loss: 0.4874421873816542\n",
            "Epoch: 300. Loss: 0.4873940307810506\n",
            "Epoch: 310. Loss: 0.4873522352185989\n",
            "Epoch: 320. Loss: 0.48731594219401964\n",
            "Epoch: 330. Loss: 0.487284412413867\n",
            "Epoch: 340. Loss: 0.487257008358619\n",
            "tensor(0.8423, dtype=torch.float64)\n",
            "2021-11-28 00:00:00\n",
            "Epoch: 0. Loss: 7.387513428753539\n",
            "Epoch: 10. Loss: 1.7139482680658924\n",
            "Epoch: 20. Loss: 0.8843585934136693\n",
            "Epoch: 30. Loss: 0.7694766678288443\n",
            "Epoch: 40. Loss: 0.7096352193250507\n",
            "Epoch: 50. Loss: 0.662134192017502\n",
            "Epoch: 60. Loss: 0.6226357734578897\n",
            "Epoch: 70. Loss: 0.5906138331344887\n",
            "Epoch: 80. Loss: 0.5655761355630919\n",
            "Epoch: 90. Loss: 0.54665467181282\n",
            "Epoch: 100. Loss: 0.5327142546305151\n",
            "Epoch: 110. Loss: 0.522575305214658\n",
            "Epoch: 120. Loss: 0.5152008331715493\n",
            "Epoch: 130. Loss: 0.5097809854765896\n",
            "Epoch: 140. Loss: 0.5057302093914735\n",
            "Epoch: 150. Loss: 0.502643162297225\n",
            "Epoch: 160. Loss: 0.5002443531389976\n",
            "Epoch: 170. Loss: 0.4983467151539589\n",
            "Epoch: 180. Loss: 0.49682191230017936\n",
            "Epoch: 190. Loss: 0.49558040384459723\n",
            "Epoch: 200. Loss: 0.4945584393342189\n",
            "Epoch: 210. Loss: 0.49370964366177256\n",
            "Epoch: 220. Loss: 0.4929995520447059\n",
            "Epoch: 230. Loss: 0.4924020234053028\n",
            "Epoch: 240. Loss: 0.49189685264666305\n",
            "Epoch: 250. Loss: 0.49146815483891376\n",
            "Epoch: 260. Loss: 0.49110325247566244\n",
            "Epoch: 270. Loss: 0.4907918951774158\n",
            "Epoch: 280. Loss: 0.4905257023547648\n",
            "Epoch: 290. Loss: 0.4902977577010725\n",
            "Epoch: 300. Loss: 0.4901023087069888\n",
            "Epoch: 310. Loss: 0.48993453999338843\n",
            "Epoch: 320. Loss: 0.4897903993890519\n",
            "Epoch: 330. Loss: 0.4896664623314279\n",
            "Epoch: 340. Loss: 0.4895598245862034\n",
            "tensor(0.8654, dtype=torch.float64)\n",
            "2021-12-05 00:00:00\n",
            "Epoch: 0. Loss: 3.666147160414253\n",
            "Epoch: 10. Loss: 1.4050268457552\n",
            "Epoch: 20. Loss: 1.0056319248399863\n",
            "Epoch: 30. Loss: 0.8288407733592634\n",
            "Epoch: 40. Loss: 0.7001103078223938\n",
            "Epoch: 50. Loss: 0.6133789366227433\n",
            "Epoch: 60. Loss: 0.5658425307772903\n",
            "Epoch: 70. Loss: 0.5433180651268894\n",
            "Epoch: 80. Loss: 0.5317940764250202\n",
            "Epoch: 90. Loss: 0.5247361457657753\n",
            "Epoch: 100. Loss: 0.519912902188251\n",
            "Epoch: 110. Loss: 0.5164935886772029\n",
            "Epoch: 120. Loss: 0.514060144924318\n",
            "Epoch: 130. Loss: 0.5123401477336028\n",
            "Epoch: 140. Loss: 0.5111354555884062\n",
            "Epoch: 150. Loss: 0.510298858349682\n",
            "Epoch: 160. Loss: 0.5097220068151778\n",
            "Epoch: 170. Loss: 0.5093264451028612\n",
            "Epoch: 180. Loss: 0.5090562585977272\n",
            "Epoch: 190. Loss: 0.5088721359806739\n",
            "Epoch: 200. Loss: 0.5087467453070825\n",
            "Epoch: 210. Loss: 0.508661253148348\n",
            "Epoch: 220. Loss: 0.5086027745954189\n",
            "Epoch: 230. Loss: 0.5085625443084486\n",
            "Epoch: 240. Loss: 0.5085346260035007\n",
            "Epoch: 250. Loss: 0.5085150133251356\n",
            "Epoch: 260. Loss: 0.508501009555792\n",
            "Epoch: 270. Loss: 0.5084908029838596\n",
            "Epoch: 280. Loss: 0.5084831779781563\n",
            "Epoch: 290. Loss: 0.5084773193442217\n",
            "Epoch: 300. Loss: 0.5084726803521871\n",
            "Epoch: 310. Loss: 0.5084688939857586\n",
            "Epoch: 320. Loss: 0.5084657134022346\n",
            "Epoch: 330. Loss: 0.5084629720661895\n",
            "Epoch: 340. Loss: 0.5084605570965472\n",
            "tensor(0.7957, dtype=torch.float64)\n",
            "2021-12-12 00:00:00\n",
            "Epoch: 0. Loss: 4.449474010135708\n",
            "Epoch: 10. Loss: 1.0011729926675244\n",
            "Epoch: 20. Loss: 0.6992752442330189\n",
            "Epoch: 30. Loss: 0.6044088850536777\n",
            "Epoch: 40. Loss: 0.5587035480413396\n",
            "Epoch: 50. Loss: 0.5390682219988279\n",
            "Epoch: 60. Loss: 0.5298481950914123\n",
            "Epoch: 70. Loss: 0.5247005148569608\n",
            "Epoch: 80. Loss: 0.5214530787280107\n",
            "Epoch: 90. Loss: 0.5192601579377972\n",
            "Epoch: 100. Loss: 0.5177209763841635\n",
            "Epoch: 110. Loss: 0.5166126390158293\n",
            "Epoch: 120. Loss: 0.5157977665308746\n",
            "Epoch: 130. Loss: 0.5151866014882229\n",
            "Epoch: 140. Loss: 0.5147186519326481\n",
            "Epoch: 150. Loss: 0.5143524879892274\n",
            "Epoch: 160. Loss: 0.5140594880190139\n",
            "Epoch: 170. Loss: 0.5138197683343182\n",
            "Epoch: 180. Loss: 0.5136194470173797\n",
            "Epoch: 190. Loss: 0.5134487764039242\n",
            "Epoch: 200. Loss: 0.513300860998389\n",
            "Epoch: 210. Loss: 0.5131707761685583\n",
            "Epoch: 220. Loss: 0.5130549626547724\n",
            "Epoch: 230. Loss: 0.5129508109207862\n",
            "Epoch: 240. Loss: 0.5128563759135786\n",
            "Epoch: 250. Loss: 0.5127701811816533\n",
            "Epoch: 260. Loss: 0.5126910840886285\n",
            "Epoch: 270. Loss: 0.5126181827372331\n",
            "Epoch: 280. Loss: 0.5125507513560593\n",
            "Epoch: 290. Loss: 0.5124881951225297\n",
            "Epoch: 300. Loss: 0.5124300182848764\n",
            "Epoch: 310. Loss: 0.5123758014154591\n",
            "Epoch: 320. Loss: 0.5123251849657446\n",
            "Epoch: 330. Loss: 0.5122778571999217\n",
            "Epoch: 340. Loss: 0.5122335451974585\n",
            "tensor(0.6591, dtype=torch.float64)\n",
            "2021-12-19 00:00:00\n",
            "Epoch: 0. Loss: 2.2847972290676477\n",
            "Epoch: 10. Loss: 1.0484966299009684\n",
            "Epoch: 20. Loss: 0.843702665538575\n",
            "Epoch: 30. Loss: 0.754774516130145\n",
            "Epoch: 40. Loss: 0.7046112650487364\n",
            "Epoch: 50. Loss: 0.6736475029527361\n",
            "Epoch: 60. Loss: 0.6524751856000232\n",
            "Epoch: 70. Loss: 0.636586838855154\n",
            "Epoch: 80. Loss: 0.6239674071343165\n",
            "Epoch: 90. Loss: 0.613652644476738\n",
            "Epoch: 100. Loss: 0.605090985158467\n",
            "Epoch: 110. Loss: 0.5979060238146671\n",
            "Epoch: 120. Loss: 0.5918130416161441\n",
            "Epoch: 130. Loss: 0.5865880797897125\n",
            "Epoch: 140. Loss: 0.5820537437856358\n",
            "Epoch: 150. Loss: 0.5780702334492945\n",
            "Epoch: 160. Loss: 0.574528260060045\n",
            "Epoch: 170. Loss: 0.571343023754598\n",
            "Epoch: 180. Loss: 0.568449092482566\n",
            "Epoch: 190. Loss: 0.5657961403686815\n",
            "Epoch: 200. Loss: 0.5633454853172015\n",
            "Epoch: 210. Loss: 0.5610673348392653\n",
            "Epoch: 220. Loss: 0.5589386331283284\n",
            "Epoch: 230. Loss: 0.5569414016769113\n",
            "Epoch: 240. Loss: 0.5550614746882685\n",
            "Epoch: 250. Loss: 0.5532875440624718\n",
            "Epoch: 260. Loss: 0.5516104433837439\n",
            "Epoch: 270. Loss: 0.5500226141645819\n",
            "Epoch: 280. Loss: 0.5485177097084443\n",
            "Epoch: 290. Loss: 0.5470903020586539\n",
            "Epoch: 300. Loss: 0.5457356656671598\n",
            "Epoch: 310. Loss: 0.544449617861697\n",
            "Epoch: 320. Loss: 0.5432284011868596\n",
            "Epoch: 330. Loss: 0.542068596515619\n",
            "Epoch: 340. Loss: 0.5409670587174727\n",
            "tensor(0.6426, dtype=torch.float64)\n",
            "2021-12-26 00:00:00\n",
            "Epoch: 0. Loss: 1.3730728889133397\n",
            "Epoch: 10. Loss: 0.5605380151638699\n",
            "Epoch: 20. Loss: 0.5440755803927906\n",
            "Epoch: 30. Loss: 0.5390950505667624\n",
            "Epoch: 40. Loss: 0.536656049687806\n",
            "Epoch: 50. Loss: 0.5350283158052844\n",
            "Epoch: 60. Loss: 0.5337723091978909\n",
            "Epoch: 70. Loss: 0.532741232691009\n",
            "Epoch: 80. Loss: 0.5318665673028609\n",
            "Epoch: 90. Loss: 0.53110753395871\n",
            "Epoch: 100. Loss: 0.5304368693422681\n",
            "Epoch: 110. Loss: 0.5298354763236083\n",
            "Epoch: 120. Loss: 0.5292896966772461\n",
            "Epoch: 130. Loss: 0.5287896270864809\n",
            "Epoch: 140. Loss: 0.5283279898729153\n",
            "Epoch: 150. Loss: 0.5278993536956895\n",
            "Epoch: 160. Loss: 0.5274995911628299\n",
            "Epoch: 170. Loss: 0.5271255005819417\n",
            "Epoch: 180. Loss: 0.5267745420810371\n",
            "Epoch: 190. Loss: 0.5264446534191369\n",
            "Epoch: 200. Loss: 0.5261341212377129\n",
            "Epoch: 210. Loss: 0.5258414908240328\n",
            "Epoch: 220. Loss: 0.5255655026010244\n",
            "Epoch: 230. Loss: 0.5253050471618467\n",
            "Epoch: 240. Loss: 0.5250591331820235\n",
            "Epoch: 250. Loss: 0.5248268642901378\n",
            "Epoch: 260. Loss: 0.5246074221893875\n",
            "Epoch: 270. Loss: 0.5244000541594086\n",
            "Epoch: 280. Loss: 0.5242040636451669\n",
            "Epoch: 290. Loss: 0.52401880303745\n",
            "Epoch: 300. Loss: 0.5238436680233033\n",
            "Epoch: 310. Loss: 0.5236780930732715\n",
            "Epoch: 320. Loss: 0.5235215477622118\n",
            "Epoch: 330. Loss: 0.5233735337100904\n",
            "Epoch: 340. Loss: 0.5232335819912158\n",
            "tensor(0.7567, dtype=torch.float64)\n",
            "2022-01-02 00:00:00\n",
            "Epoch: 0. Loss: 1.06354969878682\n",
            "Epoch: 10. Loss: 0.7119982556926512\n",
            "Epoch: 20. Loss: 0.5955730341356241\n",
            "Epoch: 30. Loss: 0.5620554873599769\n",
            "Epoch: 40. Loss: 0.5471486915086797\n",
            "Epoch: 50. Loss: 0.5395104486681385\n",
            "Epoch: 60. Loss: 0.5349632915834983\n",
            "Epoch: 70. Loss: 0.5318157459641613\n",
            "Epoch: 80. Loss: 0.5294002079561675\n",
            "Epoch: 90. Loss: 0.5274409092614976\n",
            "Epoch: 100. Loss: 0.5258100528167771\n",
            "Epoch: 110. Loss: 0.5244375464589993\n",
            "Epoch: 120. Loss: 0.5232776020481473\n",
            "Epoch: 130. Loss: 0.5222961067416165\n",
            "Epoch: 140. Loss: 0.5214656345052292\n",
            "Epoch: 150. Loss: 0.520763307802598\n",
            "Epoch: 160. Loss: 0.5201697446723547\n",
            "Epoch: 170. Loss: 0.5196684350149111\n",
            "Epoch: 180. Loss: 0.5192453004698482\n",
            "Epoch: 190. Loss: 0.5188883452006757\n",
            "Epoch: 200. Loss: 0.5185873618365404\n",
            "Epoch: 210. Loss: 0.5183336778477814\n",
            "Epoch: 220. Loss: 0.5181199352831827\n",
            "Epoch: 230. Loss: 0.517939899535704\n",
            "Epoch: 240. Loss: 0.51778829379523\n",
            "Epoch: 250. Loss: 0.5176606562567119\n",
            "Epoch: 260. Loss: 0.5175532173940618\n",
            "Epoch: 270. Loss: 0.5174627948200388\n",
            "Epoch: 280. Loss: 0.5173867034659093\n",
            "Epoch: 290. Loss: 0.5173226790344246\n",
            "Epoch: 300. Loss: 0.5172688128991836\n",
            "Epoch: 310. Loss: 0.517223496835621\n",
            "Epoch: 320. Loss: 0.5171853761683177\n",
            "Epoch: 330. Loss: 0.5171533101027291\n",
            "Epoch: 340. Loss: 0.5171263381752055\n",
            "tensor(0.7295, dtype=torch.float64)\n",
            "2022-01-09 00:00:00\n",
            "Epoch: 0. Loss: 5.787161845789349\n",
            "Epoch: 10. Loss: 1.2046963194253848\n",
            "Epoch: 20. Loss: 0.8035615521642967\n",
            "Epoch: 30. Loss: 0.6929705215196251\n",
            "Epoch: 40. Loss: 0.6237743081428909\n",
            "Epoch: 50. Loss: 0.5816304600992757\n",
            "Epoch: 60. Loss: 0.55833544518409\n",
            "Epoch: 70. Loss: 0.5463906913688514\n",
            "Epoch: 80. Loss: 0.5402469840893932\n",
            "Epoch: 90. Loss: 0.5367685310269589\n",
            "Epoch: 100. Loss: 0.53448815118554\n",
            "Epoch: 110. Loss: 0.5327851781199574\n",
            "Epoch: 120. Loss: 0.5314042004816628\n",
            "Epoch: 130. Loss: 0.5302354842030033\n",
            "Epoch: 140. Loss: 0.5292259249482987\n",
            "Epoch: 150. Loss: 0.5283449319791613\n",
            "Epoch: 160. Loss: 0.5275716419033566\n",
            "Epoch: 170. Loss: 0.5268900867337736\n",
            "Epoch: 180. Loss: 0.5262872739015063\n",
            "Epoch: 190. Loss: 0.525752331725327\n",
            "Epoch: 200. Loss: 0.5252760545674401\n",
            "Epoch: 210. Loss: 0.5248506089497862\n",
            "Epoch: 220. Loss: 0.5244693143513609\n",
            "Epoch: 230. Loss: 0.524126466389799\n",
            "Epoch: 240. Loss: 0.523817189156899\n",
            "Epoch: 250. Loss: 0.5235373102752089\n",
            "Epoch: 260. Loss: 0.523283254765982\n",
            "Epoch: 270. Loss: 0.5230519548634209\n",
            "Epoch: 280. Loss: 0.5228407734424573\n",
            "Epoch: 290. Loss: 0.5226474390757692\n",
            "Epoch: 300. Loss: 0.5224699910093592\n",
            "Epoch: 310. Loss: 0.5223067325798765\n",
            "Epoch: 320. Loss: 0.5221561918021773\n",
            "Epoch: 330. Loss: 0.5220170880363468\n",
            "Epoch: 340. Loss: 0.5218883038017404\n",
            "tensor(0.8486, dtype=torch.float64)\n",
            "2022-01-16 00:00:00\n",
            "Epoch: 0. Loss: 2.177984019125639\n",
            "Epoch: 10. Loss: 0.6957505145246793\n",
            "Epoch: 20. Loss: 0.6087736378667141\n",
            "Epoch: 30. Loss: 0.5672791760352612\n",
            "Epoch: 40. Loss: 0.5443701289175955\n",
            "Epoch: 50. Loss: 0.5324025922427149\n",
            "Epoch: 60. Loss: 0.5260994150486973\n",
            "Epoch: 70. Loss: 0.5226042465896868\n",
            "Epoch: 80. Loss: 0.520544799181656\n",
            "Epoch: 90. Loss: 0.5192672393575036\n",
            "Epoch: 100. Loss: 0.5184427124621656\n",
            "Epoch: 110. Loss: 0.5178933515831622\n",
            "Epoch: 120. Loss: 0.51751660367598\n",
            "Epoch: 130. Loss: 0.5172505504101443\n",
            "Epoch: 140. Loss: 0.5170566673603902\n",
            "Epoch: 150. Loss: 0.5169105260712409\n",
            "Epoch: 160. Loss: 0.5167964435543\n",
            "Epoch: 170. Loss: 0.516704261824973\n",
            "Epoch: 180. Loss: 0.5166273530086569\n",
            "Epoch: 190. Loss: 0.5165613614405442\n",
            "Epoch: 200. Loss: 0.5165034016636867\n",
            "Epoch: 210. Loss: 0.5164515434534447\n",
            "Epoch: 220. Loss: 0.5164044795556619\n",
            "Epoch: 230. Loss: 0.5163613105680912\n",
            "Epoch: 240. Loss: 0.5163214052880308\n",
            "Epoch: 250. Loss: 0.5162843098429638\n",
            "Epoch: 260. Loss: 0.5162496884357645\n",
            "Epoch: 270. Loss: 0.5162172846189375\n",
            "Epoch: 280. Loss: 0.5161868959212653\n",
            "Epoch: 290. Loss: 0.5161583571715062\n",
            "Epoch: 300. Loss: 0.5161315294945019\n",
            "Epoch: 310. Loss: 0.5161062930120496\n",
            "Epoch: 320. Loss: 0.5160825419671239\n",
            "Epoch: 330. Loss: 0.5160601814361636\n",
            "Epoch: 340. Loss: 0.516039125084457\n",
            "tensor(0.8889, dtype=torch.float64)\n",
            "2022-01-23 00:00:00\n",
            "Epoch: 0. Loss: 0.9229969210149452\n",
            "Epoch: 10. Loss: 0.7401976378749119\n",
            "Epoch: 20. Loss: 0.6670772683344103\n",
            "Epoch: 30. Loss: 0.6283204848348953\n",
            "Epoch: 40. Loss: 0.6048419131739325\n",
            "Epoch: 50. Loss: 0.5891620550601336\n",
            "Epoch: 60. Loss: 0.5781869436291521\n",
            "Epoch: 70. Loss: 0.5703262598824973\n",
            "Epoch: 80. Loss: 0.5645970463466162\n",
            "Epoch: 90. Loss: 0.5603396127097455\n",
            "Epoch: 100. Loss: 0.5571013953777245\n",
            "Epoch: 110. Loss: 0.5545717139627958\n",
            "Epoch: 120. Loss: 0.5525381568470039\n",
            "Epoch: 130. Loss: 0.5508560169152198\n",
            "Epoch: 140. Loss: 0.5494268754173444\n",
            "Epoch: 150. Loss: 0.5481837545764386\n",
            "Epoch: 160. Loss: 0.5470809319147095\n",
            "Epoch: 170. Loss: 0.546087010253476\n",
            "Epoch: 180. Loss: 0.5451802313876983\n",
            "Epoch: 190. Loss: 0.5443453207863049\n",
            "Epoch: 200. Loss: 0.5435713695982657\n",
            "Epoch: 210. Loss: 0.5428504158731057\n",
            "Epoch: 220. Loss: 0.5421764953684531\n",
            "Epoch: 230. Loss: 0.5415450068883555\n",
            "Epoch: 240. Loss: 0.5409522878860578\n",
            "Epoch: 250. Loss: 0.540395330431849\n",
            "Epoch: 260. Loss: 0.5398715907929398\n",
            "Epoch: 270. Loss: 0.5393788614088075\n",
            "Epoch: 280. Loss: 0.5389151844472762\n",
            "Epoch: 290. Loss: 0.5384787930768389\n",
            "Epoch: 300. Loss: 0.5380680712272033\n",
            "Epoch: 310. Loss: 0.5376815256989123\n",
            "Epoch: 320. Loss: 0.5373177665385037\n",
            "Epoch: 330. Loss: 0.5369754929625218\n",
            "Epoch: 340. Loss: 0.536653483021978\n",
            "tensor(0.3472, dtype=torch.float64)\n",
            "2022-01-30 00:00:00\n",
            "Epoch: 0. Loss: 4.953209249945463\n",
            "Epoch: 10. Loss: 0.7858635014193756\n",
            "Epoch: 20. Loss: 0.6320841507882742\n",
            "Epoch: 30. Loss: 0.5978837431544355\n",
            "Epoch: 40. Loss: 0.5844366212368155\n",
            "Epoch: 50. Loss: 0.5763392426284573\n",
            "Epoch: 60. Loss: 0.5704256024467922\n",
            "Epoch: 70. Loss: 0.5658251550775408\n",
            "Epoch: 80. Loss: 0.5621750345368683\n",
            "Epoch: 90. Loss: 0.5592604728435777\n",
            "Epoch: 100. Loss: 0.5569275572963507\n",
            "Epoch: 110. Loss: 0.5550570679640806\n",
            "Epoch: 120. Loss: 0.5535542945167499\n",
            "Epoch: 130. Loss: 0.5523436136888258\n",
            "Epoch: 140. Loss: 0.5513647447379051\n",
            "Epoch: 150. Loss: 0.5505697985465765\n",
            "Epoch: 160. Loss: 0.5499208533346914\n",
            "Epoch: 170. Loss: 0.5493879561527187\n",
            "Epoch: 180. Loss: 0.5489474889276533\n",
            "Epoch: 190. Loss: 0.5485808460966453\n",
            "Epoch: 200. Loss: 0.548273374107656\n",
            "Epoch: 210. Loss: 0.5480135271735935\n",
            "Epoch: 220. Loss: 0.547792199011178\n",
            "Epoch: 230. Loss: 0.5476021961613629\n",
            "Epoch: 240. Loss: 0.5474378242222954\n",
            "Epoch: 250. Loss: 0.5472945635396904\n",
            "Epoch: 260. Loss: 0.5471688154232313\n",
            "Epoch: 270. Loss: 0.5470577037608191\n",
            "Epoch: 280. Loss: 0.5469589200308035\n",
            "Epoch: 290. Loss: 0.5468706022458422\n",
            "Epoch: 300. Loss: 0.5467912403909354\n",
            "Epoch: 310. Loss: 0.546719602529706\n",
            "Epoch: 320. Loss: 0.5466546770252764\n",
            "Epoch: 330. Loss: 0.546595627322104\n",
            "Epoch: 340. Loss: 0.5465417565185501\n",
            "tensor(0.6180, dtype=torch.float64)\n",
            "2022-02-06 00:00:00\n",
            "Epoch: 0. Loss: 1.1320120268972238\n",
            "Epoch: 10. Loss: 0.8222199027203999\n",
            "Epoch: 20. Loss: 0.6462045062652496\n",
            "Epoch: 30. Loss: 0.5881500745727077\n",
            "Epoch: 40. Loss: 0.5733851712911181\n",
            "Epoch: 50. Loss: 0.5674186317070582\n",
            "Epoch: 60. Loss: 0.5636962260917606\n",
            "Epoch: 70. Loss: 0.5609179769019786\n",
            "Epoch: 80. Loss: 0.5587192476428584\n",
            "Epoch: 90. Loss: 0.5569381530094111\n",
            "Epoch: 100. Loss: 0.5554748542262132\n",
            "Epoch: 110. Loss: 0.5542583338011542\n",
            "Epoch: 120. Loss: 0.5532355433767477\n",
            "Epoch: 130. Loss: 0.5523661913974048\n",
            "Epoch: 140. Loss: 0.551619455362537\n",
            "Epoch: 150. Loss: 0.5509716416319863\n",
            "Epoch: 160. Loss: 0.550404449935549\n",
            "Epoch: 170. Loss: 0.5499036703728888\n",
            "Epoch: 180. Loss: 0.5494582016222038\n",
            "Epoch: 190. Loss: 0.5490593102526344\n",
            "Epoch: 200. Loss: 0.5487000714731044\n",
            "Epoch: 210. Loss: 0.5483749464866549\n",
            "Epoch: 220. Loss: 0.5480794627181783\n",
            "Epoch: 230. Loss: 0.5478099715386767\n",
            "Epoch: 240. Loss: 0.5475634643993479\n",
            "Epoch: 250. Loss: 0.5473374330196729\n",
            "Epoch: 260. Loss: 0.5471297628291739\n",
            "Epoch: 270. Loss: 0.5469386515338983\n",
            "Epoch: 280. Loss: 0.5467625466859292\n",
            "Epoch: 290. Loss: 0.5466000976429549\n",
            "Epoch: 300. Loss: 0.5464501184394808\n",
            "Epoch: 310. Loss: 0.5463115589449175\n",
            "Epoch: 320. Loss: 0.5461834823264804\n",
            "Epoch: 330. Loss: 0.5460650473189951\n",
            "Epoch: 340. Loss: 0.5459554941686517\n",
            "tensor(0.6614, dtype=torch.float64)\n",
            "2022-02-13 00:00:00\n",
            "Epoch: 0. Loss: 0.8089303571107016\n",
            "Epoch: 10. Loss: 0.7092604501884616\n",
            "Epoch: 20. Loss: 0.6569845769750717\n",
            "Epoch: 30. Loss: 0.6264064853006533\n",
            "Epoch: 40. Loss: 0.6063664892811854\n",
            "Epoch: 50. Loss: 0.5917781230695685\n",
            "Epoch: 60. Loss: 0.5805085502316769\n",
            "Epoch: 70. Loss: 0.5715950867731491\n",
            "Epoch: 80. Loss: 0.564506423180336\n",
            "Epoch: 90. Loss: 0.558879349331122\n",
            "Epoch: 100. Loss: 0.5544313205603003\n",
            "Epoch: 110. Loss: 0.550931464001622\n",
            "Epoch: 120. Loss: 0.5481894089234399\n",
            "Epoch: 130. Loss: 0.5460490529390865\n",
            "Epoch: 140. Loss: 0.5443835997744491\n",
            "Epoch: 150. Loss: 0.5430910383469878\n",
            "Epoch: 160. Loss: 0.5420899942018027\n",
            "Epoch: 170. Loss: 0.5413160233465638\n",
            "Epoch: 180. Loss: 0.5407183972576951\n",
            "Epoch: 190. Loss: 0.5402573828619088\n",
            "Epoch: 200. Loss: 0.5399019869694482\n",
            "Epoch: 210. Loss: 0.5396281152793344\n",
            "Epoch: 220. Loss: 0.5394170884847448\n",
            "Epoch: 230. Loss: 0.5392544580574675\n",
            "Epoch: 240. Loss: 0.539129068659624\n",
            "Epoch: 250. Loss: 0.5390323205214717\n",
            "Epoch: 260. Loss: 0.5389575920946655\n",
            "Epoch: 270. Loss: 0.5388997900156999\n",
            "Epoch: 280. Loss: 0.5388549994776056\n",
            "Epoch: 290. Loss: 0.5388202133457821\n",
            "Epoch: 300. Loss: 0.538793122748945\n",
            "Epoch: 310. Loss: 0.5387719554885299\n",
            "Epoch: 320. Loss: 0.5387553515339129\n",
            "Epoch: 330. Loss: 0.5387422672105582\n",
            "Epoch: 340. Loss: 0.5387319015439034\n",
            "tensor(0.7682, dtype=torch.float64)\n",
            "2022-02-20 00:00:00\n",
            "Epoch: 0. Loss: 1.524465031771029\n",
            "Epoch: 10. Loss: 1.1280478148281627\n",
            "Epoch: 20. Loss: 0.8180691125623724\n",
            "Epoch: 30. Loss: 0.6221732167828878\n",
            "Epoch: 40. Loss: 0.5525150967614182\n",
            "Epoch: 50. Loss: 0.5409666162283616\n",
            "Epoch: 60. Loss: 0.5391155716786312\n",
            "Epoch: 70. Loss: 0.5385219609093809\n",
            "Epoch: 80. Loss: 0.5381297173668954\n",
            "Epoch: 90. Loss: 0.5377913680488073\n",
            "Epoch: 100. Loss: 0.537481604341162\n",
            "Epoch: 110. Loss: 0.5371940420006671\n",
            "Epoch: 120. Loss: 0.5369258700527152\n",
            "Epoch: 130. Loss: 0.5366752158224561\n",
            "Epoch: 140. Loss: 0.5364405954991744\n",
            "Epoch: 150. Loss: 0.5362207575520859\n",
            "Epoch: 160. Loss: 0.5360146158871898\n",
            "Epoch: 170. Loss: 0.5358212109712376\n",
            "Epoch: 180. Loss: 0.5356396836067863\n",
            "Epoch: 190. Loss: 0.5354692561534828\n",
            "Epoch: 200. Loss: 0.5353092186968768\n",
            "Epoch: 210. Loss: 0.5351589186650719\n",
            "Epoch: 220. Loss: 0.5350177528997361\n",
            "Epoch: 230. Loss: 0.5348851614972103\n",
            "Epoch: 240. Loss: 0.5347606229400477\n",
            "Epoch: 250. Loss: 0.5346436501790474\n",
            "Epoch: 260. Loss: 0.5345337874228053\n",
            "Epoch: 270. Loss: 0.5344306074597328\n",
            "Epoch: 280. Loss: 0.5343337093855058\n",
            "Epoch: 290. Loss: 0.5342427166430916\n",
            "Epoch: 300. Loss: 0.5341572753070135\n",
            "Epoch: 310. Loss: 0.5340770525612202\n",
            "Epoch: 320. Loss: 0.5340017353327682\n",
            "Epoch: 330. Loss: 0.5339310290529276\n",
            "Epoch: 340. Loss: 0.5338646565242022\n",
            "tensor(0.5742, dtype=torch.float64)\n",
            "2022-02-27 00:00:00\n",
            "Epoch: 0. Loss: 1.860388155248372\n",
            "Epoch: 10. Loss: 1.3383464934434501\n",
            "Epoch: 20. Loss: 0.9089479203924627\n",
            "Epoch: 30. Loss: 0.6371007981799518\n",
            "Epoch: 40. Loss: 0.5601392737371729\n",
            "Epoch: 50. Loss: 0.5513514334794174\n",
            "Epoch: 60. Loss: 0.5490677134573434\n",
            "Epoch: 70. Loss: 0.5476097451465334\n",
            "Epoch: 80. Loss: 0.5464747948980456\n",
            "Epoch: 90. Loss: 0.5455596707944321\n",
            "Epoch: 100. Loss: 0.5448095034145771\n",
            "Epoch: 110. Loss: 0.5441853753482371\n",
            "Epoch: 120. Loss: 0.5436585046063241\n",
            "Epoch: 130. Loss: 0.5432074374580028\n",
            "Epoch: 140. Loss: 0.5428161092887503\n",
            "Epoch: 150. Loss: 0.542472433339127\n",
            "Epoch: 160. Loss: 0.5421672665835767\n",
            "Epoch: 170. Loss: 0.541893650224192\n",
            "Epoch: 180. Loss: 0.5416462507043329\n",
            "Epoch: 190. Loss: 0.5414209474063062\n",
            "Epoch: 200. Loss: 0.541214527876314\n",
            "Epoch: 210. Loss: 0.5410244620501642\n",
            "Epoch: 220. Loss: 0.5408487346519121\n",
            "Epoch: 230. Loss: 0.5406857205211026\n",
            "Epoch: 240. Loss: 0.540534091682889\n",
            "Epoch: 250. Loss: 0.5403927479333718\n",
            "Epoch: 260. Loss: 0.5402607648745461\n",
            "Epoch: 270. Loss: 0.54013735491787\n",
            "Epoch: 280. Loss: 0.5400218379399495\n",
            "Epoch: 290. Loss: 0.5399136191316829\n",
            "Epoch: 300. Loss: 0.5398121722155155\n",
            "Epoch: 310. Loss: 0.5397170266739509\n",
            "Epoch: 320. Loss: 0.5396277579795917\n",
            "Epoch: 330. Loss: 0.53954398007459\n",
            "Epoch: 340. Loss: 0.5394653395387854\n",
            "tensor(0.7705, dtype=torch.float64)\n",
            "2022-03-06 00:00:00\n",
            "Epoch: 0. Loss: 2.4453413080890334\n",
            "Epoch: 10. Loss: 0.6265324555340688\n",
            "Epoch: 20. Loss: 0.585804852625293\n",
            "Epoch: 30. Loss: 0.5663737027655804\n",
            "Epoch: 40. Loss: 0.5559866531245403\n",
            "Epoch: 50. Loss: 0.550030871162578\n",
            "Epoch: 60. Loss: 0.5464342886628057\n",
            "Epoch: 70. Loss: 0.5441920973701029\n",
            "Epoch: 80. Loss: 0.5427625776113404\n",
            "Epoch: 90. Loss: 0.541833677087373\n",
            "Epoch: 100. Loss: 0.5412193413990253\n",
            "Epoch: 110. Loss: 0.5408062499101066\n",
            "Epoch: 120. Loss: 0.5405241608070139\n",
            "Epoch: 130. Loss: 0.5403287928197604\n",
            "Epoch: 140. Loss: 0.5401917544252004\n",
            "Epoch: 150. Loss: 0.5400945337834888\n",
            "Epoch: 160. Loss: 0.5400248621013676\n",
            "Epoch: 170. Loss: 0.5399744810924274\n",
            "Epoch: 180. Loss: 0.5399377514098281\n",
            "Epoch: 190. Loss: 0.5399107714596048\n",
            "Epoch: 200. Loss: 0.5398908103503332\n",
            "Epoch: 210. Loss: 0.5398759370838784\n",
            "Epoch: 220. Loss: 0.5398647742443491\n",
            "Epoch: 230. Loss: 0.5398563319247753\n",
            "Epoch: 240. Loss: 0.5398498941875246\n",
            "Epoch: 250. Loss: 0.5398449404540677\n",
            "Epoch: 260. Loss: 0.5398410904632516\n",
            "Epoch: 270. Loss: 0.5398380653519265\n",
            "Epoch: 280. Loss: 0.5398356599028319\n",
            "Epoch: 290. Loss: 0.5398337226140614\n",
            "Epoch: 300. Loss: 0.53983214130024\n",
            "Epoch: 310. Loss: 0.5398308326386826\n",
            "Epoch: 320. Loss: 0.5398297345488311\n",
            "Epoch: 330. Loss: 0.5398288006185489\n",
            "Epoch: 340. Loss: 0.5398279960163344\n",
            "tensor(0.9472, dtype=torch.float64)\n",
            "2022-03-13 00:00:00\n",
            "Epoch: 0. Loss: 1.417312664966391\n",
            "Epoch: 10. Loss: 0.8819581394959843\n",
            "Epoch: 20. Loss: 0.737496992130972\n",
            "Epoch: 30. Loss: 0.6739579143927619\n",
            "Epoch: 40. Loss: 0.6424741461458257\n",
            "Epoch: 50. Loss: 0.624000783689433\n",
            "Epoch: 60. Loss: 0.6113055092238493\n",
            "Epoch: 70. Loss: 0.6018667855713572\n",
            "Epoch: 80. Loss: 0.5946266944672832\n",
            "Epoch: 90. Loss: 0.5889840984764158\n",
            "Epoch: 100. Loss: 0.5845274258055759\n",
            "Epoch: 110. Loss: 0.5809567655284507\n",
            "Epoch: 120. Loss: 0.5780509515340221\n",
            "Epoch: 130. Loss: 0.5756470447688691\n",
            "Epoch: 140. Loss: 0.5736252549446015\n",
            "Epoch: 150. Loss: 0.5718975443071865\n",
            "Epoch: 160. Loss: 0.5703990939106592\n",
            "Epoch: 170. Loss: 0.5690819988115534\n",
            "Epoch: 180. Loss: 0.5679106576094544\n",
            "Epoch: 190. Loss: 0.5668584225605598\n",
            "Epoch: 200. Loss: 0.5659051736253395\n",
            "Epoch: 210. Loss: 0.5650355634613692\n",
            "Epoch: 220. Loss: 0.5642377471777589\n",
            "Epoch: 230. Loss: 0.5635024615819635\n",
            "Epoch: 240. Loss: 0.5628223563515021\n",
            "Epoch: 250. Loss: 0.5621915069981392\n",
            "Epoch: 260. Loss: 0.5616050592564212\n",
            "Epoch: 270. Loss: 0.5610589686939204\n",
            "Epoch: 280. Loss: 0.5605498094745898\n",
            "Epoch: 290. Loss: 0.5600746334592266\n",
            "Epoch: 300. Loss: 0.5596308660264999\n",
            "Epoch: 310. Loss: 0.5592162287351535\n",
            "Epoch: 320. Loss: 0.5588286816420293\n",
            "Epoch: 330. Loss: 0.5584663800385609\n",
            "Epoch: 340. Loss: 0.5581276417811118\n",
            "tensor(0.4049, dtype=torch.float64)\n",
            "2022-03-20 00:00:00\n",
            "Epoch: 0. Loss: 0.8206697112564426\n",
            "Epoch: 10. Loss: 0.671908035363236\n",
            "Epoch: 20. Loss: 0.625252103999317\n",
            "Epoch: 30. Loss: 0.6114123611332998\n",
            "Epoch: 40. Loss: 0.6048539770454685\n",
            "Epoch: 50. Loss: 0.600263486812818\n",
            "Epoch: 60. Loss: 0.5965742339986574\n",
            "Epoch: 70. Loss: 0.5934528844698108\n",
            "Epoch: 80. Loss: 0.5907329114538225\n",
            "Epoch: 90. Loss: 0.5883114051413562\n",
            "Epoch: 100. Loss: 0.5861203213841861\n",
            "Epoch: 110. Loss: 0.5841134398037428\n",
            "Epoch: 120. Loss: 0.5822587379498908\n",
            "Epoch: 130. Loss: 0.5805335576671644\n",
            "Epoch: 140. Loss: 0.5789214700869432\n",
            "Epoch: 150. Loss: 0.5774102249075836\n",
            "Epoch: 160. Loss: 0.5759904016113601\n",
            "Epoch: 170. Loss: 0.5746545178175622\n",
            "Epoch: 180. Loss: 0.5733964366652471\n",
            "Epoch: 190. Loss: 0.5722109706674476\n",
            "Epoch: 200. Loss: 0.5710936152654559\n",
            "Epoch: 210. Loss: 0.5700403684406335\n",
            "Epoch: 220. Loss: 0.5690476077338937\n",
            "Epoch: 230. Loss: 0.5681120057737478\n",
            "Epoch: 240. Loss: 0.56723047177929\n",
            "Epoch: 250. Loss: 0.5664001106779645\n",
            "Epoch: 260. Loss: 0.5656181942277086\n",
            "Epoch: 270. Loss: 0.5648821403547968\n",
            "Epoch: 280. Loss: 0.5641894981330343\n",
            "Epoch: 290. Loss: 0.5635379366447691\n",
            "Epoch: 300. Loss: 0.5629252365147865\n",
            "Epoch: 310. Loss: 0.562349283282923\n",
            "Epoch: 320. Loss: 0.5618080620381383\n",
            "Epoch: 330. Loss: 0.5612996529141402\n",
            "Epoch: 340. Loss: 0.5608222271698219\n",
            "tensor(0.7105, dtype=torch.float64)\n",
            "2022-03-27 00:00:00\n",
            "Epoch: 0. Loss: 1.9338887080671945\n",
            "Epoch: 10. Loss: 0.7396558546077209\n",
            "Epoch: 20. Loss: 0.620307233326531\n",
            "Epoch: 30. Loss: 0.5894535316772217\n",
            "Epoch: 40. Loss: 0.5796814088010095\n",
            "Epoch: 50. Loss: 0.574636475319085\n",
            "Epoch: 60. Loss: 0.5713136536313627\n",
            "Epoch: 70. Loss: 0.5689592388192488\n",
            "Epoch: 80. Loss: 0.5672399002756621\n",
            "Epoch: 90. Loss: 0.5659559326412728\n",
            "Epoch: 100. Loss: 0.5649761467582113\n",
            "Epoch: 110. Loss: 0.5642119290054036\n",
            "Epoch: 120. Loss: 0.5636026194316167\n",
            "Epoch: 130. Loss: 0.5631062634534441\n",
            "Epoch: 140. Loss: 0.5626935629320218\n",
            "Epoch: 150. Loss: 0.5623438631226539\n",
            "Epoch: 160. Loss: 0.5620424627866325\n",
            "Epoch: 170. Loss: 0.5617787942923309\n",
            "Epoch: 180. Loss: 0.5615451814946131\n",
            "Epoch: 190. Loss: 0.5613359850684297\n",
            "Epoch: 200. Loss: 0.5611470101011158\n",
            "Epoch: 210. Loss: 0.5609750927563711\n",
            "Epoch: 220. Loss: 0.5608178101842559\n",
            "Epoch: 230. Loss: 0.560673275857627\n",
            "Epoch: 240. Loss: 0.5605399944892522\n",
            "Epoch: 250. Loss: 0.5604167587273404\n",
            "Epoch: 260. Loss: 0.5603025752822396\n",
            "Epoch: 270. Loss: 0.5601966118689163\n",
            "Epoch: 280. Loss: 0.5600981589228403\n",
            "Epoch: 290. Loss: 0.5600066018330097\n",
            "Epoch: 300. Loss: 0.5599214006830499\n",
            "Epoch: 310. Loss: 0.5598420753665408\n",
            "Epoch: 320. Loss: 0.559768194559508\n",
            "Epoch: 330. Loss: 0.5596993674691614\n",
            "Epoch: 340. Loss: 0.5596352375872927\n",
            "tensor(0.7523, dtype=torch.float64)\n",
            "2022-04-03 00:00:00\n",
            "Epoch: 0. Loss: 2.326563141484636\n",
            "Epoch: 10. Loss: 0.9216426718522084\n",
            "Epoch: 20. Loss: 0.6984334535041893\n",
            "Epoch: 30. Loss: 0.6265197388533966\n",
            "Epoch: 40. Loss: 0.5991310853336479\n",
            "Epoch: 50. Loss: 0.5855791133403819\n",
            "Epoch: 60. Loss: 0.5783913372317363\n",
            "Epoch: 70. Loss: 0.5744547982808791\n",
            "Epoch: 80. Loss: 0.5722104543424211\n",
            "Epoch: 90. Loss: 0.5708584956894512\n",
            "Epoch: 100. Loss: 0.5699858857564224\n",
            "Epoch: 110. Loss: 0.5693775689556859\n",
            "Epoch: 120. Loss: 0.5689203472767493\n",
            "Epoch: 130. Loss: 0.568553821419204\n",
            "Epoch: 140. Loss: 0.5682452045613633\n",
            "Epoch: 150. Loss: 0.5679762889934024\n",
            "Epoch: 160. Loss: 0.5677366439982807\n",
            "Epoch: 170. Loss: 0.5675200362225237\n",
            "Epoch: 180. Loss: 0.5673225308555087\n",
            "Epoch: 190. Loss: 0.567141476432822\n",
            "Epoch: 200. Loss: 0.5669749574816344\n",
            "Epoch: 210. Loss: 0.5668214964826676\n",
            "Epoch: 220. Loss: 0.5666798895271619\n",
            "Epoch: 230. Loss: 0.5665491141330956\n",
            "Epoch: 240. Loss: 0.5664282762943299\n",
            "Epoch: 250. Loss: 0.566316579053126\n",
            "Epoch: 260. Loss: 0.5662133030195612\n",
            "Epoch: 270. Loss: 0.5661177936282008\n",
            "Epoch: 280. Loss: 0.5660294522776422\n",
            "Epoch: 290. Loss: 0.5659477297749399\n",
            "Epoch: 300. Loss: 0.5658721212023753\n",
            "Epoch: 310. Loss: 0.565802161705319\n",
            "Epoch: 320. Loss: 0.5657374229106136\n",
            "Epoch: 330. Loss: 0.5656775098023976\n",
            "Epoch: 340. Loss: 0.5656220579486431\n",
            "tensor(0.6803, dtype=torch.float64)\n",
            "2022-04-10 00:00:00\n",
            "Epoch: 0. Loss: 2.9773807826336802\n",
            "Epoch: 10. Loss: 1.2630829025535415\n",
            "Epoch: 20. Loss: 0.8323079189430771\n",
            "Epoch: 30. Loss: 0.6782069516509588\n",
            "Epoch: 40. Loss: 0.6222647167735972\n",
            "Epoch: 50. Loss: 0.5995190398746826\n",
            "Epoch: 60. Loss: 0.5887610614940101\n",
            "Epoch: 70. Loss: 0.5829992416218545\n",
            "Epoch: 80. Loss: 0.5795936020678528\n",
            "Epoch: 90. Loss: 0.5773826216629885\n",
            "Epoch: 100. Loss: 0.5758077864375918\n",
            "Epoch: 110. Loss: 0.5745896730566669\n",
            "Epoch: 120. Loss: 0.5735852397680437\n",
            "Epoch: 130. Loss: 0.5727194966169668\n",
            "Epoch: 140. Loss: 0.5719518189966535\n",
            "Epoch: 150. Loss: 0.5712591573081247\n",
            "Epoch: 160. Loss: 0.5706276061817288\n",
            "Epoch: 170. Loss: 0.5700481350168727\n",
            "Epoch: 180. Loss: 0.5695144012082627\n",
            "Epoch: 190. Loss: 0.5690216128167833\n",
            "Epoch: 200. Loss: 0.568565924762702\n",
            "Epoch: 210. Loss: 0.5681441094187145\n",
            "Epoch: 220. Loss: 0.5677533704754538\n",
            "Epoch: 230. Loss: 0.5673912330803257\n",
            "Epoch: 240. Loss: 0.5670554755910472\n",
            "Epoch: 250. Loss: 0.5667440847305136\n",
            "Epoch: 260. Loss: 0.5664552243809752\n",
            "Epoch: 270. Loss: 0.5661872126576758\n",
            "Epoch: 280. Loss: 0.5659385042344529\n",
            "Epoch: 290. Loss: 0.5657076761555231\n",
            "Epoch: 300. Loss: 0.5654934160673764\n",
            "Epoch: 310. Loss: 0.5652945122037286\n",
            "Epoch: 320. Loss: 0.5651098446911015\n",
            "Epoch: 330. Loss: 0.5649383778848958\n",
            "Epoch: 340. Loss: 0.5647791535348257\n",
            "tensor(0.6106, dtype=torch.float64)\n",
            "2022-04-17 00:00:00\n",
            "Epoch: 0. Loss: 3.55207648235897\n",
            "Epoch: 10. Loss: 0.904339072386944\n",
            "Epoch: 20. Loss: 0.7623891842934857\n",
            "Epoch: 30. Loss: 0.70705290733932\n",
            "Epoch: 40. Loss: 0.6686834925868199\n",
            "Epoch: 50. Loss: 0.6401832860574986\n",
            "Epoch: 60. Loss: 0.6192243319969175\n",
            "Epoch: 70. Loss: 0.604228445619131\n",
            "Epoch: 80. Loss: 0.5937709668017421\n",
            "Epoch: 90. Loss: 0.5866057927006768\n",
            "Epoch: 100. Loss: 0.5817392668678231\n",
            "Epoch: 110. Loss: 0.5784376771386487\n",
            "Epoch: 120. Loss: 0.5761863759856921\n",
            "Epoch: 130. Loss: 0.574635349187322\n",
            "Epoch: 140. Loss: 0.5735505877063304\n",
            "Epoch: 150. Loss: 0.572776972982162\n",
            "Epoch: 160. Loss: 0.5722120346324907\n",
            "Epoch: 170. Loss: 0.571788109663981\n",
            "Epoch: 180. Loss: 0.5714604547992629\n",
            "Epoch: 190. Loss: 0.5711994026156523\n",
            "Epoch: 200. Loss: 0.570985207382878\n",
            "Epoch: 210. Loss: 0.5708046620847771\n",
            "Epoch: 220. Loss: 0.570648876976489\n",
            "Epoch: 230. Loss: 0.5705118191225798\n",
            "Epoch: 240. Loss: 0.5703893507970852\n",
            "Epoch: 250. Loss: 0.5702785953495693\n",
            "Epoch: 260. Loss: 0.5701775183671121\n",
            "Epoch: 270. Loss: 0.5700846506061689\n",
            "Epoch: 280. Loss: 0.5699989044123865\n",
            "Epoch: 290. Loss: 0.569919451868278\n",
            "Epoch: 300. Loss: 0.569845643744359\n",
            "Epoch: 310. Loss: 0.5697769554498878\n",
            "Epoch: 320. Loss: 0.5697129508667464\n",
            "Epoch: 330. Loss: 0.5696532580401944\n",
            "Epoch: 340. Loss: 0.5695975527399438\n",
            "tensor(0.4554, dtype=torch.float64)\n",
            "2022-04-24 00:00:00\n",
            "Epoch: 0. Loss: 1.1577138848706807\n",
            "Epoch: 10. Loss: 0.7428557111831221\n",
            "Epoch: 20. Loss: 0.6514680383603587\n",
            "Epoch: 30. Loss: 0.615277265283469\n",
            "Epoch: 40. Loss: 0.5980876999339135\n",
            "Epoch: 50. Loss: 0.5884105073664615\n",
            "Epoch: 60. Loss: 0.5824515300431552\n",
            "Epoch: 70. Loss: 0.5785725864291498\n",
            "Epoch: 80. Loss: 0.5759270663581173\n",
            "Epoch: 90. Loss: 0.5740415932204554\n",
            "Epoch: 100. Loss: 0.5726406208126619\n",
            "Epoch: 110. Loss: 0.5715587272950868\n",
            "Epoch: 120. Loss: 0.5706936975653516\n",
            "Epoch: 130. Loss: 0.5699806360808891\n",
            "Epoch: 140. Loss: 0.5693773108383579\n",
            "Epoch: 150. Loss: 0.5688556219394373\n",
            "Epoch: 160. Loss: 0.5683964895248986\n",
            "Epoch: 170. Loss: 0.5679867050856765\n",
            "Epoch: 180. Loss: 0.5676169445615625\n",
            "Epoch: 190. Loss: 0.5672804891637958\n",
            "Epoch: 200. Loss: 0.5669723885856015\n",
            "Epoch: 210. Loss: 0.5666889067471149\n",
            "Epoch: 220. Loss: 0.566427151085406\n",
            "Epoch: 230. Loss: 0.5661848226517329\n",
            "Epoch: 240. Loss: 0.5659600465072064\n",
            "Epoch: 250. Loss: 0.5657512558832261\n",
            "Epoch: 260. Loss: 0.5655571125393573\n",
            "Epoch: 270. Loss: 0.5653764515958937\n",
            "Epoch: 280. Loss: 0.5652082429739277\n",
            "Epoch: 290. Loss: 0.5650515641417214\n",
            "Epoch: 300. Loss: 0.5649055805847645\n",
            "Epoch: 310. Loss: 0.5647695315731043\n",
            "Epoch: 320. Loss: 0.5646427195798251\n",
            "Epoch: 330. Loss: 0.5645245022322484\n",
            "Epoch: 340. Loss: 0.5644142860347928\n",
            "tensor(0.3556, dtype=torch.float64)\n",
            "2022-05-01 00:00:00\n",
            "Epoch: 0. Loss: 1.2525902632212347\n",
            "Epoch: 10. Loss: 0.8823020234068513\n",
            "Epoch: 20. Loss: 0.7001339678873324\n",
            "Epoch: 30. Loss: 0.6279778942528162\n",
            "Epoch: 40. Loss: 0.5962561280620883\n",
            "Epoch: 50. Loss: 0.5809100708015011\n",
            "Epoch: 60. Loss: 0.573452587042672\n",
            "Epoch: 70. Loss: 0.5698424728071243\n",
            "Epoch: 80. Loss: 0.5680695773215789\n",
            "Epoch: 90. Loss: 0.5671638725238066\n",
            "Epoch: 100. Loss: 0.5666679153773753\n",
            "Epoch: 110. Loss: 0.5663678732325028\n",
            "Epoch: 120. Loss: 0.5661638042781765\n",
            "Epoch: 130. Loss: 0.5660087844435809\n",
            "Epoch: 140. Loss: 0.5658805986837768\n",
            "Epoch: 150. Loss: 0.5657685848608636\n",
            "Epoch: 160. Loss: 0.5656675048289648\n",
            "Epoch: 170. Loss: 0.5655746801808775\n",
            "Epoch: 180. Loss: 0.5654886495478252\n",
            "Epoch: 190. Loss: 0.5654085373267493\n",
            "Epoch: 200. Loss: 0.5653337559642493\n",
            "Epoch: 210. Loss: 0.5652638649843196\n",
            "Epoch: 220. Loss: 0.5651985038144713\n",
            "Epoch: 230. Loss: 0.5651373594223877\n",
            "Epoch: 240. Loss: 0.5650801504090366\n",
            "Epoch: 250. Loss: 0.5650266189069566\n",
            "Epoch: 260. Loss: 0.5649765262012033\n",
            "Epoch: 270. Loss: 0.5649296501439509\n",
            "Epoch: 280. Loss: 0.5648857834496728\n",
            "Epoch: 290. Loss: 0.5648447324374638\n",
            "Epoch: 300. Loss: 0.5648063160136908\n",
            "Epoch: 310. Loss: 0.5647703647953517\n",
            "Epoch: 320. Loss: 0.5647367203253082\n",
            "Epoch: 330. Loss: 0.5647052343546793\n",
            "Epoch: 340. Loss: 0.5646757681791941\n",
            "tensor(0.4341, dtype=torch.float64)\n",
            "2022-05-08 00:00:00\n",
            "Epoch: 0. Loss: 1.9615782939097297\n",
            "Epoch: 10. Loss: 1.2242806632678818\n",
            "Epoch: 20. Loss: 1.0282549599724982\n",
            "Epoch: 30. Loss: 0.881174702292212\n",
            "Epoch: 40. Loss: 0.7637885516498365\n",
            "Epoch: 50. Loss: 0.6790418428582783\n",
            "Epoch: 60. Loss: 0.6261591934839128\n",
            "Epoch: 70. Loss: 0.5975507712319734\n",
            "Epoch: 80. Loss: 0.5834821288064721\n",
            "Epoch: 90. Loss: 0.5768000173613294\n",
            "Epoch: 100. Loss: 0.5735828335573828\n",
            "Epoch: 110. Loss: 0.5719575846270368\n",
            "Epoch: 120. Loss: 0.5710722731384894\n",
            "Epoch: 130. Loss: 0.5705413621152491\n",
            "Epoch: 140. Loss: 0.570187852510155\n",
            "Epoch: 150. Loss: 0.5699284574960749\n",
            "Epoch: 160. Loss: 0.5697227009535641\n",
            "Epoch: 170. Loss: 0.5695501087204888\n",
            "Epoch: 180. Loss: 0.5693998125506639\n",
            "Epoch: 190. Loss: 0.5692657119783943\n",
            "Epoch: 200. Loss: 0.5691441665313989\n",
            "Epoch: 210. Loss: 0.5690328622153614\n",
            "Epoch: 220. Loss: 0.5689302352514626\n",
            "Epoch: 230. Loss: 0.5688351673745176\n",
            "Epoch: 240. Loss: 0.5687468177108962\n",
            "Epoch: 250. Loss: 0.5686645259034171\n",
            "Epoch: 260. Loss: 0.5685877539288139\n",
            "Epoch: 270. Loss: 0.5685160498216212\n",
            "Epoch: 280. Loss: 0.5684490243090011\n",
            "Epoch: 290. Loss: 0.568386335335329\n",
            "Epoch: 300. Loss: 0.5683276775588013\n",
            "Epoch: 310. Loss: 0.5682727750609181\n",
            "Epoch: 320. Loss: 0.5682213761741466\n",
            "Epoch: 330. Loss: 0.5681732497288592\n",
            "Epoch: 340. Loss: 0.568128182264344\n",
            "tensor(0.6079, dtype=torch.float64)\n",
            "2022-05-15 00:00:00\n",
            "Epoch: 0. Loss: 1.9347179462309334\n",
            "Epoch: 10. Loss: 1.4529822358357452\n",
            "Epoch: 20. Loss: 1.0561667334000393\n",
            "Epoch: 30. Loss: 0.7843408846078239\n",
            "Epoch: 40. Loss: 0.6573815910617115\n",
            "Epoch: 50. Loss: 0.6173472777840275\n",
            "Epoch: 60. Loss: 0.6018403387568559\n",
            "Epoch: 70. Loss: 0.5929475716786762\n",
            "Epoch: 80. Loss: 0.5872286915451277\n",
            "Epoch: 90. Loss: 0.5834890728188726\n",
            "Epoch: 100. Loss: 0.5810361718221712\n",
            "Epoch: 110. Loss: 0.57942358057915\n",
            "Epoch: 120. Loss: 0.5783606084396248\n",
            "Epoch: 130. Loss: 0.5776578446613855\n",
            "Epoch: 140. Loss: 0.57719171884744\n",
            "Epoch: 150. Loss: 0.5768814443310544\n",
            "Epoch: 160. Loss: 0.5766740726044938\n",
            "Epoch: 170. Loss: 0.5765348109425025\n",
            "Epoch: 180. Loss: 0.5764407401122879\n",
            "Epoch: 190. Loss: 0.5763767275912791\n",
            "Epoch: 200. Loss: 0.5763327610013793\n",
            "Epoch: 210. Loss: 0.5763022028919426\n",
            "Epoch: 220. Loss: 0.5762806452138671\n",
            "Epoch: 230. Loss: 0.5762651554297993\n",
            "Epoch: 240. Loss: 0.5762537791998646\n",
            "Epoch: 250. Loss: 0.5762452116469422\n",
            "Epoch: 260. Loss: 0.5762385796704396\n",
            "Epoch: 270. Loss: 0.5762332975758346\n",
            "Epoch: 280. Loss: 0.5762289712022797\n",
            "Epoch: 290. Loss: 0.576225334184645\n",
            "Epoch: 300. Loss: 0.5762222055375552\n",
            "Epoch: 310. Loss: 0.5762194614039036\n",
            "Epoch: 320. Loss: 0.5762170162224722\n",
            "Epoch: 330. Loss: 0.5762148101644013\n",
            "Epoch: 340. Loss: 0.5762128007449032\n",
            "tensor(0.6508, dtype=torch.float64)\n",
            "2022-05-22 00:00:00\n",
            "Epoch: 0. Loss: 4.499372945792659\n",
            "Epoch: 10. Loss: 0.8373961708317667\n",
            "Epoch: 20. Loss: 0.6686351023012338\n",
            "Epoch: 30. Loss: 0.6352518616807854\n",
            "Epoch: 40. Loss: 0.6204010141234017\n",
            "Epoch: 50. Loss: 0.6109156563070491\n",
            "Epoch: 60. Loss: 0.6043568401837612\n",
            "Epoch: 70. Loss: 0.5997162109544859\n",
            "Epoch: 80. Loss: 0.5963698710182262\n",
            "Epoch: 90. Loss: 0.5939064423120377\n",
            "Epoch: 100. Loss: 0.5920518278220253\n",
            "Epoch: 110. Loss: 0.5906217919515694\n",
            "Epoch: 120. Loss: 0.5894913653636942\n",
            "Epoch: 130. Loss: 0.5885750985824963\n",
            "Epoch: 140. Loss: 0.5878141791880995\n",
            "Epoch: 150. Loss: 0.5871678984813994\n",
            "Epoch: 160. Loss: 0.5866079205900383\n",
            "Epoch: 170. Loss: 0.5861143946902496\n",
            "Epoch: 180. Loss: 0.5856733011401051\n",
            "Epoch: 190. Loss: 0.5852746341166868\n",
            "Epoch: 200. Loss: 0.5849111556101767\n",
            "Epoch: 210. Loss: 0.5845775410913793\n",
            "Epoch: 220. Loss: 0.584269793967032\n",
            "Epoch: 230. Loss: 0.5839848444160741\n",
            "Epoch: 240. Loss: 0.583720274559801\n",
            "Epoch: 250. Loss: 0.583474130070659\n",
            "Epoch: 260. Loss: 0.5832447908419541\n",
            "Epoch: 270. Loss: 0.5830308819663955\n",
            "Epoch: 280. Loss: 0.5828312122043596\n",
            "Epoch: 290. Loss: 0.5826447311943374\n",
            "Epoch: 300. Loss: 0.5824704994456845\n",
            "Epoch: 310. Loss: 0.5823076670582149\n",
            "Epoch: 320. Loss: 0.5821554584116262\n",
            "Epoch: 330. Loss: 0.5820131609515471\n",
            "Epoch: 340. Loss: 0.5818801167997087\n",
            "tensor(0.6460, dtype=torch.float64)\n",
            "2022-05-29 00:00:00\n",
            "Epoch: 0. Loss: 1.9906932106318591\n",
            "Epoch: 10. Loss: 1.1015858837127386\n",
            "Epoch: 20. Loss: 0.8181172078987313\n",
            "Epoch: 30. Loss: 0.7179533650113415\n",
            "Epoch: 40. Loss: 0.6619789424354753\n",
            "Epoch: 50. Loss: 0.6277100051120521\n",
            "Epoch: 60. Loss: 0.6079821882276062\n",
            "Epoch: 70. Loss: 0.597172870157257\n",
            "Epoch: 80. Loss: 0.5913220813172797\n",
            "Epoch: 90. Loss: 0.5881006030561207\n",
            "Epoch: 100. Loss: 0.5862688682251256\n",
            "Epoch: 110. Loss: 0.5851895845304163\n",
            "Epoch: 120. Loss: 0.5845329633274589\n",
            "Epoch: 130. Loss: 0.5841231931333053\n",
            "Epoch: 140. Loss: 0.5838626796206837\n",
            "Epoch: 150. Loss: 0.5836949282155314\n",
            "Epoch: 160. Loss: 0.5835859954937714\n",
            "Epoch: 170. Loss: 0.5835148748928137\n",
            "Epoch: 180. Loss: 0.5834682818365974\n",
            "Epoch: 190. Loss: 0.5834376895851399\n",
            "Epoch: 200. Loss: 0.5834175719600708\n",
            "Epoch: 210. Loss: 0.5834043256221585\n",
            "Epoch: 220. Loss: 0.5833955923690393\n",
            "Epoch: 230. Loss: 0.5833898255706902\n",
            "Epoch: 240. Loss: 0.5833860096565795\n",
            "Epoch: 250. Loss: 0.5833834773470036\n",
            "Epoch: 260. Loss: 0.5833817900676195\n",
            "Epoch: 270. Loss: 0.5833806595159869\n",
            "Epoch: 280. Loss: 0.5833798961520706\n",
            "Epoch: 290. Loss: 0.5833793753491985\n",
            "Epoch: 300. Loss: 0.5833790151450412\n",
            "Epoch: 310. Loss: 0.5833787616168652\n",
            "Epoch: 320. Loss: 0.5833785792691263\n",
            "Epoch: 330. Loss: 0.583378444716297\n",
            "Epoch: 340. Loss: 0.5833783425318317\n",
            "tensor(0.7624, dtype=torch.float64)\n",
            "2022-06-05 00:00:00\n",
            "Epoch: 0. Loss: 3.148697112059122\n",
            "Epoch: 10. Loss: 1.0846970577498054\n",
            "Epoch: 20. Loss: 0.7852185337650538\n",
            "Epoch: 30. Loss: 0.6960649953328678\n",
            "Epoch: 40. Loss: 0.6499527068172987\n",
            "Epoch: 50. Loss: 0.6242702134259116\n",
            "Epoch: 60. Loss: 0.6107092076603319\n",
            "Epoch: 70. Loss: 0.6036997607192094\n",
            "Epoch: 80. Loss: 0.5999837715536123\n",
            "Epoch: 90. Loss: 0.5978921439220315\n",
            "Epoch: 100. Loss: 0.596618200073018\n",
            "Epoch: 110. Loss: 0.5957750461129682\n",
            "Epoch: 120. Loss: 0.5951728091506537\n",
            "Epoch: 130. Loss: 0.5947143471495353\n",
            "Epoch: 140. Loss: 0.5943473194913357\n",
            "Epoch: 150. Loss: 0.5940419399204078\n",
            "Epoch: 160. Loss: 0.5937803549226013\n",
            "Epoch: 170. Loss: 0.5935513590151822\n",
            "Epoch: 180. Loss: 0.5933476324570509\n",
            "Epoch: 190. Loss: 0.5931642212141411\n",
            "Epoch: 200. Loss: 0.592997659635563\n",
            "Epoch: 210. Loss: 0.5928454433821231\n",
            "Epoch: 220. Loss: 0.592705702747588\n",
            "Epoch: 230. Loss: 0.5925769954366934\n",
            "Epoch: 240. Loss: 0.5924581728502081\n",
            "Epoch: 250. Loss: 0.5923482926560848\n",
            "Epoch: 260. Loss: 0.5922465609784511\n",
            "Epoch: 270. Loss: 0.5921522937508575\n",
            "Epoch: 280. Loss: 0.5920648905692092\n",
            "Epoch: 290. Loss: 0.5919838167487815\n",
            "Epoch: 300. Loss: 0.5919085907966143\n",
            "Epoch: 310. Loss: 0.5918387754800266\n",
            "Epoch: 320. Loss: 0.5917739713002188\n",
            "Epoch: 330. Loss: 0.5917138115889132\n",
            "Epoch: 340. Loss: 0.5916579587130207\n",
            "tensor(0.6250, dtype=torch.float64)\n",
            "2022-06-12 00:00:00\n",
            "Epoch: 0. Loss: 1.1206346708762795\n",
            "Epoch: 10. Loss: 0.7782208843611251\n",
            "Epoch: 20. Loss: 0.6874157469724749\n",
            "Epoch: 30. Loss: 0.6432024097939697\n",
            "Epoch: 40. Loss: 0.6223899619768654\n",
            "Epoch: 50. Loss: 0.6129783721498311\n",
            "Epoch: 60. Loss: 0.6085986622187823\n",
            "Epoch: 70. Loss: 0.6063857099828737\n",
            "Epoch: 80. Loss: 0.6051323066807874\n",
            "Epoch: 90. Loss: 0.6043300326151144\n",
            "Epoch: 100. Loss: 0.603757787265347\n",
            "Epoch: 110. Loss: 0.6033143679829898\n",
            "Epoch: 120. Loss: 0.6029503633571284\n",
            "Epoch: 130. Loss: 0.6026398284992684\n",
            "Epoch: 140. Loss: 0.6023680840727701\n",
            "Epoch: 150. Loss: 0.602126214745312\n",
            "Epoch: 160. Loss: 0.6019084490627441\n",
            "Epoch: 170. Loss: 0.6017108343411117\n",
            "Epoch: 180. Loss: 0.6015305250627191\n",
            "Epoch: 190. Loss: 0.6013653793579403\n",
            "Epoch: 200. Loss: 0.601213719538933\n",
            "Epoch: 210. Loss: 0.6010741847712824\n",
            "Epoch: 220. Loss: 0.6009456378326277\n",
            "Epoch: 230. Loss: 0.6008271047228715\n",
            "Epoch: 240. Loss: 0.6007177347364877\n",
            "Epoch: 250. Loss: 0.600616773517088\n",
            "Epoch: 260. Loss: 0.6005235444652267\n",
            "Epoch: 270. Loss: 0.6004374355846311\n",
            "Epoch: 280. Loss: 0.6003578899092643\n",
            "Epoch: 290. Loss: 0.6002843983171833\n",
            "Epoch: 300. Loss: 0.6002164939585648\n",
            "Epoch: 310. Loss: 0.6001537477950136\n",
            "Epoch: 320. Loss: 0.600095764920828\n",
            "Epoch: 330. Loss: 0.6000421814490102\n",
            "Epoch: 340. Loss: 0.5999926618174293\n",
            "tensor(0.6727, dtype=torch.float64)\n",
            "2022-06-19 00:00:00\n",
            "Epoch: 0. Loss: 2.4699992010554026\n",
            "Epoch: 10. Loss: 0.7701059015673101\n",
            "Epoch: 20. Loss: 0.6832179149057922\n",
            "Epoch: 30. Loss: 0.6539465108015285\n",
            "Epoch: 40. Loss: 0.6362048628351302\n",
            "Epoch: 50. Loss: 0.6249169427840505\n",
            "Epoch: 60. Loss: 0.6177843287930029\n",
            "Epoch: 70. Loss: 0.6132955237409902\n",
            "Epoch: 80. Loss: 0.6104730369159566\n",
            "Epoch: 90. Loss: 0.6086970647467452\n",
            "Epoch: 100. Loss: 0.6075780085575108\n",
            "Epoch: 110. Loss: 0.6068716897220578\n",
            "Epoch: 120. Loss: 0.6064250954555412\n",
            "Epoch: 130. Loss: 0.6061422300417739\n",
            "Epoch: 140. Loss: 0.6059627632606638\n",
            "Epoch: 150. Loss: 0.605848705905101\n",
            "Epoch: 160. Loss: 0.6057760907429811\n",
            "Epoch: 170. Loss: 0.6057297699633979\n",
            "Epoch: 180. Loss: 0.6057001544755753\n",
            "Epoch: 190. Loss: 0.605681165483409\n",
            "Epoch: 200. Loss: 0.6056689447116411\n",
            "Epoch: 210. Loss: 0.6056610406187762\n",
            "Epoch: 220. Loss: 0.6056558939870355\n",
            "Epoch: 230. Loss: 0.6056525122342556\n",
            "Epoch: 240. Loss: 0.6056502629305266\n",
            "Epoch: 250. Loss: 0.6056487427395769\n",
            "Epoch: 260. Loss: 0.6056476941538633\n",
            "Epoch: 270. Loss: 0.6056469525519155\n",
            "Epoch: 280. Loss: 0.6056464125130259\n",
            "Epoch: 290. Loss: 0.6056460063724313\n",
            "Epoch: 300. Loss: 0.6056456905623044\n",
            "Epoch: 310. Loss: 0.6056454369079276\n",
            "Epoch: 320. Loss: 0.6056452270790356\n",
            "Epoch: 330. Loss: 0.6056450490509973\n",
            "Epoch: 340. Loss: 0.6056448948467035\n",
            "tensor(0.6050, dtype=torch.float64)\n",
            "2022-06-26 00:00:00\n",
            "Epoch: 0. Loss: 1.5794985518762585\n",
            "Epoch: 10. Loss: 0.6641969564765479\n",
            "Epoch: 20. Loss: 0.6475555875627749\n",
            "Epoch: 30. Loss: 0.6437230803805066\n",
            "Epoch: 40. Loss: 0.6406184517144133\n",
            "Epoch: 50. Loss: 0.6378596886838312\n",
            "Epoch: 60. Loss: 0.6353508828146721\n",
            "Epoch: 70. Loss: 0.633043986946901\n",
            "Epoch: 80. Loss: 0.6309102588795197\n",
            "Epoch: 90. Loss: 0.6289302129482914\n",
            "Epoch: 100. Loss: 0.6270892942056465\n",
            "Epoch: 110. Loss: 0.6253758553697768\n",
            "Epoch: 120. Loss: 0.6237801232720361\n",
            "Epoch: 130. Loss: 0.622293620577252\n",
            "Epoch: 140. Loss: 0.6209088158483037\n",
            "Epoch: 150. Loss: 0.6196188991953201\n",
            "Epoch: 160. Loss: 0.6184176327896425\n",
            "Epoch: 170. Loss: 0.6172992486841049\n",
            "Epoch: 180. Loss: 0.616258377608223\n",
            "Epoch: 190. Loss: 0.6152899984188628\n",
            "Epoch: 200. Loss: 0.6143894014217355\n",
            "Epoch: 210. Loss: 0.6135521610105249\n",
            "Epoch: 220. Loss: 0.6127741145442156\n",
            "Epoch: 230. Loss: 0.6120513453805015\n",
            "Epoch: 240. Loss: 0.6113801686653071\n",
            "Epoch: 250. Loss: 0.6107571189461134\n",
            "Epoch: 260. Loss: 0.6101789389966111\n",
            "Epoch: 270. Loss: 0.6096425694576223\n",
            "Epoch: 280. Loss: 0.6091451390457783\n",
            "Epoch: 290. Loss: 0.6086839551790809\n",
            "Epoch: 300. Loss: 0.6082564949325183\n",
            "Epoch: 310. Loss: 0.6078603962780446\n",
            "Epoch: 320. Loss: 0.6074934495888493\n",
            "Epoch: 330. Loss: 0.6071535894030763\n",
            "Epoch: 340. Loss: 0.606838886450506\n",
            "tensor(0.5485, dtype=torch.float64)\n",
            "2022-07-03 00:00:00\n",
            "Epoch: 0. Loss: 2.4820566839248746\n",
            "Epoch: 10. Loss: 1.4886436286998448\n",
            "Epoch: 20. Loss: 1.2822297938496636\n",
            "Epoch: 30. Loss: 1.141805344599371\n",
            "Epoch: 40. Loss: 1.0249663257551187\n",
            "Epoch: 50. Loss: 0.9249877330667892\n",
            "Epoch: 60. Loss: 0.8410594588421437\n",
            "Epoch: 70. Loss: 0.773137549257106\n",
            "Epoch: 80. Loss: 0.7206736870368836\n",
            "Epoch: 90. Loss: 0.6821729552068306\n",
            "Epoch: 100. Loss: 0.6552601204919671\n",
            "Epoch: 110. Loss: 0.6371743419377602\n",
            "Epoch: 120. Loss: 0.6253474525011213\n",
            "Epoch: 130. Loss: 0.617738058373689\n",
            "Epoch: 140. Loss: 0.612881792761833\n",
            "Epoch: 150. Loss: 0.609791175966543\n",
            "Epoch: 160. Loss: 0.6078230767359696\n",
            "Epoch: 170. Loss: 0.6065662323703066\n",
            "Epoch: 180. Loss: 0.6057599365932614\n",
            "Epoch: 190. Loss: 0.6052394684410288\n",
            "Epoch: 200. Loss: 0.60490078741674\n",
            "Epoch: 210. Loss: 0.6046780985206553\n",
            "Epoch: 220. Loss: 0.6045297090326371\n",
            "Epoch: 230. Loss: 0.6044291360502324\n",
            "Epoch: 240. Loss: 0.6043595143830344\n",
            "Epoch: 250. Loss: 0.6043100742790543\n",
            "Epoch: 260. Loss: 0.6042739179444926\n",
            "Epoch: 270. Loss: 0.6042466125838281\n",
            "Epoch: 280. Loss: 0.6042252980338222\n",
            "Epoch: 290. Loss: 0.6042081195526063\n",
            "Epoch: 300. Loss: 0.6041938665769805\n",
            "Epoch: 310. Loss: 0.6041817422472878\n",
            "Epoch: 320. Loss: 0.6041712161237451\n",
            "Epoch: 330. Loss: 0.6041619299209768\n",
            "Epoch: 340. Loss: 0.6041536370831657\n",
            "tensor(0.9958, dtype=torch.float64)\n",
            "2022-07-10 00:00:00\n",
            "Epoch: 0. Loss: 1.686884916906943\n",
            "Epoch: 10. Loss: 0.9126045452120304\n",
            "Epoch: 20. Loss: 0.7306477579745849\n",
            "Epoch: 30. Loss: 0.670030055385301\n",
            "Epoch: 40. Loss: 0.6378123284758792\n",
            "Epoch: 50. Loss: 0.6224006755386102\n",
            "Epoch: 60. Loss: 0.6157977567192902\n",
            "Epoch: 70. Loss: 0.6130309380906286\n",
            "Epoch: 80. Loss: 0.6117518723259721\n",
            "Epoch: 90. Loss: 0.6110310677361456\n",
            "Epoch: 100. Loss: 0.6105306849368191\n",
            "Epoch: 110. Loss: 0.6101303982970484\n",
            "Epoch: 120. Loss: 0.6097858515809366\n",
            "Epoch: 130. Loss: 0.6094790776557083\n",
            "Epoch: 140. Loss: 0.6092015904130595\n",
            "Epoch: 150. Loss: 0.6089485847628855\n",
            "Epoch: 160. Loss: 0.6087168708978031\n",
            "Epoch: 170. Loss: 0.6085040813257706\n",
            "Epoch: 180. Loss: 0.6083083302859967\n",
            "Epoch: 190. Loss: 0.6081280467996949\n",
            "Epoch: 200. Loss: 0.6079618821980406\n",
            "Epoch: 210. Loss: 0.6078086539216055\n",
            "Epoch: 220. Loss: 0.6076673091164987\n",
            "Epoch: 230. Loss: 0.6075368999703364\n",
            "Epoch: 240. Loss: 0.6074165663879161\n",
            "Epoch: 250. Loss: 0.6073055234077771\n",
            "Epoch: 260. Loss: 0.6072030517496978\n",
            "Epoch: 270. Loss: 0.6071084904686039\n",
            "Epoch: 280. Loss: 0.6070212310529627\n",
            "Epoch: 290. Loss: 0.6069407125358756\n",
            "Epoch: 300. Loss: 0.6068664173350052\n",
            "Epoch: 310. Loss: 0.606797867633152\n",
            "Epoch: 320. Loss: 0.6067346221734219\n",
            "Epoch: 330. Loss: 0.6066762733833428\n",
            "Epoch: 340. Loss: 0.6066224447686632\n",
            "tensor(0.5759, dtype=torch.float64)\n",
            "2022-07-17 00:00:00\n",
            "Epoch: 0. Loss: 3.1363075463983963\n",
            "Epoch: 10. Loss: 2.2047348285922563\n",
            "Epoch: 20. Loss: 1.426717525506382\n",
            "Epoch: 30. Loss: 0.9135543471649029\n",
            "Epoch: 40. Loss: 0.7177101525228736\n",
            "Epoch: 50. Loss: 0.6642424882769348\n",
            "Epoch: 60. Loss: 0.6428862383001757\n",
            "Epoch: 70. Loss: 0.6317032959095782\n",
            "Epoch: 80. Loss: 0.6251017748616868\n",
            "Epoch: 90. Loss: 0.6209461859158245\n",
            "Epoch: 100. Loss: 0.6182495177738936\n",
            "Epoch: 110. Loss: 0.6164780216504053\n",
            "Epoch: 120. Loss: 0.6153087002076787\n",
            "Epoch: 130. Loss: 0.6145344017385475\n",
            "Epoch: 140. Loss: 0.6140193486403894\n",
            "Epoch: 150. Loss: 0.6136741636580229\n",
            "Epoch: 160. Loss: 0.6134401513606774\n",
            "Epoch: 170. Loss: 0.6132789207232973\n",
            "Epoch: 180. Loss: 0.6131654546163536\n",
            "Epoch: 190. Loss: 0.6130834946621196\n",
            "Epoch: 200. Loss: 0.6130224894273951\n",
            "Epoch: 210. Loss: 0.6129755908911619\n",
            "Epoch: 220. Loss: 0.612938347202745\n",
            "Epoch: 230. Loss: 0.6129078539178175\n",
            "Epoch: 240. Loss: 0.6128822049692929\n",
            "Epoch: 250. Loss: 0.612860138498206\n",
            "Epoch: 260. Loss: 0.6128408088226656\n",
            "Epoch: 270. Loss: 0.6128236397958468\n",
            "Epoch: 280. Loss: 0.6128082305534239\n",
            "Epoch: 290. Loss: 0.6127942949251994\n",
            "Epoch: 300. Loss: 0.6127816224528407\n",
            "Epoch: 310. Loss: 0.6127700532647499\n",
            "Epoch: 320. Loss: 0.612759461835769\n",
            "Epoch: 330. Loss: 0.6127497464445496\n",
            "Epoch: 340. Loss: 0.6127408222871379\n",
            "tensor(0.5857, dtype=torch.float64)\n",
            "2022-07-24 00:00:00\n",
            "Epoch: 0. Loss: 1.0018726629558623\n",
            "Epoch: 10. Loss: 0.7136984036770694\n",
            "Epoch: 20. Loss: 0.6700763878357677\n",
            "Epoch: 30. Loss: 0.6496779607948651\n",
            "Epoch: 40. Loss: 0.6385155529563332\n",
            "Epoch: 50. Loss: 0.6320563225675788\n",
            "Epoch: 60. Loss: 0.6281139732125617\n",
            "Epoch: 70. Loss: 0.6255965929355959\n",
            "Epoch: 80. Loss: 0.6239243133226123\n",
            "Epoch: 90. Loss: 0.6227706006127249\n",
            "Epoch: 100. Loss: 0.6219436899122213\n",
            "Epoch: 110. Loss: 0.621327797770287\n",
            "Epoch: 120. Loss: 0.6208516498961119\n",
            "Epoch: 130. Loss: 0.6204706775277635\n",
            "Epoch: 140. Loss: 0.6201565902878933\n",
            "Epoch: 150. Loss: 0.619891137174624\n",
            "Epoch: 160. Loss: 0.6196623210811142\n",
            "Epoch: 170. Loss: 0.6194620788513883\n",
            "Epoch: 180. Loss: 0.6192848480525313\n",
            "Epoch: 190. Loss: 0.6191266752591429\n",
            "Epoch: 200. Loss: 0.6189846574572274\n",
            "Epoch: 210. Loss: 0.6188565896303649\n",
            "Epoch: 220. Loss: 0.6187407406573475\n",
            "Epoch: 230. Loss: 0.6186357094695708\n",
            "Epoch: 240. Loss: 0.618540331667731\n",
            "Epoch: 250. Loss: 0.6184536180343531\n",
            "Epoch: 260. Loss: 0.6183747133316256\n",
            "Epoch: 270. Loss: 0.6183028680946169\n",
            "Epoch: 280. Loss: 0.6182374188248178\n",
            "Epoch: 290. Loss: 0.6181777736754367\n",
            "Epoch: 300. Loss: 0.6181234017785256\n",
            "Epoch: 310. Loss: 0.6180738250305461\n",
            "Epoch: 320. Loss: 0.6180286115739272\n",
            "Epoch: 330. Loss: 0.6179873704788665\n",
            "Epoch: 340. Loss: 0.617949747299267\n",
            "tensor(0.6447, dtype=torch.float64)\n",
            "2022-07-31 00:00:00\n",
            "Epoch: 0. Loss: 4.965781248934204\n",
            "Epoch: 10. Loss: 2.6688620938569176\n",
            "Epoch: 20. Loss: 1.4435974914255463\n",
            "Epoch: 30. Loss: 0.9547403767887005\n",
            "Epoch: 40. Loss: 0.7883277501670528\n",
            "Epoch: 50. Loss: 0.7120874584754204\n",
            "Epoch: 60. Loss: 0.6741460730365475\n",
            "Epoch: 70. Loss: 0.6550047007023257\n",
            "Epoch: 80. Loss: 0.6447182132983055\n",
            "Epoch: 90. Loss: 0.638667039469026\n",
            "Epoch: 100. Loss: 0.634783590368822\n",
            "Epoch: 110. Loss: 0.6321045795547379\n",
            "Epoch: 120. Loss: 0.6301443658894016\n",
            "Epoch: 130. Loss: 0.6286391230170207\n",
            "Epoch: 140. Loss: 0.6274371548636054\n",
            "Epoch: 150. Loss: 0.626447374367695\n",
            "Epoch: 160. Loss: 0.6256129906861635\n",
            "Epoch: 170. Loss: 0.6248972565539891\n",
            "Epoch: 180. Loss: 0.6242754519429325\n",
            "Epoch: 190. Loss: 0.6237302604743202\n",
            "Epoch: 200. Loss: 0.6232490503626938\n",
            "Epoch: 210. Loss: 0.622822246555564\n",
            "Epoch: 220. Loss: 0.6224423377084054\n",
            "Epoch: 230. Loss: 0.6221032574908865\n",
            "Epoch: 240. Loss: 0.6217999896081504\n",
            "Epoch: 250. Loss: 0.6215283084982557\n",
            "Epoch: 260. Loss: 0.6212846037033457\n",
            "Epoch: 270. Loss: 0.6210657568620531\n",
            "Epoch: 280. Loss: 0.620869052557488\n",
            "Epoch: 290. Loss: 0.6206921115243519\n",
            "Epoch: 300. Loss: 0.6205328390588141\n",
            "Epoch: 310. Loss: 0.6203893840921424\n",
            "Epoch: 320. Loss: 0.6202601059855493\n",
            "Epoch: 330. Loss: 0.6201435470905038\n",
            "Epoch: 340. Loss: 0.6200384097383115\n",
            "tensor(0.6507, dtype=torch.float64)\n",
            "2022-08-07 00:00:00\n",
            "Epoch: 0. Loss: 1.9816379941491065\n",
            "Epoch: 10. Loss: 1.0990856006058007\n",
            "Epoch: 20. Loss: 0.9024431857134589\n",
            "Epoch: 30. Loss: 0.8112561240761399\n",
            "Epoch: 40. Loss: 0.7534855290218236\n",
            "Epoch: 50. Loss: 0.7179142386551672\n",
            "Epoch: 60. Loss: 0.6968091301120426\n",
            "Epoch: 70. Loss: 0.6836018931515713\n",
            "Epoch: 80. Loss: 0.6742567343114375\n",
            "Epoch: 90. Loss: 0.6668592586307133\n",
            "Epoch: 100. Loss: 0.6606186407715289\n",
            "Epoch: 110. Loss: 0.6552106508514157\n",
            "Epoch: 120. Loss: 0.6504822793151234\n",
            "Epoch: 130. Loss: 0.6463406542667618\n",
            "Epoch: 140. Loss: 0.6427149802273918\n",
            "Epoch: 150. Loss: 0.6395442805722191\n",
            "Epoch: 160. Loss: 0.6367737233243235\n",
            "Epoch: 170. Loss: 0.6343536483348724\n",
            "Epoch: 180. Loss: 0.6322393418982869\n",
            "Epoch: 190. Loss: 0.6303909273515959\n",
            "Epoch: 200. Loss: 0.6287731879538823\n",
            "Epoch: 210. Loss: 0.6273552918349715\n",
            "Epoch: 220. Loss: 0.6261104392640777\n",
            "Epoch: 230. Loss: 0.6250154648109685\n",
            "Epoch: 240. Loss: 0.6240504249013082\n",
            "Epoch: 250. Loss: 0.6231981943646024\n",
            "Epoch: 260. Loss: 0.6224440879323366\n",
            "Epoch: 270. Loss: 0.6217755159652457\n",
            "Epoch: 280. Loss: 0.6211816785288955\n",
            "Epoch: 290. Loss: 0.6206532983049885\n",
            "Epoch: 300. Loss: 0.6201823904950188\n",
            "Epoch: 310. Loss: 0.6197620665453563\n",
            "Epoch: 320. Loss: 0.619386367912402\n",
            "Epoch: 330. Loss: 0.6190501259537614\n",
            "Epoch: 340. Loss: 0.618748844192631\n",
            "tensor(0.7401, dtype=torch.float64)\n",
            "2022-08-14 00:00:00\n",
            "Epoch: 0. Loss: 2.323391031484825\n",
            "Epoch: 10. Loss: 1.1356377196977308\n",
            "Epoch: 20. Loss: 0.7072430702994102\n",
            "Epoch: 30. Loss: 0.6558757934893014\n",
            "Epoch: 40. Loss: 0.6344162656672493\n",
            "Epoch: 50. Loss: 0.6258090854149077\n",
            "Epoch: 60. Loss: 0.6224034337029899\n",
            "Epoch: 70. Loss: 0.6207620344667129\n",
            "Epoch: 80. Loss: 0.6196964077141839\n",
            "Epoch: 90. Loss: 0.618845718851568\n",
            "Epoch: 100. Loss: 0.6181036195735833\n",
            "Epoch: 110. Loss: 0.6174362567859567\n",
            "Epoch: 120. Loss: 0.6168301388674926\n",
            "Epoch: 130. Loss: 0.6162777889058441\n",
            "Epoch: 140. Loss: 0.6157737984243602\n",
            "Epoch: 150. Loss: 0.615313691514966\n",
            "Epoch: 160. Loss: 0.614893556416392\n",
            "Epoch: 170. Loss: 0.6145098975021156\n",
            "Epoch: 180. Loss: 0.6141595583141923\n",
            "Epoch: 190. Loss: 0.6138396723568479\n",
            "Epoch: 200. Loss: 0.613547627444909\n",
            "Epoch: 210. Loss: 0.6132810379556854\n",
            "Epoch: 220. Loss: 0.6130377222202152\n",
            "Epoch: 230. Loss: 0.6128156834796326\n",
            "Epoch: 240. Loss: 0.6126130934302237\n",
            "Epoch: 250. Loss: 0.6124282777246515\n",
            "Epoch: 260. Loss: 0.6122597030090066\n",
            "Epoch: 270. Loss: 0.6121059652102968\n",
            "Epoch: 280. Loss: 0.6119657788758455\n",
            "Epoch: 290. Loss: 0.6118379674223088\n",
            "Epoch: 300. Loss: 0.6117214541885693\n",
            "Epoch: 310. Loss: 0.6116152542106813\n",
            "Epoch: 320. Loss: 0.6115184666528631\n",
            "Epoch: 330. Loss: 0.6114302678391996\n",
            "Epoch: 340. Loss: 0.6113499048381104\n",
            "tensor(0.6155, dtype=torch.float64)\n",
            "2022-08-21 00:00:00\n",
            "Epoch: 0. Loss: 4.1893544943508\n",
            "Epoch: 10. Loss: 1.9052393610206437\n",
            "Epoch: 20. Loss: 0.9903284545434611\n",
            "Epoch: 30. Loss: 0.6665504741603046\n",
            "Epoch: 40. Loss: 0.6340625746883857\n",
            "Epoch: 50. Loss: 0.6270101011823525\n",
            "Epoch: 60. Loss: 0.622809628255105\n",
            "Epoch: 70. Loss: 0.620068153162816\n",
            "Epoch: 80. Loss: 0.6182468881484728\n",
            "Epoch: 90. Loss: 0.6170290054923611\n",
            "Epoch: 100. Loss: 0.6162110505950975\n",
            "Epoch: 110. Loss: 0.6156585099887237\n",
            "Epoch: 120. Loss: 0.6152819302536852\n",
            "Epoch: 130. Loss: 0.6150219604414805\n",
            "Epoch: 140. Loss: 0.6148393839933647\n",
            "Epoch: 150. Loss: 0.6147083811231783\n",
            "Epoch: 160. Loss: 0.61461199063416\n",
            "Epoch: 170. Loss: 0.614539077567433\n",
            "Epoch: 180. Loss: 0.6144823230987702\n",
            "Epoch: 190. Loss: 0.6144369009189983\n",
            "Epoch: 200. Loss: 0.6143996101858276\n",
            "Epoch: 210. Loss: 0.6143683097806495\n",
            "Epoch: 220. Loss: 0.6143415502057892\n",
            "Epoch: 230. Loss: 0.6143183345240358\n",
            "Epoch: 240. Loss: 0.614297963255891\n",
            "Epoch: 250. Loss: 0.6142799337582829\n",
            "Epoch: 260. Loss: 0.6142638748903515\n",
            "Epoch: 270. Loss: 0.6142495045057763\n",
            "Epoch: 280. Loss: 0.6142366017016703\n",
            "Epoch: 290. Loss: 0.6142249886069063\n",
            "Epoch: 300. Loss: 0.6142145183414406\n",
            "Epoch: 310. Loss: 0.6142050669736894\n",
            "Epoch: 320. Loss: 0.6141965280748352\n",
            "Epoch: 330. Loss: 0.614188808966606\n",
            "Epoch: 340. Loss: 0.6141818280796849\n",
            "tensor(0.6173, dtype=torch.float64)\n",
            "2022-08-28 00:00:00\n",
            "Epoch: 0. Loss: 3.000829554125776\n",
            "Epoch: 10. Loss: 1.6609137321581797\n",
            "Epoch: 20. Loss: 1.3076356731279148\n",
            "Epoch: 30. Loss: 1.1095546161855883\n",
            "Epoch: 40. Loss: 0.9494780446927835\n",
            "Epoch: 50. Loss: 0.8196176480783534\n",
            "Epoch: 60. Loss: 0.7244305735932826\n",
            "Epoch: 70. Loss: 0.66530657723638\n",
            "Epoch: 80. Loss: 0.6356625723379387\n",
            "Epoch: 90. Loss: 0.6236737826271929\n",
            "Epoch: 100. Loss: 0.6194763206745596\n",
            "Epoch: 110. Loss: 0.6180226979138207\n",
            "Epoch: 120. Loss: 0.6174329151041449\n",
            "Epoch: 130. Loss: 0.6171172728455259\n",
            "Epoch: 140. Loss: 0.6169016230696456\n",
            "Epoch: 150. Loss: 0.6167326842320121\n",
            "Epoch: 160. Loss: 0.616591729542558\n",
            "Epoch: 170. Loss: 0.6164705325352553\n",
            "Epoch: 180. Loss: 0.6163645734840055\n",
            "Epoch: 190. Loss: 0.6162709528458553\n",
            "Epoch: 200. Loss: 0.6161876349910098\n",
            "Epoch: 210. Loss: 0.6161131095053843\n",
            "Epoch: 220. Loss: 0.6160462096644477\n",
            "Epoch: 230. Loss: 0.6159860038890866\n",
            "Epoch: 240. Loss: 0.6159317270834743\n",
            "Epoch: 250. Loss: 0.6158827358680372\n",
            "Epoch: 260. Loss: 0.6158384787680555\n",
            "Epoch: 270. Loss: 0.6157984759563505\n",
            "Epoch: 280. Loss: 0.6157623051713185\n",
            "Epoch: 290. Loss: 0.6157295916657756\n",
            "Epoch: 300. Loss: 0.6157000008162308\n",
            "Epoch: 310. Loss: 0.6156732325130975\n",
            "Epoch: 320. Loss: 0.6156490167649334\n",
            "Epoch: 330. Loss: 0.615627110149196\n",
            "Epoch: 340. Loss: 0.6156072928693863\n",
            "tensor(0.4723, dtype=torch.float64)\n",
            "2022-09-04 00:00:00\n",
            "Epoch: 0. Loss: 3.535050855127926\n",
            "Epoch: 10. Loss: 1.2396220946251653\n",
            "Epoch: 20. Loss: 0.784055190571045\n",
            "Epoch: 30. Loss: 0.7328148371471496\n",
            "Epoch: 40. Loss: 0.710636171201976\n",
            "Epoch: 50. Loss: 0.6978692470016996\n",
            "Epoch: 60. Loss: 0.6894334411149213\n",
            "Epoch: 70. Loss: 0.6829122863386288\n",
            "Epoch: 80. Loss: 0.6773095915199955\n",
            "Epoch: 90. Loss: 0.6722553782795936\n",
            "Epoch: 100. Loss: 0.6676132171976344\n",
            "Epoch: 110. Loss: 0.6633258503357291\n",
            "Epoch: 120. Loss: 0.6593617530979559\n",
            "Epoch: 130. Loss: 0.655697898918856\n",
            "Epoch: 140. Loss: 0.6523144068070125\n",
            "Epoch: 150. Loss: 0.6491929033656334\n",
            "Epoch: 160. Loss: 0.6463160184932975\n",
            "Epoch: 170. Loss: 0.6436672262590306\n",
            "Epoch: 180. Loss: 0.6412307929191835\n",
            "Epoch: 190. Loss: 0.63899175910107\n",
            "Epoch: 200. Loss: 0.63693593243871\n",
            "Epoch: 210. Loss: 0.6350498820591517\n",
            "Epoch: 220. Loss: 0.6333209313774694\n",
            "Epoch: 230. Loss: 0.6317371476599487\n",
            "Epoch: 240. Loss: 0.6302873277853587\n",
            "Epoch: 250. Loss: 0.6289609801797623\n",
            "Epoch: 260. Loss: 0.6277483032227277\n",
            "Epoch: 270. Loss: 0.6266401606057458\n",
            "Epoch: 280. Loss: 0.6256280542127122\n",
            "Epoch: 290. Loss: 0.6247040951176263\n",
            "Epoch: 300. Loss: 0.6238609732777921\n",
            "Epoch: 310. Loss: 0.623091926457564\n",
            "Epoch: 320. Loss: 0.6223907088594754\n",
            "Epoch: 330. Loss: 0.6217515598745218\n",
            "Epoch: 340. Loss: 0.6211691732969975\n",
            "tensor(0.4550, dtype=torch.float64)\n",
            "2022-09-11 00:00:00\n",
            "Epoch: 0. Loss: 1.7076458369031944\n",
            "Epoch: 10. Loss: 1.0542463863544016\n",
            "Epoch: 20. Loss: 0.8892758613266312\n",
            "Epoch: 30. Loss: 0.7983294869783002\n",
            "Epoch: 40. Loss: 0.7341811507824828\n",
            "Epoch: 50. Loss: 0.6909249918741058\n",
            "Epoch: 60. Loss: 0.6638180703743314\n",
            "Epoch: 70. Loss: 0.6476978791093094\n",
            "Epoch: 80. Loss: 0.6383148898941413\n",
            "Epoch: 90. Loss: 0.6328152049071366\n",
            "Epoch: 100. Loss: 0.6294972712519594\n",
            "Epoch: 110. Loss: 0.627405073494548\n",
            "Epoch: 120. Loss: 0.6260130330365309\n",
            "Epoch: 130. Loss: 0.6250322178038812\n",
            "Epoch: 140. Loss: 0.6243019112543675\n",
            "Epoch: 150. Loss: 0.6237310534275213\n",
            "Epoch: 160. Loss: 0.6232668395798567\n",
            "Epoch: 170. Loss: 0.6228777808906962\n",
            "Epoch: 180. Loss: 0.6225444623707077\n",
            "Epoch: 190. Loss: 0.6222544338387561\n",
            "Epoch: 200. Loss: 0.6219993474078741\n",
            "Epoch: 210. Loss: 0.6217733317414252\n",
            "Epoch: 220. Loss: 0.6215720555723683\n",
            "Epoch: 230. Loss: 0.6213921797921331\n",
            "Epoch: 240. Loss: 0.6212310310132859\n",
            "Epoch: 250. Loss: 0.6210864027647673\n",
            "Epoch: 260. Loss: 0.6209564311136542\n",
            "Epoch: 270. Loss: 0.6208395142781789\n",
            "Epoch: 280. Loss: 0.6207342586704077\n",
            "Epoch: 290. Loss: 0.6206394411425327\n",
            "Epoch: 300. Loss: 0.6205539814207152\n",
            "Epoch: 310. Loss: 0.6204769211433735\n",
            "Epoch: 320. Loss: 0.6204074073369018\n",
            "Epoch: 330. Loss: 0.6203446789926246\n",
            "Epoch: 340. Loss: 0.6202880559008632\n",
            "tensor(0.5938, dtype=torch.float64)\n",
            "2022-09-18 00:00:00\n",
            "Epoch: 0. Loss: 2.5544376869914673\n",
            "Epoch: 10. Loss: 1.2040036496045627\n",
            "Epoch: 20. Loss: 0.648679964075914\n",
            "Epoch: 30. Loss: 0.6236931223045222\n",
            "Epoch: 40. Loss: 0.6193927310752194\n",
            "Epoch: 50. Loss: 0.6171430572192816\n",
            "Epoch: 60. Loss: 0.6158769139021046\n",
            "Epoch: 70. Loss: 0.6151482963928114\n",
            "Epoch: 80. Loss: 0.6147235269931218\n",
            "Epoch: 90. Loss: 0.6144733375501581\n",
            "Epoch: 100. Loss: 0.6143244030115643\n",
            "Epoch: 110. Loss: 0.6142345886785155\n",
            "Epoch: 120. Loss: 0.6141794958605331\n",
            "Epoch: 130. Loss: 0.6141449212474192\n",
            "Epoch: 140. Loss: 0.6141225621464733\n",
            "Epoch: 150. Loss: 0.6141075470877372\n",
            "Epoch: 160. Loss: 0.6140970070368127\n",
            "Epoch: 170. Loss: 0.614089244961814\n",
            "Epoch: 180. Loss: 0.6140832515227728\n",
            "Epoch: 190. Loss: 0.6140784218671841\n",
            "Epoch: 200. Loss: 0.6140743896693066\n",
            "Epoch: 210. Loss: 0.6140709297011521\n",
            "Epoch: 220. Loss: 0.6140679005438519\n",
            "Epoch: 230. Loss: 0.6140652108480315\n",
            "Epoch: 240. Loss: 0.6140627994276453\n",
            "Epoch: 250. Loss: 0.6140606234890256\n",
            "Epoch: 260. Loss: 0.6140586516489687\n",
            "Epoch: 270. Loss: 0.6140568597749956\n",
            "Epoch: 280. Loss: 0.6140552284907709\n",
            "Epoch: 290. Loss: 0.6140537416656092\n",
            "Epoch: 300. Loss: 0.6140523854869105\n",
            "Epoch: 310. Loss: 0.6140511478790694\n",
            "Epoch: 320. Loss: 0.6140500181293727\n",
            "Epoch: 330. Loss: 0.6140489866384996\n",
            "Epoch: 340. Loss: 0.614048044746886\n",
            "tensor(0.5201, dtype=torch.float64)\n",
            "2022-09-25 00:00:00\n",
            "Epoch: 0. Loss: 4.157485336487993\n",
            "Epoch: 10. Loss: 1.6930765443897304\n",
            "Epoch: 20. Loss: 1.1925873122159585\n",
            "Epoch: 30. Loss: 0.9550484852510693\n",
            "Epoch: 40. Loss: 0.8287025290683753\n",
            "Epoch: 50. Loss: 0.7686126408147227\n",
            "Epoch: 60. Loss: 0.7403551707822341\n",
            "Epoch: 70. Loss: 0.7241247524626767\n",
            "Epoch: 80. Loss: 0.7122418294602444\n",
            "Epoch: 90. Loss: 0.7022419675117552\n",
            "Epoch: 100. Loss: 0.6933583196080264\n",
            "Epoch: 110. Loss: 0.6853419147324957\n",
            "Epoch: 120. Loss: 0.6780978051144622\n",
            "Epoch: 130. Loss: 0.6715730642958484\n",
            "Epoch: 140. Loss: 0.665722693178345\n",
            "Epoch: 150. Loss: 0.6605002103377797\n",
            "Epoch: 160. Loss: 0.655856206233088\n",
            "Epoch: 170. Loss: 0.6517393853660134\n",
            "Epoch: 180. Loss: 0.6480982029752532\n",
            "Epoch: 190. Loss: 0.6448824143388495\n",
            "Epoch: 200. Loss: 0.6420443022601029\n",
            "Epoch: 210. Loss: 0.6395395297370782\n",
            "Epoch: 220. Loss: 0.6373276425461998\n",
            "Epoch: 230. Loss: 0.635372278553428\n",
            "Epoch: 240. Loss: 0.633641150380076\n",
            "Epoch: 250. Loss: 0.6321058663053504\n",
            "Epoch: 260. Loss: 0.6307416465788623\n",
            "Epoch: 270. Loss: 0.6295269819329624\n",
            "Epoch: 280. Loss: 0.6284432701052236\n",
            "Epoch: 290. Loss: 0.6274744559144747\n",
            "Epoch: 300. Loss: 0.6266066916241092\n",
            "Epoch: 310. Loss: 0.6258280272902808\n",
            "Epoch: 320. Loss: 0.6251281355388812\n",
            "Epoch: 330. Loss: 0.6244980715581792\n",
            "Epoch: 340. Loss: 0.6239300667502328\n",
            "tensor(0.5610, dtype=torch.float64)\n",
            "2022-10-02 00:00:00\n",
            "Epoch: 0. Loss: 2.7726934116988273\n",
            "Epoch: 10. Loss: 1.6254548503558983\n",
            "Epoch: 20. Loss: 1.0872946489362485\n",
            "Epoch: 30. Loss: 0.8328952138535023\n",
            "Epoch: 40. Loss: 0.7139313753709279\n",
            "Epoch: 50. Loss: 0.6700384418622753\n",
            "Epoch: 60. Loss: 0.6522871122339324\n",
            "Epoch: 70. Loss: 0.6432060390379618\n",
            "Epoch: 80. Loss: 0.6377412389971209\n",
            "Epoch: 90. Loss: 0.6341551045209821\n",
            "Epoch: 100. Loss: 0.6316831069302101\n",
            "Epoch: 110. Loss: 0.6299141500745338\n",
            "Epoch: 120. Loss: 0.6286012459436526\n",
            "Epoch: 130. Loss: 0.6275893175153985\n",
            "Epoch: 140. Loss: 0.6267797812654755\n",
            "Epoch: 150. Loss: 0.6261098287397537\n",
            "Epoch: 160. Loss: 0.6255393624319404\n",
            "Epoch: 170. Loss: 0.6250426180391535\n",
            "Epoch: 180. Loss: 0.6246028194356747\n",
            "Epoch: 190. Loss: 0.624208804653713\n",
            "Epoch: 200. Loss: 0.6238529179266165\n",
            "Epoch: 210. Loss: 0.6235297035287141\n",
            "Epoch: 220. Loss: 0.6232351010489564\n",
            "Epoch: 230. Loss: 0.6229659510908516\n",
            "Epoch: 240. Loss: 0.6227196916524359\n",
            "Epoch: 250. Loss: 0.6224941709566681\n",
            "Epoch: 260. Loss: 0.6222875311206669\n",
            "Epoch: 270. Loss: 0.6220981348274673\n",
            "Epoch: 280. Loss: 0.6219245181009649\n",
            "Epoch: 290. Loss: 0.6217653589648502\n",
            "Epoch: 300. Loss: 0.621619455822978\n",
            "Epoch: 310. Loss: 0.6214857118508644\n",
            "Epoch: 320. Loss: 0.6213631231650777\n",
            "Epoch: 330. Loss: 0.6212507694244868\n",
            "Epoch: 340. Loss: 0.6211478060491342\n",
            "tensor(0.6344, dtype=torch.float64)\n",
            "2022-10-09 00:00:00\n",
            "Epoch: 0. Loss: 2.5651871548773664\n",
            "Epoch: 10. Loss: 1.1395337363760976\n",
            "Epoch: 20. Loss: 0.8569810160078675\n",
            "Epoch: 30. Loss: 0.7484175624597832\n",
            "Epoch: 40. Loss: 0.7045362270539641\n",
            "Epoch: 50. Loss: 0.6833543523268502\n",
            "Epoch: 60. Loss: 0.6708052776287633\n",
            "Epoch: 70. Loss: 0.662447962973794\n",
            "Epoch: 80. Loss: 0.6565387687572949\n",
            "Epoch: 90. Loss: 0.6522006038361369\n",
            "Epoch: 100. Loss: 0.6489106125005805\n",
            "Epoch: 110. Loss: 0.6463324559677034\n",
            "Epoch: 120. Loss: 0.6442451621301246\n",
            "Epoch: 130. Loss: 0.6425035204692612\n",
            "Epoch: 140. Loss: 0.6410124119289549\n",
            "Epoch: 150. Loss: 0.639709468400875\n",
            "Epoch: 160. Loss: 0.6385534409264937\n",
            "Epoch: 170. Loss: 0.6375165503017872\n",
            "Epoch: 180. Loss: 0.6365795557155438\n",
            "Epoch: 190. Loss: 0.635728627696432\n",
            "Epoch: 200. Loss: 0.634953389965109\n",
            "Epoch: 210. Loss: 0.6342457038807598\n",
            "Epoch: 220. Loss: 0.6335989174954366\n",
            "Epoch: 230. Loss: 0.6330074018782672\n",
            "Epoch: 240. Loss: 0.6324662634718226\n",
            "Epoch: 250. Loss: 0.6319711636160247\n",
            "Epoch: 260. Loss: 0.6315182030473737\n",
            "Epoch: 270. Loss: 0.6311038457365985\n",
            "Epoch: 280. Loss: 0.6307248665907703\n",
            "Epoch: 290. Loss: 0.6303783137294978\n",
            "Epoch: 300. Loss: 0.6300614797798586\n",
            "Epoch: 310. Loss: 0.6297718788769249\n",
            "Epoch: 320. Loss: 0.6295072273956706\n",
            "Epoch: 330. Loss: 0.6292654272358204\n",
            "Epoch: 340. Loss: 0.6290445509521257\n",
            "tensor(0.4288, dtype=torch.float64)\n",
            "2022-10-16 00:00:00\n",
            "Epoch: 0. Loss: 1.153794216070735\n",
            "Epoch: 10. Loss: 0.9287675183324874\n",
            "Epoch: 20. Loss: 0.8094014081548655\n",
            "Epoch: 30. Loss: 0.7361298032956476\n",
            "Epoch: 40. Loss: 0.6943305473175554\n",
            "Epoch: 50. Loss: 0.6713102899494849\n",
            "Epoch: 60. Loss: 0.65853937061897\n",
            "Epoch: 70. Loss: 0.6512508487665453\n",
            "Epoch: 80. Loss: 0.6469159229728981\n",
            "Epoch: 90. Loss: 0.6441981474196774\n",
            "Epoch: 100. Loss: 0.6423848859520447\n",
            "Epoch: 110. Loss: 0.641091591514515\n",
            "Epoch: 120. Loss: 0.6401080634021535\n",
            "Epoch: 130. Loss: 0.6393177610249006\n",
            "Epoch: 140. Loss: 0.6386549766467543\n",
            "Epoch: 150. Loss: 0.6380818538350861\n",
            "Epoch: 160. Loss: 0.6375759359305689\n",
            "Epoch: 170. Loss: 0.6371233648381026\n",
            "Epoch: 180. Loss: 0.6367151411298582\n",
            "Epoch: 190. Loss: 0.6363450557740528\n",
            "Epoch: 200. Loss: 0.6360085401963814\n",
            "Epoch: 210. Loss: 0.6357020231299048\n",
            "Epoch: 220. Loss: 0.6354225680763896\n",
            "Epoch: 230. Loss: 0.6351676665468019\n",
            "Epoch: 240. Loss: 0.6349351179873792\n",
            "Epoch: 250. Loss: 0.6347229580831576\n",
            "Epoch: 260. Loss: 0.6345294141809393\n",
            "Epoch: 270. Loss: 0.6343528760312219\n",
            "Epoch: 280. Loss: 0.6341918752975373\n",
            "Epoch: 290. Loss: 0.6340450701941645\n",
            "Epoch: 300. Loss: 0.6339112332278788\n",
            "Epoch: 310. Loss: 0.6337892409134193\n",
            "Epoch: 320. Loss: 0.6336780648265289\n",
            "Epoch: 330. Loss: 0.633576763631108\n",
            "Epoch: 340. Loss: 0.6334844758672831\n",
            "tensor(0.6474, dtype=torch.float64)\n",
            "2022-10-23 00:00:00\n",
            "Epoch: 0. Loss: 6.614278971873182\n",
            "Epoch: 10. Loss: 1.2453193304905956\n",
            "Epoch: 20. Loss: 0.7004814020995714\n",
            "Epoch: 30. Loss: 0.659344242856824\n",
            "Epoch: 40. Loss: 0.6477395435608717\n",
            "Epoch: 50. Loss: 0.6431755651784486\n",
            "Epoch: 60. Loss: 0.6409856624437854\n",
            "Epoch: 70. Loss: 0.6398371711523616\n",
            "Epoch: 80. Loss: 0.6392051497732504\n",
            "Epoch: 90. Loss: 0.6388429013016329\n",
            "Epoch: 100. Loss: 0.6386253648960576\n",
            "Epoch: 110. Loss: 0.6384870700977562\n",
            "Epoch: 120. Loss: 0.6383931790854727\n",
            "Epoch: 130. Loss: 0.6383249427116915\n",
            "Epoch: 140. Loss: 0.6382721584028558\n",
            "Epoch: 150. Loss: 0.6382291977857297\n",
            "Epoch: 160. Loss: 0.6381928958364429\n",
            "Epoch: 170. Loss: 0.6381614226302151\n",
            "Epoch: 180. Loss: 0.6381336776620089\n",
            "Epoch: 190. Loss: 0.638108963500202\n",
            "Epoch: 200. Loss: 0.6380868092970836\n",
            "Epoch: 210. Loss: 0.6380668749127468\n",
            "Epoch: 220. Loss: 0.6380488984984498\n",
            "Epoch: 230. Loss: 0.6380326675570436\n",
            "Epoch: 240. Loss: 0.6380180027155787\n",
            "Epoch: 250. Loss: 0.6380047484038349\n",
            "Epoch: 260. Loss: 0.6379927673039657\n",
            "Epoch: 270. Loss: 0.6379819368770142\n",
            "Epoch: 280. Loss: 0.6379721470493057\n",
            "Epoch: 290. Loss: 0.6379632985612393\n",
            "Epoch: 300. Loss: 0.6379553017074618\n",
            "Epoch: 310. Loss: 0.6379480753197212\n",
            "Epoch: 320. Loss: 0.6379415459097932\n",
            "Epoch: 330. Loss: 0.6379356469256562\n",
            "Epoch: 340. Loss: 0.6379303180935078\n",
            "tensor(0.4426, dtype=torch.float64)\n",
            "2022-10-30 00:00:00\n",
            "Epoch: 0. Loss: 3.279143570133878\n",
            "Epoch: 10. Loss: 0.7129168561643684\n",
            "Epoch: 20. Loss: 0.6596074567075407\n",
            "Epoch: 30. Loss: 0.6497526190735697\n",
            "Epoch: 40. Loss: 0.6458564784468258\n",
            "Epoch: 50. Loss: 0.644070074072845\n",
            "Epoch: 60. Loss: 0.6431974362192584\n",
            "Epoch: 70. Loss: 0.6427586925088458\n",
            "Epoch: 80. Loss: 0.6425345903245667\n",
            "Epoch: 90. Loss: 0.6424188104160372\n",
            "Epoch: 100. Loss: 0.6423583268830543\n",
            "Epoch: 110. Loss: 0.6423262952776697\n",
            "Epoch: 120. Loss: 0.6423090011797986\n",
            "Epoch: 130. Loss: 0.6422993940364051\n",
            "Epoch: 140. Loss: 0.6422938316017889\n",
            "Epoch: 150. Loss: 0.6422904242643973\n",
            "Epoch: 160. Loss: 0.6422881872725019\n",
            "Epoch: 170. Loss: 0.6422866045334683\n",
            "Epoch: 180. Loss: 0.642285403379237\n",
            "Epoch: 190. Loss: 0.642284437950952\n",
            "Epoch: 200. Loss: 0.6422836286903187\n",
            "Epoch: 210. Loss: 0.642282930883192\n",
            "Epoch: 220. Loss: 0.642282318274512\n",
            "Epoch: 230. Loss: 0.6422817745134406\n",
            "Epoch: 240. Loss: 0.6422812886719211\n",
            "Epoch: 250. Loss: 0.6422808528850876\n",
            "Epoch: 260. Loss: 0.6422804610986519\n",
            "Epoch: 270. Loss: 0.6422801083950401\n",
            "Epoch: 280. Loss: 0.6422797906230974\n",
            "Epoch: 290. Loss: 0.642279504187853\n",
            "Epoch: 300. Loss: 0.6422792459254117\n",
            "Epoch: 310. Loss: 0.6422790130237559\n",
            "Epoch: 320. Loss: 0.642278802968869\n",
            "Epoch: 330. Loss: 0.6422786135053118\n",
            "Epoch: 340. Loss: 0.6422784426054612\n",
            "tensor(0.5581, dtype=torch.float64)\n",
            "2022-11-06 00:00:00\n",
            "Epoch: 0. Loss: 1.439000275798428\n",
            "Epoch: 10. Loss: 0.7402025319468547\n",
            "Epoch: 20. Loss: 0.6964808804569876\n",
            "Epoch: 30. Loss: 0.6842948434515769\n",
            "Epoch: 40. Loss: 0.6779959419548266\n",
            "Epoch: 50. Loss: 0.6736675615885356\n",
            "Epoch: 60. Loss: 0.6702360588221566\n",
            "Epoch: 70. Loss: 0.6673784336289986\n",
            "Epoch: 80. Loss: 0.6649624245920731\n",
            "Epoch: 90. Loss: 0.6629094665025886\n",
            "Epoch: 100. Loss: 0.6611611775345201\n",
            "Epoch: 110. Loss: 0.6596701433727231\n",
            "Epoch: 120. Loss: 0.6583967007453964\n",
            "Epoch: 130. Loss: 0.6573073891256126\n",
            "Epoch: 140. Loss: 0.6563739484275144\n",
            "Epoch: 150. Loss: 0.6555725383574095\n",
            "Epoch: 160. Loss: 0.6548830781454978\n",
            "Epoch: 170. Loss: 0.6542886736220379\n",
            "Epoch: 180. Loss: 0.6537751194891375\n",
            "Epoch: 190. Loss: 0.653330470102597\n",
            "Epoch: 200. Loss: 0.6529446727725049\n",
            "Epoch: 210. Loss: 0.6526092571979597\n",
            "Epoch: 220. Loss: 0.6523170743463803\n",
            "Epoch: 230. Loss: 0.6520620781372429\n",
            "Epoch: 240. Loss: 0.6518391436557849\n",
            "Epoch: 250. Loss: 0.6516439161918444\n",
            "Epoch: 260. Loss: 0.6514726860659592\n",
            "Epoch: 270. Loss: 0.6513222848904484\n",
            "Epoch: 280. Loss: 0.6511899995670485\n",
            "Epoch: 290. Loss: 0.6510735009169665\n",
            "Epoch: 300. Loss: 0.6509707843618221\n",
            "Epoch: 310. Loss: 0.6508801205228666\n",
            "Epoch: 320. Loss: 0.6508000139849386\n",
            "Epoch: 330. Loss: 0.6507291687877571\n",
            "Epoch: 340. Loss: 0.6506664594683716\n",
            "tensor(0.5940, dtype=torch.float64)\n",
            "2022-11-13 00:00:00\n",
            "Epoch: 0. Loss: 2.8696261633684927\n",
            "Epoch: 10. Loss: 1.099964781120679\n",
            "Epoch: 20. Loss: 0.7359164102038304\n",
            "Epoch: 30. Loss: 0.685319848365345\n",
            "Epoch: 40. Loss: 0.6665962383355154\n",
            "Epoch: 50. Loss: 0.6588466355177123\n",
            "Epoch: 60. Loss: 0.6553572450335753\n",
            "Epoch: 70. Loss: 0.6536968968446399\n",
            "Epoch: 80. Loss: 0.6528802827889931\n",
            "Epoch: 90. Loss: 0.6524685984448935\n",
            "Epoch: 100. Loss: 0.6522557206726626\n",
            "Epoch: 110. Loss: 0.6521420020651482\n",
            "Epoch: 120. Loss: 0.6520784465949943\n",
            "Epoch: 130. Loss: 0.65204068689026\n",
            "Epoch: 140. Loss: 0.6520164942497519\n",
            "Epoch: 150. Loss: 0.6519996774952077\n",
            "Epoch: 160. Loss: 0.6519870684714887\n",
            "Epoch: 170. Loss: 0.6519770210231824\n",
            "Epoch: 180. Loss: 0.6519686594928721\n",
            "Epoch: 190. Loss: 0.6519615009537916\n",
            "Epoch: 200. Loss: 0.6519552646824234\n",
            "Epoch: 210. Loss: 0.6519497757478314\n",
            "Epoch: 220. Loss: 0.6519449160211875\n",
            "Epoch: 230. Loss: 0.6519405991224856\n",
            "Epoch: 240. Loss: 0.651936757472685\n",
            "Epoch: 250. Loss: 0.6519333354823664\n",
            "Epoch: 260. Loss: 0.6519302858629304\n",
            "Epoch: 270. Loss: 0.6519275675371662\n",
            "Epoch: 280. Loss: 0.651925144378531\n",
            "Epoch: 290. Loss: 0.6519229843884488\n",
            "Epoch: 300. Loss: 0.6519210591127959\n",
            "Epoch: 310. Loss: 0.6519193431956997\n",
            "Epoch: 320. Loss: 0.6519178140177534\n",
            "Epoch: 330. Loss: 0.6519164513905922\n",
            "Epoch: 340. Loss: 0.6519152372923791\n",
            "tensor(0.5326, dtype=torch.float64)\n",
            "2022-11-20 00:00:00\n",
            "Epoch: 0. Loss: 1.3663466304573215\n",
            "Epoch: 10. Loss: 0.8098331627647672\n",
            "Epoch: 20. Loss: 0.6884775177011994\n",
            "Epoch: 30. Loss: 0.6638782565260591\n",
            "Epoch: 40. Loss: 0.6584158752506585\n",
            "Epoch: 50. Loss: 0.6563740110923316\n",
            "Epoch: 60. Loss: 0.6551234021584549\n",
            "Epoch: 70. Loss: 0.6541542513210528\n",
            "Epoch: 80. Loss: 0.6533358507687624\n",
            "Epoch: 90. Loss: 0.6526199515740466\n",
            "Epoch: 100. Loss: 0.6519823389197368\n",
            "Epoch: 110. Loss: 0.6514084872055921\n",
            "Epoch: 120. Loss: 0.6508887609124114\n",
            "Epoch: 130. Loss: 0.6504162858541653\n",
            "Epoch: 140. Loss: 0.649985840028683\n",
            "Epoch: 150. Loss: 0.649593234501365\n",
            "Epoch: 160. Loss: 0.6492349576341325\n",
            "Epoch: 170. Loss: 0.6489079670337202\n",
            "Epoch: 180. Loss: 0.6486095656384437\n",
            "Epoch: 190. Loss: 0.6483373260247767\n",
            "Epoch: 200. Loss: 0.6480890424642287\n",
            "Epoch: 210. Loss: 0.6478626990388022\n",
            "Epoch: 220. Loss: 0.6476564471371232\n",
            "Epoch: 230. Loss: 0.6474685885198292\n",
            "Epoch: 240. Loss: 0.6472975617800484\n",
            "Epoch: 250. Loss: 0.6471419309581246\n",
            "Epoch: 260. Loss: 0.6470003756003206\n",
            "Epoch: 270. Loss: 0.6468716818518764\n",
            "Epoch: 280. Loss: 0.6467547343444886\n",
            "Epoch: 290. Loss: 0.6466485087337068\n",
            "Epoch: 300. Loss: 0.6465520647951942\n",
            "Epoch: 310. Loss: 0.6464645400187281\n",
            "Epoch: 320. Loss: 0.6463851436556021\n",
            "Epoch: 330. Loss: 0.6463131511846345\n",
            "Epoch: 340. Loss: 0.6462478991675712\n",
            "tensor(0.6024, dtype=torch.float64)\n",
            "2022-11-27 00:00:00\n",
            "Epoch: 0. Loss: 2.1408416258701006\n",
            "Epoch: 10. Loss: 0.8005337946271959\n",
            "Epoch: 20. Loss: 0.7135307001313874\n",
            "Epoch: 30. Loss: 0.6806622849826941\n",
            "Epoch: 40. Loss: 0.6639260083028148\n",
            "Epoch: 50. Loss: 0.654896495287107\n",
            "Epoch: 60. Loss: 0.6497086953760742\n",
            "Epoch: 70. Loss: 0.6466329908697421\n",
            "Epoch: 80. Loss: 0.6447995848625859\n",
            "Epoch: 90. Loss: 0.643712387424954\n",
            "Epoch: 100. Loss: 0.643072089429371\n",
            "Epoch: 110. Loss: 0.6426967438409794\n",
            "Epoch: 120. Loss: 0.6424768815027946\n",
            "Epoch: 130. Loss: 0.6423475302957982\n",
            "Epoch: 140. Loss: 0.6422705944247233\n",
            "Epoch: 150. Loss: 0.6422239509951666\n",
            "Epoch: 160. Loss: 0.6421948435904101\n",
            "Epoch: 170. Loss: 0.6421759511843568\n",
            "Epoch: 180. Loss: 0.6421630821136878\n",
            "Epoch: 190. Loss: 0.6421538360314613\n",
            "Epoch: 200. Loss: 0.6421468339193676\n",
            "Epoch: 210. Loss: 0.6421412777366499\n",
            "Epoch: 220. Loss: 0.6421366997375804\n",
            "Epoch: 230. Loss: 0.6421328202256428\n",
            "Epoch: 240. Loss: 0.6421294670047338\n",
            "Epoch: 250. Loss: 0.642126529807931\n",
            "Epoch: 260. Loss: 0.6421239345041337\n",
            "Epoch: 270. Loss: 0.642121628468195\n",
            "Epoch: 280. Loss: 0.6421195722460911\n",
            "Epoch: 290. Loss: 0.6421177347694574\n",
            "Epoch: 300. Loss: 0.642116090573298\n",
            "Epoch: 310. Loss: 0.6421146181469621\n",
            "Epoch: 320. Loss: 0.6421132989291441\n",
            "Epoch: 330. Loss: 0.6421121166716559\n",
            "Epoch: 340. Loss: 0.6421110570169399\n",
            "tensor(0.5725, dtype=torch.float64)\n",
            "2022-12-04 00:00:00\n",
            "Epoch: 0. Loss: 1.7517043537020769\n",
            "Epoch: 10. Loss: 0.8697124136530958\n",
            "Epoch: 20. Loss: 0.7377257446021573\n",
            "Epoch: 30. Loss: 0.6953206587463188\n",
            "Epoch: 40. Loss: 0.6726489261568525\n",
            "Epoch: 50. Loss: 0.6587439298320615\n",
            "Epoch: 60. Loss: 0.6498605321810753\n",
            "Epoch: 70. Loss: 0.6441912163012692\n",
            "Epoch: 80. Loss: 0.6405934849212092\n",
            "Epoch: 90. Loss: 0.6382920294146395\n",
            "Epoch: 100. Loss: 0.6367792483699617\n",
            "Epoch: 110. Loss: 0.6357409166644943\n",
            "Epoch: 120. Loss: 0.6349908214110677\n",
            "Epoch: 130. Loss: 0.6344212011630238\n",
            "Epoch: 140. Loss: 0.6339699223832043\n",
            "Epoch: 150. Loss: 0.6336006102712746\n",
            "Epoch: 160. Loss: 0.6332912700681107\n",
            "Epoch: 170. Loss: 0.6330279732527362\n",
            "Epoch: 180. Loss: 0.632801404290893\n",
            "Epoch: 190. Loss: 0.6326049737895042\n",
            "Epoch: 200. Loss: 0.6324337764791337\n",
            "Epoch: 210. Loss: 0.6322840031697309\n",
            "Epoch: 220. Loss: 0.6321525980424786\n",
            "Epoch: 230. Loss: 0.6320370504258332\n",
            "Epoch: 240. Loss: 0.6319352619778691\n",
            "Epoch: 250. Loss: 0.6318454574806256\n",
            "Epoch: 260. Loss: 0.6317661218557215\n",
            "Epoch: 270. Loss: 0.6316959536693231\n",
            "Epoch: 280. Loss: 0.6316338295168836\n",
            "Epoch: 290. Loss: 0.631578775935463\n",
            "Epoch: 300. Loss: 0.6315299467557765\n",
            "Epoch: 310. Loss: 0.631486604534503\n",
            "Epoch: 320. Loss: 0.6314481051413219\n",
            "Epoch: 330. Loss: 0.6314138848437456\n",
            "Epoch: 340. Loss: 0.6313834494060427\n",
            "tensor(0.7501, dtype=torch.float64)\n",
            "2022-12-11 00:00:00\n",
            "Epoch: 0. Loss: 2.836550234481907\n",
            "Epoch: 10. Loss: 1.2290371214581055\n",
            "Epoch: 20. Loss: 0.7220050086165442\n",
            "Epoch: 30. Loss: 0.6850153085476728\n",
            "Epoch: 40. Loss: 0.6723519196184575\n",
            "Epoch: 50. Loss: 0.665485551267528\n",
            "Epoch: 60. Loss: 0.6614290291273586\n",
            "Epoch: 70. Loss: 0.6588173879912781\n",
            "Epoch: 80. Loss: 0.656978569670021\n",
            "Epoch: 90. Loss: 0.6555742446533538\n",
            "Epoch: 100. Loss: 0.6544311917225398\n",
            "Epoch: 110. Loss: 0.6534587609940832\n",
            "Epoch: 120. Loss: 0.6526079786095211\n",
            "Epoch: 130. Loss: 0.6518511228310246\n",
            "Epoch: 140. Loss: 0.6511714483716748\n",
            "Epoch: 150. Loss: 0.6505579812783845\n",
            "Epoch: 160. Loss: 0.6500028658818042\n",
            "Epoch: 170. Loss: 0.649500003972849\n",
            "Epoch: 180. Loss: 0.649044351203196\n",
            "Epoch: 190. Loss: 0.648631548751785\n",
            "Epoch: 200. Loss: 0.6482577263570719\n",
            "Epoch: 210. Loss: 0.6479193930894126\n",
            "Epoch: 220. Loss: 0.6476133731691416\n",
            "Epoch: 230. Loss: 0.6473367650510743\n",
            "Epoch: 240. Loss: 0.6470869126887352\n",
            "Epoch: 250. Loss: 0.646861383352182\n",
            "Epoch: 260. Loss: 0.6466579491545098\n",
            "Epoch: 270. Loss: 0.6464745708523051\n",
            "Epoch: 280. Loss: 0.6463093831955996\n",
            "Epoch: 290. Loss: 0.6461606814572408\n",
            "Epoch: 300. Loss: 0.6460269089460897\n",
            "Epoch: 310. Loss: 0.6459066453928789\n",
            "Epoch: 320. Loss: 0.6457985961375124\n",
            "Epoch: 330. Loss: 0.6457015820650123\n",
            "Epoch: 340. Loss: 0.6456145302456608\n",
            "tensor(0.7359, dtype=torch.float64)\n",
            "2022-12-18 00:00:00\n",
            "Epoch: 0. Loss: 2.5941779951903596\n",
            "Epoch: 10. Loss: 1.308961589220552\n",
            "Epoch: 20. Loss: 0.8391691715419064\n",
            "Epoch: 30. Loss: 0.7453612760133544\n",
            "Epoch: 40. Loss: 0.7091698912113451\n",
            "Epoch: 50. Loss: 0.6904261043490373\n",
            "Epoch: 60. Loss: 0.6796440006284515\n",
            "Epoch: 70. Loss: 0.6729083788304822\n",
            "Epoch: 80. Loss: 0.6683495132216396\n",
            "Epoch: 90. Loss: 0.6650551398475653\n",
            "Epoch: 100. Loss: 0.662568005098062\n",
            "Epoch: 110. Loss: 0.6606407981043094\n",
            "Epoch: 120. Loss: 0.6591246540911309\n",
            "Epoch: 130. Loss: 0.6579204650031575\n",
            "Epoch: 140. Loss: 0.6569573711416195\n",
            "Epoch: 150. Loss: 0.6561825677984545\n",
            "Epoch: 160. Loss: 0.655555850301977\n",
            "Epoch: 170. Loss: 0.6550462686829881\n",
            "Epoch: 180. Loss: 0.6546298437192533\n",
            "Epoch: 190. Loss: 0.6542879060663229\n",
            "Epoch: 200. Loss: 0.6540058523491913\n",
            "Epoch: 210. Loss: 0.653772202998284\n",
            "Epoch: 220. Loss: 0.6535778861623446\n",
            "Epoch: 230. Loss: 0.6534156928565976\n",
            "Epoch: 240. Loss: 0.6532798619319059\n",
            "Epoch: 250. Loss: 0.653165763285034\n",
            "Epoch: 260. Loss: 0.6530696552932067\n",
            "Epoch: 270. Loss: 0.6529884983123412\n",
            "Epoch: 280. Loss: 0.6529198105757188\n",
            "Epoch: 290. Loss: 0.6528615562456761\n",
            "Epoch: 300. Loss: 0.652812057940787\n",
            "Epoch: 310. Loss: 0.6527699279816438\n",
            "Epoch: 320. Loss: 0.6527340140282584\n",
            "Epoch: 330. Loss: 0.6527033558452239\n",
            "Epoch: 340. Loss: 0.6526771507216876\n",
            "tensor(0.5400, dtype=torch.float64)\n",
            "2022-12-25 00:00:00\n",
            "Epoch: 0. Loss: 0.9826617863696745\n",
            "Epoch: 10. Loss: 0.7728080620629504\n",
            "Epoch: 20. Loss: 0.7149494813518242\n",
            "Epoch: 30. Loss: 0.6876364435376762\n",
            "Epoch: 40. Loss: 0.6740674715214879\n",
            "Epoch: 50. Loss: 0.667317125225849\n",
            "Epoch: 60. Loss: 0.6639275847533869\n",
            "Epoch: 70. Loss: 0.6621470148610298\n",
            "Epoch: 80. Loss: 0.6611230431321121\n",
            "Epoch: 90. Loss: 0.6604577344073442\n",
            "Epoch: 100. Loss: 0.6599702070815233\n",
            "Epoch: 110. Loss: 0.6595790014994718\n",
            "Epoch: 120. Loss: 0.6592470176220516\n",
            "Epoch: 130. Loss: 0.6589566753523145\n",
            "Epoch: 140. Loss: 0.6586989601074636\n",
            "Epoch: 150. Loss: 0.6584686556567009\n",
            "Epoch: 160. Loss: 0.6582622831250532\n",
            "Epoch: 170. Loss: 0.6580772102409227\n",
            "Epoch: 180. Loss: 0.6579112632782508\n",
            "Epoch: 190. Loss: 0.6577625542691539\n",
            "Epoch: 200. Loss: 0.6576294004507369\n",
            "Epoch: 210. Loss: 0.6575102834552895\n",
            "Epoch: 220. Loss: 0.6574038258785098\n",
            "Epoch: 230. Loss: 0.6573087756860304\n",
            "Epoch: 240. Loss: 0.657223994370228\n",
            "Epoch: 250. Loss: 0.6571484470862838\n",
            "Epoch: 260. Loss: 0.6570811939828821\n",
            "Epoch: 270. Loss: 0.6570213823649551\n",
            "Epoch: 280. Loss: 0.6569682395083698\n",
            "Epoch: 290. Loss: 0.656921066027076\n",
            "Epoch: 300. Loss: 0.6568792297302798\n",
            "Epoch: 310. Loss: 0.6568421599253929\n",
            "Epoch: 320. Loss: 0.6568093421323143\n",
            "Epoch: 330. Loss: 0.6567803131804814\n",
            "Epoch: 340. Loss: 0.6567546566640368\n",
            "tensor(0.5835, dtype=torch.float64)\n",
            "2023-01-01 00:00:00\n",
            "Epoch: 0. Loss: 1.4485010497786843\n",
            "Epoch: 10. Loss: 0.8783291656640628\n",
            "Epoch: 20. Loss: 0.7473960898535945\n",
            "Epoch: 30. Loss: 0.7014540365053101\n",
            "Epoch: 40. Loss: 0.6775894355843682\n",
            "Epoch: 50. Loss: 0.6657331414241748\n",
            "Epoch: 60. Loss: 0.6600590805588137\n",
            "Epoch: 70. Loss: 0.6573733528745715\n",
            "Epoch: 80. Loss: 0.6560690920999084\n",
            "Epoch: 90. Loss: 0.655387917655343\n",
            "Epoch: 100. Loss: 0.6549875563423728\n",
            "Epoch: 110. Loss: 0.6547176824815387\n",
            "Epoch: 120. Loss: 0.6545130209538381\n",
            "Epoch: 130. Loss: 0.6543450598261232\n",
            "Epoch: 140. Loss: 0.6542009649189885\n",
            "Epoch: 150. Loss: 0.6540745623084935\n",
            "Epoch: 160. Loss: 0.653962529270002\n",
            "Epoch: 170. Loss: 0.6538627953964251\n",
            "Epoch: 180. Loss: 0.6537738718907214\n",
            "Epoch: 190. Loss: 0.6536945682834001\n",
            "Epoch: 200. Loss: 0.6536238704117134\n",
            "Epoch: 210. Loss: 0.6535608855589086\n",
            "Epoch: 220. Loss: 0.6535048157120472\n",
            "Epoch: 230. Loss: 0.6534549427556688\n",
            "Epoch: 240. Loss: 0.6534106188854936\n",
            "Epoch: 250. Loss: 0.6533712594431379\n",
            "Epoch: 260. Loss: 0.653336336993957\n",
            "Epoch: 270. Loss: 0.6533053761425583\n",
            "Epoch: 280. Loss: 0.6532779488607257\n",
            "Epoch: 290. Loss: 0.6532536702202784\n",
            "Epoch: 300. Loss: 0.6532321944736463\n",
            "Epoch: 310. Loss: 0.6532132114469404\n",
            "Epoch: 320. Loss: 0.6531964432203285\n",
            "Epoch: 330. Loss: 0.6531816410753933\n",
            "Epoch: 340. Loss: 0.653168582691725\n",
            "tensor(0.6276, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "parameters = pd.DataFrame(columns=['a','b','prob'])\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_ml_dataset_for_date(date)\n",
        "  a,b = train_and_get_a_b(dataset[:-1])  \n",
        "  with torch.no_grad():\n",
        "    y_test = torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) / (torch.exp (torch.matmul(torch.from_numpy(dataset[-1][:-1]), a)) + torch.exp(torch.matmul(torch.from_numpy(dataset[-1][:-1]), b)))\n",
        "    print(y_test)\n",
        "    parameters.loc[date] = [a,b,y_test.numpy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 366,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWaPoTs-NqAF",
        "outputId": "27d46389-124d-47b7-c0ea-2c3f1a51008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "ks = np.arange(0, 1, 0.05)\n",
        "backtest_returns = pd.DataFrame(columns = ks)\n",
        "\n",
        "for date in daterange:  \n",
        "  print(date)\n",
        "  prob = parameters.loc[date]['prob']\n",
        "  rets = []\n",
        "  for k in ks:\n",
        "    weight = calculate_ml_portfolio_weights(prob, k)\n",
        "    rets.append(get_backtest_return(date, weight))\n",
        "  backtest_returns.loc[date] = rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 367,
      "metadata": {
        "id": "1QJznmoa50iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92074a9e-c217-4602-86e8-091d566bca95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00    0.001456\n",
            "0.05    0.001456\n",
            "0.10    0.001456\n",
            "0.15    0.001456\n",
            "0.20    0.001456\n",
            "0.25    0.001500\n",
            "0.30    0.001476\n",
            "0.35    0.001428\n",
            "0.40    0.001566\n",
            "0.45    0.001383\n",
            "0.50    0.001265\n",
            "0.55    0.000946\n",
            "0.60    0.000908\n",
            "0.65    0.000700\n",
            "0.70    0.000756\n",
            "0.75    0.000917\n",
            "0.80    0.000855\n",
            "0.85    0.000493\n",
            "0.90    0.000595\n",
            "0.95    0.000474\n",
            "dtype: float64\n",
            "0.00    0.000522\n",
            "0.05    0.000522\n",
            "0.10    0.000522\n",
            "0.15    0.000522\n",
            "0.20    0.000522\n",
            "0.25    0.000519\n",
            "0.30    0.000518\n",
            "0.35    0.000518\n",
            "0.40    0.000509\n",
            "0.45    0.000488\n",
            "0.50    0.000458\n",
            "0.55    0.000445\n",
            "0.60    0.000388\n",
            "0.65    0.000347\n",
            "0.70    0.000303\n",
            "0.75    0.000215\n",
            "0.80    0.000181\n",
            "0.85    0.000138\n",
            "0.90    0.000101\n",
            "0.95    0.000084\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "backtest_mean = backtest_returns.mean()\n",
        "backtest_var = backtest_returns.var()\n",
        "print(backtest_mean)\n",
        "print(backtest_var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 368,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Uy0n-yp8SPt5",
        "outputId": "c4f3e206-a2aa-45e7-91ad-bab69089f9ed"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "NoPoints = len(backtest_mean)\n",
        "\n",
        "colours = \"red\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for ML Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter( np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-aPJVsE3U1u"
      },
      "source": [
        "### MV Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_mv_dataset_for_date(date(2023,1,1))\n",
        "r, cov = get_sample_return_and_covariance(dataset)"
      ],
      "metadata": {
        "id": "HQdOY59TvGDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_a4N3uUyzyz",
        "outputId": "d2091c54-e9c8-4f33-ebd0-d6bb56599c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r)\n",
        "print(cov)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfgBvPuDzNXt",
        "outputId": "a5c099d7-813c-4434-fb60-9ceab245b832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "l_Close   -0.149595\n",
            "h_Close   -0.148826\n",
            "dtype: float64\n",
            "          l_Close   h_Close\n",
            "l_Close  0.010103  0.004556\n",
            "h_Close  0.004556  0.057944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_markovitz_weights(r, cov, m):\n",
        "  r = r.to_numpy()\n",
        "  cov = cov.to_numpy()\n",
        "  cov_inv = np.linalg.inv(cov)\n",
        "  ones = [1,1]\n",
        "  a = np.matmul(np.matmul(r, cov_inv), ones)\n",
        "  b = np.matmul(np.matmul(r, cov_inv), r)\n",
        "  c = np.matmul(np.matmul(ones, cov_inv), ones)\n",
        "  # print(r, cov, cov_inv,a,b,c)\n",
        "  numerator = b * np.matmul(cov_inv, ones) - a * np.matmul(cov_inv, r)  + m * (c * np.matmul(cov_inv, r) - a * np.matmul(cov_inv, ones))\n",
        "  denominator = b*c-pow(a,2)\n",
        "  x =  numerator / denominator\n",
        "  # print(numerator,denominator,x)\n",
        "  #/ (b*c-a^2) \n",
        "  return x"
      ],
      "metadata": {
        "id": "f5jaNAq8t8NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = calculate_markovitz_weights(r , cov , 0.01)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zcZVqWVvdki",
        "outputId": "53161a89-68f5-4b01-c6e0-76f0b228fa3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-206.6925489,  207.6925489])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adjust_weight_for_constraint(weight):\n",
        "  if weight < 0:\n",
        "    return 0\n",
        "  if weight > 1:\n",
        "    return 1\n",
        "  return weight"
      ],
      "metadata": {
        "id": "-mrSWBmGFGFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef55af4-56b7-4908-cb57-f5e0c796bcdd",
        "id": "r4OTRAPogrNe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:   0.000000\n"
          ]
        }
      ],
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef27242-a41c-4143-9c79-05a255f84b64",
        "id": "KX2KDSHGgrNe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n"
          ]
        }
      ],
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratios = np.arange(0,1.5, 0.1)\n",
        "ratios"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x9YHqcv5NDA",
        "outputId": "6d0dcb08-d4b1-48e7-ffb6-35d7a331434e"
      },
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
              "       1.3, 1.4])"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XevciqKG3aJ0",
        "outputId": "effded6b-38f6-4051-a091-5c6a7c4dd572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "# mv_backtest_weights = pd.DataFrame(columns = ratios)\n",
        "mv_backtest_returns = pd.DataFrame(columns = ratios)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  weights = []\n",
        "  rets = []\n",
        "\n",
        "  result1 = MaximizeReturns(r, 2)\n",
        "  maxReturnWeights = result1.x\n",
        "  maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "\n",
        "  result2 = MinimizeRisk(cov, 2)\n",
        "  minRiskWeights = result2.x\n",
        "  minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "\n",
        "  for ratio in ratios:\n",
        "    weights = maxReturnWeights * ratio + minRiskWeights * (1-ratio)\n",
        "    low_risk_weight = weights[0]\n",
        "    high_risk_weight = weights[1]\n",
        "    ret = get_mv_backtest_return(date, low_risk_weight, high_risk_weight)\n",
        "    # weights.append(high_risk_weight)\n",
        "    rets.append(ret)\n",
        "  # mv_backtest_weights.loc[date] = weights\n",
        "  mv_backtest_returns.loc[date] = rets\n",
        "  # print(weights)\n",
        "  # print(rets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_returns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "S5MJbCKQ4wot",
        "outputId": "5a0260b0-67d9-4d2f-878d-6bc513d6554d"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0.0       0.1       0.2       0.3       0.4       0.5  \\\n",
              "2003-09-21  0.007450  0.003885  0.000320 -0.003244 -0.006809 -0.010373   \n",
              "2003-09-28 -0.003550 -0.000114  0.003321  0.006757  0.010193  0.013629   \n",
              "2003-10-05  0.002961  0.003718  0.004475  0.005232  0.005990  0.006747   \n",
              "2003-10-12 -0.009141 -0.008657 -0.008172 -0.007688 -0.007204 -0.006719   \n",
              "2003-10-19  0.009441  0.007664  0.005887  0.004110  0.002333  0.000556   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.004699 -0.004229 -0.003760 -0.003290 -0.002820 -0.002350   \n",
              "2022-12-11  0.000178  0.000160  0.000142  0.000125  0.000107  0.000089   \n",
              "2022-12-18 -0.012158 -0.010942 -0.009726 -0.008510 -0.007295 -0.006079   \n",
              "2022-12-25 -0.004228 -0.003805 -0.003382 -0.002960 -0.002537 -0.002114   \n",
              "2023-01-01  0.014649  0.013184  0.011720  0.010255  0.008790  0.007325   \n",
              "\n",
              "                 0.6       0.7       0.8       0.9       1.0       1.1  \\\n",
              "2003-09-21 -0.013938 -0.017503 -0.021067 -0.024632 -0.028196 -0.031761   \n",
              "2003-09-28  0.017064  0.020500  0.023936  0.027372  0.030808  0.034243   \n",
              "2003-10-05  0.007504  0.008262  0.009019  0.009776  0.010533  0.011291   \n",
              "2003-10-12 -0.006235 -0.005751 -0.005266 -0.004782 -0.004298 -0.003813   \n",
              "2003-10-19 -0.001221 -0.002998 -0.004775 -0.006552 -0.008329 -0.010106   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2022-12-04 -0.001880 -0.001410 -0.000940 -0.000470 -0.000000  0.000470   \n",
              "2022-12-11  0.000071  0.000053  0.000036  0.000018  0.000000 -0.000018   \n",
              "2022-12-18 -0.004863 -0.003647 -0.002432 -0.001216 -0.000000  0.001216   \n",
              "2022-12-25 -0.001691 -0.001268 -0.000846 -0.000423 -0.000000  0.000423   \n",
              "2023-01-01  0.005860  0.004395  0.002930  0.001465  0.000000 -0.001465   \n",
              "\n",
              "                 1.2       1.3       1.4  \n",
              "2003-09-21 -0.035326 -0.038890 -0.042455  \n",
              "2003-09-28  0.037679  0.041115  0.044551  \n",
              "2003-10-05  0.012048  0.012805  0.013563  \n",
              "2003-10-12 -0.003329 -0.002845 -0.002360  \n",
              "2003-10-19 -0.011883 -0.013660 -0.015437  \n",
              "...              ...       ...       ...  \n",
              "2022-12-04  0.000940  0.001410  0.001880  \n",
              "2022-12-11 -0.000036 -0.000053 -0.000071  \n",
              "2022-12-18  0.002432  0.003647  0.004863  \n",
              "2022-12-25  0.000846  0.001268  0.001691  \n",
              "2023-01-01 -0.002930 -0.004395 -0.005860  \n",
              "\n",
              "[1007 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "      <th>1.1</th>\n",
              "      <th>1.2</th>\n",
              "      <th>1.3</th>\n",
              "      <th>1.4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2003-09-21</th>\n",
              "      <td>0.007450</td>\n",
              "      <td>0.003885</td>\n",
              "      <td>0.000320</td>\n",
              "      <td>-0.003244</td>\n",
              "      <td>-0.006809</td>\n",
              "      <td>-0.010373</td>\n",
              "      <td>-0.013938</td>\n",
              "      <td>-0.017503</td>\n",
              "      <td>-0.021067</td>\n",
              "      <td>-0.024632</td>\n",
              "      <td>-0.028196</td>\n",
              "      <td>-0.031761</td>\n",
              "      <td>-0.035326</td>\n",
              "      <td>-0.038890</td>\n",
              "      <td>-0.042455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-09-28</th>\n",
              "      <td>-0.003550</td>\n",
              "      <td>-0.000114</td>\n",
              "      <td>0.003321</td>\n",
              "      <td>0.006757</td>\n",
              "      <td>0.010193</td>\n",
              "      <td>0.013629</td>\n",
              "      <td>0.017064</td>\n",
              "      <td>0.020500</td>\n",
              "      <td>0.023936</td>\n",
              "      <td>0.027372</td>\n",
              "      <td>0.030808</td>\n",
              "      <td>0.034243</td>\n",
              "      <td>0.037679</td>\n",
              "      <td>0.041115</td>\n",
              "      <td>0.044551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-05</th>\n",
              "      <td>0.002961</td>\n",
              "      <td>0.003718</td>\n",
              "      <td>0.004475</td>\n",
              "      <td>0.005232</td>\n",
              "      <td>0.005990</td>\n",
              "      <td>0.006747</td>\n",
              "      <td>0.007504</td>\n",
              "      <td>0.008262</td>\n",
              "      <td>0.009019</td>\n",
              "      <td>0.009776</td>\n",
              "      <td>0.010533</td>\n",
              "      <td>0.011291</td>\n",
              "      <td>0.012048</td>\n",
              "      <td>0.012805</td>\n",
              "      <td>0.013563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-12</th>\n",
              "      <td>-0.009141</td>\n",
              "      <td>-0.008657</td>\n",
              "      <td>-0.008172</td>\n",
              "      <td>-0.007688</td>\n",
              "      <td>-0.007204</td>\n",
              "      <td>-0.006719</td>\n",
              "      <td>-0.006235</td>\n",
              "      <td>-0.005751</td>\n",
              "      <td>-0.005266</td>\n",
              "      <td>-0.004782</td>\n",
              "      <td>-0.004298</td>\n",
              "      <td>-0.003813</td>\n",
              "      <td>-0.003329</td>\n",
              "      <td>-0.002845</td>\n",
              "      <td>-0.002360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003-10-19</th>\n",
              "      <td>0.009441</td>\n",
              "      <td>0.007664</td>\n",
              "      <td>0.005887</td>\n",
              "      <td>0.004110</td>\n",
              "      <td>0.002333</td>\n",
              "      <td>0.000556</td>\n",
              "      <td>-0.001221</td>\n",
              "      <td>-0.002998</td>\n",
              "      <td>-0.004775</td>\n",
              "      <td>-0.006552</td>\n",
              "      <td>-0.008329</td>\n",
              "      <td>-0.010106</td>\n",
              "      <td>-0.011883</td>\n",
              "      <td>-0.013660</td>\n",
              "      <td>-0.015437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-04</th>\n",
              "      <td>-0.004699</td>\n",
              "      <td>-0.004229</td>\n",
              "      <td>-0.003760</td>\n",
              "      <td>-0.003290</td>\n",
              "      <td>-0.002820</td>\n",
              "      <td>-0.002350</td>\n",
              "      <td>-0.001880</td>\n",
              "      <td>-0.001410</td>\n",
              "      <td>-0.000940</td>\n",
              "      <td>-0.000470</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000470</td>\n",
              "      <td>0.000940</td>\n",
              "      <td>0.001410</td>\n",
              "      <td>0.001880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-11</th>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000018</td>\n",
              "      <td>-0.000036</td>\n",
              "      <td>-0.000053</td>\n",
              "      <td>-0.000071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-18</th>\n",
              "      <td>-0.012158</td>\n",
              "      <td>-0.010942</td>\n",
              "      <td>-0.009726</td>\n",
              "      <td>-0.008510</td>\n",
              "      <td>-0.007295</td>\n",
              "      <td>-0.006079</td>\n",
              "      <td>-0.004863</td>\n",
              "      <td>-0.003647</td>\n",
              "      <td>-0.002432</td>\n",
              "      <td>-0.001216</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.001216</td>\n",
              "      <td>0.002432</td>\n",
              "      <td>0.003647</td>\n",
              "      <td>0.004863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-25</th>\n",
              "      <td>-0.004228</td>\n",
              "      <td>-0.003805</td>\n",
              "      <td>-0.003382</td>\n",
              "      <td>-0.002960</td>\n",
              "      <td>-0.002537</td>\n",
              "      <td>-0.002114</td>\n",
              "      <td>-0.001691</td>\n",
              "      <td>-0.001268</td>\n",
              "      <td>-0.000846</td>\n",
              "      <td>-0.000423</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.000423</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>0.001268</td>\n",
              "      <td>0.001691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-01</th>\n",
              "      <td>0.014649</td>\n",
              "      <td>0.013184</td>\n",
              "      <td>0.011720</td>\n",
              "      <td>0.010255</td>\n",
              "      <td>0.008790</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>0.005860</td>\n",
              "      <td>0.004395</td>\n",
              "      <td>0.002930</td>\n",
              "      <td>0.001465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.001465</td>\n",
              "      <td>-0.002930</td>\n",
              "      <td>-0.004395</td>\n",
              "      <td>-0.005860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1007 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76f9537b-7a0b-4bc7-b1e0-01f2a56000be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mv_backtest_mean = mv_backtest_returns.mean()\n",
        "mv_backtest_var = mv_backtest_returns.var()\n",
        "print(mv_backtest_mean)\n",
        "print(np.sqrt(mv_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdE0BXHf4Rur",
        "outputId": "f3de2dc3-cbce-4608-c2dc-c033cbc73c1e"
      },
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    0.000548\n",
            "0.1    0.000555\n",
            "0.2    0.000562\n",
            "0.3    0.000569\n",
            "0.4    0.000575\n",
            "0.5    0.000582\n",
            "0.6    0.000589\n",
            "0.7    0.000596\n",
            "0.8    0.000603\n",
            "0.9    0.000609\n",
            "1.0    0.000616\n",
            "1.1    0.000623\n",
            "1.2    0.000630\n",
            "1.3    0.000637\n",
            "1.4    0.000643\n",
            "dtype: float64\n",
            "0.0    0.007145\n",
            "0.1    0.007141\n",
            "0.2    0.007447\n",
            "0.3    0.008027\n",
            "0.4    0.008827\n",
            "0.5    0.009793\n",
            "0.6    0.010882\n",
            "0.7    0.012059\n",
            "0.8    0.013302\n",
            "0.9    0.014594\n",
            "1.0    0.015923\n",
            "1.1    0.017280\n",
            "1.2    0.018659\n",
            "1.3    0.020056\n",
            "1.4    0.021467\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "fG9H0VuB4H_i",
        "outputId": "3f94ecdf-fa3d-47f7-e5bd-f4070b00af10"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Portfolio"
      ],
      "metadata": {
        "id": "JoA9UX-AIaTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thetas = np.arange(0, 1.05, 0.05)\n",
        "thetas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC0UiR1DIdtE",
        "outputId": "05efdea8-7096-434f-c2ac-1f1cb1065bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_returns = pd.DataFrame(columns = thetas)\n",
        "\n",
        "for date in daterange:\n",
        "  print(date)\n",
        "  dataset = get_mv_dataset_for_date(date)\n",
        "  r, cov = get_sample_return_and_covariance(dataset)\n",
        "  rets=[]\n",
        "  for theta in thetas:\n",
        "    ret = get_mv_backtest_return(date, 1-theta, theta)\n",
        "    rets.append(ret)\n",
        "  naive_backtest_returns.loc[date] = rets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhYsRgLjIZmr",
        "outputId": "752aeb7e-9973-4684-e5f8-05549f86777a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2003-09-21 00:00:00\n",
            "2003-09-28 00:00:00\n",
            "2003-10-05 00:00:00\n",
            "2003-10-12 00:00:00\n",
            "2003-10-19 00:00:00\n",
            "2003-10-26 00:00:00\n",
            "2003-11-02 00:00:00\n",
            "2003-11-09 00:00:00\n",
            "2003-11-16 00:00:00\n",
            "2003-11-23 00:00:00\n",
            "2003-11-30 00:00:00\n",
            "2003-12-07 00:00:00\n",
            "2003-12-14 00:00:00\n",
            "2003-12-21 00:00:00\n",
            "2003-12-28 00:00:00\n",
            "2004-01-04 00:00:00\n",
            "2004-01-11 00:00:00\n",
            "2004-01-18 00:00:00\n",
            "2004-01-25 00:00:00\n",
            "2004-02-01 00:00:00\n",
            "2004-02-08 00:00:00\n",
            "2004-02-15 00:00:00\n",
            "2004-02-22 00:00:00\n",
            "2004-02-29 00:00:00\n",
            "2004-03-07 00:00:00\n",
            "2004-03-14 00:00:00\n",
            "2004-03-21 00:00:00\n",
            "2004-03-28 00:00:00\n",
            "2004-04-04 00:00:00\n",
            "2004-04-11 00:00:00\n",
            "2004-04-18 00:00:00\n",
            "2004-04-25 00:00:00\n",
            "2004-05-02 00:00:00\n",
            "2004-05-09 00:00:00\n",
            "2004-05-16 00:00:00\n",
            "2004-05-23 00:00:00\n",
            "2004-05-30 00:00:00\n",
            "2004-06-06 00:00:00\n",
            "2004-06-13 00:00:00\n",
            "2004-06-20 00:00:00\n",
            "2004-06-27 00:00:00\n",
            "2004-07-04 00:00:00\n",
            "2004-07-11 00:00:00\n",
            "2004-07-18 00:00:00\n",
            "2004-07-25 00:00:00\n",
            "2004-08-01 00:00:00\n",
            "2004-08-08 00:00:00\n",
            "2004-08-15 00:00:00\n",
            "2004-08-22 00:00:00\n",
            "2004-08-29 00:00:00\n",
            "2004-09-05 00:00:00\n",
            "2004-09-12 00:00:00\n",
            "2004-09-19 00:00:00\n",
            "2004-09-26 00:00:00\n",
            "2004-10-03 00:00:00\n",
            "2004-10-10 00:00:00\n",
            "2004-10-17 00:00:00\n",
            "2004-10-24 00:00:00\n",
            "2004-10-31 00:00:00\n",
            "2004-11-07 00:00:00\n",
            "2004-11-14 00:00:00\n",
            "2004-11-21 00:00:00\n",
            "2004-11-28 00:00:00\n",
            "2004-12-05 00:00:00\n",
            "2004-12-12 00:00:00\n",
            "2004-12-19 00:00:00\n",
            "2004-12-26 00:00:00\n",
            "2005-01-02 00:00:00\n",
            "2005-01-09 00:00:00\n",
            "2005-01-16 00:00:00\n",
            "2005-01-23 00:00:00\n",
            "2005-01-30 00:00:00\n",
            "2005-02-06 00:00:00\n",
            "2005-02-13 00:00:00\n",
            "2005-02-20 00:00:00\n",
            "2005-02-27 00:00:00\n",
            "2005-03-06 00:00:00\n",
            "2005-03-13 00:00:00\n",
            "2005-03-20 00:00:00\n",
            "2005-03-27 00:00:00\n",
            "2005-04-03 00:00:00\n",
            "2005-04-10 00:00:00\n",
            "2005-04-17 00:00:00\n",
            "2005-04-24 00:00:00\n",
            "2005-05-01 00:00:00\n",
            "2005-05-08 00:00:00\n",
            "2005-05-15 00:00:00\n",
            "2005-05-22 00:00:00\n",
            "2005-05-29 00:00:00\n",
            "2005-06-05 00:00:00\n",
            "2005-06-12 00:00:00\n",
            "2005-06-19 00:00:00\n",
            "2005-06-26 00:00:00\n",
            "2005-07-03 00:00:00\n",
            "2005-07-10 00:00:00\n",
            "2005-07-17 00:00:00\n",
            "2005-07-24 00:00:00\n",
            "2005-07-31 00:00:00\n",
            "2005-08-07 00:00:00\n",
            "2005-08-14 00:00:00\n",
            "2005-08-21 00:00:00\n",
            "2005-08-28 00:00:00\n",
            "2005-09-04 00:00:00\n",
            "2005-09-11 00:00:00\n",
            "2005-09-18 00:00:00\n",
            "2005-09-25 00:00:00\n",
            "2005-10-02 00:00:00\n",
            "2005-10-09 00:00:00\n",
            "2005-10-16 00:00:00\n",
            "2005-10-23 00:00:00\n",
            "2005-10-30 00:00:00\n",
            "2005-11-06 00:00:00\n",
            "2005-11-13 00:00:00\n",
            "2005-11-20 00:00:00\n",
            "2005-11-27 00:00:00\n",
            "2005-12-04 00:00:00\n",
            "2005-12-11 00:00:00\n",
            "2005-12-18 00:00:00\n",
            "2005-12-25 00:00:00\n",
            "2006-01-01 00:00:00\n",
            "2006-01-08 00:00:00\n",
            "2006-01-15 00:00:00\n",
            "2006-01-22 00:00:00\n",
            "2006-01-29 00:00:00\n",
            "2006-02-05 00:00:00\n",
            "2006-02-12 00:00:00\n",
            "2006-02-19 00:00:00\n",
            "2006-02-26 00:00:00\n",
            "2006-03-05 00:00:00\n",
            "2006-03-12 00:00:00\n",
            "2006-03-19 00:00:00\n",
            "2006-03-26 00:00:00\n",
            "2006-04-02 00:00:00\n",
            "2006-04-09 00:00:00\n",
            "2006-04-16 00:00:00\n",
            "2006-04-23 00:00:00\n",
            "2006-04-30 00:00:00\n",
            "2006-05-07 00:00:00\n",
            "2006-05-14 00:00:00\n",
            "2006-05-21 00:00:00\n",
            "2006-05-28 00:00:00\n",
            "2006-06-04 00:00:00\n",
            "2006-06-11 00:00:00\n",
            "2006-06-18 00:00:00\n",
            "2006-06-25 00:00:00\n",
            "2006-07-02 00:00:00\n",
            "2006-07-09 00:00:00\n",
            "2006-07-16 00:00:00\n",
            "2006-07-23 00:00:00\n",
            "2006-07-30 00:00:00\n",
            "2006-08-06 00:00:00\n",
            "2006-08-13 00:00:00\n",
            "2006-08-20 00:00:00\n",
            "2006-08-27 00:00:00\n",
            "2006-09-03 00:00:00\n",
            "2006-09-10 00:00:00\n",
            "2006-09-17 00:00:00\n",
            "2006-09-24 00:00:00\n",
            "2006-10-01 00:00:00\n",
            "2006-10-08 00:00:00\n",
            "2006-10-15 00:00:00\n",
            "2006-10-22 00:00:00\n",
            "2006-10-29 00:00:00\n",
            "2006-11-05 00:00:00\n",
            "2006-11-12 00:00:00\n",
            "2006-11-19 00:00:00\n",
            "2006-11-26 00:00:00\n",
            "2006-12-03 00:00:00\n",
            "2006-12-10 00:00:00\n",
            "2006-12-17 00:00:00\n",
            "2006-12-24 00:00:00\n",
            "2006-12-31 00:00:00\n",
            "2007-01-07 00:00:00\n",
            "2007-01-14 00:00:00\n",
            "2007-01-21 00:00:00\n",
            "2007-01-28 00:00:00\n",
            "2007-02-04 00:00:00\n",
            "2007-02-11 00:00:00\n",
            "2007-02-18 00:00:00\n",
            "2007-02-25 00:00:00\n",
            "2007-03-04 00:00:00\n",
            "2007-03-11 00:00:00\n",
            "2007-03-18 00:00:00\n",
            "2007-03-25 00:00:00\n",
            "2007-04-01 00:00:00\n",
            "2007-04-08 00:00:00\n",
            "2007-04-15 00:00:00\n",
            "2007-04-22 00:00:00\n",
            "2007-04-29 00:00:00\n",
            "2007-05-06 00:00:00\n",
            "2007-05-13 00:00:00\n",
            "2007-05-20 00:00:00\n",
            "2007-05-27 00:00:00\n",
            "2007-06-03 00:00:00\n",
            "2007-06-10 00:00:00\n",
            "2007-06-17 00:00:00\n",
            "2007-06-24 00:00:00\n",
            "2007-07-01 00:00:00\n",
            "2007-07-08 00:00:00\n",
            "2007-07-15 00:00:00\n",
            "2007-07-22 00:00:00\n",
            "2007-07-29 00:00:00\n",
            "2007-08-05 00:00:00\n",
            "2007-08-12 00:00:00\n",
            "2007-08-19 00:00:00\n",
            "2007-08-26 00:00:00\n",
            "2007-09-02 00:00:00\n",
            "2007-09-09 00:00:00\n",
            "2007-09-16 00:00:00\n",
            "2007-09-23 00:00:00\n",
            "2007-09-30 00:00:00\n",
            "2007-10-07 00:00:00\n",
            "2007-10-14 00:00:00\n",
            "2007-10-21 00:00:00\n",
            "2007-10-28 00:00:00\n",
            "2007-11-04 00:00:00\n",
            "2007-11-11 00:00:00\n",
            "2007-11-18 00:00:00\n",
            "2007-11-25 00:00:00\n",
            "2007-12-02 00:00:00\n",
            "2007-12-09 00:00:00\n",
            "2007-12-16 00:00:00\n",
            "2007-12-23 00:00:00\n",
            "2007-12-30 00:00:00\n",
            "2008-01-06 00:00:00\n",
            "2008-01-13 00:00:00\n",
            "2008-01-20 00:00:00\n",
            "2008-01-27 00:00:00\n",
            "2008-02-03 00:00:00\n",
            "2008-02-10 00:00:00\n",
            "2008-02-17 00:00:00\n",
            "2008-02-24 00:00:00\n",
            "2008-03-02 00:00:00\n",
            "2008-03-09 00:00:00\n",
            "2008-03-16 00:00:00\n",
            "2008-03-23 00:00:00\n",
            "2008-03-30 00:00:00\n",
            "2008-04-06 00:00:00\n",
            "2008-04-13 00:00:00\n",
            "2008-04-20 00:00:00\n",
            "2008-04-27 00:00:00\n",
            "2008-05-04 00:00:00\n",
            "2008-05-11 00:00:00\n",
            "2008-05-18 00:00:00\n",
            "2008-05-25 00:00:00\n",
            "2008-06-01 00:00:00\n",
            "2008-06-08 00:00:00\n",
            "2008-06-15 00:00:00\n",
            "2008-06-22 00:00:00\n",
            "2008-06-29 00:00:00\n",
            "2008-07-06 00:00:00\n",
            "2008-07-13 00:00:00\n",
            "2008-07-20 00:00:00\n",
            "2008-07-27 00:00:00\n",
            "2008-08-03 00:00:00\n",
            "2008-08-10 00:00:00\n",
            "2008-08-17 00:00:00\n",
            "2008-08-24 00:00:00\n",
            "2008-08-31 00:00:00\n",
            "2008-09-07 00:00:00\n",
            "2008-09-14 00:00:00\n",
            "2008-09-21 00:00:00\n",
            "2008-09-28 00:00:00\n",
            "2008-10-05 00:00:00\n",
            "2008-10-12 00:00:00\n",
            "2008-10-19 00:00:00\n",
            "2008-10-26 00:00:00\n",
            "2008-11-02 00:00:00\n",
            "2008-11-09 00:00:00\n",
            "2008-11-16 00:00:00\n",
            "2008-11-23 00:00:00\n",
            "2008-11-30 00:00:00\n",
            "2008-12-07 00:00:00\n",
            "2008-12-14 00:00:00\n",
            "2008-12-21 00:00:00\n",
            "2008-12-28 00:00:00\n",
            "2009-01-04 00:00:00\n",
            "2009-01-11 00:00:00\n",
            "2009-01-18 00:00:00\n",
            "2009-01-25 00:00:00\n",
            "2009-02-01 00:00:00\n",
            "2009-02-08 00:00:00\n",
            "2009-02-15 00:00:00\n",
            "2009-02-22 00:00:00\n",
            "2009-03-01 00:00:00\n",
            "2009-03-08 00:00:00\n",
            "2009-03-15 00:00:00\n",
            "2009-03-22 00:00:00\n",
            "2009-03-29 00:00:00\n",
            "2009-04-05 00:00:00\n",
            "2009-04-12 00:00:00\n",
            "2009-04-19 00:00:00\n",
            "2009-04-26 00:00:00\n",
            "2009-05-03 00:00:00\n",
            "2009-05-10 00:00:00\n",
            "2009-05-17 00:00:00\n",
            "2009-05-24 00:00:00\n",
            "2009-05-31 00:00:00\n",
            "2009-06-07 00:00:00\n",
            "2009-06-14 00:00:00\n",
            "2009-06-21 00:00:00\n",
            "2009-06-28 00:00:00\n",
            "2009-07-05 00:00:00\n",
            "2009-07-12 00:00:00\n",
            "2009-07-19 00:00:00\n",
            "2009-07-26 00:00:00\n",
            "2009-08-02 00:00:00\n",
            "2009-08-09 00:00:00\n",
            "2009-08-16 00:00:00\n",
            "2009-08-23 00:00:00\n",
            "2009-08-30 00:00:00\n",
            "2009-09-06 00:00:00\n",
            "2009-09-13 00:00:00\n",
            "2009-09-20 00:00:00\n",
            "2009-09-27 00:00:00\n",
            "2009-10-04 00:00:00\n",
            "2009-10-11 00:00:00\n",
            "2009-10-18 00:00:00\n",
            "2009-10-25 00:00:00\n",
            "2009-11-01 00:00:00\n",
            "2009-11-08 00:00:00\n",
            "2009-11-15 00:00:00\n",
            "2009-11-22 00:00:00\n",
            "2009-11-29 00:00:00\n",
            "2009-12-06 00:00:00\n",
            "2009-12-13 00:00:00\n",
            "2009-12-20 00:00:00\n",
            "2009-12-27 00:00:00\n",
            "2010-01-03 00:00:00\n",
            "2010-01-10 00:00:00\n",
            "2010-01-17 00:00:00\n",
            "2010-01-24 00:00:00\n",
            "2010-01-31 00:00:00\n",
            "2010-02-07 00:00:00\n",
            "2010-02-14 00:00:00\n",
            "2010-02-21 00:00:00\n",
            "2010-02-28 00:00:00\n",
            "2010-03-07 00:00:00\n",
            "2010-03-14 00:00:00\n",
            "2010-03-21 00:00:00\n",
            "2010-03-28 00:00:00\n",
            "2010-04-04 00:00:00\n",
            "2010-04-11 00:00:00\n",
            "2010-04-18 00:00:00\n",
            "2010-04-25 00:00:00\n",
            "2010-05-02 00:00:00\n",
            "2010-05-09 00:00:00\n",
            "2010-05-16 00:00:00\n",
            "2010-05-23 00:00:00\n",
            "2010-05-30 00:00:00\n",
            "2010-06-06 00:00:00\n",
            "2010-06-13 00:00:00\n",
            "2010-06-20 00:00:00\n",
            "2010-06-27 00:00:00\n",
            "2010-07-04 00:00:00\n",
            "2010-07-11 00:00:00\n",
            "2010-07-18 00:00:00\n",
            "2010-07-25 00:00:00\n",
            "2010-08-01 00:00:00\n",
            "2010-08-08 00:00:00\n",
            "2010-08-15 00:00:00\n",
            "2010-08-22 00:00:00\n",
            "2010-08-29 00:00:00\n",
            "2010-09-05 00:00:00\n",
            "2010-09-12 00:00:00\n",
            "2010-09-19 00:00:00\n",
            "2010-09-26 00:00:00\n",
            "2010-10-03 00:00:00\n",
            "2010-10-10 00:00:00\n",
            "2010-10-17 00:00:00\n",
            "2010-10-24 00:00:00\n",
            "2010-10-31 00:00:00\n",
            "2010-11-07 00:00:00\n",
            "2010-11-14 00:00:00\n",
            "2010-11-21 00:00:00\n",
            "2010-11-28 00:00:00\n",
            "2010-12-05 00:00:00\n",
            "2010-12-12 00:00:00\n",
            "2010-12-19 00:00:00\n",
            "2010-12-26 00:00:00\n",
            "2011-01-02 00:00:00\n",
            "2011-01-09 00:00:00\n",
            "2011-01-16 00:00:00\n",
            "2011-01-23 00:00:00\n",
            "2011-01-30 00:00:00\n",
            "2011-02-06 00:00:00\n",
            "2011-02-13 00:00:00\n",
            "2011-02-20 00:00:00\n",
            "2011-02-27 00:00:00\n",
            "2011-03-06 00:00:00\n",
            "2011-03-13 00:00:00\n",
            "2011-03-20 00:00:00\n",
            "2011-03-27 00:00:00\n",
            "2011-04-03 00:00:00\n",
            "2011-04-10 00:00:00\n",
            "2011-04-17 00:00:00\n",
            "2011-04-24 00:00:00\n",
            "2011-05-01 00:00:00\n",
            "2011-05-08 00:00:00\n",
            "2011-05-15 00:00:00\n",
            "2011-05-22 00:00:00\n",
            "2011-05-29 00:00:00\n",
            "2011-06-05 00:00:00\n",
            "2011-06-12 00:00:00\n",
            "2011-06-19 00:00:00\n",
            "2011-06-26 00:00:00\n",
            "2011-07-03 00:00:00\n",
            "2011-07-10 00:00:00\n",
            "2011-07-17 00:00:00\n",
            "2011-07-24 00:00:00\n",
            "2011-07-31 00:00:00\n",
            "2011-08-07 00:00:00\n",
            "2011-08-14 00:00:00\n",
            "2011-08-21 00:00:00\n",
            "2011-08-28 00:00:00\n",
            "2011-09-04 00:00:00\n",
            "2011-09-11 00:00:00\n",
            "2011-09-18 00:00:00\n",
            "2011-09-25 00:00:00\n",
            "2011-10-02 00:00:00\n",
            "2011-10-09 00:00:00\n",
            "2011-10-16 00:00:00\n",
            "2011-10-23 00:00:00\n",
            "2011-10-30 00:00:00\n",
            "2011-11-06 00:00:00\n",
            "2011-11-13 00:00:00\n",
            "2011-11-20 00:00:00\n",
            "2011-11-27 00:00:00\n",
            "2011-12-04 00:00:00\n",
            "2011-12-11 00:00:00\n",
            "2011-12-18 00:00:00\n",
            "2011-12-25 00:00:00\n",
            "2012-01-01 00:00:00\n",
            "2012-01-08 00:00:00\n",
            "2012-01-15 00:00:00\n",
            "2012-01-22 00:00:00\n",
            "2012-01-29 00:00:00\n",
            "2012-02-05 00:00:00\n",
            "2012-02-12 00:00:00\n",
            "2012-02-19 00:00:00\n",
            "2012-02-26 00:00:00\n",
            "2012-03-04 00:00:00\n",
            "2012-03-11 00:00:00\n",
            "2012-03-18 00:00:00\n",
            "2012-03-25 00:00:00\n",
            "2012-04-01 00:00:00\n",
            "2012-04-08 00:00:00\n",
            "2012-04-15 00:00:00\n",
            "2012-04-22 00:00:00\n",
            "2012-04-29 00:00:00\n",
            "2012-05-06 00:00:00\n",
            "2012-05-13 00:00:00\n",
            "2012-05-20 00:00:00\n",
            "2012-05-27 00:00:00\n",
            "2012-06-03 00:00:00\n",
            "2012-06-10 00:00:00\n",
            "2012-06-17 00:00:00\n",
            "2012-06-24 00:00:00\n",
            "2012-07-01 00:00:00\n",
            "2012-07-08 00:00:00\n",
            "2012-07-15 00:00:00\n",
            "2012-07-22 00:00:00\n",
            "2012-07-29 00:00:00\n",
            "2012-08-05 00:00:00\n",
            "2012-08-12 00:00:00\n",
            "2012-08-19 00:00:00\n",
            "2012-08-26 00:00:00\n",
            "2012-09-02 00:00:00\n",
            "2012-09-09 00:00:00\n",
            "2012-09-16 00:00:00\n",
            "2012-09-23 00:00:00\n",
            "2012-09-30 00:00:00\n",
            "2012-10-07 00:00:00\n",
            "2012-10-14 00:00:00\n",
            "2012-10-21 00:00:00\n",
            "2012-10-28 00:00:00\n",
            "2012-11-04 00:00:00\n",
            "2012-11-11 00:00:00\n",
            "2012-11-18 00:00:00\n",
            "2012-11-25 00:00:00\n",
            "2012-12-02 00:00:00\n",
            "2012-12-09 00:00:00\n",
            "2012-12-16 00:00:00\n",
            "2012-12-23 00:00:00\n",
            "2012-12-30 00:00:00\n",
            "2013-01-06 00:00:00\n",
            "2013-01-13 00:00:00\n",
            "2013-01-20 00:00:00\n",
            "2013-01-27 00:00:00\n",
            "2013-02-03 00:00:00\n",
            "2013-02-10 00:00:00\n",
            "2013-02-17 00:00:00\n",
            "2013-02-24 00:00:00\n",
            "2013-03-03 00:00:00\n",
            "2013-03-10 00:00:00\n",
            "2013-03-17 00:00:00\n",
            "2013-03-24 00:00:00\n",
            "2013-03-31 00:00:00\n",
            "2013-04-07 00:00:00\n",
            "2013-04-14 00:00:00\n",
            "2013-04-21 00:00:00\n",
            "2013-04-28 00:00:00\n",
            "2013-05-05 00:00:00\n",
            "2013-05-12 00:00:00\n",
            "2013-05-19 00:00:00\n",
            "2013-05-26 00:00:00\n",
            "2013-06-02 00:00:00\n",
            "2013-06-09 00:00:00\n",
            "2013-06-16 00:00:00\n",
            "2013-06-23 00:00:00\n",
            "2013-06-30 00:00:00\n",
            "2013-07-07 00:00:00\n",
            "2013-07-14 00:00:00\n",
            "2013-07-21 00:00:00\n",
            "2013-07-28 00:00:00\n",
            "2013-08-04 00:00:00\n",
            "2013-08-11 00:00:00\n",
            "2013-08-18 00:00:00\n",
            "2013-08-25 00:00:00\n",
            "2013-09-01 00:00:00\n",
            "2013-09-08 00:00:00\n",
            "2013-09-15 00:00:00\n",
            "2013-09-22 00:00:00\n",
            "2013-09-29 00:00:00\n",
            "2013-10-06 00:00:00\n",
            "2013-10-13 00:00:00\n",
            "2013-10-20 00:00:00\n",
            "2013-10-27 00:00:00\n",
            "2013-11-03 00:00:00\n",
            "2013-11-10 00:00:00\n",
            "2013-11-17 00:00:00\n",
            "2013-11-24 00:00:00\n",
            "2013-12-01 00:00:00\n",
            "2013-12-08 00:00:00\n",
            "2013-12-15 00:00:00\n",
            "2013-12-22 00:00:00\n",
            "2013-12-29 00:00:00\n",
            "2014-01-05 00:00:00\n",
            "2014-01-12 00:00:00\n",
            "2014-01-19 00:00:00\n",
            "2014-01-26 00:00:00\n",
            "2014-02-02 00:00:00\n",
            "2014-02-09 00:00:00\n",
            "2014-02-16 00:00:00\n",
            "2014-02-23 00:00:00\n",
            "2014-03-02 00:00:00\n",
            "2014-03-09 00:00:00\n",
            "2014-03-16 00:00:00\n",
            "2014-03-23 00:00:00\n",
            "2014-03-30 00:00:00\n",
            "2014-04-06 00:00:00\n",
            "2014-04-13 00:00:00\n",
            "2014-04-20 00:00:00\n",
            "2014-04-27 00:00:00\n",
            "2014-05-04 00:00:00\n",
            "2014-05-11 00:00:00\n",
            "2014-05-18 00:00:00\n",
            "2014-05-25 00:00:00\n",
            "2014-06-01 00:00:00\n",
            "2014-06-08 00:00:00\n",
            "2014-06-15 00:00:00\n",
            "2014-06-22 00:00:00\n",
            "2014-06-29 00:00:00\n",
            "2014-07-06 00:00:00\n",
            "2014-07-13 00:00:00\n",
            "2014-07-20 00:00:00\n",
            "2014-07-27 00:00:00\n",
            "2014-08-03 00:00:00\n",
            "2014-08-10 00:00:00\n",
            "2014-08-17 00:00:00\n",
            "2014-08-24 00:00:00\n",
            "2014-08-31 00:00:00\n",
            "2014-09-07 00:00:00\n",
            "2014-09-14 00:00:00\n",
            "2014-09-21 00:00:00\n",
            "2014-09-28 00:00:00\n",
            "2014-10-05 00:00:00\n",
            "2014-10-12 00:00:00\n",
            "2014-10-19 00:00:00\n",
            "2014-10-26 00:00:00\n",
            "2014-11-02 00:00:00\n",
            "2014-11-09 00:00:00\n",
            "2014-11-16 00:00:00\n",
            "2014-11-23 00:00:00\n",
            "2014-11-30 00:00:00\n",
            "2014-12-07 00:00:00\n",
            "2014-12-14 00:00:00\n",
            "2014-12-21 00:00:00\n",
            "2014-12-28 00:00:00\n",
            "2015-01-04 00:00:00\n",
            "2015-01-11 00:00:00\n",
            "2015-01-18 00:00:00\n",
            "2015-01-25 00:00:00\n",
            "2015-02-01 00:00:00\n",
            "2015-02-08 00:00:00\n",
            "2015-02-15 00:00:00\n",
            "2015-02-22 00:00:00\n",
            "2015-03-01 00:00:00\n",
            "2015-03-08 00:00:00\n",
            "2015-03-15 00:00:00\n",
            "2015-03-22 00:00:00\n",
            "2015-03-29 00:00:00\n",
            "2015-04-05 00:00:00\n",
            "2015-04-12 00:00:00\n",
            "2015-04-19 00:00:00\n",
            "2015-04-26 00:00:00\n",
            "2015-05-03 00:00:00\n",
            "2015-05-10 00:00:00\n",
            "2015-05-17 00:00:00\n",
            "2015-05-24 00:00:00\n",
            "2015-05-31 00:00:00\n",
            "2015-06-07 00:00:00\n",
            "2015-06-14 00:00:00\n",
            "2015-06-21 00:00:00\n",
            "2015-06-28 00:00:00\n",
            "2015-07-05 00:00:00\n",
            "2015-07-12 00:00:00\n",
            "2015-07-19 00:00:00\n",
            "2015-07-26 00:00:00\n",
            "2015-08-02 00:00:00\n",
            "2015-08-09 00:00:00\n",
            "2015-08-16 00:00:00\n",
            "2015-08-23 00:00:00\n",
            "2015-08-30 00:00:00\n",
            "2015-09-06 00:00:00\n",
            "2015-09-13 00:00:00\n",
            "2015-09-20 00:00:00\n",
            "2015-09-27 00:00:00\n",
            "2015-10-04 00:00:00\n",
            "2015-10-11 00:00:00\n",
            "2015-10-18 00:00:00\n",
            "2015-10-25 00:00:00\n",
            "2015-11-01 00:00:00\n",
            "2015-11-08 00:00:00\n",
            "2015-11-15 00:00:00\n",
            "2015-11-22 00:00:00\n",
            "2015-11-29 00:00:00\n",
            "2015-12-06 00:00:00\n",
            "2015-12-13 00:00:00\n",
            "2015-12-20 00:00:00\n",
            "2015-12-27 00:00:00\n",
            "2016-01-03 00:00:00\n",
            "2016-01-10 00:00:00\n",
            "2016-01-17 00:00:00\n",
            "2016-01-24 00:00:00\n",
            "2016-01-31 00:00:00\n",
            "2016-02-07 00:00:00\n",
            "2016-02-14 00:00:00\n",
            "2016-02-21 00:00:00\n",
            "2016-02-28 00:00:00\n",
            "2016-03-06 00:00:00\n",
            "2016-03-13 00:00:00\n",
            "2016-03-20 00:00:00\n",
            "2016-03-27 00:00:00\n",
            "2016-04-03 00:00:00\n",
            "2016-04-10 00:00:00\n",
            "2016-04-17 00:00:00\n",
            "2016-04-24 00:00:00\n",
            "2016-05-01 00:00:00\n",
            "2016-05-08 00:00:00\n",
            "2016-05-15 00:00:00\n",
            "2016-05-22 00:00:00\n",
            "2016-05-29 00:00:00\n",
            "2016-06-05 00:00:00\n",
            "2016-06-12 00:00:00\n",
            "2016-06-19 00:00:00\n",
            "2016-06-26 00:00:00\n",
            "2016-07-03 00:00:00\n",
            "2016-07-10 00:00:00\n",
            "2016-07-17 00:00:00\n",
            "2016-07-24 00:00:00\n",
            "2016-07-31 00:00:00\n",
            "2016-08-07 00:00:00\n",
            "2016-08-14 00:00:00\n",
            "2016-08-21 00:00:00\n",
            "2016-08-28 00:00:00\n",
            "2016-09-04 00:00:00\n",
            "2016-09-11 00:00:00\n",
            "2016-09-18 00:00:00\n",
            "2016-09-25 00:00:00\n",
            "2016-10-02 00:00:00\n",
            "2016-10-09 00:00:00\n",
            "2016-10-16 00:00:00\n",
            "2016-10-23 00:00:00\n",
            "2016-10-30 00:00:00\n",
            "2016-11-06 00:00:00\n",
            "2016-11-13 00:00:00\n",
            "2016-11-20 00:00:00\n",
            "2016-11-27 00:00:00\n",
            "2016-12-04 00:00:00\n",
            "2016-12-11 00:00:00\n",
            "2016-12-18 00:00:00\n",
            "2016-12-25 00:00:00\n",
            "2017-01-01 00:00:00\n",
            "2017-01-08 00:00:00\n",
            "2017-01-15 00:00:00\n",
            "2017-01-22 00:00:00\n",
            "2017-01-29 00:00:00\n",
            "2017-02-05 00:00:00\n",
            "2017-02-12 00:00:00\n",
            "2017-02-19 00:00:00\n",
            "2017-02-26 00:00:00\n",
            "2017-03-05 00:00:00\n",
            "2017-03-12 00:00:00\n",
            "2017-03-19 00:00:00\n",
            "2017-03-26 00:00:00\n",
            "2017-04-02 00:00:00\n",
            "2017-04-09 00:00:00\n",
            "2017-04-16 00:00:00\n",
            "2017-04-23 00:00:00\n",
            "2017-04-30 00:00:00\n",
            "2017-05-07 00:00:00\n",
            "2017-05-14 00:00:00\n",
            "2017-05-21 00:00:00\n",
            "2017-05-28 00:00:00\n",
            "2017-06-04 00:00:00\n",
            "2017-06-11 00:00:00\n",
            "2017-06-18 00:00:00\n",
            "2017-06-25 00:00:00\n",
            "2017-07-02 00:00:00\n",
            "2017-07-09 00:00:00\n",
            "2017-07-16 00:00:00\n",
            "2017-07-23 00:00:00\n",
            "2017-07-30 00:00:00\n",
            "2017-08-06 00:00:00\n",
            "2017-08-13 00:00:00\n",
            "2017-08-20 00:00:00\n",
            "2017-08-27 00:00:00\n",
            "2017-09-03 00:00:00\n",
            "2017-09-10 00:00:00\n",
            "2017-09-17 00:00:00\n",
            "2017-09-24 00:00:00\n",
            "2017-10-01 00:00:00\n",
            "2017-10-08 00:00:00\n",
            "2017-10-15 00:00:00\n",
            "2017-10-22 00:00:00\n",
            "2017-10-29 00:00:00\n",
            "2017-11-05 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-19 00:00:00\n",
            "2017-11-26 00:00:00\n",
            "2017-12-03 00:00:00\n",
            "2017-12-10 00:00:00\n",
            "2017-12-17 00:00:00\n",
            "2017-12-24 00:00:00\n",
            "2017-12-31 00:00:00\n",
            "2018-01-07 00:00:00\n",
            "2018-01-14 00:00:00\n",
            "2018-01-21 00:00:00\n",
            "2018-01-28 00:00:00\n",
            "2018-02-04 00:00:00\n",
            "2018-02-11 00:00:00\n",
            "2018-02-18 00:00:00\n",
            "2018-02-25 00:00:00\n",
            "2018-03-04 00:00:00\n",
            "2018-03-11 00:00:00\n",
            "2018-03-18 00:00:00\n",
            "2018-03-25 00:00:00\n",
            "2018-04-01 00:00:00\n",
            "2018-04-08 00:00:00\n",
            "2018-04-15 00:00:00\n",
            "2018-04-22 00:00:00\n",
            "2018-04-29 00:00:00\n",
            "2018-05-06 00:00:00\n",
            "2018-05-13 00:00:00\n",
            "2018-05-20 00:00:00\n",
            "2018-05-27 00:00:00\n",
            "2018-06-03 00:00:00\n",
            "2018-06-10 00:00:00\n",
            "2018-06-17 00:00:00\n",
            "2018-06-24 00:00:00\n",
            "2018-07-01 00:00:00\n",
            "2018-07-08 00:00:00\n",
            "2018-07-15 00:00:00\n",
            "2018-07-22 00:00:00\n",
            "2018-07-29 00:00:00\n",
            "2018-08-05 00:00:00\n",
            "2018-08-12 00:00:00\n",
            "2018-08-19 00:00:00\n",
            "2018-08-26 00:00:00\n",
            "2018-09-02 00:00:00\n",
            "2018-09-09 00:00:00\n",
            "2018-09-16 00:00:00\n",
            "2018-09-23 00:00:00\n",
            "2018-09-30 00:00:00\n",
            "2018-10-07 00:00:00\n",
            "2018-10-14 00:00:00\n",
            "2018-10-21 00:00:00\n",
            "2018-10-28 00:00:00\n",
            "2018-11-04 00:00:00\n",
            "2018-11-11 00:00:00\n",
            "2018-11-18 00:00:00\n",
            "2018-11-25 00:00:00\n",
            "2018-12-02 00:00:00\n",
            "2018-12-09 00:00:00\n",
            "2018-12-16 00:00:00\n",
            "2018-12-23 00:00:00\n",
            "2018-12-30 00:00:00\n",
            "2019-01-06 00:00:00\n",
            "2019-01-13 00:00:00\n",
            "2019-01-20 00:00:00\n",
            "2019-01-27 00:00:00\n",
            "2019-02-03 00:00:00\n",
            "2019-02-10 00:00:00\n",
            "2019-02-17 00:00:00\n",
            "2019-02-24 00:00:00\n",
            "2019-03-03 00:00:00\n",
            "2019-03-10 00:00:00\n",
            "2019-03-17 00:00:00\n",
            "2019-03-24 00:00:00\n",
            "2019-03-31 00:00:00\n",
            "2019-04-07 00:00:00\n",
            "2019-04-14 00:00:00\n",
            "2019-04-21 00:00:00\n",
            "2019-04-28 00:00:00\n",
            "2019-05-05 00:00:00\n",
            "2019-05-12 00:00:00\n",
            "2019-05-19 00:00:00\n",
            "2019-05-26 00:00:00\n",
            "2019-06-02 00:00:00\n",
            "2019-06-09 00:00:00\n",
            "2019-06-16 00:00:00\n",
            "2019-06-23 00:00:00\n",
            "2019-06-30 00:00:00\n",
            "2019-07-07 00:00:00\n",
            "2019-07-14 00:00:00\n",
            "2019-07-21 00:00:00\n",
            "2019-07-28 00:00:00\n",
            "2019-08-04 00:00:00\n",
            "2019-08-11 00:00:00\n",
            "2019-08-18 00:00:00\n",
            "2019-08-25 00:00:00\n",
            "2019-09-01 00:00:00\n",
            "2019-09-08 00:00:00\n",
            "2019-09-15 00:00:00\n",
            "2019-09-22 00:00:00\n",
            "2019-09-29 00:00:00\n",
            "2019-10-06 00:00:00\n",
            "2019-10-13 00:00:00\n",
            "2019-10-20 00:00:00\n",
            "2019-10-27 00:00:00\n",
            "2019-11-03 00:00:00\n",
            "2019-11-10 00:00:00\n",
            "2019-11-17 00:00:00\n",
            "2019-11-24 00:00:00\n",
            "2019-12-01 00:00:00\n",
            "2019-12-08 00:00:00\n",
            "2019-12-15 00:00:00\n",
            "2019-12-22 00:00:00\n",
            "2019-12-29 00:00:00\n",
            "2020-01-05 00:00:00\n",
            "2020-01-12 00:00:00\n",
            "2020-01-19 00:00:00\n",
            "2020-01-26 00:00:00\n",
            "2020-02-02 00:00:00\n",
            "2020-02-09 00:00:00\n",
            "2020-02-16 00:00:00\n",
            "2020-02-23 00:00:00\n",
            "2020-03-01 00:00:00\n",
            "2020-03-08 00:00:00\n",
            "2020-03-15 00:00:00\n",
            "2020-03-22 00:00:00\n",
            "2020-03-29 00:00:00\n",
            "2020-04-05 00:00:00\n",
            "2020-04-12 00:00:00\n",
            "2020-04-19 00:00:00\n",
            "2020-04-26 00:00:00\n",
            "2020-05-03 00:00:00\n",
            "2020-05-10 00:00:00\n",
            "2020-05-17 00:00:00\n",
            "2020-05-24 00:00:00\n",
            "2020-05-31 00:00:00\n",
            "2020-06-07 00:00:00\n",
            "2020-06-14 00:00:00\n",
            "2020-06-21 00:00:00\n",
            "2020-06-28 00:00:00\n",
            "2020-07-05 00:00:00\n",
            "2020-07-12 00:00:00\n",
            "2020-07-19 00:00:00\n",
            "2020-07-26 00:00:00\n",
            "2020-08-02 00:00:00\n",
            "2020-08-09 00:00:00\n",
            "2020-08-16 00:00:00\n",
            "2020-08-23 00:00:00\n",
            "2020-08-30 00:00:00\n",
            "2020-09-06 00:00:00\n",
            "2020-09-13 00:00:00\n",
            "2020-09-20 00:00:00\n",
            "2020-09-27 00:00:00\n",
            "2020-10-04 00:00:00\n",
            "2020-10-11 00:00:00\n",
            "2020-10-18 00:00:00\n",
            "2020-10-25 00:00:00\n",
            "2020-11-01 00:00:00\n",
            "2020-11-08 00:00:00\n",
            "2020-11-15 00:00:00\n",
            "2020-11-22 00:00:00\n",
            "2020-11-29 00:00:00\n",
            "2020-12-06 00:00:00\n",
            "2020-12-13 00:00:00\n",
            "2020-12-20 00:00:00\n",
            "2020-12-27 00:00:00\n",
            "2021-01-03 00:00:00\n",
            "2021-01-10 00:00:00\n",
            "2021-01-17 00:00:00\n",
            "2021-01-24 00:00:00\n",
            "2021-01-31 00:00:00\n",
            "2021-02-07 00:00:00\n",
            "2021-02-14 00:00:00\n",
            "2021-02-21 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2021-03-07 00:00:00\n",
            "2021-03-14 00:00:00\n",
            "2021-03-21 00:00:00\n",
            "2021-03-28 00:00:00\n",
            "2021-04-04 00:00:00\n",
            "2021-04-11 00:00:00\n",
            "2021-04-18 00:00:00\n",
            "2021-04-25 00:00:00\n",
            "2021-05-02 00:00:00\n",
            "2021-05-09 00:00:00\n",
            "2021-05-16 00:00:00\n",
            "2021-05-23 00:00:00\n",
            "2021-05-30 00:00:00\n",
            "2021-06-06 00:00:00\n",
            "2021-06-13 00:00:00\n",
            "2021-06-20 00:00:00\n",
            "2021-06-27 00:00:00\n",
            "2021-07-04 00:00:00\n",
            "2021-07-11 00:00:00\n",
            "2021-07-18 00:00:00\n",
            "2021-07-25 00:00:00\n",
            "2021-08-01 00:00:00\n",
            "2021-08-08 00:00:00\n",
            "2021-08-15 00:00:00\n",
            "2021-08-22 00:00:00\n",
            "2021-08-29 00:00:00\n",
            "2021-09-05 00:00:00\n",
            "2021-09-12 00:00:00\n",
            "2021-09-19 00:00:00\n",
            "2021-09-26 00:00:00\n",
            "2021-10-03 00:00:00\n",
            "2021-10-10 00:00:00\n",
            "2021-10-17 00:00:00\n",
            "2021-10-24 00:00:00\n",
            "2021-10-31 00:00:00\n",
            "2021-11-07 00:00:00\n",
            "2021-11-14 00:00:00\n",
            "2021-11-21 00:00:00\n",
            "2021-11-28 00:00:00\n",
            "2021-12-05 00:00:00\n",
            "2021-12-12 00:00:00\n",
            "2021-12-19 00:00:00\n",
            "2021-12-26 00:00:00\n",
            "2022-01-02 00:00:00\n",
            "2022-01-09 00:00:00\n",
            "2022-01-16 00:00:00\n",
            "2022-01-23 00:00:00\n",
            "2022-01-30 00:00:00\n",
            "2022-02-06 00:00:00\n",
            "2022-02-13 00:00:00\n",
            "2022-02-20 00:00:00\n",
            "2022-02-27 00:00:00\n",
            "2022-03-06 00:00:00\n",
            "2022-03-13 00:00:00\n",
            "2022-03-20 00:00:00\n",
            "2022-03-27 00:00:00\n",
            "2022-04-03 00:00:00\n",
            "2022-04-10 00:00:00\n",
            "2022-04-17 00:00:00\n",
            "2022-04-24 00:00:00\n",
            "2022-05-01 00:00:00\n",
            "2022-05-08 00:00:00\n",
            "2022-05-15 00:00:00\n",
            "2022-05-22 00:00:00\n",
            "2022-05-29 00:00:00\n",
            "2022-06-05 00:00:00\n",
            "2022-06-12 00:00:00\n",
            "2022-06-19 00:00:00\n",
            "2022-06-26 00:00:00\n",
            "2022-07-03 00:00:00\n",
            "2022-07-10 00:00:00\n",
            "2022-07-17 00:00:00\n",
            "2022-07-24 00:00:00\n",
            "2022-07-31 00:00:00\n",
            "2022-08-07 00:00:00\n",
            "2022-08-14 00:00:00\n",
            "2022-08-21 00:00:00\n",
            "2022-08-28 00:00:00\n",
            "2022-09-04 00:00:00\n",
            "2022-09-11 00:00:00\n",
            "2022-09-18 00:00:00\n",
            "2022-09-25 00:00:00\n",
            "2022-10-02 00:00:00\n",
            "2022-10-09 00:00:00\n",
            "2022-10-16 00:00:00\n",
            "2022-10-23 00:00:00\n",
            "2022-10-30 00:00:00\n",
            "2022-11-06 00:00:00\n",
            "2022-11-13 00:00:00\n",
            "2022-11-20 00:00:00\n",
            "2022-11-27 00:00:00\n",
            "2022-12-04 00:00:00\n",
            "2022-12-11 00:00:00\n",
            "2022-12-18 00:00:00\n",
            "2022-12-25 00:00:00\n",
            "2023-01-01 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_backtest_mean = naive_backtest_returns.mean()\n",
        "naive_backtest_var = naive_backtest_returns.var()\n",
        "print(naive_backtest_mean)\n",
        "print(np.sqrt(naive_backtest_var))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e4a98-facd-4559-890a-4b5cdd1a2305",
        "id": "OK8b3Re5JK4v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00    0.000407\n",
            "0.05    0.000459\n",
            "0.10    0.000512\n",
            "0.15    0.000564\n",
            "0.20    0.000617\n",
            "0.25    0.000669\n",
            "0.30    0.000722\n",
            "0.35    0.000774\n",
            "0.40    0.000827\n",
            "0.45    0.000879\n",
            "0.50    0.000932\n",
            "0.55    0.000984\n",
            "0.60    0.001037\n",
            "0.65    0.001089\n",
            "0.70    0.001142\n",
            "0.75    0.001194\n",
            "0.80    0.001246\n",
            "0.85    0.001299\n",
            "0.90    0.001351\n",
            "0.95    0.001404\n",
            "1.00    0.001456\n",
            "dtype: float64\n",
            "0.00    0.008582\n",
            "0.05    0.007926\n",
            "0.10    0.007449\n",
            "0.15    0.007187\n",
            "0.20    0.007164\n",
            "0.25    0.007381\n",
            "0.30    0.007819\n",
            "0.35    0.008444\n",
            "0.40    0.009218\n",
            "0.45    0.010106\n",
            "0.50    0.011081\n",
            "0.55    0.012122\n",
            "0.60    0.013213\n",
            "0.65    0.014344\n",
            "0.70    0.015505\n",
            "0.75    0.016690\n",
            "0.80    0.017894\n",
            "0.85    0.019114\n",
            "0.90    0.020347\n",
            "0.95    0.021590\n",
            "1.00    0.022842\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = len(mv_backtest_mean)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "08cc11d4-c4ae-4d95-ac10-7fb508b0737b",
        "id": "QP0dekjMJK4v"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Graph"
      ],
      "metadata": {
        "id": "yyBQMceuJ_-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NoPoints = 21\n",
        "\n",
        "area = np.pi*3\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "ml_var = np.sqrt(backtest_var * (trading_days_in_year /5))\n",
        "ml_mean = backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "mv_var = np.sqrt(mv_backtest_var * (trading_days_in_year /5))\n",
        "mv_mean = mv_backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "naive_var = np.sqrt(naive_backtest_var * (trading_days_in_year /5))\n",
        "naive_mean = naive_backtest_mean * (trading_days_in_year /5)\n",
        "\n",
        "fit = np.polyfit(ml_var, ml_mean, deg=4) \n",
        "p = np.poly1d(fit) \n",
        "ax1.plot(ml_var,p(ml_var),\"r--\") \n",
        "\n",
        "# fit = np.polyfit(mv_var, mv_mean, deg=4) \n",
        "# p = np.poly1d(fit) \n",
        "# ax1.plot(mv_var,p(mv_var),\"g--\") \n",
        "\n",
        "# fit = np.polyfit(naive_var, naive_mean, deg=6) \n",
        "# p = np.poly1d(fit) \n",
        "# ax1.plot(naive_var,p(naive_var),\"b--\") \n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(np.sqrt(backtest_var * (trading_days_in_year /5)), backtest_mean * (trading_days_in_year /5),s=area, c=\"red\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(mv_backtest_var * (trading_days_in_year /5)),mv_backtest_mean * (trading_days_in_year /5), s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(np.sqrt(naive_backtest_var * (trading_days_in_year /5)),naive_backtest_mean * (trading_days_in_year /5), s=area, c=\"blue\", alpha =0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "x2aGNhpuKEan",
        "outputId": "db77e9e5-faf5-4ff6-967f-59ed554453a3"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59JkxM_-c9uk"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBobZ4qo53Lo"
      },
      "outputs": [],
      "source": [
        "# model = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "def train_epoch(dataloader):\n",
        "    train_loss,train_correct=0.0,0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "        loss = loss_fn(y_output, y)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        train_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return train_loss\n",
        "  \n",
        "def valid_epoch(dataloader):\n",
        "\n",
        "    valid_loss, val_correct = 0.0, 0\n",
        "    for data in dataloader:\n",
        "\n",
        "        x = data[:,:-1]\n",
        "        y = data[:,-1]\n",
        "\n",
        "        y_output = torch.exp(torch.matmul(x, a)) / (torch.exp (torch.matmul(x, a)) + torch.exp(torch.matmul(x, b)))\n",
        "\n",
        "        loss = loss_fn(y_output, y)\n",
        "\n",
        "        valid_loss+=loss.item() * x.size(0)\n",
        "\n",
        "    return valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "DeuyMHGu_Lmy",
        "outputId": "11c663c7-9cc6-41d6-d789-6e05591addaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-c07c40cb1bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-3768fb6a26b4>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ],
      "source": [
        "history = {'train_loss': [], 'test_loss': []}\n",
        " \n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
        "\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss=train_epoch(train_loader)\n",
        "        test_loss=valid_epoch(test_loader)\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.sampler)\n",
        "        test_loss = test_loss / len(test_loader.sampler)\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1,n_epochs,train_loss,test_loss))\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsd-ud7DWRC5"
      },
      "outputs": [],
      "source": [
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Archive"
      ],
      "metadata": {
        "id": "YBYaqWwGoDBM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx3K4DmgFpd7"
      },
      "source": [
        "## MV Portfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1A4Jk4uWHDj"
      },
      "source": [
        "### Build data for high and low risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e5kg5IleWKbF",
        "outputId": "5c460d6a-b245-405b-ad81-0d12ba019502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            high        low\n",
              "25     89.540001  85.199997\n",
              "26     88.779999  85.540001\n",
              "27     90.000000  84.879997\n",
              "28     90.660004  84.760002\n",
              "29     91.699997  85.059998\n",
              "...          ...        ...\n",
              "5142  382.429993  95.779999\n",
              "5143  380.820007  96.529999\n",
              "5144  383.760010  97.269997\n",
              "5145  379.380005  97.129997\n",
              "5146  388.079987  98.379997\n",
              "\n",
              "[5122 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>89.540001</td>\n",
              "      <td>85.199997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>88.779999</td>\n",
              "      <td>85.540001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>84.879997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>90.660004</td>\n",
              "      <td>84.760002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>91.699997</td>\n",
              "      <td>85.059998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5142</th>\n",
              "      <td>382.429993</td>\n",
              "      <td>95.779999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5143</th>\n",
              "      <td>380.820007</td>\n",
              "      <td>96.529999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5144</th>\n",
              "      <td>383.760010</td>\n",
              "      <td>97.269997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5145</th>\n",
              "      <td>379.380005</td>\n",
              "      <td>97.129997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>388.079987</td>\n",
              "      <td>98.379997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5122 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f12bf68c-4f1e-4eb8-9de3-c91ecc16f3d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ],
      "source": [
        "mv_data = pd.DataFrame(data={'high': high_risk['Close'], 'low':low_risk['Close']})\n",
        "mv_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BOYoifDBaqP"
      },
      "source": [
        "### Optimization using linear programming\n",
        "\n",
        "(Reference: https://www.kaggle.com/code/vijipai/lesson-5-mean-variance-optimization-of-portfolios)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_t1dGnAtHYV"
      },
      "outputs": [],
      "source": [
        "TERMINATION = 10**-9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6r-NvbtYDDn"
      },
      "outputs": [],
      "source": [
        "def print_min_variance_portfolio(mean_returns, cov_returns):\n",
        "    number_of_assets = len(mean_returns)\n",
        "    result = MinimizeRisk(cov_returns, number_of_assets)\n",
        "\n",
        "    print()\n",
        "    minRiskWeights = result.x\n",
        "    minRiskExpPortfolioReturn = np.matmul(mean_returns.T, minRiskWeights)\n",
        "    print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)\n",
        "    minRisk = np.matmul(np.matmul(minRiskWeights, cov_returns), minRiskWeights.T) \n",
        "    print(\"Variance of Minimum Risk Portfolio : %7.6f\" % minRisk)\n",
        "    print(\"S.D. of Minimum Risk Portfolio : %7.6f\" % np.sqrt(minRisk))\n",
        "    threshold = 1e-3\n",
        "    print(\"Weights (showing only those > %.6f): \" % threshold)\n",
        "    for i in range(0, number_of_assets):\n",
        "        if result.x[i] > threshold:\n",
        "            print(f\"{mean_returns.index[i]}\\t{result.x[i]:.6f}\")\n",
        "    print('Assets Considered:')\n",
        "    print(mean_returns.index.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNuu3KurcJDL"
      },
      "outputs": [],
      "source": [
        "#function obtains Minimal risk and Maximum return portfolios\n",
        "\n",
        "#dependencies\n",
        "import numpy as np\n",
        "from scipy import optimize \n",
        "\n",
        "def MinimizeRiskConstr(MeanReturns, CovarReturns, PortfolioSize, R):\n",
        "    \n",
        "    def  f(x,CovarReturns):\n",
        "         \n",
        "        func = np.matmul(np.matmul(x,CovarReturns ), x.T)\n",
        "        return func\n",
        "\n",
        "    def constraintEq(x):\n",
        "        AEq=np.ones(x.shape)\n",
        "        bEq=1\n",
        "        EqconstraintVal = np.matmul(AEq,x.T)-bEq \n",
        "        return EqconstraintVal\n",
        "    \n",
        "    def constraintIneq(x, MeanReturns, R):\n",
        "        AIneq = np.array(MeanReturns)\n",
        "        bIneq = R\n",
        "        IneqconstraintVal = np.matmul(AIneq,x.T) - bIneq\n",
        "        return IneqconstraintVal\n",
        "    \n",
        "\n",
        "    xinit=np.repeat(0.1, PortfolioSize)\n",
        "    cons = ({'type': 'eq', 'fun':constraintEq},\n",
        "            {'type':'ineq', 'fun':constraintIneq, 'args':(MeanReturns,R) })\n",
        "    lb = 0\n",
        "    ub = 1\n",
        "    bnds = tuple([(lb,ub) for x in xinit])\n",
        "\n",
        "    opt = optimize.minimize (f, args = (CovarReturns), method ='trust-constr',  \\\n",
        "                        x0 = xinit,   bounds = bnds, constraints = cons, tol = TERMINATION)\n",
        "    \n",
        "    return  opt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "Xe_zRSHcbxxb",
        "outputId": "69bff57b-a2f7-49ef-8742-3abec15813e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          l_Close   h_Close\n",
              "l_Close  0.010103  0.004556\n",
              "h_Close  0.004556  0.057944"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ee3c5d9-72ca-4342-9514-909e4599f61d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>l_Close</th>\n",
              "      <th>h_Close</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>l_Close</th>\n",
              "      <td>0.010103</td>\n",
              "      <td>0.004556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>h_Close</th>\n",
              "      <td>0.004556</td>\n",
              "      <td>0.057944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ee3c5d9-72ca-4342-9514-909e4599f61d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ee3c5d9-72ca-4342-9514-909e4599f61d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ee3c5d9-72ca-4342-9514-909e4599f61d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRkZ69QycGDx",
        "outputId": "2c9d586a-9ff2-4635-f89c-d2c5a9a6851b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n",
            "Variance of Minimum Risk Portfolio : 0.009581\n",
            "S.D. of Minimum Risk Portfolio : 0.097884\n",
            "Weights (showing only those > 0.001000): \n",
            "l_Close\t0.905878\n",
            "h_Close\t0.094122\n",
            "Assets Considered:\n",
            "['l_Close' 'h_Close']\n"
          ]
        }
      ],
      "source": [
        "print_min_variance_portfolio(r, cov)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvkOfW5-GXpS",
        "outputId": "bef55af4-56b7-4908-cb57-f5e0c796bcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximal Expected Portfolio Return:   0.000000\n"
          ]
        }
      ],
      "source": [
        "#Maximal expected portfolio return computation for the k-portfolio\n",
        "result1 = MaximizeReturns(r, 2)\n",
        "maxReturnWeights = result1.x\n",
        "maxExpPortfolioReturn = np.matmul(r.T, maxReturnWeights)\n",
        "print(\"Maximal Expected Portfolio Return:   %7.6f\" % maxExpPortfolioReturn )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnMjflTbGaO7",
        "outputId": "eef27242-a41c-4143-9c79-05a255f84b64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected Return of Minimum Risk Portfolio:  -0.149523\n"
          ]
        }
      ],
      "source": [
        "#expected portfolio return computation for the minimum risk k-portfolio \n",
        "result2 = MinimizeRisk(cov, 2)\n",
        "minRiskWeights = result2.x\n",
        "minRiskExpPortfolioReturn = np.matmul(r.T, minRiskWeights)\n",
        "print(\"Expected Return of Minimum Risk Portfolio:  %7.6f\" % minRiskExpPortfolioReturn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minRiskWeights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrq0nFRpb8Ml",
        "outputId": "e9c58889-be3d-4384-e454-e1104ea1bc47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9058782, 0.0941218])"
            ]
          },
          "metadata": {},
          "execution_count": 324
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kw9InlwDh3v",
        "outputId": "73eed3e5-06c2-415f-af53-6899dc67fce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the  efficient set: (15, 2)\n",
            "Optimal weights of the efficient set portfolios: \n",
            " [[ 9.03663741e-01  9.63362594e-02]\n",
            " [-6.99435915e-06  9.98652333e-01]\n",
            " [-1.45120188e-05  9.97203837e-01]\n",
            " [-2.20296783e-05  9.95755341e-01]\n",
            " [-2.95473998e-05  9.94306844e-01]\n",
            " [-3.70649972e-05  9.92858348e-01]\n",
            " [-4.45826568e-05  9.91409852e-01]\n",
            " [-5.21003162e-05  9.89961356e-01]\n",
            " [-5.96181202e-05  9.88512860e-01]\n",
            " [-6.71356356e-05  9.87064364e-01]\n",
            " [-7.46531138e-05  9.85615867e-01]\n",
            " [-8.21709547e-05  9.84167371e-01]\n",
            " [-8.96888312e-05  9.82718876e-01]\n",
            " [-9.72062735e-05  9.81270379e-01]\n",
            " [-1.04724187e-04  9.79821883e-01]]\n",
            "Annualized Risk and Return of the efficient set portfolios: \n",
            " [[ 0.09788576 -0.14952253]\n",
            " [ 0.24039177 -0.13952253]\n",
            " [ 0.24004295 -0.12952253]\n",
            " [ 0.23969413 -0.11952253]\n",
            " [ 0.23934531 -0.10952253]\n",
            " [ 0.23899649 -0.09952253]\n",
            " [ 0.23864767 -0.08952253]\n",
            " [ 0.23829885 -0.07952253]\n",
            " [ 0.23795003 -0.06952253]\n",
            " [ 0.23760121 -0.05952253]\n",
            " [ 0.2372524  -0.04952253]\n",
            " [ 0.23690358 -0.03952253]\n",
            " [ 0.23655476 -0.02952253]\n",
            " [ 0.23620594 -0.01952253]\n",
            " [ 0.23585712 -0.00952253]]\n"
          ]
        }
      ],
      "source": [
        "#compute efficient set for the maximum return and minimum risk portfolios\n",
        "increment = 0.01\n",
        "low = minRiskExpPortfolioReturn\n",
        "high = maxExpPortfolioReturn\n",
        "\n",
        "#initialize optimal weight set and risk-return point set\n",
        "xOptimal =[]\n",
        "minRiskPoint = []\n",
        "expPortfolioReturnPoint =[]\n",
        "\n",
        "#repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "while (low < high):\n",
        "    \n",
        "    result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "    xOptimal.append(result3.x)\n",
        "    expPortfolioReturnPoint.append(low)\n",
        "    low = low+increment\n",
        "    \n",
        "#gather optimal weight set    \n",
        "xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "#obtain annualized risk for the efficient set portfolios \n",
        "#for trading days = 251\n",
        "minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "                                     np.transpose(xOptimalArray)))\n",
        "riskPoint =   np.sqrt(minRiskPoint) \n",
        "\n",
        "#obtain expected portfolio annualized return for the \n",
        "#efficient set portfolios, for trading days = 251\n",
        "retPoint = np.array(expPortfolioReturnPoint) \n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[riskPoint, retPoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #compute efficient set for the maximum return and minimum risk portfolios\n",
        "# increment = 0.000001\n",
        "# low = minRiskExpPortfolioReturn\n",
        "# high = maxExpPortfolioReturn\n",
        "\n",
        "# #initialize optimal weight set and risk-return point set\n",
        "# xOptimal =[]\n",
        "# minRiskPoint = []\n",
        "# expPortfolioReturnPoint =[]\n",
        "\n",
        "# #repeated execution of function MinimizeRiskConstr to determine the efficient set \n",
        "# while (low < high):\n",
        "    \n",
        "#     result3 = MinimizeRiskConstr(r, cov, 2, low)\n",
        "#     xOptimal.append(result3.x)\n",
        "#     expPortfolioReturnPoint.append(low)\n",
        "#     low = low+increment\n",
        "    \n",
        "# #gather optimal weight set    \n",
        "# xOptimalArray = np.array(xOptimal)\n",
        "\n",
        "# #obtain annualized risk for the efficient set portfolios \n",
        "# #for trading days = 251\n",
        "# minRiskPoint = np.diagonal(np.matmul((np.matmul(xOptimalArray,cov)),\\\n",
        "#                                      np.transpose(xOptimalArray)))\n",
        "# riskPoint =   np.sqrt(minRiskPoint*trading_days_in_year) \n",
        "\n",
        "# #obtain expected portfolio annualized return for the \n",
        "# #efficient set portfolios, for trading days = 251\n",
        "# retPoint = trading_days_in_year*np.array(expPortfolioReturnPoint) \n",
        "\n",
        "# #display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "# print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "#                                                 np.c_[riskPoint, retPoint])"
      ],
      "metadata": {
        "id": "CWVcn0qldNvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "2_0opIvqHAG1",
        "outputId": "79863e7e-d703-440b-e800-4b69d1be1eaa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Graph Efficient Frontier\n",
        "\n",
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"green\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for MV Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(riskPoint, retPoint, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMoyxpN5dY_z"
      },
      "source": [
        "## Naive Portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGhdT3AWHGa-"
      },
      "outputs": [],
      "source": [
        "naive_risks = []\n",
        "naive_returns = []\n",
        "\n",
        "for x in np.arange(0, 1, 0.01):\n",
        "  weights = [x, 1-x]\n",
        "  risk = np.matmul((np.matmul(weights,cov)),np.transpose(weights)) * trading_days_in_year\n",
        "  naive_risks.append(np.sqrt(risk))\n",
        "\n",
        "  #obtain expected portfolio annualized return for the \n",
        "  #efficient set portfolios, for trading days = 251\n",
        "  ret = trading_days_in_year*(np.matmul(weights,r))\n",
        "  naive_returns.append(ret)\n",
        "\n",
        "#display efficient set portfolio parameters\n",
        "# print(\"Size of the  efficient set:\", xOptimalArray.shape )\n",
        "# print(\"Optimal weights of the efficient set portfolios: \\n\", xOptimalArray)\n",
        "print(\"Annualized Risk and Return of the efficient set portfolios: \\n\", \\\n",
        "                                                np.c_[naive_risks, naive_returns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wJgflp2eJ2c"
      },
      "outputs": [],
      "source": [
        "NoPoints = len(naive_risks)\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "plt.title('Efficient Frontier for Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "plt.scatter(naive_risks, naive_returns, s=area, c=colours, alpha =0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-x_ZCjwg57n"
      },
      "source": [
        "## Combined Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpqNZRCtgYQK"
      },
      "outputs": [],
      "source": [
        "NoPoints = riskPoint.size\n",
        "\n",
        "colours = \"blue\"\n",
        "area = np.pi*3\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "ax1 = fig.add_subplot(111)\n",
        "\n",
        "plt.title('Efficient Frontier for MV and Naive Portfolio')\n",
        "plt.xlabel('Annualized Risk(%)')\n",
        "plt.ylabel('Annualized Expected Portfolio Return(%)' )\n",
        "ax1.scatter(riskPoint, retPoint, s=area, c=\"green\", alpha =0.5)\n",
        "ax1.scatter(naive_risks, naive_returns, s=area, c=\"blue\", alpha =0.5)\n",
        "# plt.xlim(riskPoint.min(), riskPoint.max())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sTlOQOIhTCZ"
      },
      "outputs": [],
      "source": [
        "cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5N-KuYQxAmQ"
      },
      "outputs": [],
      "source": [
        "print(high_risk[\"Close\"].var())\n",
        "print(high_risk[\"Close\"].var() * trading_days_in_year)\n",
        "print(high_risk[\"Close\"].pct_change().var())\n",
        "print(high_risk[\"Close\"].pct_change().var() * trading_days_in_year)\n",
        "print(np.sqrt(high_risk[\"Close\"].pct_change().var() * trading_days_in_year))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU2640mM0RnU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMy0XYLs46COmoicNRJf5l+"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}